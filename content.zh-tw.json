{"pages":[{"title":"About me","text":"我是一個後端工程師。 我對terminal的黑色視窗情有獨鍾，可能是因為在我看過的駭客電影中，厲害的駭客都是在小小的黑畫面中施展他們的妖術，印象中好像沒有看過施展妖術前還要開UI的駭客… 我曾是個職業軍人，天為被，地為枕，一個禮拜不洗澡，與弟兄們坐在野地上，相視一笑，仰望著深山沒有光害的星空，這是一種一輩子難忘但卻再也不想經歷的經驗。 我也曾是個國外業務，發現日本人對於SOP，以及猶太人對於數字，有著異常相似的執著！其實美國辦公室人員加班也是沒有加班費的啦！第一次接觸荷蘭人，還以為他們是巨人族的後裔。猶太人在戰場上，需要等敵人開槍才可以反擊，於是我說：”那如果敵人開槍你就掛了呢？”，猶太客戶回我說：”嗯，那就是你的命了”。 現在的我是個工程師，我很幸運，這輩子有幸跟coding邂逅。我喜歡任何形式的語言，當我想與人交流時，我說人類語言; 當我想獨處時，我說機器語言。機器語言的細膩與嚴謹深深的吸引我。日新月異的技術，在使我瞠目結舌之餘，不斷的充填我對知識永不枯竭的渴求。每天早晨，我不需要鬧鐘讓我起床，我的熱血喚醒我的身體，對新的一天的興奮感吹散我的睡意，因為今天的我，還可以思考，學習，並將我的邏輯，轉換成細緻而優美的機器語言。","link":"/zh-tw/about/index.html"},{"title":"Friends","text":"","link":"/zh-tw/friends/index.html"},{"title":"archives","text":"","link":"/zh-tw/archives/index.html"},{"title":"categories","text":"","link":"/zh-tw/categories/index.html"},{"title":"Schedule","text":"2019/7/31the result of my target yesterday Task: Organise GCP Load Balancer Completed testing, and going to write a documentation Figure out how to use logRotate No time for it Optimise CICD on api-server project Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Organise GCP Load Balancer Figure out how to use logRotate Linux English Japanese 2019/7/30the result of my target yesterday Task: Organise GCP Load Balancer Still working on it Work on CostDown Initially completed Figure out how to use logRotate No time for it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Organise GCP Load Balancer Figure out how to use logRotate Optimise CICD on api-server project Linux English Japanese 2019/7/29the result of my target yesterday Task: Organise GCP Load Balancer Still working on it Work on CostDown Still working on it Figure out how to use logRotate No time for it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Organise GCP Load Balancer Work on CostDown Figure out how to use logRotate Linux English Japanese 2019/7/28the result of my target yesterday Task: Organise GCP Load Balancer Still working on it Work on CostDown Still working on it Figure out how to use logRotate No time for it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Organise GCP Load Balancer Work on CostDown Figure out how to use logRotate Linux English Japanese 2019/7/27the result of my target yesterday Task: Organise GCP Load Balancer Still working on it Work on CostDown Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Organise GCP Load Balancer Work on CostDown Figure out how to use logRotate Linux English Japanese 2019/7/26the result of my target yesterday Task: Organise GCP Load Balancer Still working on it Work on CostDown Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Organise GCP Load Balancer Work on CostDown Linux English Japanese 2019/7/25the result of my target yesterday Task: Organise GCP Load Balancer Still working on it Work on CostDown We’ve got some progress Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Organise GCP Load Balancer Work on CostDown Linux English Japanese 2019/7/24the result of my target yesterday Task: Build new sites Organise pm2 config Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Organise GCP Load Balancer Work on CostDown Linux English Japanese 2019/7/23the result of my target yesterday Task: Trace edgeOnline API Initially found the issue, going to test it Organise pm2 config No time for it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Build new sites Organise pm2 config Linux English Japanese 2019/7/22the result of my target yesterday Task: Organise GCP Load Balance No time for it Organise pm2 config Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Trace edgeOnline API Organise pm2 config Linux English Japanese 2019/7/21the result of my target yesterday Task: Organise GCP Load Balance No time for it Organise pm2 config Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Organise GCP Load Balance Organise pm2 config Linux English Japanese 2019/7/20the result of my target yesterday Task: Observe new LB, and if every thing goes well, delete all previous VMs Build CICD for all of the projects Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Organise GCP Load Balance Organise pm2 config Linux English Japanese 2019/7/19the result of my target yesterday Task: Optimise the number of VM instance from 8 VMs to 2 VMs Initially completed, and going to observe it further Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Observe new LB, and if every thing goes well, delete all previous VMs Build CICD for all of the projects Linux English Japanese 2019/7/18the result of my target yesterday Task: Optimise the number of VM instance from 8 VMs to 2 VMs Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Optimise the number of VM instance from 8 VMs to 2 VMs Linux English Japanese 2019/7/17the result of my target yesterday Task: Optimise the number of VM instance from 8 VMs to 2 VMs Still working on it Shutdown qcdn-job and move the job to another VM Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Optimise the number of VM instance from 8 VMs to 2 VMs Linux English Japanese 2019/7/16the result of my target yesterday Task: Optimise the number of VM instance from 8 VMs to 2 VMs still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Optimise the number of VM instance from 8 VMs to 2 VMs Shutdown qcdn-job and move the job to another VM Linux English Japanese 2019/7/15the result of my target yesterday Task: Optimise the number of VM instance from 8 VMs to 2 VMs Still working on it Fix eon_v3 DNS issue Initially completed, but still have something to discuss with Raymond before closing this issue Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Optimise the number of VM instance from 8 VMs to 2 VMs Fix eon_v3 DNS issue Linux English Japanese 2019/7/14the result of my target yesterday Task: Optimise the number of VM instance from 8 VMs to 2 VMs Still working on it Fix eon_v3 DNS issue Initially fixed it, but still have some problems to discuss Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Optimise the number of VM instance from 8 VMs to 2 VMs Fix eon_v3 DNS issue Linux English Japanese 2019/7/13the result of my target yesterday Task: Optimise the number of VM instance from 8 VMs to 2 VMs Still working on it Fix eon_v3 DNS issue Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Optimise the number of VM instance from 8 VMs to 2 VMs Fix eon_v3 DNS issue Linux English Japanese 2019/7/12the result of my target yesterday Task: Optimise the number of VM instance from 8 VMs to 2 VMs Still working on it Added a feature sending event notification to Slack channel Completed Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Optimise the number of VM instance from 8 VMs to 2 VMs Linux English Japanese 2019/7/11the result of my target yesterday Task: Trace customer-api code to find out what might cause huge Datastore read It seems that either cloud-api and cloud-customer-api is not the cause of this issue. Optimise the number of VM instance from 8 VMs to 2 VMs Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Optimise the number of VM instance from 8 VMs to 2 VMs Linux English Japanese 2019/7/10the result of my target yesterday Task: Trace customer-api code to find out what might cause huge Datastore read Still working on it Optimise the number of VM instance from 8 VMs to 2 VMs Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Trace customer-api code to find out what might cause huge Datastore read Optimise the number of VM instance from 8 VMs to 2 VMs Linux English Japanese 2019/7/9the result of my target yesterday Task: Optimise CI with pm2 Still working on it Publish my article regarding pm2 Still working on it Trace customer-api code to find out what might cause huge Datastore read still tracing Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Trace customer-api code to find out what might cause huge Datastore read Optimise the number of VM instance from 8 VMs to 2 VMs Linux English Japanese 2019/7/8the result of my target yesterday Task: Optimise CI with pm2 Still working on it Publish my article regarding pm2 Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Optimise CI with pm2 Publish my article regarding pm2 Trace customer-api code to find out what might cause huge Datastore read Linux English Japanese 2019/7/7the result of my target yesterday Task: Change CI with pm2 Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Optimise CI with pm2 Publish my article regarding pm2 Linux English Japanese 2019/7/6the result of my target yesterday Task: Change CI with pm2 Still working on it Turn off loadAccessLog, bandwidthUsage, and emptyGzLogRemover API Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Change CI with pm2 Linux English Japanese 2019/7/5the result of my target yesterday Task: Change CI with pm2 Still working on it Keep off checkEdgeAlive API until 10 pm, and check the bill tomorrow Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Change CI with pm2 Turn off loadAccessLog, bandwidthUsage, and emptyGzLogRemover API Linux English Japanese 2019/7/4the result of my target yesterday Task: Change CI with pm2 Analyse the bill Keep off checkEdgeAlive API until 10 pm, and check the bill tomorrow Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Change CI with pm2 Keep off checkEdgeAlive API until 10 pm, and check the bill tomorrow Linux English Japanese 2019/7/3the result of my target yesterday Task: Configure ShadowSocks client setting Change CI with pm2 Make ShadowSocks automatically restart after reboot and shutdown the instance Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Change CI with pm2 Analyse the bill Keep off checkEdgeAlive API until 10 pm, and check the bill tomorrow Linux English Japanese 2019/7/2the result of my target yesterday Task: Configure ShadowSocks sever setting Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Configure ShadowSocks client setting Change CI with pm2 Make ShadowSocks automatically restart after reboot and shutdown the instance Linux English Japanese 2019/7/1the result of my target yesterday Task: Make a pm2 document Still working on it Make a Let’s Encrypt document and publish it Linux English Japanese JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: TBD Linux English Japanese 2019/6/30the result of my target yesterday Task: Complete FTP server document and publish it Linux English Japanese JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: Make a pm2 document Make a Let’s Encrypt document and publish it Linux English Japanese JavaScript 2019/6/29the result of my target yesterday Task: Make PM2 document, and optimise every VM Still working on it Made a FTP server for internal deployment Linux English Japanese JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: Complete FTP server document and publish it Linux English Japanese JavaScript 2019/6/28the result of my target yesterday Task: Auto sign three sites with Let&#39;s Encrypt Linux English Japanese JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: Make PM2 document, and optimise every VM Linux English Japanese JavaScript 2019/6/27the result of my target yesterday Task: Figure out how pm2 works and optimise VMs with pm2 Partially Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Auto sign three sites with Let&#39;s Encrypt Linux English Japanese JavaScript 2019/6/26the result of my target yesterday Task: Understand how Cloud Function works Linux English Japanese JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: Figure out how pm2 works and optimise VMs with pm2 Linux English Japanese JavaScript 2019/6/25the result of my target yesterday Task: Optimise VMs Re-purged failed edges Linux English Japanese JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: Understand how Cloud Function works Linux English Japanese JavaScript 2019/6/24the result of my target yesterday Task: Linux English Japanese JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: TBD Linux English Japanese JavaScript 2019/6/23the result of my target yesterday Task: Linux English Japanese JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: Linux English Japanese JavaScript 2019/6/22the result of my target yesterday Task: Made eov_v3 work Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Linux English Japanese JavaScript 2019/6/21the result of my target yesterday Task: Working on EON_V3 Make domain column accepts array Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: TBD Linux English Japanese 2019/6/20the result of my target yesterday Task: Working on EON_V3 Completed CI Completed revising, the service is working now. Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on EON_V3 Make domain column accepts array Linux English Japanese 2019/6/19the result of my target yesterday Task: The handover of the work with Eddie I was told to work on project EON_V3 first Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on EON_V3 Linux English Japanese 2019/6/18the result of my target yesterday Task: The handover of the work with Eddie Linux English Japanese JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: The handover of the work with Eddie Linux English Japanese 2019/6/17the result of my target yesterday Task: Linux English Japanese JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: TBD Linux English Japanese JavaScript 2019/6/16the result of my target yesterday Task: Linux English Japanese JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: Linux English Japanese JavaScript 2019/6/15the result of my target yesterday Task: Edge and Site API Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Linux English Japanese JavaScript 2019/6/14the result of my target yesterday Task: Working on DNS function Completed Working on Site and Edge API Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Edge and Site API Linux English Japanese 2019/6/13the result of my target yesterday Task: Working on DNS function Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on DNS function Linux English Japanese 2019/6/12the result of my target yesterday Task: Working on DNS function Finished GCP Cloud DNS Service part Linux English Japanese JavaScript No time for it achieved except for set target yesterdaydescriptiontoday’s target Task: Working on DNS function Linux English Japanese 2019/6/11the result of my target yesterday Task: Have a meeting with ST, Raymond, and OY Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on DNS function Linux English Japanese JavaScript 2019/6/10the result of my target yesterday Task: Figured out how to add a Load-Balancing with gcloud Got stuck on SSH issue instead. However, I learnt something from it. Linux English Japanese JavaScript The Principles of Object-Oriented JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: Have a meeting with ST, Raymond, and OY Linux English Japanese 2019/6/9the result of my target yesterday Task: Figured out how to add a Load-Balancing with gcloud Linux English Japanese JavaScript The Principles of Object-Oriented JavaScript Today I will go out with friends for dinner, I hope that I will still finish my schedule achieved except for set target yesterdaydescriptiontoday’s target Task: Figured out how to add a Load-Balancing with gcloud Linux English Japanese JavaScript The Principles of Object-Oriented JavaScript 2019/6/8the result of my target yesterday Task: Transfer the drawing from HackMD to Draw.io Figured out how to add a Load-Balancing with gcloud Linux English Japanese JavaScript The Principles of Object-Oriented JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: Figured out how to add a Load-Balancing with gcloud Linux English Japanese JavaScript The Principles of Object-Oriented JavaScript Today I will go out with friends for dinner, I hope that I will still finish my schedule 2019/6/7the result of my target yesterday Task: Discuss with Raymond to finalize initial version, and discuss with ST Linux English Japanese JavaScript The Principles of Object-Oriented JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: Transfer the drawing from HackMD to Draw.io Figured out how to add a Load-Balancing with gcloud Linux English Japanese JavaScript The Principles of Object-Oriented JavaScript 2019/6/6the result of my target yesterday Task: Discuss with Raymond to finalize initial version of programming process drawing and make it with draw.io Raymond pointed out some errors, to be revised and resubmitted Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Discuss with Raymond to finalize initial version, and discuss with ST Linux English Japanese JavaScript The Principles of Object-Oriented JavaScript 2019/6/5the result of my target yesterday Task: Revised the data path according to the discussion yesterday. Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Discuss with Raymond to finalize initial version of programming process drawing and make it with draw.io Linux English Japanese 2019/6/4the result of my target yesterday Task: Completed logic part and compare with ST’s data path Completed first version of scratch, and had a discussion with Raymond Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Revised the data path according to the discussion yesterday. Linux English Japanese 2019/6/3the result of my target yesterday Task: Add new Japanese vocabulary card Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Completed logic part and compare with ST’s data path Linux English Japanese 2019/6/2the result of my target yesterday task: add new japanese vocabulary card Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Add new Japanese vocabulary card Linux English Japanese 2019/6/1the result of my target yesterday Task: Working on architecture of Cloud API Initially finished Ready Pool and Bootstrap Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: add new japanese vocabulary card Linux English Japanese History","link":"/zh-tw/schedule/index.html"},{"title":"tags","text":"","link":"/zh-tw/tags/index.html"},{"title":"History","text":"2019MayAprilMarchFebruaryJanuary 2018DecemberNovember","link":"/zh-tw/schedule/History/index.html"},{"title":"December 2018","text":"2018/12/31The result of my target yesterday [ ] linux: 鳥哥的linux基礎篇 i read some book not related to coding yesterday. i was guilty! [ ] git: pro git i read some book not related to coding yesterday. i was guilty! [x] challenge20181217 rewriting paymentdetail function getachievedachievement function getpossessions function profile function DescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git challenge20181217 rewriting deposit achievement 2018/12/30The result of my target yesterday [ ] linux: 鳥哥的linux基礎篇 i read some book not related to coding yesterday. i was guilty! [ ] git: pro git i read some book not related to coding yesterday. i was guilty! [x] challenge20181217 rewriting shop system function rewriting DescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git challenge20181217 rewriting getachievedachievement getachievedachievement function getpossessions function profile function 2018/12/29The result of my target yesterday [x] linux: 鳥哥的linux基礎篇 head -n number filename tail -f filename cat -n filename | tail -n [x] git: pro git how to revert a merged commit and undo all the changes introduced by the branch being merged?git revert -m 1 commitid if i reverted a merged commit and chose the parent, what if i want to merge it again?revert the reverted commit when merging, how to skip mamually resolving and just choose the side we choose? git merge branchname -xours or git merge branchname -xtheirs challenge20181217 rewriting shop system function rewriting went to a movie theater. DescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git challenge20181217 rewriting shop system function rewriting 2018/12/28The result of my target yesterday [x] linux: 鳥哥的linux基礎篇 nl -ba filename nl -bt filename nl -w filename nl -nln filename nl -nrn filename nl -nrz filename [x] git: pro git git merge -xignore-all-space git merge -xignore-space-change git log --oneline --left-right --merge -p (option) challenge20181217 rewriting readability of achievement function shop system function rewriting to be completed today DescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git challenge20181217 rewriting shop system function rewriting 2018/12/27The result of my target yesterday linux: 鳥哥的linux基礎篇 cat -a cat -b cat -e cat -n cat -t cat -v [x] git: pro git git filter-branch --subdirectory-filter directoryname head git filter-branch --commit-filter &apos; if [ &quot;$git_author_email&quot; = &quot;currentemail&quot; ] ; then git_author_name=&quot;newauthornameyouwanttobe&quot;; git_author_email=&quot;newemailyouwanttobe&quot;; git commit-tree &quot;$@&quot;; else git commit-tree &quot;$@&quot;; fi&apos; head rewrite challenge20181217 achievement function achievement function was completed, but need to improvie its readability Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git challenge20181217 rewriting readability of achievement function shop system function rewriting2018/12/26 The result of my target yesterday linux: 鳥哥的linux基礎篇 went to ktv instead git: pro git went to ktv instead rewrite challenge20181217 getachievementlist &amp; getitemlist api was completed Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git i think i need to focus on my challenge code rework until i finish it 2018/12/25The result of my target yesterday linux: 鳥哥的linux基礎篇辦事項 git: pro git git commit –amend –no-edit git commit filter-branch –tree-filter –all ‘rm -f file’ head laracast: the_php_practitioner recap 23 rameke my git presentation from keynote to hackmd (2/5) rewrite challenge20181217 redesign tables Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git i think i need to focus on my challenge code rework until i finish it 2018/12/24The result of my target yesterday linux: 鳥哥的linux基礎篇辦事項 git: pro git - git grep filename -n &amp; git grep filename -n laracast: the_php_practitioner recap 23 rameke my git presentation from keynote to hackmd (1/5) Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git laracast: the_php_practitioner recap 23 rameke my git presentation from keynote to hackmd (2/5) 2018/12/23The result of my target yesterday figure out how to use moment of js to covert the timezone from utc to where you are - not completed yet wondering presentation - completed Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git laracast: the_php_practitioner recap 23 rameke my git presentation from keynote to hackmd (1/5) 2018/12/22The result of my target yesterday challenge 20181221 passed figure out how to use moment of js to covert the timezone from utc to where you are - not completed yet Achieved except for set target yesterdayDescriptionToday’s target wondering presentation 2018/12/21The result of my target yesterday challenge 20181220 passed Achieved except for set target yesterdayDescriptionToday’s target don’t special game challenge 20181221 2018/12/20The result of my target yesterday challenge 20181219 passed Achieved except for set target yesterdayDescriptionToday’s target challenge 20181220 2018/12/19The result of my target yesterday challenge 20181218 passed Achieved except for set target yesterdayDescriptionToday’s target challenge 20181219 2018/12/18The result of my target yesterday challenge 20181217 passed Achieved except for set target yesterdayDescriptionToday’s target challenge 20181218 2018/12/17The result of my target yesterdaylaravel warming up laravel warm up Achieved except for set target yesterdayDescriptionToday’s target challenge 20181217 2018/12/16The result of my target yesterdaylaracast focus on laravel warming up first laravel warming up laravel_5.7_from_scratch series (9~12/36) linux: focus on laravel warming up first git git add -i revert git add -p git reset -p git stash apply –index git stash –keep-index git add -i update Achieved except for set target yesterdayDescriptionToday’s target laravel- warming up for challenge next week 2018/12/15The result of my target yesterdaylaracast recap the php practitioner series (22/25) laravel warming up laravel_5.7_from_scratch series (4~8/36) linux: what’s cp -s? waht’s cp -r? waht’s cp -u? waht’s cp –preserve=all? if there are two sources when placing cp command, what the destination should be? waht’s cp –preserve=all? git git log origin/master..head git log master..test git log ^master test git log test –not master git log test develop ^master git log test develop –not master Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git laracast: the_php_practitioner recap 23 laravel- warming up for challenge next week 2018/12/14The result of my target yesterdaylaracast recap the php practitioner series (21/25) laravel warming up laravel_5.7_from_scratch series (1~3/36) linux: what’s cp -a? what’s cp -d? what’s cp -f? what’s cp -i? what’s cp -l? what’s cp -p? git git rebase -i ‘wondering’ presentation perfectly done Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git laracast: the_php_practitioner recap 22 laravel- warming up for challenge next week 2018/12/13The result of my target yesterdaylaracast the php practitioner series (19~20/25) linux: what’s in /var/spool folder of linux? what’s ls -a? what’s ls -f? what’s ls -h? what’s ls -i? what’s ls -n? what’s ls -r? what’s ls -r? what’s ls -s? what’s ls -t? what’s ls –full-time? challenge 20181212 passed git git rebase -i Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git laracast: the_php_practitioner recap 21 ‘wondering’ presentation laravel- warming up for challenge next week 2018/12/12The result of my target yesterdaylaracast no time for it. linux: what’s in /var/spool folder of linux? what’s nfs in full name? what’s lsb in full name? how to show true path rather than link path when using pwd? how to create folders through multipal layers? how to give authority when creating a folder? how to show $path? how to add a folder into $path? what’s ls -a? challenge 20181211 passed adaptor make every single book an object how to pass outside variable into closure git github notification flicked through github api and github hooks Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git laracast: the_php_practitioner recap 18~? challenge 20181212 ‘wondering?’ rehersal 2018/12/11The result of my target yesterdaylaracast have completed recapping of 15~17 linux: what’s in /include folder of linux? what’s in /libexec folder of linux? what’s in /usr/src folder of linux? what’s in /var folder of linux? what’s in /var/cache folder of linux? what’s in /var/lib folder of linux? what’s in /var/lock folder of linux? what’s in /var/log folder of linux? what’s in /var/mail folder of linux? what’s in /usr folder of linux? what’s in /usr/bin folder of linux? challenge 20181210 passed git how to fetch all pull-requests without adding them as remotesfetch = +refs/pull//head:refs/remotes/origin/pr/ Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git laracast: the_php_practitioner recap 18~? challenge 20181211 2018/12/10The result of my target yesterdaylaracast the_php_practitioner series (25/25) was completed. have recapped the_php_practitioner 1~15. linux: what’s in /usr folder of linux? what’s in /usr/bin folder of linux? what’s in /usr/lib folder of linux? what’s in /usr/local folder of linux? what’s in /usr/sbin folder of linux? what’s in /usr/share folder of linux? what’s in /usr/games folder of linux? what’s in /home folder of linux? what’s in /lib qual folder of linux? what’s in /root qual folder of linux? what’s in /proc qual folder of linux? what’s in /sys folder of linux? git if you see something like pull request does not merge cleanly in github, what should you do?① add the original repository as a remote named “upstream”② fetch the newest work from that remote③ merge the main branch of that repository into your topic branch④ fix the conflict that occurred⑤ push back up to the same topic branch how could we reference issue or pull-request on github?## how to use task list on github? write the code write all the tests document the code Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git laracast: the_php_practitioner recap challenge 20181210 2018/12/9The result of my target yesterdaylaracast having completed episode 24, and will recap it again and push it to github linux: what’s in /home folder of linux? what’s in /lib qual folder of linux? what’s in /root folder of linux? what’s in /lost+found folder of linux? what’s in /proc folder of linux? what’s in /sys folder of linux? git what are the steps to create a pull-request on github?① clone our fork of the project locally② create a descriptive topic branch③ make our change to the code④ check that the change is good⑤ commit our change to the topic branch⑥ push our new topic branch back up to our github fork how to condense a whole feature branch into a single commit and push it to master branch as production branch. Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git laracast: the_php_practitioner (24/25) recap and (25/25) 2018/12/8The result of my target yesterdaylaracast having completed episode 23 and pushed it to github linux: what’s in /media folder of linux? what’s in /mnt folder of linux? what’s in /opt folder of linux? what’s in /run folder of linux? what’s in /sbin folder of linux? what’s in /srv folder of linux? what’s in /tmp folder of linux? The Wondering having completed presentation for ‘wondering’ next week. git i didn’t have time for it yesterday. Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git laracast: the_php_practitioner (24/25) 2018/12/7The result of my target yesterdaylaracast yesterday i didn’t watch it at all, my goodness. i must finish it today and move on! linux: what’s in /bin folder of linux? what’s in /boot folder of linux? what’s in /dev folder of linux? what’s in /etc folder of linux? what’s in /lib folder of linux? The Wondering both rehersal and presentation were perfectly done. Achieved except for set target yesterday sharing what i learnt from the deployment event at tuesday night with the whole backend team. DescriptionToday’s target presentation for The Wondering next week, or perhaps the week after that. linux: 鳥哥的linux基礎篇 git: pro git laracast: the php practitioner(23/25) recap, and push every step of it on github 2018/12/6The result of my target yesterdaylaracast finally, i finished episode (23/25) yesterday. i will try to recap it again and push each step on github linux: when installing package, why it shows 403 forbidden? the limit of length of the name of files and repositories in linux. fhs - filesystem hierarchy standard the purpose of fhs four types of repositories in linux explanation of four types of repositories - shareable, unshareable, static, variable three defaultly defined repositries by fhs The Wondering i have finished rehersal one time, and am going to do that again before presentation.Achieved except for set target yesterdayDescriptionToday’s target The Wondering rehersal before presentation linux: 鳥哥的linux基礎篇 laracast: the php practitioner(23/25) recap, and push every step of it on github 2018/12/5The result of my target yesterdaylaracast still stuck on the_php_practitioner episode 23. maybe bacause i stayed up late the night before last night with whole backend working server deployment, yesterday i was too groggy to figure it out. i have to finish it today!git: gpg security keys for git tag signituressl: having completed ssl hand-on experiment. linux: recap authority command with jett and soj. i was supposed to read linux book last night, however, i passed out as soon as i took a shower. Achieved except for set target yesterdayDescriptionToday’s target laracast: the php practitioner(23/25) The Wondering rehersal linux: 鳥哥的linux基礎篇 2018/12/4The result of my target yesterdaylaracast the php practitioner (23/25). i was scheduled to finish episode 23 yesterday. however, the whole backend team and i were working on server configuration and deployment all day long, and i will manage to finish it today. git: as above mentioned, i counldn’t manage any time for git yesterday. linux: what’s link file what’s data file what’s device file what are block and character of device file what’s socket file what’s fifo file Achieved except for set target yesterday ssl signature frontend and backend deployment on server with apache.DescriptionToday’s target laracast: the php practitioner(23/25) git: pro git linux: 鳥哥的linux基礎篇 ssl signature hand-on experiment.2018/12/3 The result of my target yesterdaylaracast the php practitioner (23/25), i’ve recapped the logic, and ready to go further. git: hand-on experiment on rerere function linux: chmod ugoa, +-=, rwx rules of authority for files and repositories regular file: ascii, data, binary how to read data file - last how to read ascii file - cat The Wondering completed Achieved except for set target yesterdayDescriptionToday’s target laracast: the php practitioner(23/25) git: pro git linux: 鳥哥的linux基礎篇2018/12/2 The result of my target yesterdaylaracast the php practitioner (23/25): i spent a lot of time recaping what i’d leart before backend challenge. i think i will need more time to retrive the logic before getting later episode. git: merging work flow large-merging workflow git config –global rerere.enabled true linux: chgrp [-r] groupname filename chown [-r] user:group filenameorrepositoryname chmod [-r] xyz filenameorrepositoryname docker: create a dockerfile build a dockerfile run a dockerfile push a dockerfile rough concept of docker Achieved except for set target yesterdayDescriptionToday’s target laracast: the php practitioner series git linux presentation of The Wondering for next week. 2018/12/1The result of my target yesterdayapache and nginx: having learnt how to use either apache or nginx as reverse proxy and proxy_pass to webserver with whatever headers that are required. git: create a branch based off another branch - git branch thebranchyouwant thebranchyouwouldliketobebasedoff will git reflog be pushed? - no can i pull from repositories that haven’t been added as remote? - yes how to pull from repositories that haven’t been saved as remote - git pull theurl, append –allow-unrelated-histories if not related. it shows only the work your current topic branch has introduced since its common ancestor with master - git diff master…meatlinux: drwxrwxrwx, what does d mean? -rwxrwxrwx, what does - mean? lrwxrwxrwx, what does l mean? brwxrwxrwx, what does b mean? crwxrwxrwx, what does c mean?DescriptionToday’s target laracast: the php practitioner series attending docker speech held on good idea studio git linux","link":"/zh-tw/schedule/2018/December/index.html"},{"title":"November 2018","text":"2018/11/30The result of my target yesterday ‘The Wondering’ sharing was perfectily done. having learnt the purpose of $remote_addr and $proxy_add_x_forwarded_forAchieved except for set target yesterdayDescription Today’s target go deeper into apache and nginx config git linux 2018/11/29The result of my target yesterday having learnt how to use apache with php-fpmAchieved except for set target yesterday having completed backend challenge of second roundDescription Today’s target go deeper into apache and nginx config share git in ‘The Wondering’ 2018/11/28The result of my target yesterday backend challenge was completedAchieved except for set target yesterday DescriptionToday’s target go deeper into apache config 2018/11/27The result of my target yesterdayAchieved except for set target yesterdayDescriptionToday’s target aws ec2, eip, security group server default environment apache, nginx installation and config","link":"/zh-tw/schedule/2018/November/index.html"},{"title":"April 2019","text":"2019/4/30The result of my target yesterday node.js Implementing MVC on Express.js docker English Japanese achieved except for set target yesterdaydescriptiontoday’s target node.js docker English Japanese 2019/4/29The result of my target yesterday English docker Japanese Node.js Working on documentation of GCP Mountain hiking achieved except for set target yesterdaydescriptiontoday’s target node.js docker English Japanese 2019/4/28The result of my target yesterday English docker Japanese Node.js Working on documentation of GCP IWD worker achieved except for set target yesterdaydescriptiontoday’s target node.js docker English Japanese 2019/4/27The result of my target yesterday English docker Japanese Node.js Build an app server with express.js achieved except for set target yesterdaydescriptiontoday’s target node.js docker English Japanese 2019/4/26The result of my target yesterday English Japanese Node.js Go deeper into event loop What’s event loop Every phase in event loop timers I/O callbacks idle, prepare poll check close callbacks achieved except for set target yesterdaydescriptiontoday’s target node.js docker English Japanese 2019/4/25The result of my target yesterday English Japanese Node.js Parsing request bodies Understanding the concept of event driven Blocking and Non-Blocking Code Roughly reading through event loop achieved except for set target yesterdaydescriptiontoday’s target node.js docker English Japanese 2019/4/24The result of my target yesterday English Japanese Node.js module create a rudimentary server end a loop get information we want from request define response rudimentary request routing achieved except for set target yesterdaydescriptiontoday’s target node.js docker English Japanese 2019/4/23The result of my target yesterday English Japanese Get deeper into Docker Write down current progressAchieved except for set target yesterdayDescriptionToday’s target English Japanese Node.js 2019/4/22The result of my target yesterday English Japanese Get deeper into Docker Completed my first image made by Docker commitAchieved except for set target yesterdayDescriptionToday’s target English Japanese Get deeper into Docker 2019/4/21The result of my target yesterday English Japanese Get deeper into Docker Docker commit Achieved except for set target yesterdayDescriptionToday’s target English Japanese Get deeper into Docker 2019/4/20The result of my target yesterday English Japanese Get deeper into Docker docker tag, docker push, docker volume, docker save Achieved except for set target yesterdayDescriptionToday’s target English Japanese Get deeper into Docker 2019/4/19The result of my target yesterday English Japanese Finish Inboxer project Get deeper into Docker Create a MySQL container and connect to it while another MySQL is installed locally. That is, I could connect to two MySQLs in the server. Achieved except for set target yesterdayDescriptionToday’s target English Japanese Get deeper into Docker 2019/4/18The result of my target yesterday English Japanese Finish Inboxer project Still wait for DNS to update for SSL signature Achieved except for set target yesterdayDescriptionToday’s target English Japanese Finish Inboxer project Get deeper into Docker 2019/4/17The result of my target yesterday English Japanese Complete CentOS document with Docker Achieved except for set target yesterdayDescriptionToday’s target English Japanese Finish Inboxer project 2019/4/16The result of my target yesterday English Japanese Inboxer project Quote the translation feeAchieved except for set target yesterdayDescriptionToday’s target English Japanese Complete CentOS document with Docker 2019/4/15The result of my target yesterday English Japanese Inboxer project Initially completed deploying and send-mail function Achieved except for set target yesterdayDescriptionToday’s target English Japanese Inboxer project Quote the translation fee 2019/4/14The result of my target yesterday English Japanese GCP event Achieved except for set target yesterdayDescriptionToday’s target English Japanese Inboxer project 2019/4/13The result of my target yesterday English Japanese GCP Essentials review Working on docker-compose Achieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Event 2019/4/12The result of my target yesterday English Japanese GCP Essentials review Working on docker-compose Achieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Essentials review Kubernetes and Load Balance 2019/4/11The result of my target yesterday English Japanese GCP Essentials review Working on docker-compose Achieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Essentials review Go deeper into Docker 2019/4/10The result of my target yesterday English Japanese GCP Essentials review Go deeper into docker-compose Achieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Essentials review Go deeper into Docker 2019/4/9The result of my target yesterday English Japanese GCP Essentials review Docker-compose Achieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Essentials review Go deeper into Docker 2019/4/8The result of my target yesterday English Japanese GCP Essentials review Go deeper into Docker - Overlay Network Achieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Essentials review Go deeper into Docker 2019/4/7The result of my target yesterday English Japanese GCP Essentials review Go deeper into Docker - Swarm and Service Achieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Essentials review Go deeper into Docker 2019/4/6The result of my target yesterday English Japanese GCP Essentials review Docker - containerAchieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Essentials review Go deeper into Docker 2019/4/5The result of my target yesterday English Japanese GCP Essentials review Docker - image Achieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Essentials review Go deeper into Docker 2019/4/4The result of my target yesterday English Japanese GCP Essentials review Go deeper into Docker Achieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Essentials review Go deeper into Docker 2019/4/3The result of my target yesterday English Japanese GCP Essentials review Achieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Essentials review Go deeper into Docker 2019/4/2The result of my target yesterday English Japanese GCP Essentials review 1~3 Laracasts-Laravel_5.7_From_Scratch No time for it Achieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Essentials review 2019/4/1The result of my target yesterday English Japanese GCP Essentials - Kubernetes Quick Start Laracasts-Laravel_5.7_From_Scratch Achieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Essentials review Laracasts-Laravel_5.7_From_Scratch","link":"/zh-tw/schedule/2019/April/index.html"},{"title":"November 2018","text":"2019/3/31The result of my target yesterday Deploy jenkins for openData Laracasts-Laravel_5.7_From_Scratch Achieved except for set target yesterdayDescriptionToday’s target GCP Essentials - Kubernetes Laracasts-Laravel_5.7_From_Scratch 2019/3/30The result of my target yesterday Write down how to do jenkins deployment Deploy ‘backendOfMobileGames’ and ‘openData’ Achieved except for set target yesterdayDescriptionToday’s target Deploy jenkins for openData Laracasts-Laravel_5.7_From_Scratch 2019/3/29The result of my target yesterday AWS Deployment: jenkins deployment Achieved except for set target yesterdayDescriptionToday’s target Write down how to do jenkins deployment Deploy ‘backendOfMobileGames’ and ‘openData’ 2019/3/28The result of my target yesterday AWS Deployment Completed supervisor and queue setting Achieved except for set target yesterdayDescriptionToday’s target AWS Deployment: jenkins deployment 2019/3/27The result of my target yesterday AWS Deployment Still working on it Achieved except for set target yesterdayDescriptionToday’s target AWS Deployment 2019/3/26The result of my target yesterday Laracasts-Laravel_5.7_From_Scratch Episode 6-11 Achieved except for set target yesterdayDescriptionToday’s target AWS Deployment 2019/3/25The result of my target yesterday Laracasts-Laravel_5.7_From_Scratch Episode 1~5 Achieved except for set target yesterdayDescriptionToday’s target Laracasts-Laravel_5.7_From_Scratch 2019/3/24The result of my target yesterday Write down how to use queue with sqs Prepare interview tonight Well, the interview was rescheduled because the interviewer was indisposed. Achieved except for set target yesterdayDescriptionToday’s target Laracasts-Laravel_5.7_From_Scratch 2019/3/23The result of my target yesterday Write down how to use Supervisor to manage queue work with sqs Completed Supervisor part, and will work on sqs part today. Prepare interview tonight The interview time was changed to tonight. Achieved except for set target yesterdayDescriptionToday’s target Write down how to use queue with sqs Prepare interview tonight 2019/3/22The result of my target yesterday Figure out how to use Supervisor to manage queue work Write down how to use Supervisor to manage queue work ‘The Wondering’ presentation Achieved except for set target yesterdayDescriptionToday’s target Write down how to use Supervisor to manage queue work with sqs Prepare interview tonight 2019/3/21The result of my target yesterday Figure out how to use SQS to send email Recap GCP Essentials Achieved except for set target yesterdayDescriptionToday’s target Figure out how to use Supervisor to manage queue work Write down how to use Supervisor to manage queue work ‘The Wondering’ presentation 2019/3/20The result of my target yesterday Complete FB selling side project’s ReadMe Recap GCP Essentials Achieved except for set target yesterdayDescriptionToday’s target Figure out how to use SQS to send email Recap GCP Essentials 2019/3/19The result of my target yesterday Write down Ray’s git flow Complete FB selling side project’s ReadMe Not yet completed, but working on it. Achieved except for set target yesterdayDescriptionToday’s target Complete FB selling side project’s ReadMe Recap GCP Essentials 2019/3/18The result of my target yesterday The Wondering presentation. Optimize FB online selling project Achieved except for set target yesterdayDescriptionToday’s target Write down Ray’s git flow Complete FB selling side project’s ReadMe 2019/3/17The result of my target yesterday The Wondering presentation. Optimize FB online selling project Phone validation and address validation Mail system Achieved except for set target yesterdayDescriptionToday’s target The Wondering presentation. Optimize FB online selling project 2019/3/16The result of my target yesterday Optimize FB online selling project Still working on the mail system for refund Achieved except for set target yesterdayDescriptionToday’s target The Wondering presentation. Optimize FB online selling project Phone validation and address validation Mail system 2019/3/15The result of my target yesterday Write down how to use PayPal payment service I’ve done it! Optimize FB online selling project If possible, I will go validation today! Achieved except for set target yesterdayDescriptionToday’s target Optimize FB online selling project Phone validation and address validation 2019/3/14The result of my target yesterday Write down how to use PayPal payment service I’m working on it! Optimize FB online selling project Have added refund function on both PayPal and AllPay Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service Finish it! Optimize FB online selling project If possible, I will go validation today! 2019/3/13The result of my target yesterday Write down how to use PayPal payment service Finished the refund function of PayPal. Optimize FB online selling project Finished the refund function of PayPal. Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service Will start to write this article after AllPay system refund function is completed. Optimize FB online selling project Finish refund function of AllPay 2019/3/12The result of my target yesterday Write down how to use PayPal payment service Almost finished refund function Optimize FB online selling project Almost finished PayPal refund function Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service Optimize FB online selling project 2019/3/11The result of my target yesterday Write down how to use PayPal payment service Completed capture authorization function. Optimize FB online selling project Completed capture authorization function. Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service Optimize FB online selling project 2019/3/10The result of my target yesterday Write down how to use PayPal payment service Nearly finished a basic transaction with REST API of PayPal Optimize FB online selling project Nearly finished a basic transaction with REST API of PayPal Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service Optimize FB online selling project 2019/3/9The result of my target yesterday Write down how to use PayPal payment service Still working on new features Optimize FB online selling project Working on refund feature Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service Optimize FB online selling project 2019/3/8The result of my target yesterday Write down how to use PayPal payment service Still working on new features Optimize FB online selling project Working on refund feature Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service Optimize FB online selling project 2019/3/7The result of my target yesterday Write down how to use PayPal payment service Already figured out how to use REST API, and now working on how to integrate it into my system Optimize FB online selling project Restructure Currently working on refund function WebSocket Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service Optimize FB online selling project Restructure WebSocket 2019/3/6The result of my target yesterday Write down how to use PayPal payment service still working on figuring out how rest API works Optimize FB online selling project Restructure WebSocket Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service Optimize FB online selling project Restructure WebSocket 2019/3/5The result of my target yesterday Write down how to use PayPal payment service Completed Payment Standard and IPN Message method Optimize FB online selling project Refine payment service Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service Optimize FB online selling project Restructure WebSocket 2019/3/4The result of my target yesterday Write down how to use PayPal payment service Still working on it, it’s a epic task! Optimize FB online selling project Restructure Make PayPal page show items and recipient in detail WebSocket Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service Optimize FB online selling project Restructure WebSocket 2019/3/3The result of my target yesterday Write down how to get long-lived and forever token from FB One more section of my Git Course Basically, it’s completed Optimize FB online selling project Restructure WebSocket Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service Optimize FB online selling project Restructure WebSocket 2019/3/2The result of my target yesterday Write down how to use PayPal payment service One more section of my Git Course Optimize FB online selling project Added long-lived token function Achieved except for set target yesterdayDescriptionToday’s target Write down how to get long-lived and forever token from FB One more section of my Git Course Optimize FB online selling project Restructure WebSocket 2019/3/1The result of my target yesterday Write down how to use PayPal payment service One more section of my Git Course Optimize FB online selling project- Restructure - WebSocket Achieved except for set target yesterdayDescription Went to help 日安 carry the new counter she bought Went to KTV with Lester Today’s target Write down how to use PayPal payment service One more section of my Git Course Optimize FB online selling project- Restructure - WebSocket","link":"/zh-tw/schedule/2019/March/index.html"},{"title":"January 2019","text":"2019/1/31The result of my target yesterday challenge: facebook optimized selling system revised api instead git pro prepared ‘the wondering’ rehearsal 鳥哥的linux prepared ‘the wondering’ rehearsal Achieved except for set target yesterday block chain knowledgeDescriptionToday’s target challenge: facebook optimized selling system third party payment service git pro 鳥哥的linux 2019/1/30The result of my target yesterday challenge: facebook optimized selling system completed api (26/26) git course outline provided to howard Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system third party payment service git pro 鳥哥的linux2019/1/29 The result of my target yesterday challenge: facebook optimized selling system commpleted api (23/25) git pro prepared git course outline instead 鳥哥的linux prepared git course outline instead Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system git course outline 2019/1/28The result of my target yesterday challenge: facebook optimized selling system commpleted api (22/25) introduction of my blog Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system git pro 鳥哥的linux2019/1/27 The result of my target yesterday ‘the wondering’ presentation next week challenge: facebook optimized selling system completed 3 api Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system introduction of my blog 2019/1/26The result of my target yesterday challenge: facebook optimized selling system working on my blog and linkedin instead. Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system ‘the wondering’ presentation next week 2019/1/25The result of my target yesterday challenge: facebook optimized selling system working on ci with jenkins instead Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system 2019/1/24The result of my target yesterday challenge: facebook optimized selling system completed three apis Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system 2019/1/23The result of my target yesterday challenge: facebook optimized selling system completed three apis Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system 2019/1/22The result of my target yesterday challenge: facebook optimized selling system completed three apis Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system 2019/1/21The result of my target yesterday challenge: facebook optimized selling system completed six apis Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system 2019/1/20The result of my target yesterday challenge: facebook optimized selling system completed three api Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system 2019/1/19The result of my target yesterday challenge: facebook optimized selling system initially completed api document Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system 2019/1/18The result of my target yesterday challenge: facebook optimized selling system intially confirmed the specification Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system2019/1/17 The result of my target yesterday challenge: facebook optimized selling system initially discussed the feature Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system 2019/1/16The result of my target yesterdayAchieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system 2019/1/15The result of my target yesterday linux: 鳥哥的linux基礎篇 git: pro git build my own blog in github with hexo almost complete personal configuration Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system 2019/1/14The result of my target yesterday [x] linux: 鳥哥的linux基礎篇 suid full name suid’s function and limit [x] git: pro git how to configure your git to save your credentials? what are three level of git configurations? where is the configuration file that git looks for when it comes to system level configuration? where is the configuration file that git looks for when it comes to global level configuration? how to ignore files globaly in git? [x] build my own blog in github with hexo i’m still working on it, still some issues to be solved. Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git build my own blog in github with hexo 2019/1/13The result of my target yesterday iron man award ceremony Achieved except for set target yesterday completed presentation for ‘the wondering’ on 17 january 2019DescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git reorganize those presentations i’ve made from keynote to hackmd the first commit 沒遇到這些事之前，我也覺得我git超屌 episode 1 沒遇到這些事之前，我也覺得我git超屌 episode 2 沒遇到這些事之前，我也覺得我git超屌 episode 3 沒遇到這些事之前，我也覺得我git超屌 episode 4 2019/1/12The result of my target yesterday challenge20181217 rewriting optimize readme the wondering organize git presentation that i’ve shared in ‘the wondering’ presentation for ‘the wondering’ next week 鳥哥的Linux基礎篇 git: pro git Achieved except for set target yesterday build opendata project on aws and so my team members could use it for their interviews in the future.DescriptionToday’s target iron man award ceremony 2018/1/11The result of my target yesterday challenge20181217 rewriting add status code to all the functions revise api document accordingly to restful api. Achieved except for set target yesterday git: if you create a new branch, add a submodule there, and then switch back to a branch without that submodule, what will happen?DescriptionToday’s target challenge20181217 rewriting optimize readme the wondering organize git presentation that i’ve shared in ‘the wondering’ presentation for ‘the wondering’ next week linux: 鳥哥的linux基礎篇 git: pro git 2019/1/10The result of my target yesterday linux: 鳥哥的linux基礎篇 working on swagger api [ ] git: pro git working on swagger api [x] challenge20181217 rewriting added customized status code on register, login, and get profile api revise api document accordingly to restful api Achieved except for set target yesterdayDescriptionToday’s target challenge20181217 rewriting add status code to all the functions revise api document accordingly to restful api.2019/1/9 The result of my target yesterday linux: 鳥哥的linux基礎篇 working on swagger api [ ] git: pro git working on swagger api [x] challenge20181217 rewriting complete register and login function api with swagger Achieved except for set target yesterdayDescriptionToday’s target challenge20181217 rewriting make api document with swagger2019/1/8 The result of my target yesterday linux: 鳥哥的linux基礎篇 working on challenge20190107 - how to upload a file to aws-s3 via a pre-signed url instead. [x] git: pro git how to stash all the work in all our submodules? how to create a new branch and switch to it in all our submodules? how to use ‘git diff’ in your main project and all your submodules? [ ] challenge20181217 rewriting working on challenge20190107 - how to upload a file to aws-s3 via a pre-signed url instead. Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git challenge20181217 rewriting revise api document learn how to use swagger 2019/1/7The result of my target yesterday had a wonderful getaway yesterday.Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git challenge20181217 rewriting revise api document 2019/1/6The result of my target yesterday [ ] linux: 鳥哥的linux基礎篇 [x] git: pro git practice submodule [x] challenge20181217 rewriting complete transferring to restful apiAchieved except for set target yesterdayDescriptionToday’s target have a getaway today. 2019/1/5The result of my target yesterday [ ] linux: 鳥哥的linux基礎篇 [x] git: pro git practice submodule [x] challenge20181217 rewriting publish api document on github page, and sign ssl certificateAchieved except for set target yesterday how to build a blog with hexo DescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git challenge20181217 rewriting optimize api to restful api 2019/1/4The result of my target yesterday [x] linux: 鳥哥的linux基礎篇 what’s chattr [+-=] [asacdistu] how to search placed command in lunux? [x] git: pro git how to check if we find a bug after a lot of commits made, and we have no idea when and where the code went wrong? how to revise submodule url? what does 160000 mode means when commit a submodule? how to make a submodule? a better diff for submodule? [x] challenge20181217 rewriting complete ‘aws deployment’ DescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git challenge20181217 rewriting publish the api document on github page 2019/1/3The result of my target yesterday [x] linux: 鳥哥的linux基礎篇 how to execute cat command with value got previously in linux? [x] git: pro git what’s the progress of cloning project with submodule in? if, in master branch, i reset with a sha1 from develop branch, what would happen? how to specify lines with git blame? how to show where it’s originally copied from with git blame? [x] challenge20181217 rewriting complete ‘optimizing payment controller’ DescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git challenge20181217 rewriting deploy on aws2019/1/2 The result of my target yesterday [ ] linux: 鳥哥的linux基礎篇 ‘wondering’ rehearsal instead [ ] git: pro git ‘wondering’ rehearsal instead [x] challenge20181217 rewriting complete ‘deposit common achievement’ DescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git challenge20181217 rewriting optimize payment controller2019/1/1 The result of my target yesterday [x] linux: 鳥哥的linux基礎篇 what’s default authority when creating a file? what’s the default umask? so what’s the final default authority? how to see default umask? how to set umask? what’s the correct way of calculating final authority after deducting umask? [ ] git: pro git challenge20181217 rewriting do a linebot challenge held by howard instead DescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git challenge20181217 rewriting deposit achievement","link":"/zh-tw/schedule/2019/January/index.html"},{"title":"May 2019","text":"2019/5/31the result of my target yesterday Task: Working on architecture of Cloud API Started working on Discover Service Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on architecture of Cloud API Linux English Japanese 2019/5/30the result of my target yesterday Task: Working on architecture of Cloud API Initially completed Ready Pool and Bootstrap Help Raymond to check edge condition Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on architecture of Cloud API Linux English Japanese 2019/5/29the result of my target yesterday Task: A meeting in Hsinchu Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on architecture of Cloud API Linux English Japanese 2019/5/28the result of my target yesterday Task: Completed edge-ip-revising API Still working on GCP Cloud DNS documentation Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: A meeting in Hsinchu Linux English Japanese 2019/5/27the result of my target yesterday Task: Completed a course in Qwiklab Watch Game of Thrones instead, I was guilty! Fix my windows computer Containerise HX-API Watch Game of Thrones instead, I was guilty! Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Completed edge-ip-revising API Linux English Japanese 2019/5/26the result of my target yesterday Task add getting new ip feature to monitor api Organising what I have learnt those weeks English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task Completed a course in Qwiklab Fix my windows computer Containerise HX-API Linux English Japanese 2019/5/25the result of my target yesterday Task review merge request of monitor api add getting new ip feature to monitor api working on onedgeipchange api English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task add getting new ip feature to monitor api Organising what I have learnt those weeks English Japanese 2019/5/24the result of my target yesterday Task figured out how edge dns works English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task review merge request of monitor api add getting new ip feature to monitor api working on onedgeipchange api English Japanese 2019/5/23The result of my target yesterday Task Comment issue 302~310 Have a meeting with Raymond English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task Working on API developing and refactoring. English Japanese 2019/5/22The result of my target yesterday Task Added new feature into monitor API English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task Comment issue 302~310 Have a meeting with Raymond English Japanese 2019/5/21The result of my target yesterday Task English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task Added new feature into monitor API English Japanese 2019/5/20The result of my target yesterday Task English Japanese achieved except for set target yesterdaydescriptiontoday’s target Organise what I learnt those weeks English Japanese 2019/5/19The result of my target yesterday Organise what I learnt those weeks Completed gitlac CI/CD on GCP virtual machine document organisation English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task Figure out checkEdgeAlive API Complete issue 302~310 English Japanese 2019/5/18The result of my target yesterday Organise what I learnt those weeks Organised Gitlab CI/CD English Japanese achieved except for set target yesterdaydescriptiontoday’s target Organise what I learnt those weeks English Japanese 2019/5/17The result of my target yesterday Task I would like to complete API support feature of the healthCheck function, however, it depends on the task English Japanese achieved except for set target yesterdaydescriptiontoday’s target Organise what I learnt those weeks English Japanese 2019/5/16The result of my target yesterday Task Understand the logic of checkEdgeAlive API - Then, we optimise the healthCheck function instead. English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task I would like to complete API support feature of the healthCheck function, however, it depends on the task English Japanese 2019/5/15The result of my target yesterday Task Come out with a solution for checkEdgeAlive issue: Completed a health check program to check the health per 10 minutes for temporary solution. English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task Understand the logic of checkEdgeAlive API English Japanese 2019/5/15The result of my target yesterday Task Initially fixed issue from 302 to 310 English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task Come out with a solution for checkEdgeAlive issue English Japanese 2019/5/14The result of my target yesterday Task Understand the logic of API implementation of QCDN. English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task Solve issue 302~310 English Japanese 2019/5/13The result of my target yesterday Task Understand the logic of API implementation of QCDN. Deploy Node.js project on Google App Engine English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task Understand the logic of API implementation of QCDN. English Japanese 2019/5/12The result of my target yesterday Task Figured out how to use breakpoint feature in PHPStorm. English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task Understand the logic of API implementation of QCDN. English Japanese 2019/5/11The result of my target yesterday Task Have initially completed the database organising, however, still have to change the logic of API implementation. English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task Figure out how to use IDE breakpoint feature English Japanese 2019/5/10The result of my target yesterday Task Have figured out the logic, still working on it. English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task Fix siteEdge unmatched data issue English Japanese 2019/5/9The result of my target yesterday English Japanese Task Got siteEdge.host unmatched from either site.host or site.cname Learnt how to build a site achieved except for set target yesterdaydescriptiontoday’s target Task Fix siteEdge unmatched data issue English Japanese 2019/5/8The result of my target yesterday English Japanese node.js How to insert data into datastore achieved except for set target yesterdaydescriptiontoday’s target Task English Japanese 2019/5/7The result of my target yesterday English Japanese A go over with Eddie and Raymond achieved except for set target yesterdaydescriptiontoday’s target node.js English Japanese 2019/5/6The result of my target yesterday English Japanese Gitlab CI Load Balance achieved except for set target yesterdaydescriptiontoday’s target node.js English Japanese 2019/5/5The result of my target yesterday English Japanese Gitlab CI Load Balance achieved except for set target yesterdaydescriptiontoday’s target node.js English Japanese 2019/5/4The result of my target yesterday node.js English Japanese Gitlab CI achieved except for set target yesterdaydescriptiontoday’s target node.js English Japanese 2019/5/3The result of my target yesterday node.js English Japanese Gitlab CI achieved except for set target yesterdaydescriptiontoday’s target node.js English Japanese 2019/5/2The result of my target yesterday node.js add a new route in Express.js make different routes with different prefixes in Express.js send status code in Express.js docker English Japanese achieved except for set target yesterdaydescriptiontoday’s target node.js docker English Japanese Gitlab CI 2019/5/1The result of my target yesterday node.js Implementing mass delete and get function in GCP Datastore docker English Japanese achieved except for set target yesterdaydescriptiontoday’s target node.js docker English Japanese","link":"/zh-tw/schedule/2019/May/index.html"},{"title":"February 2018","text":"2019/2/28The result of my target yesterday Write down how to use PayPal payment service One more section of my Git Course Optimize FB online selling project Make recipient information only required when a order is paid Achieved except for set target yesterday Solve the problem that the canvas-nest special effect doesn’t work properly on Schedule page DescriptionToday’s target Write down how to use PayPal payment service One more section of my Git Course Optimize FB online selling project Restructure WebSocket 2019/2/27The result of my target yesterday One more section of my Git course Write down an article - how to build a multilingual blog with Hexo Optimize FB online selling project Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service One more section of my Git Course Optimize FB online selling project Make recipient information only required when a order is paid 2019/2/26The result of my target yesterday My blog - improve the layout Achieved except for set target yesterdayDescriptionToday’s target One more section of my Git course Write down an article - how to build a multilingual blog with Hexo Optimize FB online selling project 2019/2/25The result of my target yesterday Working on the blog, I would like to make a bilingual version Achieved except for set target yesterdayDescriptionToday’s target My blog - improve the layout 2019/2/24The result of my target yesterday Fix the decoded garble problem of my blog Completed a bit, but still working on it Achieved except for set target yesterdayDescriptionToday’s target Working on the blog, I would like to make a bilingual version 2019/2/23The result of my target yesterday Challenge: Facebook optimized selling system - keep optimizing Git course: The presentation Finished first course Write down how to make PayPal payment service work Working on my blog instead Achieved except for set target yesterdayDescriptionToday’s target Fix the decoded garble problem of my blog 2019/2/22The result of my target yesterday Challenge: Facebook optimized selling system Optimize and debug Demo Achieved except for set target yesterdayDescriptionToday’s target Challenge: Facebook optimized selling system - keep optimizing Git course: The presentation Write down how to make PayPal payment service work 2019/2/21The result of my target yesterday Challenge: Facebook optimized selling system - Optimize and debug Optimize images upload function with Laravel way Reorganise and write down how to make PayPal payment service works Achieved except for set target yesterday Challenge: Facebook optimized selling system Added new function that when an order is paid, the buyer will receive a notification email DescriptionToday’s target Challenge: Facebook optimized selling system optimize and debug demo 2019/2/20The result of my target yesterday challenge: facebook optimized selling system - optimize and debug added email update function in update-user-info function Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system - optimize and debug optimize images upload function with laravel way reorganise and write down how to make paypal payment service works 2019/2/19The result of my target yesterday challenge: facebook optimized selling system - paypal payment service finally app site is able to use it Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system - optimize and debug 2019/2/18 gcp quiklab training course stackdriver: qwik start set up network and http load balancers The result of my target yesterdayAchieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system - paypal payment service 2019/2/17The result of my target yesterday gcp quiklab training course completed lessons 6 Achieved except for set target yesterdayDescriptionToday’s target gcp quiklab training course 2019/2/16The result of my target yesterday gcp quiklab training course completed lessons 1~5 Achieved except for set target yesterdayDescriptionToday’s target gcp quiklab training course 2019/2/15 challenge: facebook optimized selling system - paypal payment service completed paypal payment service function The result of my target yesterdayAchieved except for set target yesterdayDescriptionToday’s target gcp quiklab training course 2019/2/14 challenge: facebook optimized selling system - paypal payment service still working on it The result of my target yesterdayAchieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system - paypal payment service 2019/2/13 challenge: facebook optimized selling system - paypal payment service still working on it The result of my target yesterdayAchieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system - paypal payment service 2019/2/12 challenge: facebook optimized selling system paypal payment service The result of my target yesterdayAchieved except for set target yesterday api revise create new api- get user status DescriptionToday’s target challenge: facebook optimized selling system - paypal payment service 2019/2/11 challenge: facebook optimized selling system write an article about how to get user’s basic information via token got from fb paypal payment service still working on it. The result of my target yesterdayAchieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system paypal payment service 2019/2/10 challenge: facebook optimized selling system write an article about how to get user’s basic information via token got from fb paypal payment service still working on it The result of my target yesterdayAchieved except for set target yesterday challenge: facebook optimized selling system debug optimize DescriptionToday’s target challenge: facebook optimized selling system write an article about how to get user’s basic information via token got from fb paypal payment service 2019/2/9 challenge: facebook optimized selling system write an article about how to handle allpay payment service paypal payment service still working on it git pro 鳥哥的linux The result of my target yesterdayAchieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system write an article about how to get user’s basic information via token got from fb paypal payment service 2019/2/8The result of my target yesterday challenge: facebook optimized selling system write down how to use task scheduling of laravel with crontab to routinely delete expired orders the presentation of hackmd for ‘the wondering’ on 14 february 2019 paypal payment service git pro git object 鳥哥的linux Achieved except for set target yesterday adopted task scheduling of laravel with crontab to routinely delete expired orders DescriptionToday’s target challenge: facebook optimized selling system write an article about how to handle allpay payment service paypal payment service git pro 鳥哥的linux 2019/2/7The result of my target yesterday challenge: facebook optimized selling system write down how to use aws ses find out why ngrok doesn’t work with aws ses it’s caused by the port. Achieved except for set target yesterday adopted task scheduling of laravel with crontab to routinely delete expired orders DescriptionToday’s target challenge: facebook optimized selling system write down how to use task scheduling of laravel with crontab to routinely delete expired orders the presentation of hackmd for ‘the wondering’ on 14 february 2019 paypal payment service git pro 鳥哥的linux 2019/2/6The result of my target yesterday challenge: facebook optimized selling system mail notification system via ses and laravel Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system write down how to use aws ses find out why ngrok doesn’t work with aws ses 2019/2/5The result of my target yesterday challenge: facebook optimized selling system optimize order system for allpay payment service Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system mail notification system via ses and laravel 2019/2/4The result of my target yesterday challenge: facebook optimized selling system third party payment service, allpay Achieved except for set target yesterday git pro: git hash-object -w stdin git cat-file -p checksum DescriptionToday’s target challenge: facebook optimized selling system optimize order system for allpay payment service 2019/2/3The result of my target yesterday challenge: facebook optimized selling system still working on third party payment service, allpay git pro no time for it = = 鳥哥的linux no time for it = = Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system third party payment service, allpay 2019/2/2The result of my target yesterday challenge: facebook optimized selling system still working on it git pro no time for it 鳥哥的linux no time for it Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system third party payment service git pro 鳥哥的linux 2019/2/1The result of my target yesterday [ ] challenge: facebook optimized selling system ‘the wondering presentation’ instead [x] git pro step into plumbing’s world 鳥哥的linux no time for it Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system third party payment service git pro 鳥哥的linux","link":"/zh-tw/schedule/2019/February/index.html"}],"posts":[{"title":"在 Server 上部署 Laravel 專案","text":"前言本篇紀錄如何在 AWS EC2 上部署 Laravel 專案主要有以下重點： LAMP 部署 Composer 部署 Laravel 部署 規格 Amazon Linux AMI 2018.03.0 (HVM), SSD Volume Type LAMPPHP 安裝 PHP sudo yum install php72;php -v 安裝 PHP Extension sudo yum install php72-mbstring sudo yum install php72-bcmath sudo yum install php72-pdo sudo yum install php72-mysqlnd sudo yum install php72-gd.x86_64 Apache 安裝 Apache sudo yum install httpd24 啟動 Apache sudo service httpd start 設定開機自動重啟 Apache sudo chkconfig httpd on 確認 httpd 已啟用 chkconfig --list httpd 設定 AWS security inbound 測試 Apache 運作，拜訪 IP 安裝 SSL module sudo yum install mod24_ssl MySQL 安裝 MySQL sudo yum install mysql57-server 啟動 MySQL sudo service mysqld start 設定 MySQL 於 Reboot 時自動重啟 sudo chkconfig mysqld on 執行 mysql_secure_installation sudo mysql_secure_installation 設定MySQL支援Sequel Pro 遠端連接 CREATE USER 'root'@'%' IDENTIFIED BY '';GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' WITH GRANT OPTION;FLUSH PRIVILEGES; 設定檔案許可 將您的使用者 (在此案例中為 ec2-user) 新增至 apache 群組 sudo usermod -a -G apache ec2-user 登出並重新登入，以取得新的群組並驗證您的成員資格。 登出 (使用 exit 命令或關閉終端機視窗)： exit 若要在 apache 群組中驗證您的會員資格，請重新連線至您的執行個體，然後執行下列命令： groups 將 /var/www 的群組所有權及其內容變更為 apache 群組。 sudo chown -R ec2-user:apache /var/www 若要新增群組寫入許可並在將來的子目錄上設定群組 ID，請變更 /var/www 及其子目錄的目錄許可。 sudo chmod 2775 /var/wwwfind /var/www -type d -exec sudo chmod 2775 &#123;&#125; \\; 若要新增群組寫入許可，請以遞迴方式變更 /var/www 及其子目錄的檔案許可： find /var/www -type f -exec sudo chmod 0664 &#123;&#125; \\; 測試您的 LAMP Web 伺服器 在 Apache 文件根資料夾中建立 PHP 檔案。 echo \"&lt;?php phpinfo(); ?&gt;\" &gt; /var/www/html/phpinfo.php 在 Web 瀏覽器中，輸入您剛才建立的檔案 URL。此 URL 為您執行個體的公有 DNS 地址，其後跟隨斜線和檔案名稱。例如： http://my.public.dns.amazonaws.com/phpinfo.php 刪除 phpinfo.php 檔案。雖然這可能是有用的資訊，但基於安全因素，您不應將其廣播至網際網路。rm /var/www/html/phpinfo.php Composer 安裝 Composer php -r \"copy('https://getcomposer.org/installer', 'composer-setup.php');\"php -r \"if (hash_file('sha384', 'composer-setup.php') === '48e3236262b34d30969dca3c37281b3b4bbe3221bda826ac6a9a62d6444cdb0dcd0615698a5cbe587c3f0fe57a54d8f5') &#123; echo 'Installer verified'; &#125; else &#123; echo 'Installer corrupt'; unlink('composer-setup.php'); &#125; echo PHP_EOL;\"php composer-setup.phpphp -r \"unlink('composer-setup.php');\" 讓 Composer 可被 Global 使用 sudo mv composer.phar /usr/local/bin/composer Git 安裝 Gitsudo yum install -y git 部署專案 Clone 專案 git clone repositoryAddress 部署 .env 檔 cp .env.example .env 安裝 Composer composer install 產生 key php artisan key:generate 建立資料庫 mysql -urootcreate database databaseName; 建立表格 php artisan migrate 若記憶體不足，可劃分磁碟為替代記憶體 sudo dd if=/dev/zero of=/swapfile bs=1M count=2000;sudo chmod 600 /swapfile;sudo mkswap /swapfile;sudo swapon /swapfile;swapon -s;sudo vim /etc/fstab; 加入以下 code/swapfile swap swap defaults 0 0 更改 Apache 的預設讀取資料夾位置sudo vim /etc/httpd/conf/httpd.conf &lt;Direction \"/var/www/html\"&gt; Allow Override All&lt;/Direction&gt; 以上為正規流程，以下為懶人版 懶人版sudo yum install -y php72;sudo yum install -y php72-mbstring;sudo yum install -y php72-bcmath;sudo yum install -y php72-pdo;sudo yum install -y php72-mysqlnd;sudo yum install -y httpd24;sudo yum install -y sudo yum install php72-gd.x86_64sudo service httpd start;sudo chkconfig httpd on;sudo yum install -y mod24_ssl;sudo yum install -y mysql57-server;sudo service mysqld start;sudo chkconfig mysqld on;sudo usermod -a -G apache ec2-user;sudo chown -R ec2-user:apache /var/www;sudo chmod 2775 /var/wwwfind /var/www -type d -exec sudo chmod 2775 &#123;&#125; \\;find /var/www -type f -exec sudo chmod 0664 &#123;&#125; \\;php -r \"copy('https://getcomposer.org/installer', 'composer-setup.php');\"php -r \"if (hash_file('sha384', 'composer-setup.php') === '48e3236262b34d30969dca3c37281b3b4bbe3221bda826ac6a9a62d6444cdb0dcd0615698a5cbe587c3f0fe57a54d8f5') &#123; echo 'Installer verified'; &#125; else &#123; echo 'Installer corrupt'; unlink('composer-setup.php'); &#125; echo PHP_EOL;\"php composer-setup.php;php -r \"unlink('composer-setup.php');\";sudo mv composer.phar /usr/local/bin/composer;sudo yum install -y git;sudo php -v 設定 AWS security inbound 測試 Apache 運作，拜訪 IP 執行 mysql_secure_installation sudo mysql_secure_installation 設定MySQL支援Sequel Pro 遠端連接 CREATE USER 'root'@'%' IDENTIFIED BY '';GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' WITH GRANT OPTION;FLUSH PRIVILEGES; 登出並重新登入，以取得新的群組並驗證您的成員資格。 登出 (使用 exit 命令或關閉終端機視窗)： exit 若要在 apache 群組中驗證您的會員資格，請重新連線至您的執行個體，然後執行下列命令： groups 在 Apache 文件根資料夾中建立 PHP 檔案。 echo \"&lt;?php phpinfo(); ?&gt;\" &gt; /var/www/html/phpinfo.php 在 Web 瀏覽器中，輸入您剛才建立的檔案 URL。此 URL 為您執行個體的公有 DNS 地址，其後跟隨斜線和檔案名稱。例如： http://my.public.dns.amazonaws.com/phpinfo.php 刪除 phpinfo.php 檔案。雖然這可能是有用的資訊，但基於安全因素，您不應將其廣播至網際網路。 rm /var/www/html/phpinfo.php Clone 專案 git clone repositoryAddress 部署 .env 檔 cp .env.example .env 安裝 Composer composer install 產生 key php artisan key:generate 建立資料庫 mysql -urootcreate database databaseName; 建立表格 php artisan migrate 若記憶體不足，可劃分磁碟為替代記憶體 sudo dd if=/dev/zero of=/swapfile bs=1M count=2000;sudo chmod 600 /swapfile;sudo mkswap /swapfile;sudo swapon /swapfile;swapon -s;sudo vim /etc/fstab; 加入以下 code/swapfile swap swap defaults 0 0 更改 Apache 的預設讀取資料夾位置sudo vim /etc/httpd/conf/httpd.conf &lt;Direction \"/var/www/html\"&gt; Allow Override All&lt;/Direction&gt; 重啟 Apachesudo service httpd restart 規格 GCP- CentOS 7 LAMPPHP 更新鏡像站 yum install epel-release;rpm -Uvh http://rpms.famillecollet.com/enterprise/remi-release-7.rpm 安裝 PHP sudo apt-get install php72;php -v 安裝 PHP Extension sudo apt-get install php7.2-mbstring sudo apt-get install php7.2-bcmath sudo apt-get install php7.2-mysqlnd sudo apt-get install php7.2-gd sudo apt-get install php-simplexml sudo apt-get install php7.2-zip sudo apt-get install php7.2-curl sudo apt install zip;sudo apt install unzip Apache 安裝 Apache sudo apt install apache2 啟動 Apache sudo service apache2 start 設定開機自動重啟 Apache sudo systemctl enable apache2 確認 Apache 已啟用 sudo systemctl is-enabled apache2 設定 AWS security inbound 測試 Apache 運作，拜訪 IP 啟動 SSL module sudo a2enmod ssl;sudo service apache2 restart MySQL 安裝 MySQL sudo apt install mysql-server 啟動 MySQL sudo systemctl start mysql 設定 MySQL 於 Reboot 時自動重啟 sudo systemctl is-enabled mysql 執行 mysql_secure_installation sudo mysql_secure_installation 設定MySQL支援Sequel Pro 遠端連接 CREATE USER 'root'@'%' IDENTIFIED BY 'yourPassword';GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' WITH GRANT OPTION;FLUSH PRIVILEGES; GCP 要特別開權限 LOCAL_IP=$(curl http://metadata.google.internal/computeMetadata/v1/instance/network-interfaces/0/ip \\ -H \"Metadata-Flavor: Google\")sudo sed -i \"s|bind-address.*|bind-address = $LOCAL_IP|\" /etc/mysql/mysql.conf.d/mysqld.cnf 更多設定可參考官方文件 設定檔案許可 將您的使用者 (在此案例中為 ec2-user) 新增至 apache 群組 sudo usermod -a -G www-data yourUserName 登出並重新登入，以取得新的群組並驗證您的成員資格。 登出 (使用 exit 命令或關閉終端機視窗)： exit 若要在 apache 群組中驗證您的會員資格，請重新連線至您的執行個體，然後執行下列命令： groups 將 /var/www 的群組所有權及其內容變更為 apache 群組。 sudo chown -R yourUserName:www-data /var/www 若要新增群組寫入許可並在將來的子目錄上設定群組 ID，請變更 /var/www 及其子目錄的目錄許可。 sudo chmod 2775 /var/wwwfind /var/www -type d -exec sudo chmod 2775 &#123;&#125; \\; 若要新增群組寫入許可，請以遞迴方式變更 /var/www 及其子目錄的檔案許可： find /var/www -type f -exec sudo chmod 0664 &#123;&#125; \\; 測試您的 LAMP Web 伺服器 在 Apache 文件根資料夾中建立 PHP 檔案。 echo \"&lt;?php phpinfo(); ?&gt;\" &gt; /var/www/html/phpinfo.php 在 Web 瀏覽器中，輸入您剛才建立的檔案 URL。此 URL 為您執行個體的公有 DNS 地址，其後跟隨斜線和檔案名稱。例如： http://my.public.dns.amazonaws.com/phpinfo.php 刪除 phpinfo.php 檔案。雖然這可能是有用的資訊，但基於安全因素，您不應將其廣播至網際網路。rm /var/www/html/phpinfo.php Composer 安裝 Composer php -r \"copy('https://getcomposer.org/installer', 'composer-setup.php');\"php -r \"if (hash_file('sha384', 'composer-setup.php') === '48e3236262b34d30969dca3c37281b3b4bbe3221bda826ac6a9a62d6444cdb0dcd0615698a5cbe587c3f0fe57a54d8f5') &#123; echo 'Installer verified'; &#125; else &#123; echo 'Installer corrupt'; unlink('composer-setup.php'); &#125; echo PHP_EOL;\"php composer-setup.phpphp -r \"unlink('composer-setup.php');\" 讓 Composer 可被 Global 使用 sudo mv composer.phar /usr/local/bin/composer Git 安裝 Gitsudo apt install -y git 部署專案 Clone 專案 git clone repositoryAddress 部署 .env 檔 cp .env.example .env 安裝 Composer composer install 產生 key php artisan key:generate 確認 MySQL root 登入方式 SELECT user, plugin, host FROM mysql.user; 更改登入 root 的方式 ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'yourPassword';FLUSH PRIVILEGES 建立資料庫 mysql -urootcreate database databaseName; 建立表格 php artisan migrate 若記憶體不足，可劃分磁碟為替代記憶體 sudo dd if=/dev/zero of=/swapfile bs=1M count=2000;sudo chmod 600 /swapfile;sudo mkswap /swapfile;sudo swapon /swapfile;swapon -s;sudo vim /etc/fstab; 加入以下 code/swapfile swap swap defaults 0 0 更改 Apache 的預設讀取資料夾位置sudo vim /etc/httpd/conf/httpd.conf &lt;Direction \"/var/www/html\"&gt; Allow Override All&lt;/Direction&gt; 以上為正規流程，以下為懶人版 懶人版sudo yum install -y php72;sudo yum install -y php72-mbstring;sudo yum install -y php72-bcmath;sudo yum install -y php72-pdo;sudo yum install -y php72-mysqlnd;sudo yum install -y httpd24;sudo yum install php72-gd.x86_64sudo service httpd start;sudo chkconfig httpd on;sudo yum install -y mod24_ssl;sudo yum install -y mysql57-server;sudo service mysqld start;sudo chkconfig mysqld on;sudo usermod -a -G apache ec2-user;sudo chown -R ec2-user:apache /var/www;sudo chmod 2775 /var/wwwfind /var/www -type d -exec sudo chmod 2775 &#123;&#125; \\;find /var/www -type f -exec sudo chmod 0664 &#123;&#125; \\;php -r \"copy('https://getcomposer.org/installer', 'composer-setup.php');\"php -r \"if (hash_file('sha384', 'composer-setup.php') === '48e3236262b34d30969dca3c37281b3b4bbe3221bda826ac6a9a62d6444cdb0dcd0615698a5cbe587c3f0fe57a54d8f5') &#123; echo 'Installer verified'; &#125; else &#123; echo 'Installer corrupt'; unlink('composer-setup.php'); &#125; echo PHP_EOL;\"php composer-setup.php;php -r \"unlink('composer-setup.php');\";sudo mv composer.phar /usr/local/bin/composer;sudo yum install -y git;sudo php -v 設定 AWS security inbound 測試 Apache 運作，拜訪 IP 執行 mysql_secure_installation sudo mysql_secure_installation 設定MySQL支援Sequel Pro 遠端連接 CREATE USER 'root'@'%' IDENTIFIED BY '';GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' WITH GRANT OPTION;FLUSH PRIVILEGES; 登出並重新登入，以取得新的群組並驗證您的成員資格。 登出 (使用 exit 命令或關閉終端機視窗)： exit 若要在 apache 群組中驗證您的會員資格，請重新連線至您的執行個體，然後執行下列命令： groups 在 Apache 文件根資料夾中建立 PHP 檔案。 echo \"&lt;?php phpinfo(); ?&gt;\" &gt; /var/www/html/phpinfo.php 在 Web 瀏覽器中，輸入您剛才建立的檔案 URL。此 URL 為您執行個體的公有 DNS 地址，其後跟隨斜線和檔案名稱。例如： http://my.public.dns.amazonaws.com/phpinfo.php 刪除 phpinfo.php 檔案。雖然這可能是有用的資訊，但基於安全因素，您不應將其廣播至網際網路。 rm /var/www/html/phpinfo.php Clone 專案 git clone repositoryAddress 部署 .env 檔 cp .env.example .env 安裝 Composer composer install 產生 key php artisan key:generate 建立資料庫 mysql -urootcreate database databaseName; 建立表格 php artisan migrate 若記憶體不足，可劃分磁碟為替代記憶體 sudo dd if=/dev/zero of=/swapfile bs=1M count=2000;sudo chmod 600 /swapfile;sudo mkswap /swapfile;sudo swapon /swapfile;swapon -s;sudo vim /etc/fstab; 加入以下 code/swapfile swap swap defaults 0 0 更改 Apache 的預設讀取資料夾位置sudo vim /etc/httpd/conf/httpd.conf &lt;Direction \"/var/www/html\"&gt; Allow Override All&lt;/Direction&gt; 重啟 Apachesudo service httpd restart 確認 OS 種類以及版本 使用 lsb_release ， 如果沒安裝的話，安裝它 sudo apt-get install lsb-release 查詢用法 lsb_release --help 輸出如下：-h, --help show this help message and exit-v, --version show LSB modules this system supports-i, --id show distributor ID-d, --description show description of this distribution-r, --release show release number of this distribution-c, --codename show code name of this distribution-a, --all show all of the above information-s, --short show requested information in short format 根據上面的資訊，想查詢明細的話 lsb_release -a 只想知道 Kernel 版本的話 uname -r","link":"/zh-tw/AWSLaravelDeployment/"},{"title":"Laravel串接歐付寶第三方金流支付","text":"建立Laravel專案Laravel new AllPay 一開始先Git，這幾乎是一定要的啊！git init 下載歐付寶SDK，本篇使用PHP SDKgit clone https://github.com/o-pay/Payment_PHP 將SDK移到Laravel裡頭的app底下 cp Payment_PHP/sdk/AllPay.Payment.Integration.php AllPay/app/ 建立等等測試用的Controllerphp artisan make:controller PaymentsController 從剛剛的SDK包裡面，複製example到我們的controller裡，本篇使用All的example，如下：/****/ //載入SDK(路徑可依系統規劃自行調整) include('AllPay.Payment.Integration.php'); try &#123; $obj = new AllInOne(); //服務參數 $obj-&gt;ServiceURL = \"https://payment-stage.opay.tw/Cashier/AioCheckOut/V5\"; //服務位置 $obj-&gt;HashKey = '5294y06JbISpM5x9' ; //測試用Hashkey，請自行帶入AllPay提供的HashKey $obj-&gt;HashIV = 'v77hoKGq4kWxNNIS' ; //測試用HashIV，請自行帶入AllPay提供的HashIV $obj-&gt;MerchantID = '2000132'; //測試用MerchantID，請自行帶入AllPay提供的MerchantID $obj-&gt;EncryptType = EncryptType::ENC_SHA256; //CheckMacValue加密類型，請固定填入1，使用SHA256加密 //基本參數(請依系統規劃自行調整) $MerchantTradeNo = \"Test\".time(); $obj-&gt;Send['ReturnURL'] = 'http://localhost/simple_ServerReplyPaymentStatus.php' ; //付款完成通知回傳的網址 $obj-&gt;Send['ReturnURL'] = 'http://gw.grazia.tw/sdk/op_sdk/op_payment/example/simple_ServerReplyPaymentStatus.php' ; //付款完成通知回傳的網址 $obj-&gt;Send['MerchantTradeNo'] = $MerchantTradeNo; //訂單編號 $obj-&gt;Send['MerchantTradeDate'] = date('Y/m/d H:i:s'); //交易時間 $obj-&gt;Send['TotalAmount'] = 2000; //交易金額 $obj-&gt;Send['TradeDesc'] = \"good to drink\"; //交易描述 $obj-&gt;Send['ChoosePayment'] = PaymentMethod::ALL; //付款方式:全功能 //訂單的商品資料 array_push($obj-&gt;Send['Items'], array('Name' =&gt; \"歐付寶黑芝麻豆漿\", 'Price' =&gt; (int)\"2000\", 'Currency' =&gt; \"元\", 'Quantity' =&gt; (int) \"1\", 'URL' =&gt; \"dedwed\")); # 電子發票參數 /* $obj-&gt;Send['InvoiceMark'] = InvoiceState::Yes; $obj-&gt;SendExtend['RelateNumber'] = $MerchantTradeNo; $obj-&gt;SendExtend['CustomerEmail'] = 'test@opay.tw'; $obj-&gt;SendExtend['CustomerPhone'] = '0911222333'; $obj-&gt;SendExtend['TaxType'] = TaxType::Dutiable; $obj-&gt;SendExtend['CustomerAddr'] = '台北市南港區三重路19-2號5樓D棟'; $obj-&gt;SendExtend['InvoiceItems'] = array(); // 將商品加入電子發票商品列表陣列 foreach ($obj-&gt;Send['Items'] as $info) &#123; array_push($obj-&gt;SendExtend['InvoiceItems'],array('Name' =&gt; $info['Name'],'Count' =&gt; $info['Quantity'],'Word' =&gt; '個','Price' =&gt; $info['Price'],'TaxType' =&gt; TaxType::Dutiable)); &#125; $obj-&gt;SendExtend['InvoiceRemark'] = '測試發票備註'; $obj-&gt;SendExtend['DelayDay'] = '0'; $obj-&gt;SendExtend['InvType'] = InvType::General; */ //產生訂單(auto submit至AllPay) $obj-&gt;CheckOut(); &#125; catch (Exception $e) &#123; echo $e-&gt;getMessage(); &#125; 我們將上面一些機敏資訊，移到Laravel的.env檔裡面，如下://服務位置$obj-&gt;HashKey = env('HASHKEY'); //測試用Hashkey，請自行帶入AllPay提供的HashKey$obj-&gt;HashIV = env('HASHIV'); //測試用HashIV，請自行帶入AllPay提供的HashIV$obj-&gt;MerchantID = env('MERCHANTID'); //測試用MerchantID，請自行帶入AllPay提供的MerchantID$obj-&gt;Send['ReturnURL'] = env('ALLPAYRETURNURL');//付款完成通知回傳的網址$obj-&gt;Send['ClientBackURL'] = $request-&gt;ClintBackURL;//付款完成後，於第三方頁面顯示回到我們服務的網址 .env檔內如下：ALLPAYRETURNURL=https://163be100.ngrok.io/api/paymentsResponseHASHKEY=5294y06JbISpM5x9HASHIV=v77hoKGq4kWxNNISMERCHANTID=2000132 使用use代替include 刪除 //載入SDK(路徑可依系統規劃自行調整)include('AllPay.Payment.Integration.php'); 新增AllPay.Payment.Integration.php到composer.json file \"autoload-dev\": &#123; \"psr-4\": &#123; \"Tests\\\\\": \"tests/\" &#125;, \"files\": [ \"app/Helpers.php\", \"app/AllPay.Payment.Integration.php\" ] 在terminal下達 composer dump-autoload` 在controller檔案裡，use新的class namespace App\\Http\\Controllers;use AllInOne;use EncryptType;use Exception;use Illuminate\\Http\\Request;use PaymentMethod; 建立金流訂單 (這部分屬個人表格設計，帶入參數每個人都不同)因為會一次性的寫入兩張表格，所以這邊會使用 Laravel 的 transaction 來寫入資料//總金額$totalAmount = Order::getTotalAmountForPayments($orders);//商品訂單編號$ordersName = Order::getOrdersNameForPayments($orders);//金流訂單編號$MerchantTradeNo = time() . Helpers::createAUniqueNumber();//金流訂單建立時間$MerchantTradeDate = date(&apos;Y/m/d H:i:s&apos;);//金流訂單敘述$TradeDesc = &apos;BuyBuyGo&apos;;//數量$quantity = 1;//因為同時建立兩張表格，這邊使用Laravel的transaction功能來防止資料庫資料不一//transaction開始DB::beginTransaction();//以下動作需全部完成無錯誤，否則終止並回朔try&#123; $payment_service_order = new PaymentServiceOrders(); $payment_service_order-&gt;user_id = User::getUserID($request); //金流服務商ID $payment_service_order-&gt;payment_service_id = $thirdPartyPaymentService-&gt;id; $payment_service_order-&gt;expiry_time = (new Carbon())-&gt;now()-&gt;addDay(1)-&gt;toDateTimeString(); $payment_service_order-&gt;MerchantID = env(&apos;MERCHANTID&apos;); $payment_service_order-&gt;MerchantTradeNo = $MerchantTradeNo; $payment_service_order-&gt;MerchantTradeDate = $MerchantTradeDate; $payment_service_order-&gt;TotalAmount = $totalAmount; $payment_service_order-&gt;TradeDesc = $TradeDesc; //商品訂單的編號 $payment_service_order-&gt;ItemName = $ordersName; $payment_service_order-&gt;save(); foreach ($orders as $order) &#123; $order_relations = new OrderRelations(); $order_relations-&gt;payment_service_id = $thirdPartyPaymentService-&gt;id; $order_relations-&gt;payment_service_order_id = $payment_service_order-&gt;id; $order_relations-&gt;order_id = $order-&gt;id; $order_relations-&gt;save(); &#125; //若有錯誤，則停止並回朔，回報自訂錯誤訊息&#125; catch (Exception $e)&#123; DB::rollBack(); return Helpers::result(&apos;false&apos;, &apos;Something went wrong with DB&apos;, 400);&#125;//若無錯誤，則寫入資料庫DB::commit(); 為PaymentsController建立一支API 到routes資料夾底下的api.php 增加routeRoute::post(&apos;pay&apos;, &apos;PaymentsController@pay&apos;); 建立一頁最簡單的的html 直接更改Laravel內建welcome.blade的內容，如下：&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Facebook Login JavaScript Example&lt;/title&gt; &lt;meta charset=&quot;UTF-8&quot;&gt;&lt;/head&gt;&lt;body&gt;// 這邊需輸入PaymentsController的API&lt;form action=&quot;/api/pay&quot; method=&quot;POST&quot;&gt; @csrf() &lt;input type=&quot;checkbox&quot; value=&quot;1&quot; name=&quot;order_id[]&quot;&gt; &lt;input type=&quot;checkbox&quot; value=&quot;2&quot; name=&quot;order_id[]&quot;&gt; &lt;input type=&quot;checkbox&quot; value=&quot;3&quot; name=&quot;order_id[]&quot;&gt; &lt;input type=&quot;hidden&quot; value=&quot;https://64b30ea0.ngrok.io/&quot; name=&quot;ClintBackURL&quot;&gt; &lt;button type=&quot;submit&quot;&gt;Submit&lt;/button&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 簡單傳送測試 到Laravel首頁，此時此頁面應已經變更為我們剛剛建立的簡單form頁面 什麼都不要勾選，點選submit 成功到了歐付寶的付款頁面 建立Log 為了要知道當我們成功付款之後，歐付寶會回傳什麼給我們，我們需要用Log來看看回傳的東西 有沒有一個地方，是所有的請求跟回饋都一定會進出通過，而且可以讓我們控制的？ 這似乎是個完美記log的地方 我們可以建立一個middleware，然後在middleware裏頭使用Laravel的Log功能，將所有進來的請求跟我們回饋的東西全都記下來 建立middleware 於terminal頁面php artisan make:middleware TestLog 註冊middleware 到/app/Http/Kernel.php檔案裡頭，加上我們剛剛建立的middleware protected $middleware = [ \\App\\Http\\Middleware\\CheckForMaintenanceMode::class, \\Illuminate\\Foundation\\Http\\Middleware\\ValidatePostSize::class, \\App\\Http\\Middleware\\TrimStrings::class, \\Illuminate\\Foundation\\Http\\Middleware\\ConvertEmptyStringsToNull::class, \\App\\Http\\Middleware\\TrustProxies::class, \\App\\Http\\Middleware\\TestLog::class,]; 建立Log 到我們剛剛建立的TestLog檔案裡頭，新增： $response = $next($request);log::info([$request-&gt;header(),$request-&gt;getMethod(),$request-&gt;getRequestUri(),$request-&gt;all(),$response-&gt;getStatusCode(),$response-&gt;getContent()]);return $response; 實際上，Log要記些什麼視乎每個人的需求 建立public url 我們要取得第三方回傳的資訊，所以我們必須要有一個public url來接收第三方的response 我們可以使用ngrok來取得public url 至ngrok官網安裝ngrok 將ngrok變更為可全域執行 mv ngrok /usr/local/bin 先取得public url，在terminal中 ngrok http 8000 在terminal中，位於AllPay專案資料夾內，開啟本機通道 php artisan serve 8000` 複製ngrok產生的public https url 建立接收的function 我們準備要來接歐付寶回傳的訊息了，我們需要建立一個function，並且接到之後，可以在裡面做我們想做的事 在PaymentsController裡頭，我們先建一個function receive，如下：public function receive()&#123; &#125; 針對此function，建立一個API Route::post(&apos;pay&apos;, &apos;PaymentsController@pay&apos;);Route::post(&apos;receive&apos;, &apos;PaymentsController@receive&apos;); 設定ReturnURL 於.env檔內，如有照之前步驟，應有以下參數，將複製的public url 貼上 ALLPAYRETURNURL=https://163be100.ngrok.io/api/recevie 你的連結跟我的不一樣哦，別貼我的 付款測試 再次連到歐付寶付款頁面 登入歐付寶提供的買家測試帳號 帳號： stageuser001 密碼： test1234 使用歐付寶提供的測試信用卡付款 卡號： 4311-9522-2222-2222 有效期限：請大於目前月/年，例：12 / 20 末三碼：222 付款後，我們到log去看一下有沒有收到歐付寶的回饋，於terminal，位於AllPay的資料夾內 cat storage/logs/laravel-2019-02-08.log` 咦，有收到歐付寶的回饋了！ &apos;MerchantID&apos; =&gt; &apos;2000132&apos;, &apos;MerchantTradeNo&apos; =&gt; &apos;Test1549597724&apos;, &apos;PayAmt&apos; =&gt; &apos;2000&apos;, &apos;PaymentDate&apos; =&gt; &apos;2019/02/08 11:49:03&apos;, &apos;PaymentType&apos; =&gt; &apos;Credit_CreditCard&apos;, &apos;PaymentTypeChargeFee&apos; =&gt; &apos;20&apos;, &apos;RedeemAmt&apos; =&gt; &apos;0&apos;, &apos;RtnCode&apos; =&gt; &apos;1&apos;, &apos;RtnMsg&apos; =&gt; &apos;交易成功&apos;, &apos;SimulatePaid&apos; =&gt; &apos;0&apos;, &apos;TradeAmt&apos; =&gt; &apos;2000&apos;, &apos;TradeDate&apos; =&gt; &apos;2019/02/08 11:48:44&apos;, &apos;TradeNo&apos; =&gt; &apos;1902081148440800&apos;, &apos;CheckMacValue&apos; =&gt; &apos;5B1EE24B0E9D600C65578DD82D3168E2ED56799453577E17E1EBEFC536BD7EAF&apos;, 驗證 試想，如果有人不小心知道了你的API，然後對方也是開發者，他如果跑到你的服務購買商品，然後呼叫你的API結帳，你如何辨別？ 所以說，第三方跟廠商會有一套只有雙方身份對了，驗證才能通過的機制 驗證機制大概就是，所以你傳出去的資料，每一項欄位，會經過一套只有雙方適用的公式下去計算，最後會得出一串CheckMacValue，眼尖的朋友應該已經看到，在我們收到的訊息最下面一個欄位帶的就是這串資料。 詳細的公式各位朋友可參照官方網站。 由於本篇使用官方的SDK，所以本篇將教大家如何使用官方SDK來驗證收到的資訊 首先，我們到官方SDK的檔案中app/AllPay.Payment.Integration.php，搜尋名為CheckMacValue的class CheckMacValue class裡頭，有一個名為generate的function，大家可以看一下它是怎麼寫的，這就是產生這串CheckMacValue的公式。 所以說，我們只要通過這套公式，驗證我們收到的訊息之中，除了CheckMacValue這個欄位的資訊，那理應得到跟回傳的CheckMacValue一模一樣的值 先取得回傳資訊中，除了CheckMacValue之外的所有資訊，我們可以使用以下的code $parameters = $paymentResponse-&gt;except(&apos;CheckMacValue&apos;); 再來，取得歐付寶回傳的CheckMacValue $receivedCheckMacValue = $paymentResponse-&gt;CheckMacValue; 接下來，使用官方的generate function，帶入我們收到的資訊，來產出正確的CheckMacValue $calculatedCheckMacValue = CheckMacValue::generate($parameters, env(&apos;HASHKEY&apos;), env(&apos;HASHIV&apos;), EncryptType::ENC_SHA256); 最後，比較兩者的值是否一樣？如果一樣，表示這則訊息的確來自歐付寶，如果不同，那此資訊沒有可信度 if($receivedCheckMacValue == $calculatedCheckMacValue) return true;return false; 驗證之後呢？ 確認資訊來源正確之後，我們就可以依據收到的資訊下去做事了！ 比方說，付款了做些什麼，付款失敗又做些什麼 本篇範例為收到付款之後，將資料庫內訂單標記付款，並發email通知買家，如下： if (PaymentServiceOrders::checkIfCheckMacValueCorrect($request) &amp;&amp; PaymentServiceOrders::checkIfPaymentPaid($request-&gt;RtnCode))&#123; $paymentServiceOrder = (new PaymentServiceOrders)-&gt;where(&apos;MerchantTradeNo&apos;, $request-&gt;MerchantTradeNo)-&gt;first(); $paymentServiceOrder-&gt;update([&apos;status&apos; =&gt; 1, &apos;expiry_time&apos; =&gt; null]); $orderRelations = $paymentServiceOrder-&gt;where(&apos;MerchantTradeNo&apos;, $request-&gt;MerchantTradeNo)-&gt;first()-&gt;orderRelations; Order::updateStatus($orderRelations); $payerEmail = $paymentServiceOrder-&gt;user-&gt;email; if ($payerEmail !== null) Mail::to($payerEmail)-&gt;send(new PaymentReceived($paymentServiceOrder, $orderRelations)); return &apos;1|OK&apos;;&#125; 最後記得別忘記return ‘1|OK’, 通知歐付寶我們已經收到付款囉！ 一些沒說到的事 歐付寶測試帳號中，除了信用卡之外，也支援多種其他方式付款哦！可於登入買家測試帳號之後使用。 超商或轉帳付款方式，需特別登入歐付寶提供的後台測試帳號，方可達到模擬付款！ 帳號： StageTest 密碼： test1234 退款 退款範例如下： public static function refund($order, $paymentServiceInstance, $orderRelation)&#123; try &#123; $obj = new AllInOne(); $obj-&gt;ServiceURL = &quot;https://payment-stage.opay.tw/Cashier/AioChargeback&quot;; // 服務位置 $obj-&gt;HashKey = env(&apos;HASHKEY&apos;); // 測試用Hashkey，請自行帶入AllPay提供的HashKey $obj-&gt;HashIV = env(&apos;HASHIV&apos;); // 測試用HashIV，請自行帶入AllPay提供的HashIV $obj-&gt;MerchantID = env(&apos;MERCHANTID&apos;); // 測試用MerchantID，請自行帶入AllPay提供的MerchantID $obj-&gt;EncryptType = EncryptType::ENC_SHA256; // CheckMacValue加密類型，請固定填入1，使用SHA256加密 $obj-&gt;ChargeBack[&apos;MerchantTradeNo&apos;] = $paymentServiceInstance-&gt;MerchantTradeNo; // 當初訂單成立時，提供的訂單號碼 $obj-&gt;ChargeBack[&apos;TradeNo&apos;] = $paymentServiceInstance-&gt;TradeNo; // AllPay提供的訂單號碼 $obj-&gt;ChargeBack[&apos;ChargeBackTotalAmount&apos;] = $order-&gt;total_amount; // 退款金額 $obj-&gt;AioChargeback(); &#125; catch (Exception $e) &#123; // 若錯誤，return return Helpers::result(true, &apos;Something wrong happened&apos;, 200); // Debug模式，印出錯誤 echo $e-&gt;getMessage(); &#125;&#125; 帶入參數可參考官方文件，選項12，會員通知退款。","link":"/zh-tw/AllPayPaymentService/"},{"title":"讓我們開始Cloud Shell及gcloud吧！","text":"前言本篇主要是利用Google的Qwiklab平台學習的同時，做的一份學習筆記原文可參閱:官方連結 本篇將會做什麼？ 練習使用gcloud指令 連結到Google Cloud Platform的儲存裝置 設定及要求Qwiklabs setup在你按下 Start Lab 按鈕之前詳讀所有的教學。Labs 是有時間限制的，而且你不可以停止時間倒數。倒數計時器在你按下 Start Lab 按鈕後開始倒數，上面顯示的時間為你還能使用 Cloud 資源的時間。 Quiklabs 的手把手環境，讓你可以在真實環境中來操作進行 Quiclabs 上提供的課程，而不是在一個模擬或是展示的環境。我們透過提供你一個全新的、暫時的帳號密碼，在計時器歸零之前，你可以用來登入並存取 Google Cloud Platform。 你需要什麼？要完成這個 lab ，你需要: 一個一般的網路瀏覽器（推薦 Chrome） 完成這個 lab 的時間 備註： 如果你已經有你自己的個人 GCP 帳號或專案，請不要使用在這一個 lab Google Cloud Platform Console如何開始你的 lab ，然後登入 Console? 按下 Start Lab 按鈕。如果你需要付費，會有一個彈出視窗來讓你選擇付費的方式。在左方你會看到一個面板，上面有暫時的帳號密碼，你必須使用這些帳號密碼在此次 lab 複製 username , 然後點擊 Open Google Console。 Lab 會開啟另外一個視窗，顯示選擇帳號的頁面 tip: 開啟一個全新的視窗，然後跟原本的頁面並排 在選擇帳號頁面, 點擊 Use Another Account 登入頁面開啟，貼上之前複製的 username 以及 password ，然後貼上 重要：必須使用之前於 Connection Details 面板 取得的帳號密碼，不要使用你自己的 Qwiklabs 帳號密碼。 如果你有自己的 GCP 帳號，請不要用在這裡（避免產生費用） 點擊並通過接下來的頁面: 接受terms以及conditions 不要增加recovery optoins 或 two factor authentication (因為這只是一個臨時帳號) 不要註冊免費體驗 稍待一些時候， GCP 控制台將會在這個視窗開啟。 注意：按下左上方位於Google Cloud Platform 隔壁的 Navigation menu ，你可以瀏覽選單，裡面有一系列的 GCP 產品以及服務 Cloud Shell啟動 Google Cloud ShellGoogle Cloud Shell 是載有開發工具的虛擬機器。它提供了5GB的 home 資料夾，並且運行在 Google Cloud 上。 Google Cloud Shell 讓你可以利用 command-line 存取 GCP 資源 在 GCP 控制台 ，右上的工具列，點擊 Open Cloud Shell 按鈕 在打開的對話框裡，按下 START CLOUD SHELL: 你可以立即按下 START CLOUD SHELL 當對話視窗打開。 連結並提供環境會需要一點時間。當你連結成功，這代表你已成功獲得授權，且此專案已被設為你的專案ID，例如： gcloud 是 Google Cloud Platform 的 command-line 工具，他已事先被安裝在 Cloud Shell 並且支援自動補齊 使用這個 command ,你可以列出有效帳戶名稱:gcloud auth list 輸出:Credentialed accounts: - &lt;myaccount&gt;@&lt;mydomain&gt;.com (active) 範例輸出:Credentialed accounts: - google1623327_student@qwiklabs.net 你可以使用以下 command 來列出專案 IDgcloud config list project 輸出：[core]project = &lt;project_ID&gt; 範例輸出：[core]project = qwiklabs-gcp-44776a13dea667a6 gcloud 的完整文件可以參閱 Google Cloud gcloud Overview 理解Regions 和 Zones 特定的Compute Engine 資源位於特定的regions或zones. Region表示一個特定的地理位置，而你的資源就跑在那邊。 每個region都有一個或多個zones，舉例來說，us-central1 region位於Central United States，並且下面有us-central1-a, us-central1-b, us-central1-c, us-central1-f這些zones 位於zone的資源算是zonal資源。 Virtual machine instance還有persistent disk都位於zone, 如果要在一個virtual machine上加一個persistent disk，那兩者必須位於同一個zone 相同的，如果你要分配一個static IP位址到一個instance，這個instance必須要跟這個static IP同一個region 使用終端機 點擊位於GCP主控台右上角的圖案來開始一個新的Cloud Shell視窗，如下圖： 在Cloud Shell成功開啟後，我們可以使用終端機來下達Cloud SDK gcloud，或任何其他vurtual machine instance有提供的指令。 我們也可以在不同的專案，或著Cloud Shell，把檔案儲存在persistent disk的HOME資料夾。 HOME資料夾只屬於你個人，任何其他USER將無法存取。 gcloud提供使用指南，只要在指令的後面加上-h，試試下面的指令: gcloud -h 或者，你也可以打長一點 gcloud config --help gcloud help config 使用你的Home資料夾現在，讓我們來試試Home資料夾。就算你結束或者重開你的virtual machine，Cloud Shell Home 資料夾內的內容也會繼續存在，不同的專案或者Cloud Shell都可以存取。 改變目前的工作資料夾 cd $HOME 使用vim打開.bashrc設定檔 vim .bashrc 使用gcloud指令 讓我們來檢視一下我們環境內的設定列表 gcloud config list 檢視其他的property是怎麼被設定的 gcloud config list --all 管理Cloud儲存資料 建立一個Cloud Storage bucket, bucket 的名字必須獨一無二，所以請給一個名稱來取代下面的unique-namegsutil mb gs://unique-name 現在，我們可以建立一些資料，並上傳的我們的bucket 建立一個test檔案 vim test.dat 加一些資料進去 welcome to gcloud! 存檔 :wq 現在，上傳一些檔案到我們建立的bucket，請使用我們之前給的名字來取代下面的unique-name gsutil cp test.dat gs://unique-name 如果想看一下我們建立的bucket，以及我們上傳的檔案，可以打開Navigation menu &gt; Storage &gt; Browser，然後點擊bucket，應該可以看到test.dat檔案，如下圖： 考考你！ Three basic ways to interact with the GCP services and resources: Command-line interface Client libraries GLib GStreamer GCP Console Which tool in cloud shell helps to manage Cloud Storage resources? gcloud gsutil compute bq","link":"/zh-tw/CloudShellAndgcloud/"},{"title":"gcloud shell","text":"前言本篇記錄 gcloud shell 用法 computeinstance 建立一台虛擬機 gcloud compute instances create example-instance-1 \\--image-project=ubuntu-os-cloud \\--image-family=ubuntu-1804-lts \\--boot-disk-size=10GB \\--boot-disk-type=pd-standard \\--machine-type=f1-micro \\--tags=example-instance-1,http-server,https-server \\--zone=asia-east1-c 由自己建立的 image 建一台 VM gcloud compute instances create example-instance-1 \\--image-project=yourProject \\--image=yourImage \\--boot-disk-size=10GB \\--boot-disk-type=pd-standard \\--machine-type=f1-micro \\--tags=example-instance-1,http-server,https-server \\--zone=asia-east1-c 停止 instance gcloud compute instances stop instanceName1 instanceName2 instanceName3 啟動 instance gcloud compute instances start instanceName1 instancesName2 instanceName3 刪除 instance gcloud compute instances delete instanceName 列出 instances 列表 gcloud compute instances list 列出特定 instance 細節資料 gcloud compute instances describe instanceName 查詢執行個體的 ssh 金鑰 gcloud compute instances describe instanceName | grep -A 5 ssh-keys 移除或新增執行個體 ssh 金鑰 gcloud compute instances add-metadata instanceName --metadata-from-file ssh-keys=fileName 指令如上，以下是 fileName 的格式[USERNAME_2]:ssh-rsa [EXISTING_KEY_VALUE_2] [USERNAME_2][USERNAME_3]:ssh-rsa [NEW_KEY_VALUE] [USERNAME_3] 為 instance 增加 tagsgcloud compute instances add-tags instanceName \\--tags tag1,tag2,tag3... firewall-rules 增加防火牆規則gcloud compute firewall-rules create firewallRuleName --allow tcp:50005,port2,port3 --target-tags targetTags 文件連結 images 查詢可用的 images 相關資訊 gcloud compute images list 從現有的 disk 創立 image gcloud compute images create shadowsocks \\--source-disk test-shadowsock \\--source-disk-zone asia-east1-a \\--family ubuntu-1804-lts project 查詢全專案公開 ssh 金鑰並且顯示 5 行資料 gcloud compute project-info describe | grep -A 5 ssh-keys 移除或新增全專案公開 ssh 金鑰 gcloud compute project-info add-metadata --metadata-from-file ssh-keys=fileName 指令如上，以下是 fileName 的格式[USERNAME_2]:ssh-rsa [EXISTING_KEY_VALUE_2] [USERNAME_2][USERNAME_3]:ssh-rsa [NEW_KEY_VALUE] [USERNAME_3] addresses 將現有 VM 使用的 IP 轉為靜態 gcloud compute addresses create addressName \\--addresses IP \\--region regionName 列出 IP gcloud compute addresses list 刪除 IP gcloud compute addresses delete ip1 ip2 ip3 regions 取得 regions 列表gcloud compute regions list backend-service 更新 draining-time-outgcloud compute backend-services update [BACKEND_SERVICE] \\ --connection-draining-timeout [CONNECTION_TIMEOUT_SECS] DNSrecord-sets顯示區域的當前 DNS 紀錄gcloud dns record-sets list --zone=\"myzonename\" 此指令會以含有前 100 筆記錄的資源記錄集，輸出 JSON 回應。您可以指定下列額外參數： limit：要列出的記錄集數目上限。 name：只列出含有這個確切網域名稱的記錄集。 type：只列出這個類型的記錄。如果有這類記錄，則必須同時使用 –name 參數。 新增 A record 開始 transaction gcloud dns record-sets transaction start --z zoneName 增加 A 紀錄 gcloud dns record-sets transaction add 'ip' --name 'domainName' --ttl 5 --type A --zone 'zoneName' 增加 cname 紀錄 gcloud dns record-sets transaction add -z=zoneName --type=CNAME --name=\"www.ray.com\" --ttl 5 \"ray.com.\" 增加 MX 紀錄 gcloud dns record-sets transaction add --z=zoneName --name=\"ray.com\" --ttl 5 --type MX \"10 mail1.ray.com.\" \"20 mail2.ray.com.\" 執行 gcloud dns record-sets transaction execute -z 'zoneName' managed-zones列出所有 zone 列表gcloud dns managed-zones list config切斷 projectgcloud config set projectID projects取得 project listgcloud projects list","link":"/zh-tw/GCP/"},{"title":"取得 Facebook 長期權杖 (long lived token)，以及 永不過期權杖 (never expired token)","text":"前言本篇將分享如何利用 Facebook 的圖形 API 測試工具，以及 PHP 來取得長期權杖 (long lived token)，以及永不過期權杖 (never expired token)目前正在做一個 Facebook 的直播拍賣優化系統的後端，發現前端的短期 (short lived token) 權杖有效時間只有不到兩個小時，相較於 Android 的三個月，以及 iOS 的兩個月，實在是有夠短。雖然說 code 寫好之後其實也無所謂，但是就想來研究一下如何拿到長期的權杖 (long lived token) Facebook 的圖形 API 測試工具長期權杖 (long lived token)首先，讓我們先用 Facebook 的圖形 API 來拿長期權杖 (long lived token) 測試帳號 取得測試測試帳號權杖 圖形 API 測試工具 輸入剛剛獲得的權杖 按下’提交’ 按下權杖左邊的驚嘆號，並選擇，以存取權杖工具開啟 點擊左下方的，延伸存取權杖 得到兩個月的長期權杖 (long lived token) 永不過期的粉絲專頁權杖接下來，讓我們使用 Facebook 的圖形 API 測試工具來取得永不過期的權杖 (never expired token) 首先，讓我們登入測試帳號，並申請一個粉絲團 跟上面的流程完全一模一樣，我們就可以拿到永不過期的權杖 (never expired token) PHP長期權杖 (long lived token)現在讓我們使用 PHP 來透過呼叫 Facebook 的 API 來取得長期權杖 (long lived token) 使用 PHP 的 function file_get_contents來呼叫 Facebook 的 API public static function getLongLivedToken($token)&#123; $url = 'https://graph.facebook.com/oauth/access_token?grant_type=fb_exchange_token&amp;client_id=yourClientID&amp;client_secret=yourClientSecret&amp;fb_exchange_token=shortLivedToken; return json_decode(file_get_contents($url), true);&#125; 會得到以下資訊: &#123; \"result\": true, \"response\": &#123; \"access_token\": \"EAAEpKfFACZA8BAGyTFU29VFIlEjhDaUe66eliyWdGQDfVTBUUdFZBZAGeZBEgTEwxgthvdABuzECYi1ahqm8ZCYNRSV9YMnegq7XxCouP1sR8kXMdnNFysGb2IHZBhSB3KENeTZCBzHrFSJ9BJLt9k6xkuWkJsVHnG0KahmFmybKTG6pVaFoZATN\", \"expires_in\": 5182393 &#125;&#125; 結語至於如何利用 PHP 來取得永不過期的粉絲專頁權杖 (never expired token)，似乎需要提升 APP 的權限，這方面需要審查，所以我就暫時無法測試啦。","link":"/zh-tw/FacebookLongLivedToken/"},{"title":"利用GCP Marketplace來提供服務","text":"前言本篇主要是利用Google的Qwiklab平台學習的同時，做的一份學習筆記 本篇將會做什麼？ 使用Marketplace來建立一套網路工具包 核對部署 設定及要求Qwiklabs setup在你按下 Start Lab 按鈕之前詳讀所有的教學。Labs 是有時間限制的，而且你不可以停止時間倒數。倒數計時器在你按下 Start Lab 按鈕後開始倒數，上面顯示的時間為你還能使用 Cloud 資源的時間。 Quiklabs 的手把手環境，讓你可以在真實環境中來操作進行 Quiclabs 上提供的課程，而不是在一個模擬或是展示的環境。我們透過提供你一個全新的、暫時的帳號密碼，在計時器歸零之前，你可以用來登入並存取 Google Cloud Platform。 你需要什麼？要完成這個 lab ，你需要: 一個一般的網路瀏覽器（推薦 Chrome） 完成這個 lab 的時間 備註： 如果你已經有你自己的個人 GCP 帳號或專案，請不要使用在這一個 lab Google Cloud Platform Console如何開始你的 lab ，然後登入 Console? 按下 Start Lab 按鈕。如果你需要付費，會有一個彈出視窗來讓你選擇付費的方式。在左方你會看到一個面板，上面有暫時的帳號密碼，你必須使用這些帳號密碼在此次 lab 複製 username , 然後點擊 Open Google Console。 Lab 會開啟另外一個視窗，顯示選擇帳號的頁面 tip: 開啟一個全新的視窗，然後跟原本的頁面並排 在選擇帳號頁面, 點擊 Use Another Account 登入頁面開啟，貼上之前複製的 username 以及 password ，然後貼上 重要：必須使用之前於 Connection Details 面板 取得的帳號密碼，不要使用你自己的 Qwiklabs 帳號密碼。 如果你有自己的 GCP 帳號，請不要用在這裡（避免產生費用） 點擊並通過接下來的頁面: 接受terms以及conditions 不要增加recovery optoins 或 two factor authentication (因為這只是一個臨時帳號) 不要註冊免費體驗 稍待一些時候， GCP 控制台將會在這個視窗開啟。 注意：按下左上方位於Google Cloud Platform 隔壁的 Navigation menu ，你可以瀏覽選單，裡面有一系列的 GCP 產品以及服務 Cloud Shell啟動 Google Cloud ShellGoogle Cloud Shell 是載有開發工具的虛擬機器。它提供了5GB的 home 資料夾，並且運行在 Google Cloud 上。 Google Cloud Shell 讓你可以利用 command-line 存取 GCP 資源 在 GCP 控制台 ，右上的工具列，點擊 Open Cloud Shell 按鈕 在打開的對話框裡，按下 START CLOUD SHELL: 你可以立即按下 START CLOUD SHELL 當對話視窗打開。 連結並提供環境會需要一點時間。當你連結成功，這代表你已成功獲得授權，且此專案已被設為你的專案ID，例如： gcloud 是 Google Cloud Platform 的 command-line 工具，他已事先被安裝在 Cloud Shell 並且支援自動補齊 使用這個 command ,你可以列出有效帳戶名稱:gcloud auth list 輸出:Credentialed accounts: - &lt;myaccount&gt;@&lt;mydomain&gt;.com (active) 範例輸出:Credentialed accounts: - google1623327_student@qwiklabs.net 你可以使用以下 command 來列出專案 IDgcloud config list project 輸出：[core]project = &lt;project_ID&gt; 範例輸出：[core]project = qwiklabs-gcp-44776a13dea667a6 gcloud 的完整文件可以參閱 Google Cloud gcloud Overview 導覽到Marketplace 在Google Cloud Console，找到Marketplace如下： 然後應該可以看到Marketplace首頁 選擇Nginx 在搜尋欄輸入Nginx, 然後選擇Nginx Certified by Bitnami的版本 建立Nginx 工具組VM instance 設定一旦專案建立了，我們將會被帶到位於Cloud主控台，新的Nginx部署頁面來設定我們的Nginx instance 為instance取名，例如，nginxstack-1 選擇zone 以下保持預設值 Machine type: micro(1-shared vCPU)0.6GB memory Boot Disk: 10 GB SSD “Allow HTTP Traffic” 以及 “Allow HTTPS Traffic” 需要被勾選 請接受GCP Marketplace Terms of Service，在頁面的下方 點擊Deploy來建立我們的Nginx 工具組 核對部署 當Cloud主控台回報，我們的Nginx套組已經部署完畢，我們可以核實一下，是否所有東西都正常運行，我們的畫面看起來應該如下圖： 核對網頁 點擊上圖的藍色按鈕Visit the site，我們可以存取部署好的Nginx套組，看起來如下圖： 核對SSH 我們也可以點擊SSH連結來打開一個新的VM instance視窗。我們可以使用Unix指令，像是ps來看看Nginx是否正常的運行在我們的instanceps aux | grep nginx 考考你！！ Does Google Cloud Platform Marketplace allow you to deply a software package now, and scale that deployment later when your application require additional capacity without updating the software that you have already deployed true false","link":"/zh-tw/GCPMarketplace/"},{"title":"設定 Network 以及 HTTP 平衡負載器","text":"前言本篇主要是利用 Google 的 Qwiklab 平台學習的同時，做的一份學習筆記 本篇將會做什麼？ 設定一個網路平衡負載器 設定一個 HTTP(S) 平衡負載器 通過實作，學習兩者之間的不同之處 設定及要求需熟悉 Linux 內建的編輯器，像是 vim , emacs, 或是nanoQwiklabs setup在你按下 Start Lab 按鈕之前詳讀所有的教學。Labs 是有時間限制的，而且你不可以停止時間倒數。倒數計時器在你按下 Start Lab 按鈕後開始倒數，上面顯示的時間為你還能使用 Cloud 資源的時間。 Quiklabs 的手把手環境，讓你可以在真實環境中來操作進行 Quiclabs 上提供的課程，而不是在一個模擬或是展示的環境。我們透過提供你一個全新的、暫時的帳號密碼，在計時器歸零之前，你可以用來登入並存取 Google Cloud Platform。 你需要什麼？要完成這個 lab ，你需要: 一個一般的網路瀏覽器（推薦 Chrome） 完成這個 lab 的時間 備註： 如果你已經有你自己的個人 GCP 帳號或專案，請不要使用在這一個 lab Google Cloud Platform Console如何開始你的 lab ，然後登入 Console? 按下 Start Lab 按鈕。如果你需要付費，會有一個彈出視窗來讓你選擇付費的方式。在左方你會看到一個面板，上面有暫時的帳號密碼，你必須使用這些帳號密碼在此次 lab 複製 username , 然後點擊 Open Google Console。 Lab 會開啟另外一個視窗，顯示選擇帳號的頁面 tip: 開啟一個全新的視窗，然後跟原本的頁面並排 在選擇帳號頁面, 點擊 Use Another Account 登入頁面開啟，貼上之前複製的 username 以及 password ，然後貼上 重要：必須使用之前於 Connection Details 面板 取得的帳號密碼，不要使用你自己的 Qwiklabs 帳號密碼。 如果你有自己的 GCP 帳號，請不要用在這裡（避免產生費用） 點擊並通過接下來的頁面: 接受terms以及conditions 不要增加recovery optoins 或 two factor authentication (因為這只是一個臨時帳號) 不要註冊免費體驗 稍待一些時候， GCP 控制台將會在這個視窗開啟。 注意：按下左上方位於Google Cloud Platform 隔壁的 Navigation menu ，你可以瀏覽選單，裡面有一系列的 GCP 產品以及服務 Cloud Shell啟動 Google Cloud ShellGoogle Cloud Shell 是載有開發工具的虛擬機器。它提供了5GB的 home 資料夾，並且運行在 Google Cloud 上。 Google Cloud Shell 讓你可以利用 command-line 存取 GCP 資源 在 GCP 控制台 ，右上的工具列，點擊 Open Cloud Shell 按鈕 在打開的對話框裡，按下 START CLOUD SHELL: 你可以立即按下 START CLOUD SHELL 當對話視窗打開。 連結並提供環境會需要一點時間。當你連結成功，這代表你已成功獲得授權，且此專案已被設為你的專案ID，例如： gcloud 是 Google Cloud Platform 的 command-line 工具，他已事先被安裝在 Cloud Shell 並且支援自動補齊 使用這個 command ,你可以列出有效帳戶名稱:gcloud auth list 輸出:Credentialed accounts: - &lt;myaccount&gt;@&lt;mydomain&gt;.com (active) 範例輸出:Credentialed accounts: - google1623327_student@qwiklabs.net 你可以使用以下 command 來列出專案 IDgcloud config list project 輸出：[core]project = &lt;project_ID&gt; 範例輸出：[core]project = qwiklabs-gcp-44776a13dea667a6 gcloud 的完整文件可以參閱 Google Cloud gcloud Overview 為你的資源設定預設的 region 以及 zone 在 Cloud Shell ，設定預設 zone gcloud config set compute/zone us-central1-a 在 Cloud Shell ，設定預設 region gcloud config set compute/region us-central1 建立多個 web server instance為了模擬使用一個群組的機器來服務，我們可以利用 Instance Template 以及 Managed Instance Groups 來創建一個群集的 Nginx web servers 用以服務靜態的內容。 Instance Template 定義了在這個群組中的 virtual machine 的規格（ disk, CPUs, memory, 等等）。 Managed Instance Groups 可以初始化多台使用 Instance Template 定義的 virtual machine 要建立一個 Nginx web server 服務群，建立以下事物: 一份用來設定所有 virtual machine 上的 Nginx server 的 script 一份 instance template 來使用上述的 script 一個 target pool 一個使用 instance template 的 managed instance group 以下開始建立上述事物: 建立 startup script cat &lt;&lt; EOF &gt; startup.sh#! /bin/bashapt-get updateapt-get install -y nginxservice nginx startsed -i -- 's/nginx/Google Cloud Platform - '\"\\$HOSTNAME\"'/' /var/www/html/index.nginx-debian.htmlEOF 建立使用 startup script 的 instance template gcloud compute instance-templates create nginx-template \\ --metadata-from-file startup-script=startup.sh 建立 target pool 。一個 target pool 將針對所有的群組內的 instance 提供一個存取點，且在之後的平衡負載步驟，這是必須的。 gcloud compute target-pools create nginx-pool 建立一個使用 instance template 的 managed instance group gcloud compute instance-groups managed create nginx-group \\ --base-instance-name nginx \\ --size 2 \\ --template nginx-template \\ --target-pool nginx-pool 這將會建立兩個擁有相同前綴名稱 nginx-的vurtual machine ，需要幾分鐘。 檢視所有已建立的 instances gcloud compute instances list 現在設定防火牆，所以我們可以經由 port 80，EXTERNAL_IP 位址來連接我們的機器 gcloud compute firewall-rules create www-firewall --allow tcp:80 現在我們應該要可以經由上述的 external IP 位址連接到任何一台的 instance 建立Network Load BalancerNetwork Load Balancing 允許我們依據收到的 IP 協議資料，像是位址， port 號，還有協議類型，來平衡負載我們的系統。我們還可以取得一些 HTTP(S) load balancing 沒有提供的選項，例如說，基於 TCP/UDP 的協議- SMTP traffic ，且如果你的應用對 TCP 連結相關的特性感興趣的話， Network Load Balacing 也允許你的 app 去檢查封包，這是 HTTP(S) Load Balancing 沒有提供的。 針對我們的 instance ，建立一個 L3 network load balancer gcloud compute forwarding-rules create nginx-lb \\ --region us-central1 \\ --ports=80 \\ --target-pool nginx-pool 列出所有 Google Compute Engine 轉發的規則 gcloud compute forwarding-rules list 經由瀏覽器來拜訪 load balancer http://IP_ADDRESS/ where IP_ADDRESS is the address shown as the result of running the previous command. 建立一個 HTTP(S) Load BalancerHTTP(S) Load Balancing 提供全球性的所有對我們的 instance 所做的請求。我們可以設定 URL 規則來將某些 URL 導向一些 instance ，而將另一些 URL 導向另外一些 instance 。正常下，請求將會被導向離使用者最近的 instance ，以確保該群組的 instance 有足夠的資源可以提供給使用者。如果被導向的 instance 沒有足夠的資源，那請求將會被導向離使用者最近的並且有足夠資源的 instance 首先，建立一個 health check 。 Health check 可以核實 instance 有針對 HTTP 或 HTTPS 通道做回應 gcloud compute http-health-checks create http-basic-check 定義一個 HTTP 服務，並且給予我們 instance 使用的 port 號 gcloud compute instance-groups managed \\ set-named-ports nginx-group \\ --named-ports http:80 建立後端服務gcloud compute backend-services create nginx-backend \\ --protocol HTTP --http-health-checks http-basic-check --global 將我們的 instance 群組加到後端服務:gcloud compute backend-services add-backend nginx-backend \\ --instance-group nginx-group \\ --instance-group-zone us-central1-a \\ --global 建立一個預設的 URL 指定，他將會把所有收到的請求導向我們的 instancegcloud compute url-maps create web-map \\ --default-service nginx-backend 建立一個 target HTTP proxy 來將請求導向我們的 URL mapgcloud compute target-http-proxies create http-lb-proxy \\ --url-map web-map 建立一個全球轉發規則來處理導向所有收到的請求。一個轉發規則將流量送到指定的 HTTP 或 HTTPS 代理根據請求的 IP 位址， IP 協議，或特定的 port 號。全球轉發規則不支援多個 port gcloud compute forwarding-rules create http-content-rule \\ --global \\ --target-http-proxy http-lb-proxy \\ --ports 80 全球轉發規則建立之後，需要幾分鐘時間生效gcloud compute forwarding-rules list 我們現在應該要可以從瀏覽器經由http://IP_ADDRESS/來連接，這可能會需要幾分鐘生效。如果無法連接，多等一些時間，重新整理瀏覽器。 考考你 Network Load Balancing is regional, non-proxied load balancer true false","link":"/zh-tw/HTTPAndNetworkLoadBalancer/"},{"title":"My learning journey in Linux","text":"前言這是一份未整理過的 Linux 學習筆記OS 系統基本上為 GCP 的 Ubuntu, 若有使用其他 OS，在 Google 相對應的用法 搜尋類find 搜尋屬於特定 user 或 group 的檔案 find localtion -type f -user userName -group groupName -name fileName 搜尋屬於特定 user 或 group 的資料夾 find localtion -type d -user userName -group groupName -name fileName 系統程序ps 列出系統正在執行的 process, 並且從中搜尋關鍵字ps -ef | node kill 立刻強制刪除一個工作kill -9 processID 檔案系統ln 建立一個捷徑ln -s sourceAbsoluteLink targetAbsoluteLink 檔案容量du 查檔案大小du -sh fileOrFolder df 查硬碟空間使用率df -h shell script[[]] 回傳 true or false[[ -f /.dockerenv ]] [[]] 會將裡頭的參數結果回傳 true or false-f 表示 file exists所以意思是，如果 /.dockerenv 存在，則回傳 true 搜尋內容並顯示附近的行數從 gcloud command 中取得資料，並且顯示 ssh-keys 後面的 5 行 gcloud compute project-info describe | grep -A 5 ssh-keys 刪除 group groupdel groupName 刪除 user userdel userName 建立一個 user, 並加到指定 group useradd -G groupName userName 給予一個資料夾 SGID 屬性 chmod 2777 folderName 確認 OS 種類以及版本 使用 lsb_release ， 如果沒安裝的話，安裝它 sudo apt-get install lsb-release 查詢用法 lsb_release --help 輸出如下：-h, --help show this help message and exit-v, --version show LSB modules this system supports-i, --id show distributor ID-d, --description show description of this distribution-r, --release show release number of this distribution-c, --codename show code name of this distribution-a, --all show all of the above information-s, --short show requested information in short format 根據上面的資訊，想查詢明細的話lsb_release -a 變量的設置 curl假設請求如下：curl -X POST \\ https://requestedURL \\ -H 'Content-Type: application/json' \\ -d '&#123;\"dataA\":\"content of data A\",\"dataB\":\"content of data B\"&#125;' -k -v -X 代表 request 的方式 ip 請由此查詢 -H 代表 header -d 代表傳送資料，等同於以 Content-Type: application/x-www-form-urlencoded 方式傳送 -k 若經由 https 發請求，需加上 -k -v 代表 verbose , 若要顯示回覆訊息，需加上 -v bash 環境配置文件bash 會根據有沒有登入來讀取相對應的環境配置文件 login shell /etc/profile /etc/profile.d/*.sh 被調用的條件如下： 在 /etc/profile.d/ 這個目錄內 擴展名為 .sh 使用者能夠具有 r 的權限 ~/.bash_profile or ~/.bash_login or ~/.profile (照順序讀，只會讀其中一個) ~/.bashrc (最終會讀取這一個文件) non-login shell ~/.bashrc etc/bashrc (會調用此文件) 流程圖 不小心刪除了 ~/.bashrc, 或是沒有這個文件，想創建怎麼辦？ 複製預設文件 cp /etc/skel/.bashrc ~/ 視需求修改 使立即生效source ~/.bashrc or . ~/.bashrc Base 64 decodebase64 --decode /tmp/encoded.txt &gt; /tmp/decoded.txt ncftpncftpput -u account -p password -P port -m -R ipOrDomain remoteLocation locationFileOrDirectory -u：指定登錄FTP服務器時使用的用戶名； -p：指定登錄FTP服務器時使用的密碼； -P：如果FTP服務器沒有使用默認的TCP協議的21端口，則使用此選項指定FTP服務器的端口號。 -m：在傳之前嘗試在目錄位置創建目錄(用於傳目錄的情況) -R：遞規傳子目錄 ufw 啟用防火牆服務 ufw enable 關閉防火牆服務 ufw disable 打開指定 port ufw allow port/tcp install 使用 install 指令，我們可以在創立一個 folder 或 file 的同時，指定 owner, group 以及 mode install -d -o &lt;user&gt; -g &lt;group&gt; -m &lt;mode&gt; &lt;path&gt; -d : directory -o : owner -g : group -m : mode 建立一個資料夾，並給予權限 install -d -o ray -g ray -m 2770 /tmp/ray 建立一個檔案，並給予權限 install -m 777 -o ray -g ray /dev/null filename.txt yumwhatprovides 找出有提供特定 command 的 packageyum whatprovides */commandYouAreLookingFor install 安裝特定的 packageyum insatll packageName regular expression特殊符號表 特殊符號 代表意義 [:alnum:] 代表英文大小寫字符及數字，亦即 0-9, A-Z, a-z [:alpha:] 代表任何英文大小寫字符，亦即 A-Z, a-z [:blank:] 代表空白鍵與 [Tab] 按鍵兩者 [:cntrl:] 代表鍵盤上面的控制按鍵，亦即包括 CR, LF, Tab, Del.. 等等 [:digit:] 代表數字而已，亦即 0-9 [:graph:] 除了空白字符 （空白鍵與 [Tab] 按鍵） 外的其他所有按鍵 [:lower:] 代表小寫字符，亦即 a-z [:print:] 代表任何可以被打印出來的字符 [:punct:] 代表標點符號 （punctuation symbol），亦即：” ‘ ? ! ; : # $… [:upper:] 代表大寫字符，亦即 A-Z [:space:] 任何會產生空白的字符，包括空白鍵, [Tab], CR 等等 [:xdigit:] 代表 16 進位的數字類型，因此包括： 0-9, A-F, a-f 的數字與字符 crontab 輸入 crontab job crontab -e 確認 crontab 狀態 /etc/init.d/cron status 停止 crontab /etc/init.d/cron stop 啟動 crontab /etc/init.d/cron start sed","link":"/zh-tw/Linux/"},{"title":"你好！Kubernetes","text":"前言本篇主要是利用Google的Qwiklab平台學習的同時，做的一份學習筆記原文連結如下：Refer to QWIKLABS official website 本篇將會做什麼？ 建立一個 Node.js server 建立一個 Docker container image 建立一個 container cluster 建立一個 Kubernetes pod 擴大服務 設定及要求需熟悉Linux內建的編輯器，像是vim, emacs, 或是nanoQwiklabs setup在你按下 Start Lab 按鈕之前詳讀所有的教學。Labs 是有時間限制的，而且你不可以停止時間倒數。倒數計時器在你按下 Start Lab 按鈕後開始倒數，上面顯示的時間為你還能使用 Cloud 資源的時間。 Quiklabs 的手把手環境，讓你可以在真實環境中來操作進行 Quiclabs 上提供的課程，而不是在一個模擬或是展示的環境。我們透過提供你一個全新的、暫時的帳號密碼，在計時器歸零之前，你可以用來登入並存取 Google Cloud Platform。 你需要什麼？要完成這個 lab ，你需要: 一個一般的網路瀏覽器（推薦 Chrome） 完成這個 lab 的時間 備註： 如果你已經有你自己的個人 GCP 帳號或專案，請不要使用在這一個 lab Google Cloud Platform Console如何開始你的 lab ，然後登入 Console? 按下 Start Lab 按鈕。如果你需要付費，會有一個彈出視窗來讓你選擇付費的方式。在左方你會看到一個面板，上面有暫時的帳號密碼，你必須使用這些帳號密碼在此次 lab 複製 username , 然後點擊 Open Google Console。 Lab 會開啟另外一個視窗，顯示選擇帳號的頁面 tip: 開啟一個全新的視窗，然後跟原本的頁面並排 在選擇帳號頁面, 點擊 Use Another Account 登入頁面開啟，貼上之前複製的 username 以及 password ，然後貼上 重要：必須使用之前於 Connection Details 面板 取得的帳號密碼，不要使用你自己的 Qwiklabs 帳號密碼。 如果你有自己的 GCP 帳號，請不要用在這裡（避免產生費用） 點擊並通過接下來的頁面: 接受terms以及conditions 不要增加recovery optoins 或 two factor authentication (因為這只是一個臨時帳號) 不要註冊免費體驗 稍待一些時候， GCP 控制台將會在這個視窗開啟。 注意：按下左上方位於Google Cloud Platform 隔壁的 Navigation menu ，你可以瀏覽選單，裡面有一系列的 GCP 產品以及服務 Cloud Shell啟動 Google Cloud ShellGoogle Cloud Shell 是載有開發工具的虛擬機器。它提供了5GB的 home 資料夾，並且運行在 Google Cloud 上。 Google Cloud Shell 讓你可以利用 command-line 存取 GCP 資源 在 GCP 控制台 ，右上的工具列，點擊 Open Cloud Shell 按鈕 在打開的對話框裡，按下 START CLOUD SHELL: 你可以立即按下 START CLOUD SHELL 當對話視窗打開。 連結並提供環境會需要一點時間。當你連結成功，這代表你已成功獲得授權，且此專案已被設為你的專案ID，例如： gcloud 是 Google Cloud Platform 的 command-line 工具，他已事先被安裝在 Cloud Shell 並且支援自動補齊 使用這個 command ,你可以列出有效帳戶名稱:gcloud auth list 輸出:Credentialed accounts: - &lt;myaccount&gt;@&lt;mydomain&gt;.com (active) 範例輸出:Credentialed accounts: - google1623327_student@qwiklabs.net 你可以使用以下 command 來列出專案 IDgcloud config list project 輸出：[core]project = &lt;project_ID&gt; 範例輸出：[core]project = qwiklabs-gcp-44776a13dea667a6 gcloud 的完整文件可以參閱 Google Cloud gcloud Overview 建立Node.js 應用 建立server.js檔案 vim server.js 在檔案內新增以下代碼 var http = require('http');var handleRequest = function(request, response) &#123; response.writeHead(200); response.end(\"Hello World!\");&#125;var www = http.createServer(handleRequest);www.listen(8080); Cloud Shell以內建node，直接執行node server node server.js 使用Cloud Shell內建的Web預覽功能，開一個新的視窗並發請求到port 8080，如下圖： 結果如下： 在更進一步之前，讓我們先到Cloud Shell按下Ctrl+c停止正在運行中的node server，我們將打包這個運用，並置於Docker container內 建立一個Docker container image 接下來，建立一個Dockerfile來敘述我們想要建立的image，Docker container images可以是已經存在image的延伸，所以我們將從已經存在的Node image來延伸 vim Dockerfile 增加以下內容FROM node:6.9.2EXPOSE 8080COPY server.js .CMD node server.js 上面的內容將： 從Docker hub中開始一個找到的node image 開啟port 8080 複製server.js檔案到此docker image 如之前操作般，手動開始node server 輸入以下的指令以建立image，將下面的PROJECT_ID替換成你的GCP Project ID，可以從主控台以及Connection Details區找到 docker build -t gcr.io/PROJECT_ID/hello-node:v1 . 接下來會花一些時間來下載以及擷取需要的東西，但你可以從進度條看到image建立的進度 完成之後，於本地端使用下面的指令測試一下這個image，這個指令會從剛新建立的container image中，將Docker container以常駐的方式跑在port 8080，(將下面的PROJECT_ID替換成你的GCP Project ID，可以從主控台以及Connection Details區找到) docker run -d -p 8080:8080 gcr.io/PROJECT_ID/hello-node:v1 結果大概如下 325301e6b2bffd1d0049c621866831316d653c0b25a496d04ce0ec6854cb7998 可使用Web預覽功能 或在Cloud Shell中使用curlkcurl http://localhost:8080 停止Docker container 尋找Docker container ID docker ps 結果大概如下 CONTAINER ID IMAGE COMMAND2c66d0efcbd4 gcr.io/PROJECT_ID/hello-node:v1 &quot;/bin/sh -c &apos;node 關閉docker container docker stop containerID 結果會輸出你的container ID，如下： 2c66d0efcbd4 現在，image如我們預期般的運作著，接下來我們將它推到Google Container Registry，一個可倍Google Cloud Projects存取的Docker image私人資料夾, 執行下面的指令(將下面的PROJECT_ID替換成你的GCP Project ID，可以從主控台以及Connection Details區找到) gcloud docker -- push gcr.io/PROJECT_ID/hello-node:v1 Container image將會被列在主控台中，可從Navigation menu &gt; Container Registry找到 現在我們擁有project-wide的Docker image，可供Kubernetes存取以及編排 建立cluster 現在我們已經準備好可以建立Kubernetes Engine cluster。一個cluster內，有由Google的Kubernetes master API server，以及一組worker nodes。Woker nodes是Compute Engine virtual machines. 確保我們已經使用gcould來設定我們的專案(將下面的PROJECT_ID替換成你的GCP Project ID，可以從主控台以及Connection Details區找到) gcloud config set project PROJECT_ID 使用兩個n1-standard-1 nodes來建立cluster(將會耗費幾分鐘) gcloud container clusters create hello-world \\ --num-nodes 2 \\ --machine-type n1-standard-1 \\ --zone us-central1-a 你也可以透過主控台來建立cluster: Kubernetes Engine &gt; Kubernetes cluster &gt; Create cluster cluster建立的區域，建議跟container registry使用的儲存區的所在區域一樣 Vavigation menu &gt; Kubernetes Engine 可以看到，現在有一個由Kubernetes Engine驅動的完全運作的Kubernetes clsuter 接下來，是時候將我們容器化的application部署到Kubernetes cluster，從現在開始，我們將使用kubectl命令行（在Cloud Shell環境中，這已經被設定完畢） 建立pod Kubernetes pod由多個container組成，用於管理以及連結。它可以容納單一或多個containers。這邊我們將會使用儲存於私人的container registry，由Node.js image 建立的container。內容將會用在8080 port 使用kubectl run 指令來建立一個pod(將下面的PROJECT_ID替換成你的GCP Project ID，可以從主控台以及Connection Details區找到) kubectl run hello-node \\--image=gcr.io/PROJECT_ID/hello-node:v1 \\--port=8080 可以看到，我們已經建立一個deployment物件。Deployments是建立跟擴大pods推薦的方法。這邊，一個新的deployment管理一個執行hello-node:v1 image的pod 允許外部連結 在預設中，pod只可被cluster內部的ip存取。為了要讓hello-node container可倍Kubernetes virtual network之外的來源存取，我們必須設定pod成可被存取的Kubernates的服務 在Cloud Shell，透過使用kubectl expose指令，並結合--type=&quot;LoadBalancer&quot; flag, 我們可以讓pod可被公用網路存取。要建立一個外部存取IP，這個flag是必須的。kubectl expose deployment hello-node --type=\"LoadBalancer\" 這個flag指定我們將使用underlying infrostructure提供的load-balancer (在此範例中，為Compute Engine load balancer)。需注意我們是使deployment可視化，並非直接暴露pod。這代表，產生的服務將會讀取所有由此depolyment管理的pod(於此範例中，為一個pod，但我們之後可以增加) 此Kubernetes master建立了load balancer，相關的Compute Engline 轉發規格，target pools，以及防火牆規則， 所以服務可被Google Cloud Platform之外的來源所存取 若要找公開可存取IP，可要求kubectl列出所有的cluster服務 kubectl get services 結果如下： NAME CLUSTER-IP EXTERNAL-IP PORT(S) AGEhello-node 10.3.250.149 104.154.90.147 8080/TCP 1mkubernetes 10.3.240.1 &lt;none&gt; 443/TCP 5m 上圖可以看到，hello-node service有兩組IP，兩組都使用port 8080，CLUSTER-IP 是內部IP，只可被內部cloud vertial network所見，EXTERNAL-IP為外部load-balanced IP 外部IP可能需要幾分鐘生效 通過輸入IP來存取 http://&lt;EXTERNAL_IP&gt;:8080 擴充服務 通過指令來擴充服務kubectl scale deployment hello-node --replicas=4 查看deployment kubectl get deployment 查看所有pod kubectl get pods 以下圖示顯示Kubernetes的大概運作方式: 升級服務 某些時候，已經被部署的應用需要debug或增加新的功能。Kubernetes幫我們部署新的版本，並且不影響使用者 首先，修改應用，編輯server.js vim server.js 更新回覆訊息 response.end(&quot;Hello Kubernetes World!&quot;); 現在，我們可以透過往上增加的版本號，建立以及發布一個新的container image到registry。 使用以下指令(將下面的PROJECT_ID替換成你的GCP Project ID，可以從主控台以及Connection Details區找到) docker build -t gcr.io/PROJECT_ID/hello-node:v2 . gcloud docker -- push gcr.io/PROJECT_ID/hello-node:v2 編輯已經存在的hello-node deployment以及將image由gcr.io/PROJECT_ID/hello-node:v1變更為gcr.io/PROJECT_ID/hello-node:v2 kubectl edit deployment hello-node 修改如下：# Please edit the object below. Lines beginning with a '#' will be ignored,# and an empty file will abort the edit. If an error occurs while saving this file will be# reopened with the relevant failures.#apiVersion: extensions/v1beta1kind: Deploymentmetadata: annotations: deployment.kubernetes.io/revision: \"1\" creationTimestamp: 2016-03-24T17:55:28Z generation: 3 labels: run: hello-node name: hello-node namespace: default resourceVersion: \"151017\" selfLink: /apis/extensions/v1beta1/namespaces/default/deployments/hello-node uid: 981fe302-f1e9-11e5-9a78-42010af00005spec: replicas: 4 selector: matchLabels: run: hello-node strategy: rollingUpdate: maxSurge: 1 maxUnavailable: 1 type: RollingUpdate template: metadata: creationTimestamp: null labels: run: hello-node spec: containers: - image: gcr.io/PROJECT_ID/hello-node:v1 ## Update this line ## imagePullPolicy: IfNotPresent name: hello-node ports: - containerPort: 8080 protocol: TCP resources: &#123;&#125; terminationMessagePath: /dev/termination-log dnsPolicy: ClusterFirst restartPolicy: Always securityContext: &#123;&#125; terminationGracePeriodSeconds: 30 更新新的image到deployment，新的pods將被建立，舊的將被刪除kubectl get deployments Kubernetes圖形化面板 (optional) 取得cluster層級權限 kubectl create clusterrolebinding cluster-admin-binding --clusterrole=cluster-admin --user=$(gcloud config get-value account) 權限已經取得，建立新的面板服務 kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml 編輯面板服務的表面形式 kubectl -n kube-system edit service kubernetes-dashboard 將type: ClusterIP改成type: NodePort 要登入Kubernetes面板，需要經過token驗證，產生token如下： kubectl -n kube-system describe $(kubectl -n kube-system \\get secret -n kube-system -o name | grep namespace) | grep token: 打開連線 kubectl proxy --port 8081 使用Cloud Shell Web 預覽功能來改變port到8081 我們將收到一串API endpoint，要連結到面板，將/?authuser=0移除，然後加上下面的url: /api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/#!/overview?namespace=default 然後你會被帶到一個網頁預覽 點選Token radio，然後貼上剛剛拿到的token，然後Sign in 你可以從主控台存取面板服務，Navigation menu &gt; Kubernetes Engine，然後選擇Connect按鈕連接到我們想要連接的cluster 習題測驗 which of the following are features of the Kubernetes Engine? Identity and Access Management Integrated Logging and Monitoring None of these Stateful Application Support 非必要指令 如果想要檢視這個deployment，可以使用以下指令： kubectl get deployments 若想檢視由deployment建立的pod，可以使用以下指令: kubectl get pods 以下也是一些有趣的kubectl指令： kubectl cluster-info kubectl config view kubectl get events kubectl logs podName","link":"/zh-tw/Kubernetes/"},{"title":"GCP-Essentials","text":"前言此篇為我在QWIKLABS上學習GCP-Essentials系列課程所做的學習筆記目錄，以下為每堂課的學習筆記連結： Create a Virtual Machine / 建立一台虛擬機https://tn710617.github.io/zh-tw/createAVirtualMachineInGCP/ Getting Started with Cloud Shell &amp; gcloud / 讓我們從Cloud Shell 以及 gloud開始吧https://tn710617.github.io/zh-tw/CloudShellAndgcloud/ Provision Services with GCP Marketplace / 利用GCP Marketplace來提供服務https://tn710617.github.io/zh-tw/GCPMarketplace/ Creating a Persistent Disk / 建立一個Persistent Diskhttps://tn710617.github.io/zh-tw/createAPersistentDisk/ Kubernetes - Quick Start / Kubernetes - 快速開始https://tn710617.github.io/zh-tw/KubernetesEngineQuickStart/ Hello Node Kubernetes / 你好，Kubernetes!https://tn710617.github.io/zh-tw/Kubernetes/ Stackdriver - Quick Start / Stackdriver - 快速開始https://tn710617.github.io/zh-tw/Stackdriver/ Set Up Network and HTTP Load Balancers / 設定Network 以及 HTTP 平衡負載器https://tn710617.github.io/zh-tw/HTTPAndNetworkLoadBalancer/","link":"/zh-tw/GCP-Essentials/"},{"title":"Kubernetes Engine 快速開始","text":"前言本篇為 GCP Kubernetes Engine 的學習筆記Google Kubernetes Engine (GKE) 為使用 Google 基礎架構的應用提供了一個部署，管理，以及可調整規模的環境。Kubernetes Engine 環境包含了多台的群集機器(這邊專指為 Google Compute Engine 的實例)，形成一個容器的群集。在這個課程中，你將可以實際操作練習如何建立一個容器，以及在 GKE 上部署你的應用。 Kubernetes Engine 的群集管理Kunernetes Engline 群集器由 Kunernetes 開源群集管理系統所提供。Kubernetes 提供與你的容器群集互動的機制。使用Kebernetes的指令以及資源來部署、管理你的應用，執行管理任務、制訂政策，以及監控部屬工作量的健康度。 Kubernetes 使用了與目前運行在 Google 熱門服務相同的設計原則，並提供相同的優勢:自動管理, 應用容器的監控以及健康檢查, 自動擴展, 滾動升級, 以及更多…當你在一個容器群集中運行你的應用, 相當於你使用了 Google 這10幾年正式在容器內上線的經驗來運行你的應用。 Kubernetes on Google Cloud Platform當你使用Kubernetes Engline 群集，你同時也得到了 Google Cloud Platform 提供的優勢以及進階的群集管理功能, 如下： Compute Engine 實例的平衡負載 節點池：在群集內分配子集節點以提升靈活度 群集節點實例數量的自動擴展 群集節點軟體的自動升級 節點自動修復:保持節點的健康度以及可用性 使用 Stackdriver 來紀錄與監控，讓您可以掌握群集的狀態 現在你已經對 Kubernetes 有基本的認識，你將在30分鐘內，學習如何使用 Kubernetes Engline 來部署你的容器化應用。繼續往下看並遵照每一個步驟來設定你的Lab環境。 設定及要求Qwiklabs setup在你按下 Start Lab 按鈕之前詳讀所有的教學。Labs 是有時間限制的，而且你不可以停止時間倒數。倒數計時器在你按下 Start Lab 按鈕後開始倒數，上面顯示的時間為你還能使用 Cloud 資源的時間。 Quiklabs 的手把手環境，讓你可以在真實環境中來操作進行 Quiclabs 上提供的課程，而不是在一個模擬或是展示的環境。我們透過提供你一個全新的、暫時的帳號密碼，在計時器歸零之前，你可以用來登入並存取 Google Cloud Platform。 你需要什麼？要完成這個 lab ，你需要: 一個一般的網路瀏覽器（推薦 Chrome） 完成這個 lab 的時間 備註： 如果你已經有你自己的個人 GCP 帳號或專案，請不要使用在這一個 lab Google Cloud Platform Console如何開始你的 lab ，然後登入 Console? 按下 Start Lab 按鈕。如果你需要付費，會有一個彈出視窗來讓你選擇付費的方式。在左方你會看到一個面板，上面有暫時的帳號密碼，你必須使用這些帳號密碼在此次 lab 複製 username , 然後點擊 Open Google Console。 Lab 會開啟另外一個視窗，顯示選擇帳號的頁面 tip: 開啟一個全新的視窗，然後跟原本的頁面並排 在選擇帳號頁面, 點擊 Use Another Account 登入頁面開啟，貼上之前複製的 username 以及 password ，然後貼上 重要：必須使用之前於 Connection Details 面板 取得的帳號密碼，不要使用你自己的 Qwiklabs 帳號密碼。 如果你有自己的 GCP 帳號，請不要用在這裡（避免產生費用） 點擊並通過接下來的頁面: 接受terms以及conditions 不要增加recovery optoins 或 two factor authentication (因為這只是一個臨時帳號) 不要註冊免費體驗 稍待一些時候， GCP 控制台將會在這個視窗開啟。 注意：按下左上方位於Google Cloud Platform 隔壁的 Navigation menu ，你可以瀏覽選單，裡面有一系列的 GCP 產品以及服務 Cloud Shell啟動 Google Cloud ShellGoogle Cloud Shell 是載有開發工具的虛擬機器。它提供了5GB的 home 資料夾，並且運行在 Google Cloud 上。 Google Cloud Shell 讓你可以利用 command-line 存取 GCP 資源 在 GCP 控制台 ，右上的工具列，點擊 Open Cloud Shell 按鈕 在打開的對話框裡，按下 START CLOUD SHELL: 你可以立即按下 START CLOUD SHELL 當對話視窗打開。 連結並提供環境會需要一點時間。當你連結成功，這代表你已成功獲得授權，且此專案已被設為你的專案ID，例如： gcloud 是 Google Cloud Platform 的 command-line 工具，他已事先被安裝在 Cloud Shell 並且支援自動補齊 使用這個 command ,你可以列出有效帳戶名稱:gcloud auth list 輸出:Credentialed accounts: - &lt;myaccount&gt;@&lt;mydomain&gt;.com (active) 範例輸出:Credentialed accounts: - google1623327_student@qwiklabs.net 你可以使用以下 command 來列出專案 IDgcloud config list project 輸出：[core]project = &lt;project_ID&gt; 範例輸出：[core]project = qwiklabs-gcp-44776a13dea667a6 gcloud 的完整文件可以參閱 Google Cloud gcloud Overview 設定預設的 compute zonecompute zone 是一個你的群集以及資源的大概的區域。舉例來說，us-central1-a是一個位於 us-central1 region 的 zone 在 Cloud Shell 輸入以下的 command 來將你的預設 compute zone 設為 us-central1-agcloud config set compute/zone us-central1-a 輸出如下：Updated property [compute/zone]. 建立一個 Kubernetes Engline 群集一個群集包含至少一個群集主要機器，以及多台工作機器，稱為 nodes (節點)。 Nodes 是 Compute Engline 虛擬機器實例，運行著 Kubernetes 的必要程序，使他們成為群集的一部分。 執行以下的 command 來建立一個群集。以你喜歡的群集名稱(例如： my-cluster )來取代 command 中的 CLUSTER-NAME 。群集的名稱必須由一個字母開始，並且需同時包含字母以及數字，且長度不可超過40個字。gcloud container clusters create [CLUSTER-NAME] 你可以無視輸出裡的任何警告。建立群集會需要一些時間，很快的你將會收到類似下面的輸出：NAME LOCATION ... NODE_VERSION NUM_NODES STATUSmy-cluster us-central1-a ... 1.10.9-gke.5 3 RUNNING 取得群集的授權證明在建立群集之後，你需要取得授權證明來進行對群集的進一步操作執行下面的 command 來授權群集，並用你自己的群集名稱取代 command 裡面的 CLUSTER-NAMEgcloud container clusters get-credentials [CLUSTER-NAME] 你將會收到類似下面的輸出：Fetching cluster endpoint and auth data.kubeconfig entry generated for my-cluster. 部署應用到群集上現在你已經建立了一個群集，你可以部署一個容器化的應用到這上面。在這個 Lab ，你將會部署 hello-app 到你的群集上 Kubernetes Engline 使用 Kubernets 物件來建立以及管理你的群集資源。 Kubernetes 提供 部署 物件來部署無狀態的應用，像是 web server。服務物件定義了從網路上存取你應用的規則，以及負載平衡。 在 Cloud Shell 執行下面的 [kubectl run] 指令，在 hello-app 容器鏡像裡建立一個新的部署 hello-serverkubectl run hello-server --image=gcr.io/google-samples/hello-app:1.0 --port 8080 你應該會收到以下的輸出:deployment.apps \"hello-server\" created 這一個 Kubernetes 的指令，建立了一個代表 hello-app 的部署物件，在此指令中： --image 指定了一個容器鏡像來部署，在此範例中，這個指令從Google Container Registry儲存區裡，拉下一個範例鏡像。gcr.io/google-samples/hello-app:1.0 表示一個特定的鏡像。如果版本沒有明確標示，最新的版本將會被使用。 --port 指定容器暴露的 port 號 執行以下的 kubectl 暴露指令，建立一個 Kubernetes 的服務，一個 Kubernetes 的資源，讓你暴露你的應用到外部。 kubectl expose deployment hello-server --type=\"LoadBalancer\" 你應該會收到以下的輸出：service \"hello-server\" exposed 帶入參數 type=&quot;LoadBalancer&quot; ，在容器中建立一個 Compute Engline 平衡負載 執行 kubectl get 來檢查 hello-server 服務kubectl get service hello-server 你應該會收到類似以下的輸出： NAME TYPE ... EXTERNAL-IP PORT(S) AGEhello-server LoadBalancer ... 35.184.112.169 8080:30840/TCP 2m 備註：外部IP位址的產生，可能需要1分鐘。如果外部IP一直在沒有產生，你可以在執行一次上面的指令 從這個指令的輸出，從 `EXTERNAL-IP 欄位，複製服務的外部 IP 位址。 從瀏覽器，經由外部 IP 還有對應的 port 號來拜訪我們的應用 http://[EXTERNAL-IP]:8080 你的頁面應該看起來如下： 清除執行下面的指令來清除群集gcloud container clusters delete [CLUSTER-NAME] 當選項跳出，輸入 Y 確認。清除群集將會花費一些時間。你可以參閱 文件 來獲得更多刪除 Google Kubernetes Engline 群集 的資訊","link":"/zh-tw/KubernetesEngineQuickStart/"},{"title":"使用 Laravel Queue 以及 AWS SQS","text":"前言本篇重點如下： 使用 Laravel queue 完成寄 Email 功能 使用 AWS SQS 為什麼要使用 queue 呢？當我們執行一些耗時較久的工作時，像是發送 Email ， 或是上傳圖片或是影片，讓使用者等到工作執行完畢才進行下一個動作的話，是不太現實的。所以當使用者發出一些需要較長時間執行的請求時，我們要使用 queue 來幫我們隊列，在背景慢慢執行，然後讓使用者可以立即執行下一個動作。 申請 AWS SQS 服務 首先，你要有 AWS 帳號 到 AWS 上申請 SQS 服務 這邊可以參考 AWS教學，完成設定。 記住下面的資料，後面會用到 到右上角，選擇帳戶的地方，選擇My Security Credentials 到左邊選擇 Users 建立新的 User 輸入 user 名稱，打勾 Programmatic access ，然後下一步 然後 Create group ，如下圖 再來把剛剛建立的 user 加到這個新建的 group 接下來 Add tags 是選填，不一定要填 然後就可以獲得 Access key ID 以及 Secret access key ，如果怕忘記的話，可以下載下來哦！ 這個 Secret access key 只會出現一次哦，如果不小心忘記或沒有記下來的話，就要重新產生哦！ 實作 Laravel queue配置 AWS SQS 以下操作均參考官方文件 安裝 AWS 官方 SDK ，參照官方文件 ，在專案資料夾底下： composer require aws/aws-sdk-php 在.env檔案中，做以下配置 QUEUE_CONNECTION=sqsSQS_KEY=上面拿到的 keySQS_SECRET=上面拿到的 secretSQS_QUEUE=testSQSSQS_REGION=ap-northeast-1SQS_PREFIX=依照上面的URL去掉queue名稱後填入 建立 jobsphp artisan make:job ProcessPodcast job 範本如下&lt;?phpnamespace App\\Jobs;use App\\Helpers;use Illuminate\\Bus\\Queueable;use Illuminate\\Queue\\SerializesModels;use Illuminate\\Queue\\InteractsWithQueue;use Illuminate\\Contracts\\Queue\\ShouldQueue;use Illuminate\\Foundation\\Bus\\Dispatchable;class SendMailWhenOrderPlaced implements ShouldQueue&#123; use Dispatchable, InteractsWithQueue, Queueable, SerializesModels; protected $job; // 嘗試執行最高次數 public $tries = 5; /** * Create a new job instance. * * @return void */ public function __construct($order, $FB_email, $Local_email) &#123; $this-&gt;order = $order; $this-&gt;FB_email = $FB_email; $this-&gt;Local_email = $Local_email; $this-&gt;job = Helpers::mailWhenOrderPlaced($order, $FB_email, $Local_email); &#125; /** * Execute the job. * * @return void */ public function handle() &#123; return $this-&gt;job; &#125;&#125; 上面的範例，是使用 queue 來執行 Ray 專案裡頭的一個寄送 Email 的功能，叫做 mailWhenOrderPlaced。 使用 dispatch 在我們想要執行這一個job的地方，使用dispatch，就可以囉！SendMailWhenOrderPlaced::dispatch($order, $FB_email, $Local_email); 執行 queue 在專案底下，執行php artisan queue:work 測試 這個時候，當程式執行到 dispatch 那行時，就會使用 queue 來執行哦！ 總結是不是很簡單啊？另外，因為我們使用了 queue ，所以必須要確保 queue 的運作是正常的。以這個例子來說的話，如果 queue 不幸失效了，那這個發 Email 的功能就會失效哦！為了確保 queue 在失敗後重新自動執行，我們需要 Supervisor 來幫我們監控並管理程序！關於 Supervisor ，可以參考 Ray 的另外一篇文章哦！如果想知道如何用 Laravel Mail 以及 AWS SES 來發送 mail ，也可以參考 Ray 的另外一篇文章","link":"/zh-tw/LaravelQueueWithSQS/"},{"title":"使用 `Laravel` `template` 與 `blade`","text":"前言本篇為Laravel 的學習筆記，主要紀錄 Laravel blade 的用法，重點如下： 建立並重複使用 template 使用 yield 及 section 將值傳到 view {{ }} 幫我們做了什麼？ 建立 template 建立 template ，名為 layout ，如下&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; // 使用 yield 設定 title 的範圍，並將 Laracasts 設為預設值，若在頁面中沒有特別指定 title 的值時，會自訂套用預設 &lt;title&gt;@yield('title', 'Laracasts')&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;ul&gt; &lt;li&gt;&lt;a href=\"/\"&gt;Welcome&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=\"/about\"&gt;About&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=\"/contact\"&gt;contact&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;// 使用 yield 設定區塊的範圍，範圍名稱為 content@yield('content')&lt;/body&gt;&lt;/html&gt; 使用 section 上面已經建立好了 template ，所以我們可以在新的頁面直接套用 template// 下面我們直接套用名為 layout 的 template@extends('layout')// 使用 section ， 在 template 中已經設定好的區塊，插入我們想要的元素。在 title 區塊插入新的值@section('title', 'Welcome Page')// 使用 section ， 在 content 區塊插入值@section('content') &lt;h1&gt;Welcome here&lt;/h1&gt;// 使用 endsection 來明確範圍@endsection 重複上面的操作，在多個新頁面上套用 template 將值傳到 view 要將值帶到 view 其實也很多種做法，以下列舉四種 1. Route::get(&apos;/&apos;, function () &#123; $task = [ &apos;Go to the school&apos;, &apos;Go to the market&apos;, &apos;Go to work&apos; ]; return view(&apos;welcome&apos;, compact(&apos;task&apos;) );&#125;); 2. Route::get(&apos;/&apos;, function () &#123; $task = [ &apos;Go to the school&apos;, &apos;Go to the market&apos;, &apos;Go to work&apos; ]; return view(&apos;welcome&apos;, [&apos;tasks&apos; =&gt; $task] ); Route::get(&apos;/&apos;, function () &#123; return view(&apos;welcome&apos;, [&apos;tasks&apos; =&gt; [ &apos;Go to the school&apos;, &apos;Go to the market&apos;, &apos;Go to work&apos; ]]);&#125;); Route::get(&apos;/&apos;, function () &#123; return view(&apos;welcome&apos;)-&gt;withTasks([ &apos;Go to the school&apos;, &apos;Go to the market&apos;, &apos;Go to work&apos; ]);&#125;); 以上四種做法， Ray 比較常用第一種。 在 view 接值 在 view 把剛剛傳過來的值取出，並顯示 @extends(&apos;layout&apos;)@section(&apos;title&apos;, &apos;Welcome Page&apos;)@section(&apos;content&apos;) &lt;h1&gt;Welcome here&lt;/h1&gt; &lt;ul&gt; @foreach ($tasks as $task) &lt;li&gt; &#123;&#123; $task &#125;&#125; &lt;/li&gt; @endforeach &lt;/ul&gt;@endsection 在Laravel 的 blade 檔案中，可以在 {{ }} 中使用變數 畫面如下： blade {{ }} 幫我們做了什麼？ {{ }} 除了可讓我們取得傳過來的變數之外，還自動執行了 PHP的 function htmlspecialchars ，防止有心人 XSS 攻擊。 做個實驗，使用blade:Route::get(&apos;/&apos;, function () &#123; $test = &apos;&lt;script&gt;alert(&quot;test&quot;)&lt;/script&gt;&apos;; return view(&apos;welcome&apos;)-&gt;withTasks([ &apos;Go to the school&apos;, &apos;Go to the market&apos;, &apos;Go to work&apos; ])-&gt;withTest($test);&#125;); @extends(&apos;layout&apos;)@section(&apos;title&apos;, &apos;Welcome Page&apos;)@section(&apos;content&apos;) &lt;h1&gt;&#123;&#123; $test &#125;&#125;&lt;/h1&gt; &lt;ul&gt; @foreach ($tasks as $task) &lt;li&gt; &#123;&#123; $task &#125;&#125; &lt;/li&gt; @endforeach &lt;/ul&gt;@endsection 如上面的 code ，我們傳了有著 script tag 的 變數過去經由瀏覽器渲染出來後，如下： 再做個實驗，我們可以使用{!! !!} 來取消htmlspecialchars，慎用！@extends(&apos;layout&apos;)@section(&apos;title&apos;, &apos;Welcome Page&apos;)@section(&apos;content&apos;) &lt;h1&gt;&#123;!! $test !!&#125;&lt;/h1&gt; &lt;ul&gt; @foreach ($tasks as $task) &lt;li&gt; &#123;&#123; $task &#125;&#125; &lt;/li&gt; @endforeach &lt;/ul&gt;@endsection 瀏覽器渲染出來後，如下： 可以看到，該 script 真的被執行了 總結有關於blade的應用還有很多，之後會繼續更新。","link":"/zh-tw/LaravelView/"},{"title":"My learning journey in Node.js","text":"前言這是一份未整理的 Node.js 學習筆記 正文安裝 在 CentOS 7 上安裝 Node.js 和 NPMNodeSource 是一家致力於提供企業級Node 支持的公司，他們為Linux 發行版維護一致更新的Node.js 軟件倉庫。要從CentOS 7 系統上的NodeSource 軟件倉庫安裝Node.js 和npm ，請按照下列步驟操作： 添加NodeSource yum 軟件倉庫Node.js 的當前LTS 版本是10.x 版。如果你想安裝的版本8 只吧下面的命令中setup_10.x 更改為setup_8.x 。運行以下curl命令將NodeSource yum軟件倉庫添加到您的系統： curl -sL https://rpm.nodesource.com/setup_10.x | bash - 安裝Node.js 和npm啟用NodeSource 軟件倉庫後，通過以下命令安裝Node.js 和npm ： yum install nodejs 驗證Node.js 和npm 安裝 node -v npm -v 如何使用NVM 安裝Node.js 和npmNVM （Node 版本管理器）是一個bash 腳本，用於管理多個活動的Node.js 版本。NVM 允許我們安裝和卸載任何特定的Node.js 版本，這意味著我們可以擁有任何數量的Node.js 版本供我們使用或測試。curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.34.0/install.sh | bash &amp;&amp; export NVM_DIR=\"$HOME/.nvm\" &amp;&amp; [ -s \"$NVM_DIR/nvm.sh\" ] &amp;&amp; \\. \"$NVM_DIR/nvm.sh\" &amp;&amp; [ -s \"$NVM_DIR/bash_completion\" ] &amp;&amp; \\. \"$NVM_DIR/bash_completion\" 參考資料來源 要在CentOS 系統上使用NVM 安裝Node.js 和npm ，請按照下列步驟操作： 使用 fs module fs.writeFileSyncconst fs = require(&#39;fs);在 Node.js 裏頭，如果要引用一個 module ，要用一個變數引用，然後之後就可以使用它例如fs.writeFileSync('hello.txt', 'Hello fromNode.js'); 上面的 function ，是將 Hello fromNode.js 寫進 hello.txt 這個檔案### 建立一個最簡單的 server首先，我們先引用 `http` module，當我們要調用本地 module 時，我們可以指定路徑，像是 `./http` ，但我們要調用 global 的 module 時，我們不加任何路徑， 如下```javascriptconst http = require(&apos;http&apos;); 接下來，我們利用剛剛引用的 http module 來建立一個 server ，如下：const server = http.createServer((req, res) =&gt; &#123; console.log(req);&#125;); orconst server = http.createServer(function(req, res)&#123; console.log(req);&#125;); or function rqListener(req, res) &#123; console.log(req);&#125;const server = http.createServer(rqListener); 最後，我們雖然已經建立了 server ，但是我們還沒有指定它的位址。 我們指定 3000 port 給這個 server ，如下：server.listen(3000); 此時，我們可以從瀏覽器，輸入 localhost:3000 來拜訪這個 server 停止這個 loopconst http = require('http');const server = http.createServer((req, res) =&gt; &#123; console.log(req); process.exit();&#125;);server.listen(3000); 從 request 中取得我們想要的資訊舉例來說，我們要取得 url , method , 以及 header 三項資訊，如下：const http = require('http');const server = http.createServer((req, res) =&gt; &#123; console.log(req.url, req.method, req.header); // process.exit();&#125;);server.listen(3000); 下圖，我們可以看到我們特別指定的三項資訊: 設定 response我們可以在 server 中，指定 response ，如下：const http = require('http');const server = http.createServer((req, res) =&gt; &#123; console.log(req.url, req.method, req.header); // process.exit(); res.setHeader('Content-Type', 'text/html'); res.write('&lt;html&gt;'); res.write('&lt;head&gt;&lt;title&gt;My First Page&lt;/title&gt;&lt;/head&gt;'); res.write('&lt;body&gt;&lt;ht&gt;Hello from my NOde.js Server&lt;/ht&gt;&lt;/body&gt;'); res.write('&lt;/html&gt;'); res.end();&#125;);server.listen(3000); 然後打開開發者工具，我們可以看到我們剛剛設定的 header 然後 response 的地方可以看到我們剛剛設定的 response 簡易的 request routing我們可以指定觸發特定 response 的 url ，當 client 呼叫這個 url 時，就會觸發我們指定的 response ，反之，則觸發另外的 response const http = require('http');const server = http.createServer((req, res) =&gt; &#123; const url = req.url; if (url === '/') &#123; res.write('&lt;html&gt;'); res.write('&lt;head&gt;&lt;title&gt;Enter Message&lt;/title&gt;&lt;/head&gt;'); res.write('&lt;body&gt;&lt;form action=\"/message\" method=\"post\"&gt;&lt;input type=\"text\" name=\"message\"&gt;&lt;button type=\"submit\"&gt;Send&lt;/button&gt;&lt;/form&gt;&lt;/body&gt;'); res.write('&lt;/html&gt;'); return res.end(); &#125; res.setHeader('Content-Type', 'text/html'); res.write('&lt;html&gt;'); res.write('&lt;head&gt;&lt;title&gt;My First Page&lt;/title&gt;&lt;/head&gt;'); res.write('&lt;body&gt;&lt;ht&gt;Hello from my NOde.js Server&lt;/ht&gt;&lt;/body&gt;'); res.write('&lt;/html&gt;'); res.end();&#125;);server.listen(3000); 由上面的 code 可以看到，我們指定 req.url 必須要絕對等於 / 才會觸發條件內，我們指定的 response 如下： 當我們按下 send ，會執行 post method, action /message ，如下： 因為 action 的關係，會嘗試拜訪 message url ，而因為這個 url 並不符合我們設定的條件，所以會執行預設 response 簡單的 redirect request現在，我們要簡易的 redirect 我們的 request ，如下：const http = require('http');const fs = require('fs');const server = http.createServer((req, res) =&gt; &#123; const url = req.url; const method = req.method; if (url === '/') &#123; res.write('&lt;html&gt;'); res.write('&lt;head&gt;&lt;title&gt;Enter Message&lt;/title&gt;&lt;/head&gt;'); res.write('&lt;body&gt;&lt;form action=\"/message\" method=\"post\"&gt;&lt;input type=\"text\" name=\"message\"&gt;&lt;button type=\"submit\"&gt;Send&lt;/button&gt;&lt;/form&gt;&lt;/body&gt;'); res.write('&lt;/html&gt;'); return res.end(); &#125; if (url === '/message' &amp;&amp; method === 'POST') &#123; fs.writeFileSync('message.txt', 'DUMMY'); res.statusCode = 302; res.setHeader('Location', '/'); return res.end(); &#125; res.setHeader('Content-Type', 'text/html'); res.write('&lt;html&gt;'); res.write('&lt;head&gt;&lt;title&gt;My First Page&lt;/title&gt;&lt;/head&gt;'); res.write('&lt;body&gt;&lt;ht&gt;Hello from my NOde.js Server&lt;/ht&gt;&lt;/body&gt;'); res.write('&lt;/html&gt;'); res.end();&#125;);server.listen(3000); 從上面的 code 可以看到，我們新增了第二個 if statement。如果 url 等於 //message 以及 method 等於 post ，雙重條件都符合之下，就會觸發我們設定的條件我們使用了之前我們曾經使用的 fs module ，如果條件觸發，我們就會將 DUMMY 寫入一個叫做 message.txt 的檔案接著回傳 status code 302最後回導到 /在 res.end() 之後，我們不可以在 define 新的 res ，否則就會出現錯誤，因為這邊我們要使用 return ，後續的代碼就不會再執行 Parsing request bodies本章節，我們將解析 request 裡頭的 body 資料並且初次接觸到了 stream 以及 buffer 的概念。首先，我們先設定一個事件。 當接收到 data 時，觸發一個 function 並且帶入 chunk ， chunk 是資料的最小單位。接著我們使用了 console.log 來把 chunk 印出來！同時，我們建立一個 body 常數 array ，並且將每一次觸發 data 事件時，我們都將 chunk 丟到這個 array 裏頭， 代碼如下：const body = [];req.on('data', (chunk) =&gt; &#123; console.log(chunk); body.push(chunk);&#125;); 接著，我們在建立一個事件，當 request 接收完成，我們在定義一個常數，叫做 parsedBody ， 至於這個常數的內容，我們使用 buffer 物件，來將 body array 裡頭的 chunk 都串起來，然後轉換成 string 。最後，我們使用 console.log 把常數 parsedBody 印出來，代碼如下：req.on('end', () =&gt; &#123; const parsedBody = Buffer.concat(body).toString(); console.log(parsedBody);&#125;); 結果如下： 接下來，我們在定義一個常數 message ，它的內容是用 ‘=’ 來將常數 parsedBody 分隔，變成一個 array ，然後我們取 [1] ，就是 array 中的第二項資料。然後，我們將這個常數 message 一方面利用 console.log 印出來，一方面利用 fs module 來寫到一個叫做 message.txt 的檔案中。代碼如下：req.on('end', () =&gt; &#123; const parsedBody = Buffer.concat(body).toString(); const message = parsedBody.split('=')[1]; console.log(message); fs.writeFileSync('message.txt', message);&#125;); 至此, 此 episode 告一段落，最後全部的 code 如下：const http = require('http');const fs = require('fs');const server = http.createServer((req, res) =&gt; &#123; const url = req.url; const method = req.method; if (url === '/') &#123; res.write('&lt;html&gt;'); res.write('&lt;head&gt;&lt;title&gt;Enter Message&lt;/title&gt;&lt;/head&gt;'); res.write('&lt;body&gt;&lt;form action=\"/message\" method=\"post\"&gt;&lt;input type=\"text\" name=\"message\"&gt;&lt;button type=\"submit\"&gt;Send&lt;/button&gt;&lt;/form&gt;&lt;/body&gt;'); res.write('&lt;/html&gt;'); return res.end(); &#125; if (url === '/message' &amp;&amp; method === 'POST') &#123; const body = []; req.on('data', (chunk) =&gt; &#123; console.log(chunk); body.push(chunk); &#125;); req.on('end', () =&gt; &#123; const parsedBody = Buffer.concat(body).toString(); const message = parsedBody.split('=')[1]; console.log(message); fs.writeFileSync('message.txt', message); &#125;); res.statusCode = 302; res.setHeader('Location', '/'); return res.end(); &#125; res.setHeader('Content-Type', 'text/html'); res.write('&lt;html&gt;'); res.write('&lt;head&gt;&lt;title&gt;My First Page&lt;/title&gt;&lt;/head&gt;'); res.write('&lt;body&gt;&lt;ht&gt;Hello from my NOde.js Server&lt;/ht&gt;&lt;/body&gt;'); res.write('&lt;/html&gt;'); res.end();&#125;);server.listen(3000); 了解事件驅動代碼的執行本章節介紹了事件驅動代碼的執行規則以及順序舉例來說，如果我們對目前的代碼做了一些調整，如下:req.on('end', () =&gt; &#123; const parsedBody = Buffer.concat(body).toString(); const message = parsedBody.split('=')[1]; fs.writeFileSync('message.txt', message); res.statusCode = 302; res.setHeader('Location', '/'); return res.end();&#125;); 首先，在一開始我們就引用了 http module 以及 fs module ，然後我們利用 http module 來建立一個 server ，並且讓這個 server 聽 3000 port 。當有任何 requets 呼叫這個 server 時，都會觸發這個 server 。我們帶入 request 以及 response ， 在 server 內可以用。首先，我們定義發請求的 url 為常數 url ， 再來，我們定義發請求的方法為常數 method如果常數 url 等於 / 時，會觸發一系列的 response ，並且 return res.end(); 做結束。如果常數 url 等於 /message 且常數 method 等於 POST 的話，定義常數 body 為 array。接下來進入事件驅動, 當開始解析 request 時，我們帶入 chunk ，印出 chunk ，並且將 chunk 放入一個叫做 body 的 array 常數另外一個事件，當 request 解析完成後， 定義一個常數叫做 parsedBody ，它是利用 buffer 物件來將在常數 body 內的所有 chunk 串連起來，然後變成 string在定義一個常數叫做 message ， 首先， 常數 parsedBody 是一個 string ，我們將這個 string 用 = 為分隔點，將這個 string 變成 array 之後，取 [1] ，就是這個 array 的第二項資料，這個就是常數 message 的值接下來，我們利用一開始引用的 fs module ， 將常數 message 的內容寫入一個叫做 message.txt 的檔案。接下來，定義 response 的 status code 為 302定義 response 跳轉的 location 為 /最後， return res.end(); 出了事件驅動之後，是定義 header ，然後定義另外一些 html 的 response ， 最後是 res.end(); Server 內的執行部分到此做一個結尾。 由於 js 的事件驅動屬性，事件 end 並不會先被執行，反之，後面的代碼會先被執行。所以這個更動會造成一個錯誤，那就是當 res.end(); 已經被執行了，才開始執行 end 事件內的 setHeader 以及 statusCode ，這樣就會造成如下的錯誤 如果，我們在 end 事件之下加了 return ，那錯誤就不會出現 ， 修改代碼如下：req.on('end', () =&gt; &#123; const parsedBody = Buffer.concat(body).toString(); const message = parsedBody.split('=')[1]; fs.writeFileSync('message.txt', message); res.statusCode = 302; res.setHeader('Location', '/'); return res.end();&#125;);return; 因為 end 事件之下的 res.setHeader(&#39;Content-Type&#39;, &#39;text/html&#39;); 就不會被執行了。注意！ 在 return 的當下，其實 end 的監聽事件是還沒有被執行的，但是當 server 裡頭的動作執行完畢之後， request 被解析完成，觸發了 end 的監聽事件，然後才開始執行這個事件裡頭的動作。 至此，此 Episode 告一段落，截至目前的完整程式碼如下：const http = require('http');const fs = require('fs');const server = http.createServer((req, res) =&gt; &#123; const url = req.url; const method = req.method; if (url === '/') &#123; res.write('&lt;html&gt;'); res.write('&lt;head&gt;&lt;title&gt;Enter Message&lt;/title&gt;&lt;/head&gt;'); res.write('&lt;body&gt;&lt;form action=\"/message\" method=\"post\"&gt;&lt;input type=\"text\" name=\"message\"&gt;&lt;button type=\"submit\"&gt;Send&lt;/button&gt;&lt;/form&gt;&lt;/body&gt;'); res.write('&lt;/html&gt;'); return res.end(); &#125; if (url === '/message' &amp;&amp; method === 'POST') &#123; const body = []; req.on('data', (chunk) =&gt; &#123; console.log(chunk); body.push(chunk); &#125;); req.on('end', () =&gt; &#123; const parsedBody = Buffer.concat(body).toString(); const message = parsedBody.split('=')[1]; fs.writeFileSync('message.txt', message); res.statusCode = 302; res.setHeader('Location', '/'); return res.end(); &#125;); return; &#125; res.setHeader('Content-Type', 'text/html'); res.write('&lt;html&gt;'); res.write('&lt;head&gt;&lt;title&gt;My First Page&lt;/title&gt;&lt;/head&gt;'); res.write('&lt;body&gt;&lt;ht&gt;Hello from my NOde.js Server&lt;/ht&gt;&lt;/body&gt;'); res.write('&lt;/html&gt;'); res.end();&#125;);server.listen(3000); Blocking and Non-Blocking Code所以，fs.writeFile 跟 fs.writeFileSync 差在哪？fs.writeFileSync 會待這個檔案寫入的任務完成之後，才會繼續向後執行，而 fs.writeFIle 會異步執行，儘管檔案寫入的任務還沒完成，程式一樣會繼續向後執行，並且，我們可以在任務完成時執行一項 callback ，修改代碼如下： req.on('end', () =&gt; &#123; const parsedBody = Buffer.concat(body).toString(); const message = parsedBody.split('=')[1]; fs.writeFile('message.txt', message, (err)=&gt;&#123; res.statusCode = 302; res.setHeader('Location', '/'); return res.end(); &#125;);&#125;); 從以上的代碼來看，當程式執行到寫入檔案那一行， fs.writeFile ，程式不會停下來等待 fs.writeFile 執行完畢，反之，程式會繼續往下跑 ， 而當 fs.writeFile 執行完畢後，會觸發我們設定的 callback ，進而執行以下的代碼res.statusCode = 302;res.setHeader('Location', '/');return res.end(); 簡述事件迴圈本章節主要參閱官方文件 ， 以及這位大大的文章 。在本章節中，主要是搞懂 Node.js 中事件迴圈的概念。 Node.js 的架構圖 上圖可以看到，除了 V8 Engine ， Node.js 使用了 libuv 來處理 I/O 的部分，提供了 asynchronous 以及 Non-Blocking API 以及事件迴圈 ， 下面提到的事件迴圈，主要與 libuv 有關。 什麼是事件迴圈？事件迴圈，藉由將工作量分擔給 Kernel 來處理，使 Node.js 得以做非阻塞 I/O 的操作，儘管 JsvaScript 是單線程的。 因為目前新型的 Kernel 都是多線程的，它們可以在背景運行多個程序。當其中一個程序完成了， Kernel 會通知 Node.js ，所以 Node.js 會調整將適合的 callback 加到 poll 階段的 queue 當中 ，這些 callback 最終將會被執行。 深談事件迴圈以下是事件迴圈各個階段圖，以及運行順序 每個階段都有自己的 先進先出 的要被執行的 callback queue 。每個階段都有自己特別的運行方式，一般來說，當事件迴圈跑到一個特定的階段，事件迴圈將會執行這個特定階段裡頭的操作，然後執行它的 callback ，這個執行的動作會重複，直到該階段內的 callback 都被執行完畢了，或者已經達到最大的執行數量。當 queue 裡頭的工作都被處理完了，或者已達最大執行數量限制，事件迴圈會進入下一個階段，反覆循環。 因為上述提到的這些程序很有可能排定更多的程序，且由 poll 階段處理的事件將被 kernel 佇列著 ， 所以 poll 事件可以在被佇列的同時也被執行。 造成的結果是，一個耗時較長的 callback ， 會允許 poll 階段執行的久一點，甚至讓 timer 階段的工作等待。 各階段概述 timers: 這個階段主要處理 setTimeout() 以及 setInterval() 排程的 callback I/O callbacks: 除了 timers, setImmediate(), close 之外的多數類型 idle, prepare: 只供內部使用 poll: 取回新的 I/O 事件; 某些情況， node 將會阻塞在這裡 check: setImmediate() callbacks 將會在這階段被觸發 close callbacks: socket, on … libuv 各階段詳述timers:簡單來說， timers 階段將處理 setTimeout() 以及 setInterval() 的工作。 timers 並不保證可以準確地在給予的時間點執行 callback ， 反之 ，給予的時間更像是一個最低的門檻，唯有過了這個給予的時間點， callback 才會被執行，這視乎當時的工作狀態。 系統的排程或者是其他 callback 的運行都可能會延遲 timers 執行的確切時間。總而言之，過了指定的時間點之後， timers 會盡可能地盡快執行排程的 callback可以看看以下的範例： var fs = require('fs');function someAsyncOperation (callback) &#123; // Assume this takes 0 ms to complete fs.readFile('/path/to/file', callback);&#125;function anotherAsyncOperation (callback) &#123; // Assume this takes 0 ms to complete fs.readFile('/path/to/file', callback);&#125;var timeoutScheduled = Date.now();setTimeout(function () &#123; var delay = Date.now() - timeoutScheduled; console.log(delay + \"ms have passed since I was scheduled\");&#125;, 100);// do someAsyncOperation which takes 200 ms to completesomeAsyncOperation(function () &#123; var startCallback = Date.now(); // do something that will take 10ms... while (Date.now() - startCallback &lt; 200) &#123; ; // do nothing &#125;&#125;);// do anotherSyncOperation which takes 200 ms to completeanotherAsyncOperation(function () &#123; var startCallback = Date.now(); // do something that will take 10ms... while (Date.now() - startCallback &lt; 200) &#123; ; // do nothing &#125;&#125;); 從上面的範例中可以看到， setTimeout 任務原定 100 ms 之後被執行，但是 someAsyncOperation 任務花了 0 + 200 ms ，當執行這個任務時，事件迴圈正處在 poll 階段，所以在一個循環中, 需等待 poll 階段中的任務完全處理完畢，或者達到最大處理數量限制。所以在上面的範例中，需等待 poll 階段的任務 someSyncOperation 以及 anotherSyncOperation 被執行完畢，總共花費 400 ms 左右， 之後才會執行 setTimeout() 的任務。 I/O callbacks這個階段主要執行系統端操作的 callbacks, 像是 TCP 錯誤。舉例來說，當試圖連接時，如果一個 TCP socket 接收到 ECONNREFUSED, 某個 *nix 系統想要等待並回報錯誤，這些都會在 I/O callbacks 階段被佇列。 pollpoll 階段有兩種主要功能: 替時間點已經到的 timers 執行腳本 處理 poll queue 當中的事件 當事件進入 poll 階段，且沒有 timers 排程事件 ， 下面兩件事中，其中一件會發生: 如果 poll 階段不為空，事件迴圈將會執行佇列中的所有 callbacks ，又或者達到最大 callbacks 處理上限 如果 poll 階段為空，以下兩件事中，其中一件會發生： 如果腳本已經被 setImmediate() 排程，事件迴圈將會結束 poll 階段，並且繼續進入到 check 階段來處理該佇列中的排程 如果腳本沒有 setImmediate() 的排程，那事件迴圈將會等待新的事件被加入到佇列，然後立即處理他們 一旦 poll 循環為空，事件迴圈將會檢查 timer 中有沒有可以執行的 callback。 如果有一個或多個可以執行了, 事件迴圈會回去執行 timer 階段的 callback check這個階段允許在 poll 階段完成後，立即執行 callback。如果 poll 階段處於空轉，或者已經有 setImmediate() 的排程，事件迴圈將會繼續進入到 check 階段，而不會等待。 setImmediate() 事實上，是一個很特別的 timer 階段，它跟 timer 在事件迴圈內跑在不同的階段。 它使用 libuv API ，這個 API 排程 callback 使之在 poll 階段結束後被執行 通常，事件迴圈會停在 poll 階段等待新的 request 或 connection ，但是當 setImmediate() 有排程，且 poll 階段處於空轉, 那事件迴圈將會結束 poll 階段，並且進入 check 階段 close callbacks如果一個 socket 或 handle 忽然被關閉， close 事件將會被置於這個階段，除非我們指定 process.nextTick 來執行它 setImmediate() vs setTimeout()setImmediate() 和 setTimeout() 很類似，但根據被呼叫的時機不一樣，行為也不同。 setImmediate() 被設計為，一旦 poll 階段結束時執行 setTimeout() 排程任務，在特定的時間之後執行 兩者之間執行的順序，根據被呼叫時的情況而有所不同。如果兩者都在主模組的時候被呼叫，那順序將由當時的程序的表現所決定，意思就是說，順序無法預測。範例如下：// timeout_vs_immediate.jssetTimeout(function timeout () &#123; console.log('timeout');&#125;,0);setImmediate(function immediate () &#123; console.log('immediate');&#125;); 然而，如果兩者是在 I/O cycle 中被呼叫，那 sedImmediate() 將會優先於 setTimeout() // timeout_vs_immediate.jsvar fs = require('fs')fs.readFile(__filename, () =&gt; &#123; setTimeout(() =&gt; &#123; console.log('timeout') &#125;, 0) setImmediate(() =&gt; &#123; console.log('immediate') &#125;)&#125;) 對比 setTimeout() , 使用 setImmediate() 的主要優勢為，如果在 I/O cycle 中， setImmediate() 將會被優先執行，不管 setTimeout() 有幾個 process.nextTick()理解 process.nextTick()你可能已經注意到， process.nextTick() 並沒有被顯示在圖表上，儘管它也是 asynchronous API 的一部分。 這是因為 process.nextTick() 技術上來說不算是事件迴圈的一部分。 nextTickQueue 將會在目前操作完成後，立即被執行，不管目前是在事件迴圈內的哪一個循環。 看看我們的圖表，不管在什麼時候，只要你在特定的階段呼叫 process.nextTick() ， 所以經由 process.nextTick() 送出的 callbacks 將會在事件迴圈啟動下一個階段之前全部都處理完畢。 這樣的模式可能會造成一些不好的情況發生，因為如果你遞迴的使用 process.nextTick() callback ，就會造成所謂的 I/O 飢餓 ，事件迴圈將會無法進入 poll 階段 為什麼這樣的行為會被容許？你可能會想，為什麼這樣的行為在 Node.js 終會被容許？ Node.js 部分的設計哲學是， API 總是異步的，不管是否必要，可以參考以下範例:// this has an asynchronous signature, but calls callback synchronouslyfunction someAsyncApiCall (callback) &#123; callback(); &#125;;// the callback is called before `someAsyncApiCall` completes.someAsyncApiCall(() =&gt; &#123; // since someAsyncApiCall has completed, bar hasn't been assigned any value console.log('bar', bar); // undefined&#125;);var bar = 1; 如果我們執行上面的代碼，會出現輸出如下： 因為 someAsyncApiCall 並沒有做任何異步的動作，照同步的流程跑到 console.log 時， bar 還沒有被定義 如果我們將代碼改成以下：function someAsyncApiCall (callback) &#123; process.nextTick(callback);&#125;;someAsyncApiCall(() =&gt; &#123; console.log('bar', bar); // 1&#125;);var bar = 1; 可以得到以下的輸出： 如上所述， process.nextTick() 的執行時間，是在當前的階段內所有的工作都完成了，在進入下個階段之前，會將所有的 process.nextTick() 處理完畢。在上面的例子中， process.nextTick() 會等到所有在此階段的代碼都被執行完畢，也就是待 var bar = 1 執行後，才去執行這個 callback ，所以不會出現 undefined 的情況。請注意！這沒有最大處理數量限制，所以如果利用 process.nextTick() 指派遞迴任務，那就會造成 I/O 飢餓 情況， 事件迴圈將無法接收到新的 request 一個 tick 到底是多長？一個 tick 的時間長度，是 Event Loop 繞完一圈，把所有 queues 中的 callbacks 依序且同步地執行完，所消耗的總時間。因此，一個 tick 的值是不固定的。可能很長，可能很短，但我們希望它能盡量地短。 process.nextTick() vs setImmediate()千萬不要被這兩個階段的命名搞混了！ process.nextTick():在當前階段結束前執行完畢 setImmediate():在下一個階段，或者下一個事件迴圈的 tick 中執行 基本上，這兩個命名應該是要互換。 process.nextTick() 比 setImmediate() 更快地被觸發。這算是一個很難更動的部分，因為當初命名錯誤之後，隨時時間的推移，越來越多 npm 的 package 都是使用這樣的命名，所以一旦這命名變更了，影響會非常的大。 官方文件上建議開發者，在任何情況中，都使用 setImmediate() ，因為它可以更簡單的被邏輯思考，然後在不同的環境上，有著更廣的相容性。 Promise從下面的原始碼可以看到 Promise ， 或者又稱為 microtasks 的執行優先順序依照原始碼的執行順序來看，在一個階段結束之前，process.nextTick() 會先被執行，緊接著, 執行 Promise 。 startup.processNextTick = function() &#123; var nextTickQueue = []; // Callbacks 會排進這個 queue!! var pendingUnhandledRejections = []; var microtasksScheduled = false; var _runMicrotasks = &#123;&#125;; // ... 略 process.nextTick = nextTick; // nextTick 函式在下面 // ... 略 // process._setupNextTick 在 node.cc 中, 我認為意思到了, 就不用再挖下去了 const tickInfo = process._setupNextTick(_tickCallback, _runMicrotasks); _runMicrotasks = _runMicrotasks.runMicrotasks; // ... 略 function _tickCallback() &#123; var callback, args, tock; do &#123; while (tickInfo[kIndex] &lt; tickInfo[kLength]) &#123; // callbacks 從 queue 中一個一個被挖出來執行 tock = nextTickQueue[tickInfo[kIndex]++]; callback = tock.callback; args = tock.args; if (args === undefined) &#123; nextTickCallbackWith0Args(callback); &#125; else &#123; switch (args.length) &#123; case 1: nextTickCallbackWith1Arg(callback, args[0]); // ... &#125; &#125; if (1e4 &lt; tickInfo[kIndex]) tickDone(); &#125; tickDone(); // process.nextTick 的 callbacks 跑完, 接著跑 Promise 的 microtasks _runMicrotasks(); emitPendingUnhandledRejections(); &#125; while (tickInfo[kLength] !== 0); &#125; // ...略 function nextTick(callback) &#123; var args; if (arguments.length &gt; 1) &#123; args = []; for (var i = 1; i &lt; arguments.length; i++) args.push(arguments[i]); &#125; // 將 callback 連它的 arguments 用一個物件存起來推進 queue nextTickQueue.push(new TickObject(callback, args)); tickInfo[kLength]++; &#125; // ... &#125;; 事件迴圈總結 順序:timers &rarr; I/O callbacks &rarr; idle, pare &rarr; poll &rarr; check &rarr; close callbacks &rarr; timers … 往復循環 順序細節 timers 設定的時間過了之後，才會被’盡快’的執行。如果 poll 階段內還有工作還沒做完，會先做完，才會執行 timers 的工作，所以可能會延遲 當處於 I/O 程序中，比如說， fs 模組中， setImmediate() 順序一定大於 setTimeout() ，因為 check 階段緊接在 poll 階段之後 當處於主要模組中， setImmediate() 以及 setTimeout 的優先順序，取決於運行狀況，這個狀態下，次序無法確定 process.nextTick() 將在當前階段的工作結束前，在進入下一個階段之前執行, 所以他的優先性是第一名的 promise 的執行次序緊接在 process.nextTick() 之後，也是在當前階段結束前執行完畢 Express.js建立一個 app server npm install --save 2.npm install --save express npm install --save-dev nodemon Set script as nodemon fileName.js 指定 status coderes.status (statusCode); Promise以下的範例中， function test 中，我們 return 了一個 Promise ，如果帶入 test function 中的 argument 是 1 ，那就走 resolve 路線 ， 而除了 1 之外所有的 argument, 都走 reject 路線。在 function main 中, 我們使用了 function test, 並帶入 argument 1, Ray 個人覺得這有點像是 PHP 當中的 ternary 用法。當 argument 等於我們在 promise 當中指定的 1 時，走 resolve 路線, 而 then 就是當 promise 為 resolve 路線時該做的事。當 argument 等於是除了 1 之外的任何數，也就是會走 promise 當中的 reject 路線, 此時將會執行 catch 的動作。我們在 promise 當中指定，當走 resolve 路線時，輸出為字串 Success, 所以在 then 的 closure 當中，被帶入的 argument 就是 Success反之，當走 reject 路線時，輸出字串為 Error, 所以在 catch 的 closure 當中，被帶入的 argument 則為 Errorfunction test(number) &#123; return new Promise((resolve, reject) =&gt; &#123; if (number === 1) &#123; resolve(\"Success\") &#125; else &#123; reject(\"Failed\") &#125; &#125;)&#125;function main() &#123; test(1).then((result) =&gt; &#123; // result === \"Success\" console.log(result) &#125;).catch((error) =&gt; &#123; // 不會被執行, 因為狀態是成功 &#125;) test(2).then((result) =&gt; &#123; // 不會被執行, 因為狀態是成功 console.log(result) &#125;).catch((error) =&gt; &#123; // error === \"Failed\" console.log(error) &#125;)&#125; 建立 Datastore Model// 從 google SDK 引用 Datastore functionconst &#123;Datastore&#125; = require('@google-cloud/datastore');// 輸入 project_idconst projectId = 'balmy-sanctuary-238903';// 初始一個 Datastore instanceconst datastore = new Datastore(&#123; projectId: projectId,&#125;);// 匯出這個 modulemodule.exports = datastore; 建立一個 Controller// 匯出這個 functionexports.test = function (req, res) &#123; async function quickStart() &#123; // The kind for the new entity const kind = 'abc'; // The name/ID for the new entity const name = 'sampletask1'; // The Cloud Datastore key for the new entity const taskKey = datastore.key([kind, name]); // Prepares the new entity const task = &#123; key: taskKey, data: &#123; description: 'Buy milk', &#125;, &#125;; console.log(datastore.key(['name', 'kind'])); // Saves the entity await datastore.save(task); console.log(`Saved $&#123;task.key.name&#125;: $&#123;task.data.description&#125;`); res.send(`Saved $&#123;task.key.name&#125;: $&#123;task.data.description&#125;`); &#125; quickStart().catch(console.error);&#125;; Routevar express = require('express');var router = express.Router();// 導入 controller 模組, 並給予名稱var datastore = require('../controllers/datastoreController');/* GET home page. */router.get('/', function(req, res, next) &#123; res.render('index', &#123; title: 'Express' &#125;);&#125;);// 建一個 router, 並且導向 datastoreController 裡頭的 test functionrouter.get('/test', datastore.test);module.exports = router; Root address// 找一個地方新增一個檔案，輸入以下的 code// 之後我們就可以在任何一個檔案中，透過 require 這個檔案來 const rootDirconst path = require('path');module.exports = path.dirname('/Users/ray/code/datastore/app.js'); 若我們 console.log 上面 exports 的值，可以得到該專案下的 root 位址 Path利用 path module 來指定路徑// p 會等於專案根目錄下, data 資料夾之下的一個叫做 `products.json` 的檔案// 專案根目錄請參考 `root address` 章節const p = path.join(rootDir, 'data', 'products.json') object.assign 可用來複製或覆蓋目標物件let exampleObject = &#123;a:1, b:2, c:3, c:4&#125;;let copy = object.assign(&#123;&#125;, exampleObject, &#123;a:4, b:4, c:4, d:4&#125;); test 用來確認該 string 是否符合該 regex pattenvar str = \"Hello world!\";// look for \"Hello\"var patt = /Hello/g;var result = patt.test(str);// result = true 時間var moment = require('moment-timezone');var test = moment(createdDate).tz(\"Asia/Taipei\").format('YYYY-MM-DD HH:MM:SS');console.log(test); // 2019-05-21 08:05:44 同時異步發多請求，並待全部有結果後繼續// 需安裝兩個套件 `request-promise` 以及 `p-limit`const request = require('request-promise');const pLimit = require('p-limit');class HealthCheckService &#123; static async getHealthCheckResults(sites) &#123;// 指定 limit 同時最多發十個 request const limit = pLimit(10);// 利用 map 從 sites 中拿到我們要發請求的 url// 然後利用套件 `limit` 來限制同時發請求的數量，再來使用 `request-promise` 套件來對上面拿到的 url 發請求 let promises = sites.map((site) =&gt; &#123; let url = `https://yourAPI?host=$&#123;site.host&#125;&amp;cname=$&#123;site.cname&#125;`; return limit(() =&gt; request(url)); &#125;);// 上面的每一個 promises, 都是一個請求。 現在我們利用 `Promise.all`, 待所有的結果都回來之後，在 return return await Promise.all(promises); &#125;&#125;","link":"/zh-tw/Node-js/"},{"title":"PayPal REST API 串接金流好簡單","text":"前言本篇將會分享，如何使用 PayPal REST API，來做到以下的動作： 建立授權訂單 授權 請款 退款 部分款項凍結 本篇屬於個人學習筆記，所以可能會參雜一些個人的專案內容，請選擇性參考。 安裝 PayPal REST API 官方 SDK本篇使用的為目前 PayPal 最新釋出的 SDK 版本 安裝composer require paypal/paypal-checkout-sdk 設定個人設定 安裝完成之後，可在 SDK 的資料夾底下，找到範例，如下圖： 設定 PayPalClient.php 檔案，如下: 申請開發者帳號並登入 建立一個App 取得 Client ID 以及 Secret 將取得的 Client ID 以及 Secret 填入， Ray 是設在環境變數 public static function environment()&#123; $clientId = env('PAYPAL_SANDBOX_API_ClientID'); $clientSecret = env('PAYPAL_SANDBOX_API_SECRET'); return new SandboxEnvironment($clientId, $clientSecret);&#125; 開始在上面提到的範例資料夾中，可以找到幾乎所有會用到的範例。這邊可以根據每個人的需求不同來客制，以下是 Ray 自己的版本任何疑惑，請參考 sample 裡頭的範例，以及官方文件如下:orderpayment order 跟 payment 的差異主要的差異如下： order： 只支援 PayPal 的會員。可以延後付款，並且視乎貨物的狀態做部分的請款 payment: 可以延後付款，但不可以分批請款。 詳細的介紹可以參考原文解說 建立訂單 ( order )public function createOrder($toBeSavedInfo, Recipient $recipient, $debug = false)&#123; // 引用SDK $request = new OrdersCreateRequest(); $request-&gt;headers[\"prefer\"] = \"return=representation\"; // 這邊的RequestBody等等會貼在下面 $request-&gt;body = self::buildRequestBody($toBeSavedInfo, $recipient); // 這邊引用剛剛設定好的 PayPalClient $client = PayPalClient::client(); $response = $client-&gt;execute($request); if ($debug) &#123; print \"Status Code: &#123;$response-&gt;statusCode&#125;\\n\"; print \"Status: &#123;$response-&gt;result-&gt;status&#125;\\n\"; print \"Order ID: &#123;$response-&gt;result-&gt;id&#125;\\n\"; print \"Intent: &#123;$response-&gt;result-&gt;intent&#125;\\n\"; print \"Links:\\n\"; foreach ($response-&gt;result-&gt;links as $link) &#123; print \"\\t&#123;$link-&gt;rel&#125;: &#123;$link-&gt;href&#125;\\tCall Type: &#123;$link-&gt;method&#125;\\n\"; &#125; // To toggle printing the whole response body comment/uncomment below line echo json_encode($response-&gt;result, JSON_PRETTY_PRINT), \"\\n\"; &#125; // 建立建立完成後，我只取讓使用者用來確認的連結，預設 PayPal 提供了很多的連結，但是其他的我們都可以靠 API 來達成。 foreach (($response-&gt;result-&gt;links) as $link) &#123; if ($link-&gt;rel === 'approve') &#123; $linkForApproval = $link-&gt;href; break; &#125; &#125; // 這邊取得建立訂單之後的一些會用到的資訊，然後 return $toBeSavedInfo['payment_id'] = $response-&gt;result-&gt;id; $toBeSavedInfo['statusCode'] = $response-&gt;statusCode; $toBeSavedInfo['custom_id'] = $response-&gt;result-&gt;purchase_units[0]-&gt;custom_id; $toBeSavedInfo['PayPal_total_amount'] = $response-&gt;result-&gt;purchase_units[0]-&gt;amount-&gt;value; $toBeSavedInfo['orderStatus'] = $response-&gt;result-&gt;status; $toBeSavedInfo['linkForApproval'] = $linkForApproval; return $toBeSavedInfo;&#125; 下面是建立訂單功能會用到的 RequestBodypublic static function buildRequestBody($toBeSavedInfo, Recipient $recipient)&#123; // 這邊的設定，使得我們可以在 PayPal 的付款頁面，看到多個商品的明細 $item = []; $i = 1; foreach ($toBeSavedInfo['orders'] as $order) &#123; $item[] = [ 'name' =&gt; $order-&gt;item_name, 'description' =&gt; $order-&gt;item_description, 'sku' =&gt; $i, 'unit_amount' =&gt; [ 'currency_code' =&gt; $toBeSavedInfo['mc_currency'], 'value' =&gt; $order-&gt;unit_price, ], 'quantity' =&gt; $order-&gt;quantity, ]; $i ++; &#125; // 這邊我們指定 intent ，我設在環境變數， return [ 'intent' =&gt; env('PAYPAL_SANDBOX_INTENT_OF_CREATED_ORDERS'), 'application_context' =&gt; [ 'return_url' =&gt; env('PAYPAL_SANDBOX_RETURN_URL'), 'cancel_url' =&gt; env('PAYPAL_SANDBOX_CANCEL_URL'), 'brand_name' =&gt; env('APP_NAME'), 'locale' =&gt; env('PAYPAL_SANDBOX_LOCALE'), 'landing_page' =&gt; env('PAYPAL_SANDBOX_LANDING_PAGE'), 'shipping_preferences' =&gt; env('PAYPAL_SANDBOX_SHIPPING_PREFERENCES'), 'user_action' =&gt; env('PAYPAL_SANDBOX_USER_ACTION'), ], // 這邊可以設定 purchase_unit ，一個 purchase_unit 裡面可以設定税、運費、等等，這邊省略 'purchase_units' =&gt; [ [ 'custom_id' =&gt; $toBeSavedInfo['merchant_trade_no'], 'amount' =&gt; [ 'currency_code' =&gt; $toBeSavedInfo['mc_currency'], 'value' =&gt; $toBeSavedInfo['total_amount'], 'breakdown' =&gt; [ 'item_total' =&gt; [ 'currency_code' =&gt; $toBeSavedInfo['mc_currency'], 'value' =&gt; $toBeSavedInfo['total_amount'], ], ], ], 'items' =&gt; $item, // 這邊可以指定收件人 'shipping' =&gt; array( 'name' =&gt; array( 'full_name' =&gt; $recipient-&gt;name, ), 'address' =&gt; array( 'address_line_1' =&gt; $recipient-&gt;others, 'admin_area_2' =&gt; $recipient-&gt;district, 'admin_area_1' =&gt; $recipient-&gt;city, 'postal_code' =&gt; $recipient-&gt;postcode, 'country_code' =&gt; $recipient-&gt;country_code, ), ), ], ], ];&#125; 授權 ( authorization )接下來，我們要使用 REST API 中的特別功能， Authorization 。 授權之後，我們有29天的時間可以使用 capture 來從使用者的帳戶裡面扣錢。 不過呢，雖然有效期限是29天，但是 PayPal 只能保證給予單次授權開始計算的三天內，使用者的帳戶裡頭會有足夠的金額。 意思就是說呢，在 authorization 開始計算的三天， PayPal 會暫時性的在付款方的 PayPal 帳戶中，凍結申請的款項，記住只有三天哦！ 這三天稱為 honor period 。 在首次的 authorization 之後，我們可以申請多次，最多10次的 authorization ，稱為 reauthorize 。如果你覺得這樣次數還是太少，可以通過跟 PayPal 客服聯絡的方式，將次數提升到最多99次！ 其實只要將時間算好，10次的授權應該很夠用了。平均三天授權一次，10次也一個月了，海運都到了！ 授權可以更改金額，最高可以授權115% 或 不超過 75 USD 的金額，如果運費或者稅務方面，或是其他原因造成費用有些許變動的話，可以透過重新授權來更改費用。 細節可以參考官方文件 授權的範例如下:記住這是 Ray 自己的版本，大家可以參考官方的範例，再依照自己的需求作更改，或者乾脆取SDK裡面的功能自己寫一個！ 這才是我認為的最佳解！ /** * This function can be used to perform authorization on the approved order. * Valid Approved order id should be passed as an argument. */ // 這邊我們可以變更授權的金額，根據你的需求public static function authorizeOrder($orderId, $amount = null, $debug = false)&#123; $request = new OrdersAuthorizeRequest($orderId); // RequestBody 跟上面提到的差不多，可以參考官方的範例！ $request-&gt;body = self::buildRequestBodyForAuthorizeOrder($amount); $client = PayPalClient::client(); $response = $client-&gt;execute($request); if ($debug) &#123; print \"Status Code: &#123;$response-&gt;statusCode&#125;\\n\"; print \"Status: &#123;$response-&gt;result-&gt;status&#125;\\n\"; print \"Order ID: &#123;$response-&gt;result-&gt;id&#125;\\n\"; print \"Authorization ID: &#123;$response-&gt;result-&gt;purchase_units[0]-&gt;payments-&gt;authorizations[0]-&gt;id&#125;\\n\"; print \"Links:\\n\"; foreach ($response-&gt;result-&gt;links as $link) &#123; print \"\\t&#123;$link-&gt;rel&#125;: &#123;$link-&gt;href&#125;\\tCall Type: &#123;$link-&gt;method&#125;\\n\"; &#125; print \"Authorization Links:\\n\"; foreach ($response-&gt;result-&gt;purchase_units[0]-&gt;payments-&gt;authorizations[0]-&gt;links as $link) &#123; print \"\\t&#123;$link-&gt;rel&#125;: &#123;$link-&gt;href&#125;\\tCall Type: &#123;$link-&gt;method&#125;\\n\"; &#125; // To toggle printing the whole response body comment/uncomment below line echo json_encode($response-&gt;result, JSON_PRETTY_PRINT), \"\\n\"; &#125; return $response;&#125; 授權之後呢，我們需要驗證授權是否成功，所以我利用回傳的response，寫一個驗證的 function，如下：public static function checkIfAuthorizedSuccessfully($response)&#123; $newPayPal = (new NewPayPal())-&gt;where('payment_id', request()-&gt;token)-&gt;first(); // 確認授權是否完成 if (($response-&gt;result-&gt;status) !== 'COMPLETED') return 'Authorization isn\\'t completed'; // 確認授權是否已開始 if (($response-&gt;result-&gt;purchase_units[0]-&gt;payments-&gt;authorizations[0]-&gt;status) !== 'CREATED') return 'Authorization was not created'; // 確認幣別是否一致 if (($response-&gt;result-&gt;purchase_units[0]-&gt;payments-&gt;authorizations[0]-&gt;amount-&gt;currency_code) !== ($newPayPal-&gt;mc_currency)) return 'The currency is mismatched'; // 確認授權金額是否正確。這邊是我自己的版本，有需要變動授權金額的話，這邊可以變一下。 if (intval($response-&gt;result-&gt;purchase_units[0]-&gt;payments-&gt;authorizations[0]-&gt;amount-&gt;value) !== ($newPayPal-&gt;total_amount)) return 'The total amount is not correct';&#125; 提款 ( capture ) 就像上面提到的，成功授權之後，我們可以在29天內隨時向買家請款。 不過 PayPal 只有保證三天買家帳戶裡頭會有足夠的金額，又稱 honor period 一般來說，我們只要把時間算好，可以透過 授權 以及 再次授權 ，將 這筆金額臨時凍結30天。 以下是提款 ( capture ) 的範例：public static function captureAuthorization(NewPayPal $newPayPal, $final_capture = false, $debug = false)&#123; $NewPayPal = (new NewPayPal)-&gt;where('merchant_trade_no', $newPayPal-&gt;merchant_trade_no)-&gt;first(); // 提款功能，需要帶入授權id $request = new AuthorizationsCaptureRequest($newPayPal-&gt;authorization_id); // 這邊帶入要提款的金額，如上所敘，提款金額是可以分批次的！ Final_capture 如果設定為true的話，會結束此次授權，此次授權之後無法再進行提款，若要提款需要再重新授權。 $request-&gt;body = self::buildRequestBodyForCaptureAuthorization($NewPayPal-&gt;to_be_captured_amount, $final_capture, $newPayPal-&gt;mc_currency); $client = PayPalClient::client(); $response = $client-&gt;execute($request); if ($debug) &#123; print \"Status Code: &#123;$response-&gt;statusCode&#125;\\n\"; print \"Status: &#123;$response-&gt;result-&gt;status&#125;\\n\"; print \"Capture ID: &#123;$response-&gt;result-&gt;id&#125;\\n\"; print \"Links:\\n\"; foreach ($response-&gt;result-&gt;links as $link) &#123; print \"\\t&#123;$link-&gt;rel&#125;: &#123;$link-&gt;href&#125;\\tCall Type: &#123;$link-&gt;method&#125;\\n\"; &#125; // To toggle printing the whole response body comment/uncomment below line echo json_encode($response-&gt;result, JSON_PRETTY_PRINT), \"\\n\"; &#125; return $response;&#125; 以下是提款 ( capture ) 的 RequestBodypublic static function buildRequestBodyForCaptureAuthorization($amount = null, $final_capture = false, $currency = 'USD')&#123; if ($amount != null) &#123; // 指定提款的金額與幣別，需要跟授權的一致 return [ \"amount\" =&gt; [ 'currency_code' =&gt; $currency, 'value' =&gt; $amount, ], 'final_capture' =&gt; $final_capture ]; &#125; return \"&#123;&#125;\";&#125; 以下是提款的邏輯Ray 的邏輯是設定一個提款期限來決定什麼時候提款，因為每次退款都會扣掉手續費，所以 Ray 的想法是利用金額凍結取代退款，在提款期限之前，如果買家申請退款的話， Ray 這邊只需要去更改要提款的最終數字，這樣就可以避免掉手續費的部分。 Ray 自己設定的容許退款期限為七天，所以 Ray 會將這筆金額凍結七天，在七天後等到一切都確定了再依照最終的提款金額一次提款。所以下面的function每天都會跑一次，如果已經過了提款期限就會真正執行提款，並更新該訂單在所有資料庫裡頭相對應的狀態。public static function dailyCaptureAuthorization()&#123; $toBeCapturedPayments = NewPayPal::whereNotNull(&apos;authorization_id&apos;)-&gt;whereNull(&apos;capture_id&apos;)-&gt;where(&apos;to_be_captured_date&apos;, &apos;&lt;&apos;, Carbon::now()-&gt;toDateTimeString())-&gt;get(); foreach ($toBeCapturedPayments as $toBeCapturedPayment) &#123; $response = NewPayPal::captureAuthorization($toBeCapturedPayment); if (($response-&gt;result-&gt;status) === &apos;COMPLETED&apos;) &#123; $toBeCapturedPayment-&gt;update([&apos;capture_id&apos; =&gt; $response-&gt;result-&gt;id, &apos;status&apos; =&gt; 7]); foreach ($toBeCapturedPayment-&gt;orderRelations as $orderRelation) &#123; if (($orderRelation-&gt;status == 5) || ($orderRelation-&gt;status == 6)) &#123; $orderRelation-&gt;order-&gt;update([&apos;status&apos; =&gt; 7]); $orderRelation-&gt;update([&apos;status&apos; =&gt; 7]); &#125; &#125; &#125; &#125;&#125; 退款 ( refund ) 退款的規則是，可以針對特定授權，進行一次性或者分批次的退款。 若屬於分批次，可以指定退款金額 若想要一次性，可以將整個 RequestBody 留空，像官方範例那樣public static function refundOrder($captureId, $amount, $currency, $debug = false)&#123; $request = new CapturesRefundRequest($captureId); // 這邊帶入指定的退款金額以及幣別，幣別必須要跟授權的一樣哦 $request-&gt;body = self::buildRequestBodyForRefundOrder($amount, $currency); $client = PayPalClient::client(); $response = $client-&gt;execute($request); if ($debug) &#123; print \"Status Code: &#123;$response-&gt;statusCode&#125;\\n\"; print \"Status: &#123;$response-&gt;result-&gt;status&#125;\\n\"; print \"Order ID: &#123;$response-&gt;result-&gt;id&#125;\\n\"; print \"Links:\\n\"; foreach ($response-&gt;result-&gt;links as $link) &#123; print \"\\t&#123;$link-&gt;rel&#125;: &#123;$link-&gt;href&#125;\\tCall Type: &#123;$link-&gt;method&#125;\\n\"; &#125; // To toggle printing the whole response body comment/uncomment below line echo json_encode($response-&gt;result, JSON_PRETTY_PRINT), \"\\n\"; &#125; return $response;&#125; 以下是退款的 RequestBodypublic static function buildRequestBodyForRefundOrder($amount = null, $currency = 'USD', $final_capture = false)&#123; // 若金額有指定就為指定值，若無指定便為預設格式 if ($amount != null) &#123; return [ \"amount\" =&gt; [ 'currency_code' =&gt; $currency, 'value' =&gt; $amount, ], 'final_capture' =&gt; $final_capture ]; &#125; return \"&#123;&#125;\";&#125; 退款的邏輯 相對應提款時所做的操作，在商家真正對買家做出提款之前，買家所申請的退款請求都只是去更改資料庫的數字。 如果過了七天，但實屬特殊案例，買家也還是可以申請退款，不過到時候就會有手續費產生 以上邏輯只適用於 PayPal ，因為本專案整合兩家金流，所以上面的邏輯並不適用於歐付寶，不過總體來說，對買家來說都是沒有影響的。public static function refund(Order $order, NewPayPal $paymentServiceInstance, OrderRelations $orderRelation)&#123; // 當該申請訂單為已授權，但尚未請款 if (($paymentServiceInstance-&gt;capture_id === null) &amp;&amp; ($paymentServiceInstance-&gt;authorization_id !== null)) &#123; // 如上所敘，我們只更新資料庫的請款金額 $paymentServiceInstance-&gt;update([ &apos;to_be_captured_amount&apos; =&gt; $paymentServiceInstance-&gt;to_be_captured_amount - $order-&gt;total_amount, &apos;total_amount&apos; =&gt; $paymentServiceInstance-&gt;total_amount - $order-&gt;total_amount ]); $order-&gt;update([&apos;status&apos; =&gt; 4]); $orderRelation-&gt;update([&apos;status&apos; =&gt; 4]); &#125; // 當該訂單已經請款了 if ($paymentServiceInstance-&gt;capture_id !== null) &#123; // 真正執行退款 API ，將款項退給買家 $response = self::refundOrder($paymentServiceInstance-&gt;capture_id, $order-&gt;total_amount, $paymentServiceInstance-&gt;mc_currency); // 如果退款確定成功，更新訂單狀態 if ($response-&gt;result-&gt;status == &apos;COMPLETED&apos;) &#123; $order-&gt;update([&apos;status&apos; =&gt; 4]); $orderRelation-&gt;update([&apos;status&apos; =&gt; 4]); $paymentServiceInstance-&gt;update([ &apos;total_amount&apos; =&gt; $paymentServiceInstance-&gt;total_amount - $order-&gt;total_amount ]); &#125; &#125;&#125; 取消授權取消方法非常簡單，只要使用官方範例，並且依照格式帶入授權的id就可以，這邊就不特別舉例！授權id在你成功授權的時候會回傳，在那時記得把它存起來！ 取得授權資料取得授權方法非常簡單，只要使用官方範例，並且依照格式帶入授權的id就可以，這邊就不特別舉例！授權id在你成功授權的時候會回傳，在那時記得把它存起來！ 取得提款資料取得提款方法非常簡單，只要使用官方範例，並且依照格式帶入提款的id就可以，這邊就不特別舉例！提款id在你成功提款的時候會回傳，在那時記得把它存起來！ 總結依照官方文件， PayPal REST API 是可以搭配 JavaScript 的 Smart Button 一起使用的，不過 Ray 負責的是後端的角色，所以這一部分就沒有深究。看起來還蠻有趣的！有興趣的可以花時間研究一下！PayPal 不愧是國際的金流系統，各項的支援都十分全面以及功能也十分多樣，可惜已經退出台灣了！不過據了解應該是因為相關法令的關係，退出在另一個角度來說也是在捍衛台灣的稅法，未嘗不是一件好事，這邊就不多做評論。這陣子算是針對 PayPal 的金流深入的研究了一下，當然還有許多比較細緻的功能因為時間的關係還沒有去接觸到，待之後有時間有機會再來好好研究，再把心得過程都記錄下來分享給大家！ 歡迎轉載，但麻煩請註明出處，感謝！","link":"/zh-tw/PayPalRestAPI/"},{"title":"OOP-Class and Object","text":"大家好，我是Ray! 今天想跟大家分享，什麼是Ｃlass，以及什麼是Object，還有他們之間的關係！ 講到class就不得不講到object，而要解釋object就離不開class，這也常常是讓許多人感到困惑與不解的地方。 簡單來說，class算是一用來創造object的code模板。 廢話不多說，讓我們來創一個class先： 我們可以自訂我們喜歡的class的名稱，class的名稱可以是數字與字母的組成，但開頭的第一個字不可以是數字，如下面的code：class ＭyAccessories&#123; // class body&#125; 雖然上面的東西看起來沒什麼用，但是這已經是一個符合標準的class 如上所述，我們說class是產出object的一個模板，現在讓我們來產出幾個object，如以下的code:$accessory1 = MyAccessories();$accessory2 = MyAccessories(); 以上我們使用MyAccessories class 造出了兩個object，由於這兩個object是由同樣的class造出來的，所以他們有著相同的功能與類型。 那你會問，他們一樣嗎？ 答案是，不。 或許在功能以及類型上它們是一樣的，但他們的確是不同的object。 我知道你可能還有疑惑，讓我們把他們印出來看看！新增以下的code:var_dump($accessory1);var_dump($accessory2); 沒有意外的話，你應該會印出下面的東西。#後面的編號代表著他們的獨特性。或許你會說，啊～這會不會是照順序來顯示＃後面數字啊？object(MyAccessories)#1 (0) &#123;&#125;object(MyAccessories)#2 (0) &#123;&#125; 那我們再來做一個實驗 我們將var_dump內的object名稱互換，如果說＃後面的數字只是照順序來顯示的話，照理說印出來的東西應該不會變，是吧？var_dump($accessory2);var_dump($accessory1); 你應該會印出下面的東西： object(MyAccessories)#2 (0) &#123;&#125;object(MyAccessories)#1 (0) &#123;&#125; ＃後面的數字變了！ 這代表一個事實，那就是每個object，儘管他們是由同一個class所產出的，都會有屬於自己的一組編號，代表他們的獨特性，所以每一個object都會是不同的。 如果你還有些困惑，讓我再來舉個例子： Class就像是生產鑄件的模具，而object就像是被壓出來的鑄件，可以是一個鍵帽，或是一個同型號的耳機。外觀看來他們都是一模一樣的，但是他們確實是不同的獨立個體。你或許可以在上面看到生產流水編號，那就相當於上面印出來的#後面的數字。 看完以上的文章，各位是否對class以及object有更深一層的認識了呢？","link":"/zh-tw/OOP-ClassAndObject/"},{"title":"Stackdriver 快速開始","text":"前言本篇主要是利用Google的Qwiklab平台學習的同時，做的一份學習筆記原文連結如下：Refer to QWIKLABS official website 本篇將會做什麼？本篇實作將告訴你如何利用Stackdriver來監看Google Compute Engine virtual machine instance，你也將安裝監看以及紀錄的服務在你的VM上，他們可以從你的instance上收集更多的資訊 設定及要求需熟悉Linux內建的編輯器，像是vim, emacs, 或是nanoQwiklabs setup在你按下 Start Lab 按鈕之前詳讀所有的教學。Labs 是有時間限制的，而且你不可以停止時間倒數。倒數計時器在你按下 Start Lab 按鈕後開始倒數，上面顯示的時間為你還能使用 Cloud 資源的時間。 Quiklabs 的手把手環境，讓你可以在真實環境中來操作進行 Quiclabs 上提供的課程，而不是在一個模擬或是展示的環境。我們透過提供你一個全新的、暫時的帳號密碼，在計時器歸零之前，你可以用來登入並存取 Google Cloud Platform。 你需要什麼？要完成這個 lab ，你需要: 一個一般的網路瀏覽器（推薦 Chrome） 完成這個 lab 的時間 備註： 如果你已經有你自己的個人 GCP 帳號或專案，請不要使用在這一個 lab Google Cloud Platform Console如何開始你的 lab ，然後登入 Console? 按下 Start Lab 按鈕。如果你需要付費，會有一個彈出視窗來讓你選擇付費的方式。在左方你會看到一個面板，上面有暫時的帳號密碼，你必須使用這些帳號密碼在此次 lab 複製 username , 然後點擊 Open Google Console。 Lab 會開啟另外一個視窗，顯示選擇帳號的頁面 tip: 開啟一個全新的視窗，然後跟原本的頁面並排 在選擇帳號頁面, 點擊 Use Another Account 登入頁面開啟，貼上之前複製的 username 以及 password ，然後貼上 重要：必須使用之前於 Connection Details 面板 取得的帳號密碼，不要使用你自己的 Qwiklabs 帳號密碼。 如果你有自己的 GCP 帳號，請不要用在這裡（避免產生費用） 點擊並通過接下來的頁面: 接受terms以及conditions 不要增加recovery optoins 或 two factor authentication (因為這只是一個臨時帳號) 不要註冊免費體驗 稍待一些時候， GCP 控制台將會在這個視窗開啟。 注意：按下左上方位於Google Cloud Platform 隔壁的 Navigation menu ，你可以瀏覽選單，裡面有一系列的 GCP 產品以及服務 Cloud Shell啟動 Google Cloud ShellGoogle Cloud Shell 是載有開發工具的虛擬機器。它提供了5GB的 home 資料夾，並且運行在 Google Cloud 上。 Google Cloud Shell 讓你可以利用 command-line 存取 GCP 資源 在 GCP 控制台 ，右上的工具列，點擊 Open Cloud Shell 按鈕 在打開的對話框裡，按下 START CLOUD SHELL: 你可以立即按下 START CLOUD SHELL 當對話視窗打開。 連結並提供環境會需要一點時間。當你連結成功，這代表你已成功獲得授權，且此專案已被設為你的專案ID，例如： gcloud 是 Google Cloud Platform 的 command-line 工具，他已事先被安裝在 Cloud Shell 並且支援自動補齊 使用這個 command ,你可以列出有效帳戶名稱:gcloud auth list 輸出:Credentialed accounts: - &lt;myaccount&gt;@&lt;mydomain&gt;.com (active) 範例輸出:Credentialed accounts: - google1623327_student@qwiklabs.net 你可以使用以下 command 來列出專案 IDgcloud config list project 輸出：[core]project = &lt;project_ID&gt; 範例輸出：[core]project = qwiklabs-gcp-44776a13dea667a6 gcloud 的完整文件可以參閱 Google Cloud gcloud Overview 建立一個Compute Engline Instance 在GCP主控台的控制面板， Navigation menu &gt; Compute Engine &gt; VM instance，然後點擊 Create￼ 照下面的資訊填入相對應的空格，無提到的空格內請保持預設值 Name: lamp-1-vm Region: us-central1 (Iowa)` Zone: us-central1-a Machine type: small (1 shared vCPU) Firewall: Select Allow HTTP traffic 點擊Create 安裝Apache2 Server 在主控台，點擊SSH來開啟一個連接此instance的terminal 在SSH視窗中，執行下面的指令來設定Apache2 sudo apt-get update sudo apt-get install apache2 php7.0 當詢問是否繼續y 如果你無法安裝php7.0，裝php5 sudo service apache2 restart 回到主控台，在VM instance的頁面，點選External IP處以連接到Apache2預設頁面 建立Stackdriver帳號 要使用Stackdriver，你的專案必須要在一個Stackdriver 帳號內，接下的步驟將建立一個有試用期的Stackdriver帳號 在GCP主控台，點擊Navigation menu &gt; Monitoring 這將在一個新視窗開啟Stackdriver，並顯示你的Qwiklabs專案。 點擊Create workspace 在接下來的頁面: 加入GCP專案到monitor，你將看到你的專案顯示已勾選 點擊Continue 監看AWS帳號 - 略過設定 安裝Stackdriver監看代理curl -sSO https://dl.google.com/cloudagents/install-monitoring-agent.sh` sudo bash install-monitoring-agent.sh 安裝Stachdriver記錄代理curl -sSO https://dl.google.com/cloudagents/install-logging-agent.sh sudo bash install-logging-agent.sh 點擊Continue 點擊Launch monitoring 建立運行時間確認Uptime check用以確認資源總是可以被存取，在此範例中，我們將建立一個uptime check來確認Google網頁正常運行中1. 在Stackdriver console主控台，在控制面板上，點擊Create an Uptime Check按鈕。你也可以從左邊到menu中，找到Uptime Checks &gt; Uptime Checks Overview，然後點擊 Create an Uptime Check2. 編輯New Uptime Check，加入以下資訊 - Title: Lamp Uptime Check - Check type: HTTP - Resource Type: Instacne - Applies to: Single, lamp-1-vm - Path: leave at default - Check every: 1 min如果instance沒有自動載入在我們寫則”single”之後，取消這次的uptime check，重新整理Stackdriver頁面，然後重新試一遍 點擊Test來確認我們的uptime check可以連結到資源 點擊save，當顯示所有的資源都已經可以連接 點擊No thanks來為這個uptime check 建立一個警告政策 Uptime Check的設置將會需要一些時間生效，我們繼續我們的進度，等等我們再來確認結果。讓我們先來建立一個警告政策。 建立一個警告政策利用Stackdriver來建立一個或多個的alerting policies.從左邊的選單，點擊Alerting &gt; Create a Policy，然後設置Conditions, Notifications, and Documentation 條件： 點擊Add Condition 依照下面的資訊來設置空格處，如果沒有提到，請保留為默認值 Target: Resource Type: GCE VM Instance (gce_instance)Metric: Type &quot;network&quot; then select Network traffic ConfigurationCondition: is aboveThreshold: 500 bytesFor: 1 minute 點擊Save Notifications: 選擇Email Address，然後輸入你的個人信箱地址 Documentation: 點擊Add Documentation然後新增一個訊息，這個訊息將會被包含在郵件警告中 Name this policy: Inbound Traffic Alert 點擊save 我們已經建立一個警告了！在等待系統觸發警告的同時，建立一個控制面板和圖表，然後看一下紀錄 建立控制面板和圖表 左邊選單，Dashboards &gt; Create Dashboard 螢幕右上方，點擊Add Chart 在Find resource type and metric區域，輸入CPU，然後選擇 CPU Load(1m). GCE VM instance根據資源類型自動被選擇，圖表名稱自動命名，但如果你想要的話，你可以自訂命名 點擊save 現在建立第二個圖表 在新的控制面板右上方的選單，選擇Add Chart Find resource type and metric欄位內輸入Network，選擇Received Packets，其餘欄位保持預設值，你可以在預覽區域看到圖表資料 點擊save 重新命名新的控制面板，從Untitled Dashboard改成Stackdriver LAMP Qwik Start Dashboard 檢視紀錄Stackdriver Monitoring 和 Stackdriver Logging緊密地互相整合著 在Stackdriver 左手邊選單，點擊Logging來檢視紀錄 選擇GCE VM instance &gt; lamp-1-vm在第一個下拉選單 從第二個下拉選單選擇syslog，然後點擊OK 其餘欄位保留預設 選擇Start streaming logs 圖案 可以看到這個VM instance的logs 現在來看看，當我們開始跟結束時，會發生什麼事 點擊並拖曳Logs Viewer brower視窗，所以Compute Engine console 和 Stackdriver Logging console會並排 在主控台內，VM instance視窗，點擊lamp-1-vm instance 在VM instance details 視窗，於螢幕上方點擊Stop，然後確認停止instance，這會需要幾分鐘，我們來看log messages 我們可以看著Logs View 視窗，然後看VM什麼時候被結束 在VM instance detail 視窗，在螢幕最上方點擊Start，然後確認。這會需要幾分鐘的時間，我們可以檢視log訊息 確認uptime check結果以及警告觸發 在Stackdriver左邊區域，點擊Uptime Checks &gt; Lamp Uptime Check。這將顯示uptime check的細節，包含等待時間，uptime 百分比，區域結果以及設定檢查。如果你看到的Location result 是 “No checks have run yet”，那請等待幾分鐘，然後重新整理頁面 左方區域點擊Uptime Checks &gt; Uptime Checks Overview，這將提供所有運行中的uptime checks，包含網站在不同區域的狀態 確認警報是否有觸發 在StackDriver 主控台，左方頁面點擊Alerting &gt; Incidents，如果你沒有看到開啟的事件，請確定一下你在看的是RESOLVED頁面 依然在Stackdriver 主控台，點擊Alerting &gt; Events，你應該會看到一個事件列表 確認一下我們的email帳號，應該會收到警報 習題測試 Stackdriver supports which of the following cloud platforms Google Cloud Platform Azure Amazon Web Services","link":"/zh-tw/Stackdriver/"},{"title":"My learning journey in Docker","text":"前言這是一份未整理過的 Linux 學習筆記 環境GCP - ubuntu 18.04 安裝 移除舊版本sudo apt-get remove docker docker-engine docker.io containerd runc 從 Docker 倉庫安裝 更新 apt sudo apt-get update 安裝以下套件，使 apt 可以經由 HTTPS 使用倉庫 sudo apt-get install -y \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-common 增加 Docker 的正式 GPG 密鑰 curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - 核對一下我們現在擁有含有 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88 指印的密鑰，我們可以搜尋最後八碼 sudo apt-key fingerprint 0EBFCD88 理應得到輸出如下： pub rsa4096 2017-02-22 [SCEA] 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88uid [ unknown] Docker Release (CE deb) &lt;docker@docker.com&gt;sub rsa4096 2017-02-22 [S] 將 Docker 倉庫 設定為 stable 版，若要設定為 nightly 或 test 版，可在以下的指令中自由取代 stable sudo add-apt-repository \\ \"deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable\" 安裝最新的 Docker CE 版本 sudo apt-get install docker-ce docker-ce-cli containerd.io -y 你也可以安裝特定版本的 Docker: 列出版本 apt-cache madison docker-ce 應該會得到輸出如下： docker-ce | 5:18.09.1~3-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 5:18.09.0~3-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 18.06.1~ce~3-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 18.06.0~ce~3-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages ... 使用上面輸出的第二欄位版本號，結合下面的指令來安裝特定版本 sudo apt-get install docker-ce=&lt;VERSION_STRING&gt; docker-ce-cli=&lt;VERSION_STRING&gt; containerd.io 運行鏡像 hello-world 來驗證 Docker CE 是否已經正確安裝 sudo docker run hello-world 如果要使用非 root 身份運行 Docker 的話，可以把你的使用者加到 Docker 群組 sudo usermod -aG docker your-user 解除安裝 解除安裝 Docker CE sudo apt-get purge docker-ce 刪除所有的 image, containers, volumes, 可以使用以下指令。慎用！此指令適合解除安裝後使用。 sudo rm -rf /var/lib/docker/ 基本指令Docker 列出 Docker 的指令 docker 查看 Docker 版本 docker version 查看 Docker 完美安裝資訊 docker info 以 root 身份登入 docker exec -it --user root &lt;container id&gt; /bin/bash 開啟防火牆 登入 gcloud auth 帳號 gcloud auth login 輸入網頁上得到的驗證碼 登入成功後，利用 gcloud 身份，開啟防火牆gcloud compute firewall-rules create ruleName --allow tcp:thePortYouWantToExpose 傳檔案進 containerdocker cp file containerName:/location Docker container 運行 containerdocker container run -it ubuntu:latest /bin/bash Docker container run 告訴 Docker daemon 開始一個新的 container -i 告訴 Docker daeman 讓 container 可以互動 -t 使目前的 terminal 視窗連接 container 的 shell ubuntu:latest 為開始這個 container 的 image /bin/bash 指定了我們想要運行 container 裡頭的哪一個程序 確認 Docker daemon 運行狀況service docker status systemctl is-active docker 離開 container 但不關掉它 CTRL + PQ 連接還在運行中的 container docker container exec -it yourContainerIDOrContainerName bash exec 在運行中的 container 中運行一個新的程序 列出運行中的 container docker container ls 列出所有的 container ， 包含已停止的 docker container ls -a 列出 hello-world container（由 image 產生），他們在顯示訊息之後就退出了，如果他們還在運行中的話，以下指令中的 --all 可以不用加 docker container ls --all ordocker ps -a 理應得到輸出如下： CONTAINER ID IMAGE COMMAND CREATED STATUS54f4984ed6a8 hello-world \"/hello\" 20 seconds ago Exited (0) 19 seconds ago 停止 container docker container stop containerIdOrContainerName 重新開始停止中的 container docker container start containerName 刪除 container docker rm containerID 刪除所有的 container docker rm $(docker container ls -aq) -f 根據指定的 image 運行 container 並指定 port, 賦予 container name。若想自定義 port 的話， Dockerfile 跟 server 的 port 需一致，且防火牆要開啟該 port docker container run -d \\--name web1 \\ -p 8080:8080 \\test:latest -d 表示讓 container 運行在背景 ， 與 -it 相反，無法共存--name 指定 container 的名稱-p 指定 port ， 左邊的是外部可以從瀏覽器存取的 port ，右邊的是 container 向外暴露的 port 將現有的 container 存成一個新的 imagedocker commit -m 'imageMessage' -a 'AuthorName' containerSHA imageName:imageTag Multi Stage Multi Stage Build 範本FROM node:latest AS storefrontWORKDIR /usr/src/atsea/app/react-appCOPY react-app .RUN npm installRUN npm run buildFROM maven:latest AS appserverWORKDIR /usr/src/atseaCOPY pom.xml .RUN mvn -B -f pom.xml -s /usr/share/maven/ref/settings-docker.xml dependency:resolveCOPY . .RUN mvn -B -s /usr/share/maven/ref/settings-docker.xml package -DskipTestsFROM java:8-jdk-alpineRUN adduser -Dh /home/gordon gordonWORKDIR /staticCOPY --from=storefront /usr/src/atsea/app/react-app/build/ .WORKDIR /appCOPY --from=appserver /usr/src/atsea/target/AtSea-0.0.1-SNAPSHOT.jar .ENTRYPOINT [\"java\", \"-jar\", \"/app/AtSea-0.0.1-SNAPSHOT.jar\"]CMD [\"--spring.profiles.active=postgres\"] -t 用來指定 image 的名字-f 可以用來指定名稱不是 Dockfile 的 DockerfileFrom 指定基礎 image 來源RUN 可以在 image 內執行 command 並建立新的 layer ，每一個 RUN 都會建立一層 layerCOPY 可以增加複製檔案到你的 image 內EXPOSE 暴露 APP 用的 portENTRYPOINT 設定當 image 被啟動為一個 container 時，預設執行的指令 Docker image 拉下 image docker image pull ubuntu:latest 根據 digests 拉下 image docker image pull imageNane@sha256:specificDigests 列出下載過的 image docker image ls 刪除 image docker rmi imageID 刪除所有的 image docker image rm $(docker image ls -q) -f 建立 image docker image build -t imageName:tagName . 列出下載過的 image 以及 digest docker image ls --digests 列出一個 image 的結構 docker image inspect inamgeID 將 image 存成映像檔 docker save -o outputFileName imageName:imageTag -o 代表 output 架設一個私有倉庫docker run -d -p 5000:5000 registry 我們也可以將上傳的映像檔備份一份到容器外docker run -d -p 5000:5000 -v outsideAddress:insideAddress registry Docker push 首先， tag 本地的 image 一個可以用來推上 DockerHub 的名字 docker tag localImageName:localTagName userAccount/toBeTaggedImageName:toBeTaggedImageTagName 推上 DockerHub docker push userAccount/taggedImageName:taggedImageTag Docker-Compose 安裝 Docker Compose, 儘管我們可以從官方的 ubuntu 倉庫 安裝 Docker Compose ，但因為最新的版本中有很多細小的版本差異，所以我們從 Docker GitHub 來安裝。 先到官方頁面確認版本，並且視需求更新下面指令的版本號。 sudo curl -L https://github.com/docker/compose/releases/download/1.21.2/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose 設定權限 sudo chmod +x /usr/local/bin/docker-compose 確認 Docker-compose 版本 docker-compose --version 建立 yaml 檔案 vim docker-compose.yml 輸入內容如下： my-test:image: hello-world 建立一個 container docker-compose up 輸出理應如下： 建立一個 Swarm 開啟 docker swarm 模式docker swarm init \\--advertise-addr 0.0.0.1:8080 \\--listen-addr 0.0.0.1:8080 上面的 IP 跟 PORT 自己訂的--advertise-addr: 指定別的節點要連接這個 manager 時該使用的 IP 以及 port。這不是個必要的選項，但是你可以對哪個 IP 被使用有完全的控制權，並且你也可以訂一個不存在於節點上的 IP ，像是負載平衡的 IP --listen-addr: 讓你可以指定用來聽 swarm traffic 的 IP 以及 port ，通常他會跟 --advertise-addr 相同，但如果你想要限制 swarm 在特定的 IP，就特別有用。 還有一種情況，當 advertise-addr 是一個遠端的 IP ，像是平衡負載器，那這個也是必要的。 建議總是使用兩個附加選項。 從一個 node 開始 swarm mode ，並且設為 leader docker swarm init \\--advertise-addr yourInternalIP:yourPort \\--listen-addr yourInternalIP:yourPort 取得新增 manager 的 token docker swarm join-token manager 輸出大概如下： docker swarm join \\token SWMTKN-1-0uahebax...c87tu8dx2c \\10.0.0.1:2377 取得新增 worker 的 tokendocker swarm join-token token 輸出大概如下： docker swarm join \\token SWMTKN-1-0uahebax...c87tu8dx2c \\10.0.0.1:2377 重新產生 token docker swarm join-token --rotate managerOrWorker 開啟並且登入一台新的 instance ， 輸入上面的 token 還有自己的 IP 位址 docker swarm join \\token SWMTKN-1-0uahebax...c87tu8dx2c \\10.0.0.1:2377 \\advertise-addr yourInternalIP:yourPort \\listen-addr yourInternalIP:yourPort 不管你是想加入成為 manager 或是 workder ，只要輸入相對應的 token 就可以加入。 在 Leader 的 node 上可以查看 swarm 的詳細資料 docker swarm node ls 離開當前的 swarm docker swarm leave --force 開啟一個 SERVICE 要開立 service 首先必須確定， swarm 已建立。docker service create --name web-fe \\-p 8080:8080 \\--replicas 5 \\nigelpoulton/pluralsight-docker-ci docker service create: 建立一個 service--name: 指定 service 的名稱-p: 指定 container 內以及連接外部的 port--replicas: 在這個服務內，至少要有 5 個 containernigelpoulton/pluralsight-docker-ci: image 以及 tag 開立 service 之後， swarm 會一直的監看真實的狀態是否跟我的理想的狀態一致，如果一致的話那很好，如果不， swarm 會採取相對應的動作。舉例來說，如果五個 container 裡面有一個關閉了， swarm 會自動在啟動一個 查看 service 清單 docker service ls 查看 service 內的任務狀態 docker service ps serviceName 更詳盡的資訊 docker service inspect --pretty serviceName 擴展規模 docker service scale web-fe=10 刪除 service docker service rm web-fe 建立一個 overlay network docker network create -d overlay uber-net 連接到相同 overlay network 的 container ， 儘管他們的 docker host 連接的網路不同，彼此也可以互相溝通連接。 列出 network 資料 docker network ls 刪除一個 network docker network rm networkName 依據指定的 network 建立一個新的服務 docker service create --name uber-svc \\--network uber-net \\-p 80:80 --replicas 12 \\nigelpoulton/tu-demo:v1 --network: 指定 network 滾動升級 rolling update 滾動升級運行中的服務docker service update \\--image nigelpoulton/tu-demo:v2 \\--update-parallelism 2 \\--update-delay 20s uber-svc docker service update: 升級 service--image: 升級的 image 來源--update-parallelism 2: 一次升級兩個 container--update-delay 20s uber-svc: 每批次的等待時間為 20 秒 ， 需等當前批次的升級完成，時間才會開始計算。 最後指定要升級的 service 名稱 查看上次升級的參數docker service inspect --pretty serviceName 如上圖，前一次升級的參數都會被保留下來，除非你再次升級去覆蓋它 Composer 利用 container 安裝 Composer docker run --rm -v $(pwd):/app composer install --rm: 當 container 關閉後，自動刪除-v: 使用 volumes$(pwd):/app: $(pwd) 表示當前資料夾, /app 表示 container 裡頭一個叫做 app 的資料夾, 所以這個指令代表 : 前後的兩個資料夾會在 container 關閉之前，同步所有資料composer install: 安裝 composer 所以這個指令實際上做的事情，就是從 Docker Hub 拉下官方的 composer image ，然後開啟一個 container 並執行安裝， composer 會依照資料夾內 composer.json 或 composer.lock 來安裝相對應的 package 。 package 會被安裝在 app 這個資料夾內，但因為 volumes 的關係，所以兩個資料夾會同步， $(pwd) 內也會有安裝的 package 。 當安裝結束後， container 關閉，因為 --rm 的作用， container 會自動刪除。 利用 Docker-compose 部署 Laravel環境環境為 Ubuntu 18.04 安裝 docker-compose 安裝 Docker Compose, 儘管我們可以從官方的 ubuntu 倉庫 安裝 Docker Compose ，但因為最新的版本中有很多細小的版本差異，所以我們從 Docker GitHub 來安裝。 先到官方頁面確認版本，並且視需求更新下面指令的版本號。 sudo curl -L https://github.com/docker/compose/releases/download/1.21.2/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose 設定權限sudo chmod +x /usr/local/bin/docker-compose 利用 Docker 來安裝環境MySQL 安裝 MySQL ， 並指定連接一個外部不同的 port 號 ， 像是 52000docker run --name serviceName -e MYSQL_ROOT_PASSWORD=yourPassword -d -p 52000:3306 mysql:5.7 docker run: 啟動一個 container--name: 指定這個服務的名稱-e MYSQL_ROOT_PASSWORD: 指定環境參數-d: 使這個服務跑在 container 當中-p: 指定外跟內的 port 號， container 內部的 3306 連接外部的 52000mysql:5.7: 指定 image 以及 tag 連接本地安裝的 MySQL 以及 Docker container 內的 MySQL 本地安裝的 sudo mysql -uroot Docker Container mysql -h 127.0.0.1 -uroot -p2434 -P52000 製作 Docker image 時區問題我的第一個目標，是利用 Docker commit 來做一個專屬的 image。簡單來說，就是起一個純淨的 container ，然後在這個 container 裡頭部署完之後，再使用 docker commit 將這個 container 變成一個 image ， 結果發現在安裝 php7.2-imagick 中會出現 Configuring tzdata ，會彈出一個視窗並要求選擇時區，如下圖 後來找到解決方法，是在安裝 php7.2-imagick 之前就把時區設定好，所以在一開始就加入export DEBIAN_FRONTEND=noninteractive &amp;&amp; apt-get install -y tzdata &amp;&amp; ln -fs /usr/share/zoneinfo/Asia/Taipei /etc/localtime &amp;&amp; dpkg-reconfigure --frontend noninteractive tzdata MySQL 問題接下來，又遇到一個問題，在我利用我製作好的 image 開一個 container 時， MySQL 無法成功啟動，會一直出現 Failed後來的解決方法非常的奇怪，我是到 /var/www/mysql/mysql 中，下 chown -R mysql:mysql . 的指令，然後它就好了…可問題是，我仔細地確認過，在我下這指令之前，這個資料夾下的所有 user 以及 group 早就已經是 mysql:mysql 了 Apache 以及 MySQL 無法設定自動重啟的問題所以我們必須要在 container 裏頭啟動這些服務，需要啟動的服務如下： Apache MySQL 所以從目前的進度看來， container 啟動之後，我們必須要執行三個指令，如下：chown -R mysql:mysql /var/www/mysql/mysqlservice apache restartservice mysql restart 沒想到實際執行之後，我們遇到了一個新的問題… Container 自動退出的問題Container 的特性，是只要 command 執行完畢後，就會自動退出。 container 一旦退出了，我們原本建構的環境當然也就不在了。我們怎麼可以容許這種事情發生呢？因此，我們需要給 container 一個會一直持續存在的指令，好比是 /bin/bash 該怎麼樣讓 container 在啟動的時候又執行多個指令呢？在 container 啟動時， 我們需要執行多個指令來啟動 container 裡面的服務，但是 entrypoint 只能帶一個指令進去，所以我們要寫一個 shell script ，然後當 container 開啟之後去執行這個 shell script ，當然，這個 shell script 裡頭的指令就是上述提到的指令，如下： chown -R mysql:mysql /var/www/mysql/mysqlservice apache2 restartservice mysql restart/bin/bash 假設這個 shell script 叫做 test.sh ，然後放在 /usr/sbin/ 之下，那我們的 docker 指令如下：docker run -dt --entrypoint \"/usr/sbin/test.sh\" -p 8880:80 --name containerName yourAccount/imageName:tagName Debug 查 logdocker logs -f containerID man 指令Docker 為了縮小 image 大小，預設不產生 man 說明文件。 在安裝 man 以及 man-pages 之前，需要先將此設定改掉 修改設定Docker 為了縮小 image 大小，預設不產生 man 說明文件。 在安裝 man 以及 man-pages 之前，需要先將此設定改掉vi /etc/yum.conf 將以下這行 comment 掉tsflags=nodocs 安裝 yum install man-pages -y; yum install man -y 更新 mandb mandb 安裝 vim 套件測試 yum install vim 測試 man vim 可以用了","link":"/zh-tw/docker/"},{"title":"使用Laravel儲存並重新縮放圖片大小","text":"前言本篇為實際上使用Laravel，以及套件Intervention來儲存及重新修改圖片尺寸的學習筆記。 安裝套件Intervention安裝流程請參照InterventionGitHub官網composer require intervention/image 打開config/app.php, 在array $providers 裏頭加上Intervention\\Image\\ImageServiceProvider::class 在array aliases裏頭加上&apos;Image&apos; =&gt; Intervention\\Image\\Facades\\Image::class 建立上傳資料夾與storage資料夾的連結 依照官網說明建立連結 在terminal輸入 php artisan storage:link 連結之後，project/storage/app/public 會跟 project/public/storage這兩個資料夾就回相連。 如果你是要儲存檔案，請儲存到project/storage/app/public/(anySubdirectoryYouWant) 如果你是要提供外部存取的URL，請使用project/public/storage/(anySubdirectoryYouWant)/fileName，因為對外部來說，預設可存取資料夾為public，所以直接使用asset(&#39;storage/(anySubdirectoryYouWant/fileName)&#39;) 驗證圖片是否有被帶進來// 因為我們不需要太多的東西，只需要request array裡頭的東西$parameters = request()-&gt;all();if (request()-&gt;hasFile('image'))&#123; // 檔案存在，所以存到project/storage/app/public，並拿到url，此範例會拿到public/fileName $imageURL = request()-&gt;file('image')-&gt;store('public'); // 因為我們只想要將純粹的檔名存到資料庫，所以特別做處理 $parameters['image'] = substr($imageURL, 7);&#125; 重新縮放圖片大小 要縮放大小，所以會需要使用到套件intervention 在namespace下加上use Intervention\\Image\\ImageManagerStatic as Image; // 拿到剛剛存進DB的item實例$item = Item::update($parameters);// 設定driverImage::configure(array('driver' =&gt; 'gd'));// 如果我們dd (storage_phth)，我們將會得到'project/storage/'，但這不是我們要的// 所以我們在後面加上'app/public/，如上所敘，這是內部儲存的資料夾位址// 請注意，當我們重新縮放圖片大小，目標都是我們的內部資料夾// 並且，再重新縮放之後，也是要存到同樣的地方Image::make(storage_path('app/public/' . $item-&gt;image))-&gt;resize(300, 300)-&gt;save(storage_path('app/public/' . $item-&gt;image)); 刪除圖片(如果使用者要求)if ($request-&gt;imageDelete == true)&#123; Storage::delete($item-&gt;images); $item-&gt;update(['images' =&gt; null]);&#125; 產出可存取資源的URL// 當產出公開存取的URL，它必須要是外部存取位址return asset(&apos;storage/&apos; . $parameters[&apos;image&apos;]);","link":"/zh-tw/UploadAndResizeImagesWithLaravel/"},{"title":"利用 Hexo 來建立一個 多語系 部落格","text":"前言這幾天為了建立一個個人部落格，真是沒少折騰了！個人除了對程式分享有熱愛之外，對語言也很有愛，像是英日語等等，所以一直以來，就想建一個多語系的部落格，除了可以讓分享的受眾更廣之外，另一方面也可以強制練習自己的語言！在請教 Google 大神無數次之後，大概歸納出以下三種可行的方法：利用i18n，再透過修改源碼的方式建兩個站點，一個中文，一個英文利用Hexo的minos主題在花了一些時間研究之後，毅然決然的選擇第三種，原因如下：原本我是使用 Hexo 的 Next 主題，可惜該主題在這方面並沒有支援，需要特別去修改源碼。這代表，維護成本會相當可觀，每修改一個地方，就需要修改兩份檔案，看你有幾種語言就得修改幾份檔案所以，本篇會針對 Hexo 的 minos 主題來做分享 安裝Hexo 安裝 NodeJS ，會連帶安裝 npm 套件管理器 brew install node 透過 npm 安裝 Hexo 主程式 npm install hexo-cli -g 在指定資料夾內，建立一個 Hexo 網站需要的檔案 hexo init folderName 安裝 minos 主題 進到資料夾 cd folderName 從官方GitHub上clone https://github.com/ppoffice/hexo-theme-minos.git themes/minos 原始資料夾，預設只有_config.yml.example，所以copy或rename為_config.yml，並於檔案中，搜尋theme，並設為minos 開始配置配置 Hexo 配置檔 config(配置檔)又分為 Hexo 本身的，以及主題的，以下先針對 Hexo 配置檔做說明，以下為必要設定的選項，其餘都維持預設即可: language: [&apos;en&apos;, &apos;zh-tw&apos;] //這邊的配置，表示默認以English語系為主，並以Taiwan語系為輔 url: https://tn710617.github.io/ (此為你的網站地址) permalink: :title/ deploy: type: git repo: https://github.com/tn710617/tn710617.github.io.git (此為你在GitHub上的資料夾clone地址) branch: master 主題配置檔內的設定都跟多語系無直接關係，所以這邊不特別做說明，大家依照官方文件以及個人喜好設定完成即可。 配置網頁語系檔 配置完 Hexo 的配置檔後，我們需要先新建一個自己國家的語系檔，如果主題內原本就已經有的話就不必，以本篇例子來說，我需要一個 Taiwan 語系，但是主題內的配置沒有，所以我必須要自己建一個。這個檔案的功用為，當切換到指定語系時， Hexo 會去讀指定語系的配置檔，就是這個檔案，並且依照這個語系檔裡面的內容來顯示 到 minos 的 languages 資料夾內，新建一個檔名為zh-tw.yml的檔案 內容可以比照其他國家的格式，如下：name: &apos;繁體中文&apos;common: archives: &apos;歸檔&apos; category: &apos;分類&apos; tag: &apos;標籤&apos; categories: &apos;分類&apos; tags: &apos;標籤&apos;nav: next: &apos;下一頁&apos; prev: &apos;上一頁&apos; search: &apos;搜尋&apos; toc: &apos;目錄&apos;article: read_more: &apos;點擊閱讀&apos; read: &apos;讀完&apos; about: &apos;大概&apos; words: &apos;字&apos; comments: &apos;留言&apos; contents: &apos;目錄&apos;search: hint: &apos;站內搜尋&apos;insight: hint: &apos;站內搜尋&apos; posts: &apos;文章&apos; pages: &apos;頁面&apos; categories: &apos;分類&apos; tags: &apos;標籤&apos; untitled: &apos;(無標題)&apos; 配置主題下的語系導向檔案 語系檔設定完成後，複製這個主題配置檔，並創立另外兩份配置檔。這幾個檔案的作用為，當我們切換到指定語系，網頁會依照這個檔案內配置的路徑來開啟相對應的檔案，比方說，中文開中文的檔案，英文開英文的檔案。 _config.zh-tw.yml _config.en.yml 先針對’en’配置檔做以下配置： // 這邊的配置可以依照個人需求menu: Archives: /archives Categories: /categories Tags: /tags Schedule: /schedule About: /about Friends: /friends 再來針對’zh-tw’配置檔做以下配置： menu: 歸檔: /zh-tw/archives 分類: /zh-tw/categories 標籤: /zh-tw/tags 行程: /zh-tw/schedule 關於: /zh-tw/about 好友: /zh-tw/friends 大家可能會注意到，這三個檔案內有著重複的配置。規則是這樣的，當我們切換到該語系的網頁時，默認會套用該語系的配置檔裡頭的配置，若該語系配置檔裡頭沒有這個配置，會自動套用主題原本的配置檔裡面的配置，所以這邊可以很靈活的針對不同語系的網頁來做配置調整。 view檔案的配置 現在我們開始針對view的檔案來做配置， minos 的規則是，除了源碼以及主體架構之外，所有的檔案根據語系的數量來配置，簡單來說，有幾種語系，該檔案就要有幾份。這也很合理，不然透過機器翻譯的文章你敢貼出來嗎？ 現在開始針對source底下的檔案來做配置: _posts上圖應該不會很難理解吧？ 簡單來說，_posts資料夾下面放的，是默認語系的檔案，以本篇例子來說，就是英文語系。而在_posts資料夾下面，建立一個名為zh-tw的資料夾，裡頭放著自然是中文語系的檔案 其他的：檔案配置就跟上圖一樣，是不是簡單到言語無法形容了？ 語言切換選單位置調整以我個人來說，當我進到一個網頁，如果密密麻麻的都是我看不懂的語言，我希望我第一個可以找到的就是語言切換的按鈕（如果有的話啦），以目前Ray使用的minos主題版本來說，切換語言的選單默認是在最下面的，所以我希望把它調整到一個顯眼的地方 到footer.ejs中，找到以下的代碼 &lt;%- partial('common/languages') %&gt; 把它剪下之後，貼到navbar.ejs檔案的最下方&lt;/body&gt;上面 如果現在從今整理頁面，應該已經可以看到語言切換選單已經換到上頭去了！可是呢… 怎麼是向上開啟選單的ＸＤ，根本無法選啊！所以我們還要再做一些調整。找到layout裡頭的languages.ejs檔案，並在裡頭找到下面這一行，並加入style=&quot;top:100%&quot;&lt;div class=&quot;dropdown-menu has-text-left&quot; role=&quot;menu&quot; style=&quot;top:100%&quot;&gt; 結語照著上面配置，大概就可以實現雙語系網站了，效果可以看看我的blog 若有說的不對的地方，歡迎指教歡迎轉載，但請註明出處，謝謝！","link":"/zh-tw/buildABilingualBlog/"},{"title":"伸縮自如的 git flow","text":"前言今天將分享一個具有以下特性的 git flow: 在開發過程中，可以隨意 commit 測試完成後，即可將相對較友善於開發的 commit 轉換成正式上線標準的 commit 兩個分支檔案內容完全相同，但卻擁有完全不相干的 commit 歷史 以 Ray 來說，我在開發時，習慣畫流程圖，並且將我腦中覺得可行的邏輯一條條寫下來，然後實踐。 通常一個大功能可能會由好幾個邏輯組成，而這個 git flow 讓我可以在一個 feature 分支上，將我的每一個小邏輯都記錄下來，分成一個個 commit 。 最後確定沒有問題了，在轉換成正式上線時需要的大功能 commit 。在實踐這個 git flow 的過程中，我對 git rebase 的熟悉與日俱增，並且訓練自己以更嚴謹的方式來做每一個 commit。以下 Ray 個人覺得這個 git flow 可以帶來的好處： 因為 commit 很小，邏輯單一，不管是在實驗或是除錯方面，都有不可言諭的便利性。 利用小 commit 的方式將邏輯都記錄下來，一方面讓自己的思緒清晰，一方面讓每一個功能的邏輯清清楚楚。 看似複雜的流程，但其實熟悉之後，分支的整理只是一瞬間，可以在開發過程中更加的熟悉 Git 的進階操作。 因為 commit 很小，可以訓練較嚴謹的 commit 風格。 理想的 commit今天提出的 git flow 只是一個舉例，不一定適用於每一個人，但重點是在實現這個 git flow 所需要的概念！ 當我們在本地 commit 時，我們傾向這個 commit 可以越小越好，因為越小越純粹功能越單一的 commit ，不管是在 Debug ，或是邏輯實驗與印證都有不可言傳，只可意會的妙用！ 例如呢？讓我們具體一點! 當今天你在 Debug ，發現印出來的東西不如你的預期。你嘗試不同的方式來測試，直到印出的數據是你想要的！ 如果你的 commit 有符合上面的原則，在這個時候呢，在每一次失敗的嘗試之後，你不需要繁複的修修改改。你只需要簡單的git reset --hard 就算你一個 commit 邏輯整個錯了，如果你的 commit 功能夠單一，要拿掉這個 commit ，你只需要git reset @^ --hard 我們想要的是什麼？然而，正式上線的 git flow 不容許我們這樣做。正式上線的 git flow 通常會要求推上去的每一個 commit 都要’指定的功能正常’。意思可以理解說，如果要將 commit 最小化，那很有可能我們會需要多個最小化的 commit 來組成一個正式上線公司所需要的大功能。 需求整理 開發時： 我們需要隨時可以 commit 的靈活度，功能越單一越好 正式上線後： 我們需要每一個 commit 都符合公司指定的要求，功能正常 該選哪一種？人家說，魚與熊掌，不可兼得，真的是這樣嗎？可以兩種都要嗎？ 歸納具體需求那先來歸納一下，我們具體上，需要的東西 我們需要一支本地開發的 develop 分支，在這分支上，只要你爽，你想怎麼 commit 就怎麼 commit 我們需要一支正式要推上線的 master 分支，在這分支上，每個 commit 都代表著公司指定的功能 上面兩個分支，被 commit 的檔案內容是完全一樣 (選擇性)以上兩個分支我都要保留其各自獨特的歷史 具體看起來是？如下圖可以看到，左邊是檔案內容，右邊是 commit ，大家可以看到，在 develop branch 上，每個 small function 都對應到相應的檔案，這只是範例，表達我們所要的最小 commit 的概念。 master 分支:接下來，如下圖我們來看看實際上線時， commit 應該是什麼樣子。我們可以看到，在 master branch 上，我們只有4個 commit ，而每個 commit 都包含了4個檔案(除了 .gitignore 的 commit 之外)。這只是範例，表達正式上線時所需求的 commit 標準往往比我們理想的最小 commit 還要大。 範例連結 實作一切的起點通常 .gitignore 會是一切的起點！ 使用 vim 建立 .gitignore 檔案，然後輸入想要 ignore 的檔案，再按 :wq 離開。 vim .gitignore 完成第一個 commit git add .ignore; git commit -m 'Added .gitignore'; develop 分支接下來，我們將以 master branch 為基礎，建立 develop branch ，如同前面敘述的， develop branch 上面的 commit 會是最細最小的，而 master branch 上的 commit 會是符合正式上線標準的。 首先，從已經設定好 .gitignore 的 master 分支為基礎，建立 develop 分支 git checkout -b develop feature 分支然後呢，我們要開始開發了！ 建立一個 feature 分支 這個 feature 分支代表當前正在開發的功能 這邊所說的功能，是依照正式上線的標準 所以，一個功能等於一個 feature 分支git checkout -b feature; 自由的 commit 在 feature branch 上，我們可以隨便 commit ，可以完全依照我們本身的 commit 習慣，把 commit 做到最細小，以享受在開發以及測試過程中帶來的方便 建立檔案1~4，然後每個檔案分別代表一個最細小的 committouch &#123;1..4&#125;;git add 1;git commit 1 -m 'small function 1';git add 2;git commit 2 -m 'small function 2';git add 3;git commit 3 -m 'small function 3';git add 4;git commit 4 -m 'small function 4'; 功能完成了 在測試完成之後，確定沒有問題了！現在我們要把我們 commit 的標準轉換成正式上線的標準 如同前面提過的， feature branch 的開發範圍，是以正式上線的一個功能為單位 所以呢？我們要將一整個 feature branch ，濃縮成一個 commit 因為我們要保有兩個分支，所以我們不可以直接在 feature branch 幹這件事，因為 develop branch 會需要它！ 這邊特別說明一下，其實以這個 git flow 來說，開發過程中的 develop 分支不見得需要保留，但本篇範例會以如果你需要保留的狀況下來實作。如果開發用的 develop 不須保留的話，程序上會簡化很多。 用來 merged 的分支 為正式上線的 master branch 來建一個一次性的 toBeMerged branch git checkout -b toBeMerged 接下來，要把 toBeMerged branch 變成符合被 master branch merge 的狀態 git rebase -i master 壓縮、重新命名 commit 然後，我們剛剛有說過，我們要將多個開發流程中的最小 commit 壓縮成一個正式上線的 commit ，對吧？所以我們要將所有的 commit 往前壓縮，可以利用 fixup 這個選項，再來，正式上線的 commit 名稱肯定會跟我們開發時的 commit 名稱不同，所以這邊我們要重新命名這個壓縮後的 commit ，如下： reword 96c6c18 small function 1fixup 1dd84d2 small function 2fixup 1a71401 small function 3fixup f9c90c6 small function 4 接下來，我們將這個壓縮過後的 commit 命名為 big function 1 然後:wq存檔離開 此時使用git log來看看，看起來會像是下圖那樣git log merge 讓我們回到 master 來把它 merge 掉吧！ git checkout master;git merge toBeMerged; 接下來，切到 develop ，並且 merge feature branch git checkout develop;git merge feature; 最後，把已經被 merge 完成的 feature branch 以及 toBeMerge branch 刪掉吧！ git branch -D feature toBeMerged 複習一下，還記得我們要的是什麼嗎？ 在 develop 分支上，是最小的 commit 在 master 分支上，是正式上線標準的 commit 兩個分支的檔案內容必須要一模一樣 (選擇性的)同時保有兩個分支 看看我們的現在的 master 分支是否跟我們要的一樣？ git checkout master;git log 看看檔案內容ls 看看 develop 分支的 commit git checkout develop;git tag 'bigFunction1'git log 看看檔案內容 ls 第二階段 一樣的流程，建立 feature branch ，然後是 toBeMerge branch git checkout develop;git checkout -b feature;touch &#123;5..8&#125;;git add 5;git commit -m 'small function 5';git add 6;git commit -m 'small function 6';git add 7;git commit -m 'small function 7';git add 8;git commit -m 'small function 8';git checkout -b toBeMerged; 重點來了，這時我們不能使用傳統的 rebase 來改造 toBeMerged branch ，因為 toBeMerged branch 的歷史不曾存在於 master branch 。 讓我們想想，toBeMerged branch 應該要是什麼樣子才符合我們要的，適合被 master branch merge ？ 兩者要有共同的歷史(同sha1值) 先前已經被 merge 過的，未壓縮過的 commit 不可以重複出現。簡單來說， samll function 1~4 早就被壓縮成 big function 1 了，所以 small funciton 1~4 不可以再出現 master branch 上面沒有的內容，要壓縮成一個 commit 完成以上條件之後， toBeMerged branch 就可以被 master merge 了 第二次 rebase 與壓縮 所以具體該怎麼操作？ 我們將會使用到 git rebase 的進階應用 git rebase --onto 。我們 rebase toBeMerged branch 到 master branch 上，然後只要是 develop branch 上已經存在的 commit ，我們都不要，最後，將被 rebase 的 branch 叫做 toBeMerged，照這個順序往下排列，就成了以下的指令。 git rebase --onto 的用法，可以參考官方的文件 git rebase -i --onto master develop toBeMerged 然後同上，將最小的 commit 壓縮成一個正式上線的 commit reword 3668e72 small function 5fixup fd05fa1 small function 6fixup 3a87c08 small function 7fixup c38957e small function 8 壓縮後的 commit ，名稱為big function 2 重複之前步驟，該 merge 的 merge ，該刪的刪 來看看當前 develop 分支上的 commit 狀態，以及檔案內容 git checkout develop;git tag bigFunction2;git log --oneline develop 分支上的 commit ls develop 分支上的檔案內容 來看看當前 master 分支上的 commit 狀態，以及檔案內容 git checkout master;git log develop 分支上的 commit ls develop 分支上的檔案內容 總結此範例中的git flow，可以讓我們在開發過程中以最小的 commit 來進行，甚至是以任何我們喜歡的方式來進行，而不需因為正式上線的 commit 標準有所犧牲。過程看似複雜，看就 Ray 的使用經驗，如果相關原理都已經非常熟悉，其實指令輸入很快就完成了。範例中的 develop 分支不一定需要保留，因為日後若正式上線的 commit 有錯誤的話還是得從正式上線的 commit 來做修正，當然如果保留的話，應該還可以衍生一些其他的變化以及應用，這些就留待各位自己去發掘啦！若大家有任何想法歡迎在下面留言，我相信意見想法的交流是進步的捷徑。","link":"/zh-tw/flexibleGitFlow/"},{"title":"使用 vsftpd 在 GCP VM 上部署 FTP Server","text":"前言本篇將分享： vsftpd 的設定細節 建立一個特定的 FTP user 使用 gcloud command line 開啟相對應的防火牆 環境 GCP VM ubuntu 18.04 安裝 vsftpdsudo apt install vsftpd 設定檔 打開設定檔 sudo vim /etc/vsftpd.conf 設定參數如下： # 如果不想跑在預設的 21 port, 這個必須要打開listen=YES# 承上，如果 listen 為 yes, 這個必須是 NOlisten_ipv6=NO# 是否允許匿名者登入，預設是 NO。此例子中，我們只允許我們設定的 user 存取 server, 所以設定為 NOanonymous_enable=NO# 本篇目的是要建立一個特定使用者，並且只允許這位使用者登入，所以須為 YESlocal_enable=YES## 允許寫入的權限write_enable=YES# 該使用者的預設 umasklocal_umask=002# 在每個資料夾內，我們可以建一個檔名為 `.mssage` 的檔案，裡頭輸入訊息，當登入者進到這個資料夾實，就會顯示這則訊息dirmessage_enable=YES# 使用當地時間use_localtime=YES# 當登入者上傳或下載檔案時，都將之記錄下來xferlog_enable=YES# 檔案傳輸的 port 為 20, 我們用被動模式, 所以選 NOconnect_from_port_20=NO# 啟用被動模式pasv_enable=YES# xferlog 的位置，可以更改xferlog_file=/var/log/vsftpd.log# 是否使用正式格式。 選擇 NO 的話會比較易讀，但若有使用 log 分析軟體，建議選 YESxferlog_std_format=YES# 當使用者登入時，會顯示的歡迎訊息ftpd_banner=\"Welcome to QCDN's FTP server, feel free to upload whatever you would like to deploy on Website.\"# chroot 意思就是 change root，是否要將使用者預設就限制在自己的根目錄內，為了安全性考量，此選項建議打開, 否則登入者就被允許在你的 server 裡面閒晃chroot_local_user=YES# 允許這項功能的話，我們可以建立一個列表，列表裡頭的使用者將被允許可以離開自己的根目錄chroot_list_enable=YES# 乘上，該列表位置chroot_list_file=/etc/vsftpd.chroot_list# 須為一個名稱為 empty 的資料夾，且使用者不可對該資料夾有寫入的權限。當使用者未獲得檔案存取權限之前，會被限制在這個資料夾內secure_chroot_dir=/var/run/vsftpd/empty# 這是用來管理使用者權限的一個檔案，檔案位於 /etc/pam.d/vsftpd, 裡頭可以找到一個被限制存取的列表, /etc/ftpusers, 如果你不想讓哪一位使用者存取，你只要把他的帳號加到這個檔案裡頭就行了pam_service_name=vsftpd## 利用 TLS 加密傳輸的資料，本篇不使用rsa_cert_file=/etc/ssl/certs/ssl-cert-snakeoil.pemrsa_private_key_file=/etc/ssl/private/ssl-cert-snakeoil.keyssl_enable=NO# 為了要指定每個不同登入者的家目錄，這邊取得登入者的變數user_sub_token=$USER# 指定本地登入者的 root 位置, 若指定在別的位置，會跟 chroot 相衝突，如果要將使用者限制在自己的根目錄，需指定此路徑local_root=/home/$USER/ftp# 如果不想使用預設的 21 port, 可以自己指定 port 號listen_port=21212# 預設0, 使用任何 port 號。 這邊是一個被動模式的 port 使用範圍。 當伺服器端收到使用者端的被動模式要求，伺服器端會從這個區間內回覆使用者端一個用來傳輸資料的 port 供資料傳輸使用pasv_min_port=40000# 預設0, 使用任何 port 號。 這邊是一個被動模式的 port 使用範圍。 當伺服器端收到使用者端的被動模式要求，伺服器端會從這個區間內回覆使用者端一個用來傳輸資料的 port 供資料傳輸使用pasv_max_port=50000# 啟用 userlist 功能來限制可以存取的使用者，其功能基本上跟 pam 是類似的，是另外一種方式, 若要啟用，為 YESuserlist_enable=YES# 當此值為 YES, 則填入下一個設定檔中的帳號為禁止存取。 當此值為 NO, 為嚴格模式，只有被加入檔案的使用者可以存取userlist_deny=NO# 呈上，為使用者限制的列表檔案userlist_file=/etc/vsftpd.userlist# 每秒存取的最大流量 bytslocal_max_rate=10000000# 是否允許被限制在 chroot 的使用者有寫入的權限，因為我們要允許使用者上傳檔案，所以為 YESallow_writeable_chroot=YES# 預設為0, 表示無限制。 最大允許連線 server 的用戶端數量max_clients=50# 預設為0, 表示無限制。 來自同 ip 的最大允許連線數量max_per_ip=5# 是否使用 TCP Wrappers。TCP wrappers 是透過用戶端想要連結的程式檔名，然後分析用戶端的 IP ，看看是否需要放行tcp_wrappers=YES# 是否允許紀錄兩種不同格式的 logdual_log_enable=YES# log 的位置vsftpd_log_file=/var/log/vsftpd.log 建立 usersudo adduser test 之後再輸入密碼，假設為 1234 建立相關設定檔sudo touch /etc/vsftpd.chroot_list &amp;&amp; sudo mkdir /home/test/ftp &amp;&amp; sudo touch /etc/vsftpd.userlist &amp;&amp; sudo touch /var/log/vsftpd.log 權限設定 我架設這個 FTP Server 主要是要讓前端可以簡單地利用上傳來做簡單的部署，所以下面才會有 www-data 的相關權限設定。 有興趣可以看看，不然跳過也沒關係，因為這跟 FTP Server 沒有很直接的關係 建立共同群組此資料夾，預設只有該使用者以及 nginx 的 www-data 可以存取，所以先建立共同群組 sudo groupadd ftp_access 將 ftp 使用者以及 www-data 加入此群組 sudo usermod -a -G ftp_access test &amp;&amp; sudo usermod -a -G ftp_access www-data 設定權限 sudo find /home/test/ftp -type d -exec chmod 2770 &#123;&#125; \\; &amp;&amp; sudo find /home/test/ftp -type f -exec chmod 0664 &#123;&#125; \\; &amp;&amp; sudo chmod /home/test/ftp test:ftp_access 設定允許存取者echo 'test' &gt; /etc/vsftpd.userlist GCP 防火牆設定給機器加 tag 我個人習慣用 gcloud shell, 可以選擇以下兩種方式 從官網安裝SDK 可參考 GCP 提供的 gcloud shell 網頁版, 快速教學 在此 若你對 gcloud 不熟，也可以選擇使用網頁 UI 操作 登入跟開機器的部分就略過，因為不在本篇主題範圍內 給機器加 taggcloud compute instances add-tags instanceName \\--tags test 開啟防火牆 依據指定的 tag 來開啟防火牆，這樣才不會開到所有的機器上 開啟連線 port gcloud compute firewall-rules create ftp-communication --allow tcp:21212 --target-tags test 開啟 passive port 的範圍 gcloud compute firewall-rules create ftp-dataportrange --allow tcp:40000-50000 --target-tags test FTP 連線安裝 mac brew install inetutils ubuntu應該已經有了 重啟sudo service vsftpd restart;sudo service vsftpd status 應該要是 running 連線ftp -p yourIP 21212 輸入我們設定 user: test 輸入密碼: 1234 試試上傳一個檔案put whateverFile 結論沈浸在技術研究的感覺總是令人沈醉，雖然當遇到難題時，還真的想大醉一場有設定到 www-data 的部分，那是因為其實這個 FTP server 是架設來讓前端可以做簡單的部署，只要把 code 上傳，我的 NginX 會有一個 config 是反向代理這個資料夾, 不過因為跟本篇較無關係，看看就好！ 參考資料 我心目中的 Linux 之神，鳥哥大http://linux.vbird.org/linux_server/0410vsftpd.php Digital Ocean 的大神https://www.digitalocean.com/community/questions/proper-permissions-for-web-server-s-directory","link":"/zh-tw/ftpServer/"},{"title":"在GCP建立一個persistent disk","text":"前言本篇主要是利用Google的Qwiklab平台學習的同時，做的一份學習筆記原文請參閱Refer to official link Persistent分為兩種 一般persistent disk SSD persistent disk 本篇將會做什麼？ 建立一個新的VM instance，然後在其新增persistent disk 掛載並格式化persistent disk 設定及要求Qwiklabs setup在你按下 Start Lab 按鈕之前詳讀所有的教學。Labs 是有時間限制的，而且你不可以停止時間倒數。倒數計時器在你按下 Start Lab 按鈕後開始倒數，上面顯示的時間為你還能使用 Cloud 資源的時間。 Quiklabs 的手把手環境，讓你可以在真實環境中來操作進行 Quiclabs 上提供的課程，而不是在一個模擬或是展示的環境。我們透過提供你一個全新的、暫時的帳號密碼，在計時器歸零之前，你可以用來登入並存取 Google Cloud Platform。 你需要什麼？要完成這個 lab ，你需要: 一個一般的網路瀏覽器（推薦 Chrome） 完成這個 lab 的時間 備註： 如果你已經有你自己的個人 GCP 帳號或專案，請不要使用在這一個 lab Google Cloud Platform Console如何開始你的 lab ，然後登入 Console? 按下 Start Lab 按鈕。如果你需要付費，會有一個彈出視窗來讓你選擇付費的方式。在左方你會看到一個面板，上面有暫時的帳號密碼，你必須使用這些帳號密碼在此次 lab 複製 username , 然後點擊 Open Google Console。 Lab 會開啟另外一個視窗，顯示選擇帳號的頁面 tip: 開啟一個全新的視窗，然後跟原本的頁面並排 在選擇帳號頁面, 點擊 Use Another Account 登入頁面開啟，貼上之前複製的 username 以及 password ，然後貼上 重要：必須使用之前於 Connection Details 面板 取得的帳號密碼，不要使用你自己的 Qwiklabs 帳號密碼。 如果你有自己的 GCP 帳號，請不要用在這裡（避免產生費用） 點擊並通過接下來的頁面: 接受terms以及conditions 不要增加recovery optoins 或 two factor authentication (因為這只是一個臨時帳號) 不要註冊免費體驗 稍待一些時候， GCP 控制台將會在這個視窗開啟。 注意：按下左上方位於Google Cloud Platform 隔壁的 Navigation menu ，你可以瀏覽選單，裡面有一系列的 GCP 產品以及服務 Cloud Shell啟動 Google Cloud ShellGoogle Cloud Shell 是載有開發工具的虛擬機器。它提供了5GB的 home 資料夾，並且運行在 Google Cloud 上。 Google Cloud Shell 讓你可以利用 command-line 存取 GCP 資源 在 GCP 控制台 ，右上的工具列，點擊 Open Cloud Shell 按鈕 在打開的對話框裡，按下 START CLOUD SHELL: 你可以立即按下 START CLOUD SHELL 當對話視窗打開。 連結並提供環境會需要一點時間。當你連結成功，這代表你已成功獲得授權，且此專案已被設為你的專案ID，例如： gcloud 是 Google Cloud Platform 的 command-line 工具，他已事先被安裝在 Cloud Shell 並且支援自動補齊 使用這個 command ,你可以列出有效帳戶名稱:gcloud auth list 輸出:Credentialed accounts: - &lt;myaccount&gt;@&lt;mydomain&gt;.com (active) 範例輸出:Credentialed accounts: - google1623327_student@qwiklabs.net 你可以使用以下 command 來列出專案 IDgcloud config list project 輸出：[core]project = &lt;project_ID&gt; 範例輸出：[core]project = qwiklabs-gcp-44776a13dea667a6 gcloud 的完整文件可以參閱 Google Cloud gcloud Overview 建立VM instance 建立一個名為’gcelab’的新虛擬機instance gcloud compute instances create gcelab --zone us-central1-c 新建的VM instance將有內建10GB的初始化disk 建立新的persistent disk 在Cloud Shell中輸入以下指令，注意zone參數需與VM instance一致gcloud compute disks create mydisk --size=200GB --zone us-centrall-c 在運轉中的VM instance上新增剛建立的persistent diskgcloud compute instances attach-disk gcelab --disk mydisk --zone us-central1-c 在VM instance 上找到剛剛新增的persistent disk SSH到virtual machinegcloud compute ssh gcelab --zone us-central1-c 輸入y繼續 如果需要設定密碼，可以輸入密碼 在/dev/disk/by-id/下找到disk裝置 ls -l /dev/disk/by-id/ 找到預設裝置名稱如下: scsi-0Google_PersistentDisk_persistent-disk-1. 如果你想要一個不一樣的裝置名稱，當你在新增disk時，你可以加入裝置名稱參數 gcloud compute instances attach-disk gcelab --disk mydisk --device-name yourDeviceName --zone us-central1-c 格式化，並且掛載persistent disk 在找到裝置後，我們可以將disk分區，格式化，並且掛載 建立一個掛載點sudo mkdir /mnt/mydisk 使用mkfs工具，格式化disk為ext4格式，這個指令將會刪除指定disk下的所有資料 sudo mkfs.ext4 -F -E lazy_itable_init=0,lazy_journal_init=0,discard /dev/disk/by-id/scsi-0Google_PersistentDisk_persistent-disk-1 利用mount工具，掛載disk sudo mount -o discard,defaults /dev/disk/by-id/scsi-0Google_PersistentDisk_persistent-disk-1 /mnt/mydisk 設定自動掛載 預設值中，在VM instance重新啟動之後，persistent disk並不會自動掛載，我們需要在/etc/fstab檔案中增加一些輸入 sudo vim /etc/fstab 在開頭是UUID那段程式碼之後，加入： /dev/disk/by-id/scsi-0Google_PersistentDisk_persistent-disk-1 /mnt/mydisk ext4 defaults 1 1 此時，你的/etc/fstab應該看起來要像這樣:UUID=e084c728-36b5-4806-bb9f-1dfb6a34b396 / ext4 defaults 1 1/dev/disk/by-id/scsi-0Google_PersistentDisk_persistent-disk-1 /mnt/mydisk ext4 defaults 1 1 按:wq 小習題： Can you prevent the destruction of an attached persistent disk when the instance is deleted? No, attached persistent disks are always associated with the lifetime of the instance. Yes, deselect the option Delete boot disk when instance is deleted when creating an instance Yes, use the -keep-disks option with the gcloud compute instances delete command For migrating data from a persistent disk to another region, reorder the following steps in which they should be performed: Attach disk Create disk Create snapshot Create instance Unmount file system(s) (4, 1, 2, 3, 5) (2, 3, 1, 4, 5) (1, 3, 2, 4, 5) (5, 3, 2, 4, 1) 非必要指令 顯示活躍中帳戶gcloud auth list 顯示project idgcloud config list project","link":"/zh-tw/createAPersistentDisk/"},{"title":"Git-從哪裡開始？","text":"嗨大家好，我是Ray! 如上一篇提到，Git對於一個coder來說可以說是不可或缺的，今天我就來分享一下Git的基本操作 首先呢，讓我們先來創一個範例資料夾，名稱就叫做my-git-repository吧！ 到Command Line cd 你想要這個資料夾在哪的路徑/ 輸入mkdir my-git-repository 然後cd code/my-git-repository 進到資料夾內，code是我自己的母資料夾，各位請輸入你們自己的路徑 進到資料夾的位置，如下圖：￼ 讓我們在裡面建立一個檔案touch example1.html 然後在該檔案裡面添加以下內容：&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;First example&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;This is the first example&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 輸入git init ￼ 然後輸入 git status ￼ 如上圖所示，我們已經可以開始使用git的相關功能，目前example1的檔案還處於untracked狀態，在建立任何存擋點之前，我們必須要先將檔案加入追蹤，就好像我們在FB上追蹤那些名人一樣！ 輸入git add example1.html 如下圖：￼ 再來輸入git commit 看起來如下：￼ 應該會出現以下的畫面￼ 接著我們隨便輸入first example當作這個存擋點的訊息記錄 接著我們按:wq 儲存並離開視窗 輸入git status 看起來如上圖： 輸入git log 然後你應該可以看到一串代表著此次commit，獨一無二的號碼。￼ 你應該會看到以下的commit，commit 的號碼每個人都不同，所以如果你的號碼跟我的不同是正常的，不用覺得奇怪！ 這樣一來就算是完成了一次的存擋啦！之後我們可以隨時回到這個狀況只要我們想要的話！ 今天的分享就先到這啦，之後若有機會會再做進一步的介紹！","link":"/zh-tw/gitInit/"},{"title":"Git-標注一個版本號碼","text":"哈囉大家好，我是Ray！ 今天我將跟大家分享git tag，如何建立一個版本號。 當我們接二連三地完成了專案裡的一些功能，一系列的功能可能代表著一個版本的產生，比方來說，大家都玩過線上遊戲吧？ 每次改版時，常常都是釋出一些新的功能，這個版本號常常意味著，除了這些功能開發完成之外，並且都正常的運作著。 這個版本號對於開發者來說非常方便與重要，這樣來解釋，一系列的小功能構成一個大功能，而這個大功能的完成也代表著新版本的推出。 當每一次我們完成了一個小功能，我們使用git commit把它記錄下來，而當我們陸陸續續完成一系列的小功能而構成一個大功能時，我們使用git tag來標注，代表著一個版本的釋出。若日後我們需要回到這一版來做相關的一些測試的話，非常的方便！ 輸入 git log --oneline 以上是我們還沒有tag之前的樣子。 輸入git tag -a v1.0 -m “The stable version of example” 如上圖你可以看到我們剛剛加入的版本號 v1.0 輸入 git tag 可以看到我們至今tag的任何版本號 現在讓我們新增一個檔案，example2.html，並且新增以下的code: &lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;This is the experimental file created after reversion v1.0&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 然後輸入Git add example2.htmlgit commit -am “An example2 file after v1.0”Git log --oneline 如上圖，我們目前在第六個commit，而我們的版本是在第五個commit 當我們想要回到v1.0的版本時，我們不需要checkout第五個commit的名稱，我們只需要輸入版本編號即可，如下輸入： Git checkout v1.0Git log --oneline 如上圖，我們已經回到版本v1.0的紀錄了 希望我今天的文章對你有所幫助！","link":"/zh-tw/gitTag/"},{"title":"My learning note on Gitlab","text":"前言個人 Gitlab 學習筆記，內容未整理過。 Event 通知Project =&gt; Settings =&gt; Integrations =&gt; Slack notifications","link":"/zh-tw/gitlab/"},{"title":"推錯了Commit該怎麼辦？","text":"有時我們把功能做好並且推上公共資料夾之後才發現，靠…我commit好像推錯了…別緊張，這時候我們可以使用git revert 來取消我們的commit。現在讓我來為各位做個示範： 建立一個本地遠端資料夾 因為有些朋友可能沒有網路，所以本篇範例將創立一個在本地的遠端資料夾 到你一般存放專案的資料夾底下 mkdir git_demonstration git_demonstration_central cd git_demonstration_central git init --bare git_demonstration_central將會是本篇範例中的遠端資料夾 建造本地測試環境 進到本範例本地資料夾 cd ../git_demonstration 初始化git git init 建立名為test的檔案 touch test 在檔案內增加內容1 cat 1 &gt; test 將test檔案加到git追蹤清單 git add test 針對目前檔案以及內容做一個commit名為1 git commit -m&#39;1&#39; 在檔案test中增加數字2，並做一個新的commit名為2 cat 2 &gt;&gt; test;git commit -am&#39;2&#39; 在檔案test中增加數字3，並做一個新的commit名為3 cat 3 &gt;&gt; test;git commit -am&#39;3&#39; 建立遠端branchBuild remote branch 將我們一開始建立的位於本地的模擬遠端資料夾加到當前測試環境的遠端 git remote add origin /user/yourUserName/yourDirectory/git_demonstration_central 將目前master branch 推到此遠端，並將遠端新增的分支設為本地的上游分支 git push -u origin master 到遠端資料夾看一下，目前狀況 cd ../git_demonstration_central;git log Revert已存在的commit 假設今天我們要將commit 3的內容移除 git revert f06550f7 更新到遠端 git push 看一下檔案test的內容是否已變更 cat test 得值1 2，原本數字3已經在revert之後被移除了 確認遠端歷史狀況 cd ../git_demonstration_central;git log 總結有些剛接觸git的人可能會跟我當初有同樣的疑問，那為啥不要整個git的log紀錄都抹掉就好，為啥要多一個commit？這邊跟大家解釋一下，如果今天我們已經把我們完成的進度推到共同資料夾了，我們就不建議去修改歷史了，因為你一但修改了歷史再往上推，整個共同資料夾的歷史就會改變，共同資料夾的紀錄相當於所有協作者的紀錄，所以如果你單方面變動了歷史，很可能會造成所有協作者的歷史都跟你的不一致，甚至在commit的過程中會有衝突，這在多人協作是相當不建議的。我們要拿掉的，是我們檔案內的一段有commit紀錄的code，所以實際上我們要取消的是code，不是歷史，而在多人協作中，歷史是可以增加，不建議修改的。你可以新增一個commit明確說明我這段commit是新增或者拿掉了什麼東西，但是不建議單方面地把東西拿掉並且去修改你的歷史紀錄，因為你改的東西只有你自己知道，對於其他的協作者來說他們並不知道在你的電腦上發生了什麼事。簡單來說，在你上傳到共同資料夾之前，你可以對你的歷史做任何事（這邊僅限於還未上傳的部分，已經上傳的不建議去修改），但是一但上傳之後，就不建議去修改歷史。如果你要對檔案內容做任何修改，請新增一個commit說明修改的內容，這樣才不會造成其他協作者的疑惑以及大家的git歷史有衝突。以上就是今天的分享，我們明天見！","link":"/zh-tw/gitRevert/"},{"title":"在GCP上開立一台虛擬機","text":"前言本篇主要是利用Google的Qwiklab平台學習的同時，做的一份學習筆記原文可參閱Refer to official link 本篇將會做什麼？ 利用GCP主控台建立一個virtual machine 利用gcloud command line建立一個virtual machine 在virtual machine上部署一個web server 設定及要求Qwiklabs setup在你按下 Start Lab 按鈕之前詳讀所有的教學。Labs 是有時間限制的，而且你不可以停止時間倒數。倒數計時器在你按下 Start Lab 按鈕後開始倒數，上面顯示的時間為你還能使用 Cloud 資源的時間。 Quiklabs 的手把手環境，讓你可以在真實環境中來操作進行 Quiclabs 上提供的課程，而不是在一個模擬或是展示的環境。我們透過提供你一個全新的、暫時的帳號密碼，在計時器歸零之前，你可以用來登入並存取 Google Cloud Platform。 你需要什麼？要完成這個 lab ，你需要: 一個一般的網路瀏覽器（推薦 Chrome） 完成這個 lab 的時間 備註： 如果你已經有你自己的個人 GCP 帳號或專案，請不要使用在這一個 lab Google Cloud Platform Console如何開始你的 lab ，然後登入 Console? 按下 Start Lab 按鈕。如果你需要付費，會有一個彈出視窗來讓你選擇付費的方式。在左方你會看到一個面板，上面有暫時的帳號密碼，你必須使用這些帳號密碼在此次 lab 複製 username , 然後點擊 Open Google Console。 Lab 會開啟另外一個視窗，顯示選擇帳號的頁面 tip: 開啟一個全新的視窗，然後跟原本的頁面並排 在選擇帳號頁面, 點擊 Use Another Account 登入頁面開啟，貼上之前複製的 username 以及 password ，然後貼上 重要：必須使用之前於 Connection Details 面板 取得的帳號密碼，不要使用你自己的 Qwiklabs 帳號密碼。 如果你有自己的 GCP 帳號，請不要用在這裡（避免產生費用） 點擊並通過接下來的頁面: 接受terms以及conditions 不要增加recovery optoins 或 two factor authentication (因為這只是一個臨時帳號) 不要註冊免費體驗 稍待一些時候， GCP 控制台將會在這個視窗開啟。 注意：按下左上方位於Google Cloud Platform 隔壁的 Navigation menu ，你可以瀏覽選單，裡面有一系列的 GCP 產品以及服務 Cloud Shell啟動 Google Cloud ShellGoogle Cloud Shell 是載有開發工具的虛擬機器。它提供了5GB的 home 資料夾，並且運行在 Google Cloud 上。 Google Cloud Shell 讓你可以利用 command-line 存取 GCP 資源 在 GCP 控制台 ，右上的工具列，點擊 Open Cloud Shell 按鈕 在打開的對話框裡，按下 START CLOUD SHELL: 你可以立即按下 START CLOUD SHELL 當對話視窗打開。 連結並提供環境會需要一點時間。當你連結成功，這代表你已成功獲得授權，且此專案已被設為你的專案ID，例如： gcloud 是 Google Cloud Platform 的 command-line 工具，他已事先被安裝在 Cloud Shell 並且支援自動補齊 使用這個 command ,你可以列出有效帳戶名稱:gcloud auth list 輸出:Credentialed accounts: - &lt;myaccount&gt;@&lt;mydomain&gt;.com (active) 範例輸出:Credentialed accounts: - google1623327_student@qwiklabs.net 你可以使用以下 command 來列出專案 IDgcloud config list project 輸出：[core]project = &lt;project_ID&gt; 範例輸出：[core]project = qwiklabs-gcp-44776a13dea667a6 gcloud 的完整文件可以參閱 Google Cloud gcloud Overview 理解Regions 和 Zones 特定的Compute Engine 資源位於特定的regions或zones. Region表示一個特定的地理位置，而你的資源就跑在那邊。 每個region都有一個或多個zones，舉例來說，us-central1 region位於Central United States，並且下面有us-central1-a, us-central1-b, us-central1-c, us-central1-f這些zones 位於zone的資源算是zonal資源。 Virtual machine instance還有persistent disk都位於zone, 如果要在一個virtual machine上加一個persistent disk，那兩者必須位於同一個zone 相同的，如果你要分配一個static IP位址到一個instance，這個instance必須要跟這個static IP同一個region 從Cloud Console建立一個新的instance Navigation menu &gt; Compute Engine &gt; VM instance 按create 欄位 值 額外資訊 name gcelab region us-central1(Iowa) or asia-south1(Mumbai) 更多regions的資訊 zone us-central1-c or asia-south1-c 注意：記住你選擇的zone，待會會用到 更多zone的資訊 Machine Type 2 vCPUs 這是一個(n1-standard-1), 1-CPU, 3.75GB RAM instance 有很多種類型可以選擇，從基礎型的到32-core/208GB RAM的都有，更多資訊可以參考機型種類文件 一個新專案有所謂的resource quota, 他會限制可以開立的機型規格。我們可以要求更高規格的機型在此lab之外 Boot Disk New 10 GB standard persistent disk OS Image: Debian GNU/Linux 9 (Stretch) 有很多種類的images可以選擇，包含Debian, Ubuntu, CoreOS，以及一些高級的iamges，像是RedHat Enterprise, Linux，和Windows Server，更多資訊可以參考作業系統文件 Firewall 勾選 Allow HTTP traffic 勾選這個選項，所以我們等等才能存取安裝好的server 注意：這會自動建立防火牆規則，容許HTTP 80 port通道 點擊Create 點擊SSH，經由瀏覽器連到virtual machine 注意：更多資訊可以參考文件 安裝NGINX web server 經由SSH連接virtual machine之後，先取得root權限 sudo su - 更新OS apt-get update 安裝NGINX apt-get install nginx -y 確認NGINX正常運行中 ps auwx | grep nginx 現在我們可以經由點擊Cloud Console上的External IP連結按鈕，或者直接在瀏覽器上輸入http://EXTERNAL_IP/ IP位址來連結到Server的網頁 使用gcloud來建立一個instance除了使用GCP主控台之外，我們也可以使用gcloud的command line 工具來建立一個virtual machine instance，這個工具已經事先被安裝在Google Cloud Shell中了。Cloud Shell 是一台以Debian為基礎的virtual machine，預載有所有你需要的開發工具(gcloud, git, 還有其他的等等), 並且提供5GB persistent disk的home目錄如果你之後想要在自己的機器上嘗試看看，可以參考gcloud command line tool guide 在Cloud Shell，利用command line gloud工具建立一台新的virtual machine instance gcloud compute instances create gcelab2 --zone us-central1-c 建立的instance將會有以下的預設值 最新的Debian 9 image n1-standard-1 machine type, 在這個lab中，你可以選擇其他的machine type，像是n1-highmen-4或n1-highcpu-4，如果你在做這個lab之外的專案，你可以選擇客製化的machinee type 預設的persistent disk名稱將與此instance一樣，並自動加到此instance 使用 gcloud compute instances create --help 檢視所有預設 如果你總是使用同一個區域，你可以將指定的地區設為預設，這樣就不需要每次都要使用--zone參數gcloud config set compute/zone gcloud config set compute/region 檢視你的instance, Navigation menu &gt; Compute Engine &gt; VM instances 最後，你可以使用gcloud經由SSH連線到你的instance，當你在連接時，確定一下後面的zone是跟你當初建的時候指定的一樣，或者如果你已經使用的上述的指定默認指令，那就不需要在指定一次。 gcloud compute ssh gcelab2 --zone us-central1-c 選y繼續 考考你！ Through which of the following ways you can create a VM instance in Google Compute Engine(GCE)? Through web console The gcloud command line tool.","link":"/zh-tw/createAVirtualMachineInGCP/"},{"title":"利用 Gitlab CI/CD 部署專案到 GCP virtual machine","text":"前言本篇將分享如下： 利用 gcloud 開立一台 GCP instance 如何利用 gcloud 在 instance 上匯入 ssh key 利用 Daemon 使服務常駐 利用 gitlab pusher 部署專案到 GCP virtual machine 上 環境建立開啟一台 GCP 虛擬機以下是個人做法，不需要照做 Ray 使用 Mac 所以我在本地端安裝了 Google Cloud SDK, 安裝方式可以參考官方文件 建立一台 VM 建立一台機器, 叫做 example-instance-1 開機碟的空間為 10GB 從 ubuntu-os-cloud, 來 pull 我們需要的 image 我們使用 ubuntu-1804-lts 的 image 版本, 這會自動使用這個版本的最新版 硬碟類型為 pd-stand, 不知道類型可以跑 gcloud compute disk-types list 來看看 機器型號為 f1-micro, 不知道類型可以跑 gcloud compute machine-types list 來看看 tags 用來當作該 instance 的一個識別，等等開防火牆的時候會用到 zone 指定該 instance 的地區, 有些資源只有相同 zone 或者 region 可以取用，要注意 如下:gcloud compute instances create example-instance-1 \\--image-project=ubuntu-os-cloud \\--image-family=ubuntu-1804-lts \\--boot-disk-size=10GB \\--boot-disk-type=pd-standard \\--machine-type=f1-micro \\--tags=example-instance-1,http-server,https-server \\--zone=asia-east1-a 開啟後，我們先來產 keyssh-keygen -t rsa -b 4096 -C \"root@example\" 假設 key 的名稱為 examplecat example.pub &gt; instanceSSHConfig &amp;&amp; vim instanceSSHList 在最前面加上 root, 格式如下：[USERNAME]:ssh-rsa [KEY] [USERNAME] 我們只有一把 key 獲得 instance 名稱gcloud compute instances list 新增 public key 到 instance(這邊請注意，這個指令會替換掉這個 instance 在 GCP 的 SSH key, 換言之，這個檔案裡面沒有的 key 都會消失)gcloud compute instances add-metadata instanceName --metadata-from-file ssh-keys=instanceSSHList 安裝以下主要是安裝 nvm, node 版本v12.1.0, 以及 npm, 細節可以參考官方文件apt-get update -y &amp;&amp; apt-get install curl -y &amp;&amp; curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.34.0/install.sh | bash &amp;&amp; export NVM_DIR=\"$HOME/.nvm\" &amp;&amp; [ -s \"$NVM_DIR/nvm.sh\" ] &amp;&amp; \\. \"$NVM_DIR/nvm.sh\" &amp;&amp; [ -s \"$NVM_DIR/bash_completion\" ] &amp;&amp; \\. \"$NVM_DIR/bash_completion\" &amp;&amp; nvm install v12.1.0 &amp;&amp; apt-get install npm -y Daemon接下來，以下為 Daemon 設定, 我們將使用 Daemon 來幫我們跑我們的服務，並且讓我們的服務在斷開的時候可以自動重啟sudo vim /etc/init.d/serviceName #!/bin/sh### BEGIN INIT INFO# Provides: yourServiceName (optional)# Required-Start: $remote_fs $syslog# Required-Stop: $remote_fs $syslog# Default-Start: 2 3 4 5# Default-Stop: 0 1 6# Short-Description: Start daemon at boot time# Description: Enable service provided by daemon.### END INIT INFOdir=\"yourProjectLocation\"cmd=\"theCommandItRequiresToStartYourService\"user=\"root\"name=`basename $0`pid_file=\"/var/run/$name.pid\"stdout_log=\"/var/log/$name.log\"stderr_log=\"/var/log/$name.log\"get_pid() &#123; cat \"$pid_file\"&#125;is_running() &#123; [ -f \"$pid_file\" ] &amp;&amp; ps -p `get_pid` &gt; /dev/null 2&gt;&amp;1&#125;case \"$1\" in start) if is_running; then echo \"Already started\" else echo \"Starting $name\" cd \"$dir\" export NODE_ENV=test if [ -z \"$user\" ]; then sudo $cmd &gt;&gt; \"$stdout_log\" 2&gt;&gt; \"$stderr_log\" &amp; else sudo -u \"$user\" $cmd &gt;&gt; \"$stdout_log\" 2&gt;&gt; \"$stderr_log\" &amp; fi echo $! &gt; \"$pid_file\" if ! is_running; then echo \"Unable to start, see $stdout_log and $stderr_log\" exit 1 fi fi ;; stop) if is_running; then echo -n \"Stopping $name..\" kill `get_pid` for i in 1 2 3 4 5 6 7 8 9 10 # for i in `seq 10` do if ! is_running; then break fi echo -n \".\" sleep 1 done echo if is_running; then echo \"Not stopped; may still be shutting down or shutdown may have failed\" exit 1 else echo \"Stopped\" if [ -f \"$pid_file\" ]; then rm \"$pid_file\" fi fi else echo \"Not running\" fi ;; restart) $0 stop if is_running; then echo \"Unable to stop, will not attempt to start\" exit 1 fi $0 start ;; status) if is_running; then echo \"Running\" else echo \"Stopped\" exit 1 fi ;; *) echo \"Usage: $0 &#123;start|stop|restart|status&#125;\" exit 1 ;;esacexit 0 若發現找不到 service 的話，那需要重新載入 daemon sudo systemctl daemon-reload 記得更改權限，讓 deamon 可以執行 sudo chmod 755 serviceName 開啟自動重啟，當 VM 重啟時，服務會跟著重啟 sudo systemctl enable serviceName Daemon 的名稱在此範例中，會設置的跟專案名稱一樣 CI/CDGitlab variables setting 我們將使用 Gitlab 的 pusher 來做 CI/CD 的部分，所以這邊先建立一組 ssh key, 並且在 gitlab 中設定為 $SSH_PRIVATE_KEY ssh-keygen -t rsa -b 4096 -C \"root@deploy\" Gitlab yaml config file下面我們會開始設定 Gitlab 的 pusher config yaml 檔案在我們的專案中：vim .gitlab-ci.yml # This file is a template, and might need editing before it works on your project.# Official framework image. Look for the different tagged releases at:# https://hub.docker.com/r/library/node/tags/# 在 Docker 內部，我們要使用的環境 imageimage: node:8# This folder is cached between builds# http://docs.gitlab.com/ce/ci/yaml/README.html#cache# cache 可以讓我們使用在所有的 buildcache: paths: - node_modules/stages:- build- deploy# 只是個名字npm-build: stage: build script: # 刪掉 node_modules, 安裝最新版的 npm, 並更新 project 裡頭的 npm 套件 - rm -rf node_modules/ &amp;&amp; npm i npm@latest -g &amp;&amp; npm install # 只是個名字depoly-test:# 將在 `deploy` stage 做以下的事 stage: deploy script: # cfr. https://docs.gitlab.com/ee/ci/ssh_keys/README.html # Install ssh-agent if not already installed, it is required by Docker. # (change apt-get to yum if you use a CentOS-based image) # 如果 ssh-agent 不存在，更新 apt-get 並且安裝 openssh-client - 'which ssh-agent || ( apt-get update -y &amp;&amp; apt-get install openssh-client -y )' # Run ssh-agent (inside the build environment) # 當運行 ssh-agent -s 時，會輸出一些 command, 但是他們並還沒有被執行，所以必須使用 eval ，他可以用來執行迭代運算 - eval $(ssh-agent -s) # Add the SSH key stored in SSH_PRIVATE_KEY variable to the agent store # 將 $SSH_PRIVATE_KEY 加到 ssh agent - ssh-add &lt;(echo \"$SSH_PRIVATE_KEY\") # For Docker builds disable host key checking. Be aware that by adding that # you are suspectible to man-in-the-middle attacks. # WARNING: Use this only with the Docker executor, if you use it with shell # you will overwrite your user's SSH config. #- mkdir -p ~/.ssh #- '[[ -f /.dockerenv ]] &amp;&amp; echo -e \"Host *\\n\\tStrictHostKeyChecking no\\n\\n\" &gt; ~/.ssh/config' # In order to properly check the server's host key, assuming you created the # SSH_SERVER_HOSTKEYS variable previously, uncomment the following two lines # instead. # 在 docker container 中，建立 .ssh 資料夾, 並設立權限 - mkdir -m 700 -p /root/.ssh # 使用 gz 格式來將位於當層的專案資料夾整個壓縮，並將壓縮檔丟到上一層目錄去 - tar zcf ../$CI_PROJECT_NAME.tar.gz ./ # 將壓縮檔丟到指定機器上的指定目錄 - scp -o StrictHostKeyChecking=no ../$CI_PROJECT_NAME.tar.gz root@35.201.171.244:/locationYouPrefer # 接下來，我們利用 ssh 到指定的機器，然後開始做以下的事 # 建立一個跟專案同名的資料夾 # 將剛剛打包好的檔案，解壓縮到這個資料夾內，並不顯示解壓縮訊息 # 更改專案資料夾的權限 # 進到資料夾中, npm rebuild, 並且打開事先設定好的 daemon service - ssh root@yourIP \"rm -rf /locationYouPrefer/$CI_PROJECT_NAME &amp;&amp; mkdir -p locationYouPrefer/$CI_PROJECT_NAME &amp;&amp; tar zxf locationYouPrefer/$CI_PROJECT_NAME.tar.gz -C locationYouPrefer/$CI_PROJECT_NAME &amp;&amp; chmod -R 655 locationYouPrefer/$CI_PROJECT_NAME &amp;&amp; cd locationYouPrefer/$CI_PROJECT_NAME &amp;&amp; npm rebuild &amp;&amp; /etc/init.d/$CI_PROJECT_NAME restart\" # 以上的 deploy stage 唯有在你指定的 branch 觸發 only: - branchYouPrefer 結論到這邊，當我們 git push 到指定的 branch 時，就會觸發 gitlab 的 pusher 來達成自動部署。","link":"/zh-tw/gitlabCICDOnGCP/"},{"title":"串接Facebook graph API","text":"前言本篇將分享如何使用JavaScript SDK讓用戶登入並取得token，然後利用PHP SDK向Facebook發請求，進而取得使用者的資訊。 到FB的開發者頁面，申請一個帳號，並且在主控台的地方，新增一個應用程式 到應用程式內的基本資料裡頭，複製應用程式編號以及應用程式密鑰創建Laravel專案laravel new Facebook 初始化Gitgit init 安裝Facebook PHP SDK 於專案目錄下composer require facebook/graph-sdk 建立一個稍後用來向FB拿資料的Controllerphp artisan make:controller FBController 建立一個getFacebookResources function 複製Facebook SDK 首頁的範例程式碼，並貼在這個function裏頭 require_once __DIR__ . &apos;/vendor/autoload.php&apos;; // change path as needed$fb = new \\Facebook\\Facebook([ &apos;app_id&apos; =&gt; &apos;&#123;app-id&#125;&apos;, &apos;app_secret&apos; =&gt; &apos;&#123;app-secret&#125;&apos;, &apos;default_graph_version&apos; =&gt; &apos;v2.10&apos;, //&apos;default_access_token&apos; =&gt; &apos;&#123;access-token&#125;&apos;, // optional]);// Use one of the helper classes to get a Facebook\\Authentication\\AccessToken entity.// $helper = $fb-&gt;getRedirectLoginHelper();// $helper = $fb-&gt;getJavaScriptHelper();// $helper = $fb-&gt;getCanvasHelper();// $helper = $fb-&gt;getPageTabHelper();try &#123; // Get the \\Facebook\\GraphNodes\\GraphUser object for the current user. // If you provided a &apos;default_access_token&apos;, the &apos;&#123;access-token&#125;&apos; is optional. $response = $fb-&gt;get(&apos;/me&apos;, &apos;&#123;access-token&#125;&apos;);&#125; catch(\\Facebook\\Exceptions\\FacebookResponseException $e) &#123; // When Graph returns an error echo &apos;Graph returned an error: &apos; . $e-&gt;getMessage(); exit;&#125; catch(\\Facebook\\Exceptions\\FacebookSDKException $e) &#123; // When validation fails or other local issues echo &apos;Facebook SDK returned an error: &apos; . $e-&gt;getMessage(); exit;&#125;$me = $response-&gt;getGraphUser();echo &apos;Logged in as &apos; . $me-&gt;getName(); 填入應用程式編號以及應用程式密鑰 上頭的範例中，在以下地方填入我們從FB開發者帳號中得到的資訊$fb = new \\Facebook\\Facebook([ &apos;app_id&apos; =&gt; &apos;應用程式編號&apos;, &apos;app_secret&apos; =&gt; &apos;應用程式密鑰&apos;, &apos;default_graph_version&apos; =&gt; &apos;目前版本&apos;, //&apos;default_access_token&apos; =&gt; &apos;&#123;access-token&#125;&apos;, // optional]); 建立使用者登入按鈕 使用者要先登入進而拿到token，我們才可以使用token來做事 於routes/web.php檔案中，新建一個給登入頁面使用的route Route::get(&apos;/FBToken&apos;, function()&#123;return view(&apos;FBToken&apos;);&#125;); 於resources/views/資料夾底下，新增FBToken.blade PHP檔, 然後在裡頭貼上以下的JS code &lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Facebook Login JavaScript Example&lt;/title&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;/head&gt;&lt;body&gt;&lt;script&gt; // This is called with the results from from FB.getLoginStatus(). function statusChangeCallback(response) &#123; console.log(&apos;statusChangeCallback&apos;); console.log(response); // The response object is returned with a status field that lets the // app know the current login status of the person. // Full docs on the response object can be found in the documentation // for FB.getLoginStatus(). if (response.status === &apos;connected&apos;) &#123; // Logged into your app and Facebook. testAPI(); &#125; else &#123; // The person is not logged into your app or we are unable to tell. document.getElementById(&apos;status&apos;).innerHTML = &apos;Please log &apos; + &apos;into this app.&apos;; &#125; &#125; // This function is called when someone finishes with the Login // Button. See the onlogin handler attached to it in the sample // code below. function checkLoginState() &#123; FB.getLoginStatus(function(response) &#123; statusChangeCallback(response); &#125;); &#125; window.fbAsyncInit = function() &#123; FB.init(&#123; appId : &apos;&#123;your-app-id&#125;&apos;, cookie : true, // enable cookies to allow the server to access // the session xfbml : true, // parse social plugins on this page version : &apos;&#123;api-version&#125;&apos; // The Graph API version to use for the call &#125;); // Now that we&apos;ve initialized the JavaScript SDK, we call // FB.getLoginStatus(). This function gets the state of the // person visiting this page and can return one of three states to // the callback you provide. They can be: // // 1. Logged into your app (&apos;connected&apos;) // 2. Logged into Facebook, but not your app (&apos;not_authorized&apos;) // 3. Not logged into Facebook and can&apos;t tell if they are logged into // your app or not. // // These three cases are handled in the callback function. FB.getLoginStatus(function(response) &#123; statusChangeCallback(response); &#125;); &#125;; // Load the SDK asynchronously (function(d, s, id) &#123; var js, fjs = d.getElementsByTagName(s)[0]; if (d.getElementById(id)) return; js = d.createElement(s); js.id = id; js.src = &quot;https://connect.facebook.net/en_US/sdk.js&quot;; fjs.parentNode.insertBefore(js, fjs); &#125;(document, &apos;script&apos;, &apos;facebook-jssdk&apos;)); // Here we run a very simple test of the Graph API after login is // successful. See statusChangeCallback() for when this call is made. function testAPI() &#123; console.log(&apos;Welcome! Fetching your information.... &apos;); FB.api(&apos;/me&apos;, function(response) &#123; console.log(&apos;Successful login for: &apos; + response.name); document.getElementById(&apos;status&apos;).innerHTML = &apos;Thanks for logging in, &apos; + response.name + &apos;!&apos;; &#125;); &#125;&lt;/script&gt;&lt;!-- Below we include the Login Button social plugin. This button uses the JavaScript SDK to present a graphical Login button that triggers the FB.login() function when clicked.--&gt;&lt;fb:login-button scope=&quot;public_profile,email&quot; onlogin=&quot;checkLoginState();&quot;&gt;&lt;/fb:login-button&gt;&lt;div id=&quot;status&quot;&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 同樣，在上面的程式碼中需填入編號及版本號，如下 FB.init(&#123; appId : &apos;編號&apos;, cookie : true, // enable cookies to allow the server to access // the session xfbml : true, // parse social plugins on this page version : &apos;版本&apos; // The Graph API version to use for the call&#125;); 熟悉FB graph API 工具 利用FB graph API測試工具，我們可以找到我們需要的API 客製endpoint 因為之後我們可能會直接複製經由graph API 工具 取得的endpoint，如下： 所以我們可以把endpoint這段移到.env中，如下： $endpoint = env(&apos;FBEndpoint&apos;);try&#123; // Get the \\Facebook\\GraphNodes\\GraphUser object for the current user. // If you provided a &apos;default_access_token&apos;, the &apos;&#123;access-token&#125;&apos; is optional. $response = $fb-&gt;get($endpoint, $token); 然後.env裡頭 FBEndpoint=me?fields=id,name,email 如此一來，之後我們只要直接複製graph API取得的值，貼到.env，打完收工！ 修改錯誤回傳值 PHP SDK預設錯誤時，會依照錯誤狀況回傳錯誤訊息，可我只需知道true or false，就行了，token無效有可能是因為以下幾種狀況 根本沒帶 帶的是錯的 過期了 不管是哪一種，我都需要回傳錯誤訊息給前端，並要求前端再去跟FB要一次，拿對的來，所以說，我必須要判斷PHP SDK的輸出，有沒有錯誤，若錯做一件事，對也做一件事，因此我們需要修改原本錯誤訊息輸出的地方，改成簡單的true or false，如下：catch (\\Facebook\\Exceptions\\FacebookResponseException $e) { return false; // echo &apos;Graph returned an error: &apos; . $e-&gt;getMessage(); // exit; } 取得public url 使用ngrok取得用來拿token，HTML頁面的public url 登入開發者應用程式 =&gt; 找到產品Facebook登入 =&gt; 快速入門 =&gt; 網站 =&gt; 貼上public url 登入取得token將token打到Laravel裡的FBController裡頭的getFacebookResources將取得的資料，存入資料庫，完成會員建檔打完收工","link":"/zh-tw/getINFOViaFBToken/"},{"title":"Hello World","text":"FeaturesEnglish version中文版日本語版 Do not modify this note. Thank you very much :smile:If you want to say hello or play with something, please go to Playground Introduction HackMD is a realtime, multi-platform collaborative markdown note editor.This means that you can write notes with other people on your desktop, tablet or even on the phone.You can sign-in via multiple auth providers like Facebook, Twitter, GitHub and many more on the homepage. Please report new issues in GitHub.If you need instant help, please send us a Facebook message.Thank you very much! WorkspaceModesDesktop &amp; Tablet Edit: See only the editor. View: See only the result. Both: See both in split view. Mobile View: See only the result. Edit: See only the editor. Image Upload:You can upload an image simply by clicking on the camera button .Alternatively, you can drag-n-drop an image into the editor. Even pasting images is possible!This will automatically upload the image to imgur, nothing to worry. :tada: Share Notes:If you want to share an editable note, just copy the URL.If you want to share a read-only note, simply press publish button and copy the URL. Save a Note:Currently, you can save to Dropbox or save an .md file locally. Import Notes:Similarly to the save feature, you can also import an .md file from Dropbox ,or import content from your clipboard , and that can parse some html which might be useful :smiley: Permissions:It is possible to change the access permission to a note through the little button on the top right of the view.There are six possible options: Owner read/write Signed-in read Signed-in write Guest read Guest write Freely ✔ ✔ ✔ ✔ ✔ Editable ✔ ✔ ✔ ✔ ✖ Limited ✔ ✔ ✔ ✖ ✖ Locked ✔ ✔ ✖ ✔ ✖ Protected ✔ ✔ ✖ ✖ ✖ Private ✔ ✖ ✖ ✖ ✖ Only the owner of the note can change the note’s permissions. Embed a Note:Notes can be embedded as follows: &lt;iframe width=\"100%\" height=\"500\" src=\"https://hackmd.io/features\" frameborder=\"0\"&gt;&lt;/iframe&gt; Slide Mode:You can use a special syntax to organize your note into slides.After that, you can use the Slide Mode to make a presentation.Visit the above link for details. Book Mode:You can make your notes into a book.List your links in order or nest them.Then use the Book Mode to make a collection.Visit the above link for details. ViewTable of Contents:You can look at the bottom right section of the view area, there is a ToC button .Pressing that button will show you a current Table of Contents, and will highlight which section you’re at.ToCs support up to three header levels. PermalinkEvery header will automatically add a permalink on the right side.You can hover and click to anchor on it. Edit:Shortcut Keys:Just like Sublime text, which is pretty quick and convenient. For more infomation, see here. Auto-Complete:This editor provides full auto-complete hints in markdown. Emojis: type : to show hints. Code blocks: type ` and plus a character to show hint. ```- Headers: type `#` to show hint.- Referrals: type `[]` to show hint.- Externals: type `&#123;&#125;` to show hint.- Images: type `!` to show hint.## Title:This will take the first **level 1 header** as the note title.## Tags:Using tags as follows, the specified tags will show in your **history**.###### tags: `features` `cool` `updated`## [YAML Metadata](/yaml-metadata)You can provide advanced note information to set the browser behavior (visit above link for details):- title: set note title- description: set note description- image: set note default image (for link preview)- tags: set note tags- robots: set web robots meta- lang: set browser language- dir: set text direction- breaks: set to use line breaks- GA: set to use Google Analytics- disqus: set to use Disqus- slideOptions: setup slide mode options## ToC:Use the syntax `[TOC]` to embed table of content into your note.[TOC]## EmojiYou can type any emoji like this :smile: :smiley: :cry: :wink:&gt; See full emoji list [here](http://www.emoji-cheat-sheet.com/).## ToDo List:- [ ] ToDos - [x] Buy some salad - [ ] Brush teeth - [x] Drink some water## Code Block:We support many programming languages, use the auto complete function to see the entire list.```javascript=var s = &quot;JavaScript syntax highlighting&quot;;alert(s);function $initHighlight(block, cls) &#123; try &#123; if (cls.search(/\\bno\\-highlight\\b/) != -1) return process(block, true, 0x0F) + &apos; class=&quot;&quot;&apos;; &#125; catch (e) &#123; /* handle exception */ &#125; for (var i = 0 / 2; i &lt; classes.length; i++) &#123; if (checkCondition(classes[i]) === undefined) return /\\d+[\\s/]/g; &#125;&#125; If you want line numbers, type = after specifying the code block languagues.Also, you can specify the start line number.Like below, the line number starts from 101:var s = \"JavaScript syntax highlighting\";alert(s);function $initHighlight(block, cls) &#123; try &#123; if (cls.search(/\\bno\\-highlight\\b/) != -1) return process(block, true, 0x0F) + ' class=\"\"'; &#125; catch (e) &#123; /* handle exception */ &#125; for (var i = 0 / 2; i &lt; classes.length; i++) &#123; if (checkCondition(classes[i]) === undefined) return /\\d+[\\s/]/g; &#125;&#125; Or you might want to continue the previous code block’s line number, use =+ var s = \"JavaScript syntax highlighting\";alert(s); Somtimes you have a super long text without breaks. It’s time to use ! to wrap your code. When you’re a carpenter making a beautiful chest of drawers, you’re not going to use a piece of plywood on the back. Blockquote Tags: Using the syntax below to specifiy your name, time and color to vary the blockquotes.[name=ChengHan Wu] [time=Sun, Jun 28, 2015 9:59 PM] [color=#907bf7] Even support the nest blockquotes![name=ChengHan Wu] [time=Sun, Jun 28, 2015 10:00 PM] [color=red] ExternalsYouTube Vimeo Gist SlideShareMathJaxYou can render LaTeX mathematical expressions using MathJax, as on math.stackexchange.com, except the space after the start $ and the space before the end $ are not allowed in the inline math: The Gamma function satisfying $\\Gamma(n) = (n-1)!\\quad\\forall n\\in\\mathbb N$ is via the Euler integral $$x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}.$$ $$\\Gamma(z) = \\int_0^\\infty t^{z-1}e^{-t}dt\\,.$$ More information about LaTeX mathematical expressions here. UML DiagramsSequence DiagramsYou can render sequence diagrams like this: Alice-&gt;Bob: Hello Bob, how are you?Note right of Bob: Bob thinksBob--&gt;Alice: I am good thanks!Note left of Alice: Alice respondsAlice-&gt;Bob: Where have you been? Flow ChartsFlow charts can be specified like this:st=&gt;start: Starte=&gt;end: Endop=&gt;operation: My Operationop2=&gt;operation: lalalacond=&gt;condition: Yes or No?st-&gt;op-&gt;op2-&gt;condcond(yes)-&gt;econd(no)-&gt;op2 Graphvizdigraph hierarchy &#123; nodesep=1.0 // increases the separation between nodes node [color=Red,fontname=Courier,shape=box] //All nodes will this shape and colour edge [color=Blue, style=dashed] //All the lines look like this Headteacher-&gt;&#123;Deputy1 Deputy2 BusinessManager&#125; Deputy1-&gt;&#123;Teacher1 Teacher2&#125; BusinessManager-&gt;ITManager &#123;rank=same;ITManager Teacher1 Teacher2&#125; // Put them on the same level&#125; Mermaidgantt title A Gantt Diagram section Section A task :a1, 2014-01-01, 30d Another task :after a1 , 20d section Another Task in sec :2014-01-12 , 12d anther task : 24d AbcX:1T:Speed the PloughM:4/4C:Trad.K:G|:GABc dedB|dedB dedB|c2ec B2dB|c2A2 A2BA|GABc dedB|dedB dedB|c2ec B2dB|A2F2 G4:||:g2gf gdBd|g2f2 e2d2|c2ec B2dB|c2A2 A2df|g2gf g2Bd|g2f2 e2d2|c2ec B2dB|A2F2 G4:| More information about sequence diagrams syntax here.More information about flow charts syntax here.More information about graphviz syntax hereMore information about mermaid syntax hereMore information about abc syntax here Alert Area:::successYes :tada:::: :::infoThis is a message :mega:::: :::warningWatch out :zap:::: :::dangerOh No! :fire:::: TypographyHeaders# h1 Heading## h2 Heading### h3 Heading#### h4 Heading##### h5 Heading###### h6 Heading Horizontal Rules Typographic ReplacementsEnable typographer option to see result. (c) (C) (r) (R) (tm) (TM) (p) (P) +- test.. test… test….. test?….. test!…. !!!!!! ???? ,, Remarkable – awesome “Smartypants, double quotes” ‘Smartypants, single quotes’ EmphasisThis is bold text This is bold text This is italic text This is italic text Deleted text lu~lala~ Superscript: 19^th^ Subscript: H~2~O ++Inserted text++ ==Marked text== Blockquotes Blockquotes can also be nested… …by using additional greater-than signs right next to each other… …or with spaces between arrows. ListsUnordered Create a list by starting a line with +, -, or * Sub-lists are made by indenting 2 spaces: Marker character change forces new list start: Ac tristique libero volutpat at Facilisis in pretium nisl aliquet Nulla volutpat aliquam velit Very easy! Ordered Lorem ipsum dolor sit amet Consectetur adipiscing elit Integer molestie lorem at massa You can use sequential numbers… …or keep all the numbers as 1. feafw 332 242 2552 e2 Start numbering with offset: foo bar CodeInline code Indented code // Some comments line 1 of code line 2 of code line 3 of code Block code “fences” Sample text here... Syntax highlighting var foo = function (bar) &#123; return bar++;&#125;;console.log(foo(5)); Tables Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. Right aligned columns Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. Left aligned columns Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. Center aligned columns Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. Linkslink textlink with titleAutoconverted link https://github.com/nodeca/pica ImagesLike links, Images also have a footnote style syntaxWith a reference later in the document defining the URL location: Show the image with given size FootnotesFootnote 1 link[^first].Footnote 2 link[^second].Inline footnote^[Text of inline footnote] definition.Duplicated footnote reference[^second]. [^first]: Footnote can have markup and multiple paragraphs.[^second]: Footnote text. Definition ListsTerm 1 : Definition 1with lazy continuation. Term 2 with inline markup : Definition 2 { some code, part of Definition 2 } Third paragraph of definition 2. Compact style: Term 1 ~ Definition 1 Term 2 ~ Definition 2a ~ Definition 2b AbbreviationsThis is an HTML abbreviation example.It converts “HTML”, but keeps intact partial entries like “xxxHTMLyyy” and so on. *[HTML]: Hyper Text Markup Language","link":"/zh-tw/hello-world/"},{"title":"如何設置Git的個人資訊？","text":"大家好，我是Ray! 今天要來跟大家分享，如何配置Git的基本資訊。 讓我們新增一行敘述在現有的example1.html 的檔案裡，如下： &lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;First example&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;This is the first example&lt;/p&gt;&lt;p&gt;We add a new paragraph on the first example&lt;/p&gt;&lt;p&gt;This is the example commit for git commit -am&lt;/p&gt;&lt;p&gt;This is the example1 for git configuration&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; Git commit -am “Before configuration” Git log 各位可以看一下上面我們我們剛剛所commit的Author 資料。 現在加入另一段敘述在example1.html檔案內，如下： &lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;First example&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;This is the first example&lt;/p&gt;&lt;p&gt;We add a new paragraph on the first example&lt;/p&gt;&lt;p&gt;This is the example commit for git commit -am&lt;/p&gt;&lt;p&gt;This is the example1 for git configuration&lt;/p&gt;&lt;p&gt;This is the example after git configuration&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 現在讓我們來定義git 配置的使用者資訊： 輸入 Git config --global user.name RayGit config --global user.email example@email.com 上面的Ray以及example@email欄位請填你們自己的！ 接下來輸入 Git commit -am “after configuration” Git log 由上面的截圖可以看到，我們已經成功的配置的使用者的名稱還有信箱改掉了！ 這邊補充說明，這裡使用–global進行配置，所以這裡的設定是全域通用的，簡單來說，你電腦內的所有資料夾都套用這個資料，之後有機會我們再介紹如何針對單一資料夾進行更改。 今天的分享就到這裡了，我們明天見！","link":"/zh-tw/howToConfigureGit/"},{"title":"如何在AWS上部署多個專案？","text":"建立一個AWS EC2 instance, 本文章使用的instance型號為 Amazon Linux 2 AMI (HVM), SSD Volume Type - ami-0d7ed3ddb85b521a6 連結到你的EC2 instance, 輸入：sudo vim /etc/httpd/conf.d/yourProjectName.conf 貼上下面的code &lt;VirtualHost *:443&gt; # port 443，給https用的 ServerName letussleep.space # 你的Domain名稱 DocumentRoot &quot;/var/www/html/yourLaravelProjectName/public&quot; # 你在EC2上的專案絕對路徑 SSLEngine on SSLCertificateFile /whateverLocationYouWant/certificate.crt SSLCertificateKeyFile /whateverLocationYouWant/private.key SSLCertificateChainFile /whateverLocationYouWant/ca_bundle.crt # 簽署SSL簽證，分別對應你從從簽證網站上面取得的簽證檔案&lt;/VirtualHost&gt;&lt;VirtualHost *:80&gt; # port 80 給 http用的 ServerName letussleep.space DocumentRoot &quot;/var/www/html/yourLaravelProjectName/public&quot; redirect / Https://letussleep.space # 當使用者使用http連接，重新導向到https&lt;/VirtualHost&gt;&lt;VirtualHost *:80&gt;ServerName oldletussleep.space # 在同一個conf檔案裡頭，其實就可以部署不同的專案，只要把Domain name區分好DocumentRoot &quot;/var/www/html/yourProjectName/public&quot;&lt;/VirtualHost&gt; 雖然在同一個config檔案裡頭，只要設好domain name 以及不同的專案路徑就可以完成多專案部署，但是這樣難免混亂，所以個人偏好一個專案一個conf檔案。 所以只要重複上面的步驟，創一個新的config檔，並且輸入相對應的資訊，最後輸入sudo service httpd restart 連到你的Domain, 應該已經沒問題了！","link":"/zh-tw/howToDeployMultipleProjectOnAWS/"},{"title":"如何經由PHP導入中文到MySQL而不會出現亂碼？","text":"如何正確的導入中文而不會出現亂碼？ 大家好，我是Ray!今天我想跟大家分享CSV檔案匯入MySQL的更多細節部分，像是如何正確的導入中文字而不會出現亂碼。 首先，先講PHP的部分： &lt;?phpmysqli_set_charset($dbc,&quot;utf8&quot;); 在連接資料庫之後，請記得一定要加入上面的code，目的是明確來往資料庫的資料編碼格式。 檔案部分： 首先，打開Excel，然後開啓新檔案 接下來，點選Data，並且選取From text 這邊請選擇使用分界符號 這裏選擇使用逗號來做分隔 最後選擇一般即可 接下來爲，資料庫部分： 如果你是使用Sequel Pro,那請務必在創建表格時點選UTF-8，如下圖 如果你是使用終端機部分，如下圖，請記得要在創立表格的同時賦予utf8的編碼。 如果依然在匯入之後顯示亂碼，請確認column的編碼是否爲utf-8 基本上如果以上的細節都有注意到，應該就可以順利的導入中文，並且成功的在資料庫內顯示中文，如下圖： 大家寫code愉快！","link":"/zh-tw/howToImportChineseIntoDatabaseWithoutGarble/"},{"title":"如何省略 git add?","text":"大家好，我是Ray! 今天要跟大家分享，git commit -am 如之前的文章跟大家分享的，每次在commit 之前，我們需要使用git add來明確要commit 的進度，然後commit的同時我們需要留下屬於該commit的訊息。 有些人覺得這樣的設計很好，然而有些則不然，他們覺得這樣有點麻煩。 不管您是屬於哪一派，今天我要跟大家分享，如何將這兩個步驟化為一個動作。 首先，讓我們新增一行code在我們現有的檔案example1.html，如下：&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;First example&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;This is the first example&lt;/p&gt;&lt;p&gt;We add a new paragraph on the first example&lt;/p&gt;&lt;p&gt;This is the example commit for git commit -am&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 現在輸入 git status 如下圖，example1.html已經被修改了，必且如果要commit，我們需要先git add來明確要commit的進度。 依照之前的文章分享，我們需要先git add，然後git commit，並留下屬於此次commit的訊息來完成這次的commit。 現在讓我們來試試看比較簡單一點的方法吧！ 輸入git commit -am &quot;example for git commit -am&quot; 輸入git status 確認狀況 輸入Git log 如下圖，我們已經成功的commit了！ 這邊要跟大家更進一步解釋一下git add的功能。 當我們今天新增一個新的檔案時，我們需要將該檔案加入“追蹤”的檔案清單中，我們使用git add 來達到這個功能。 當“已經入追蹤”的檔案有更改，且我們要做commit時，我們需要更新該檔案將被commit記錄下來的進度！簡單來說，就是訂出將被commit的資料範圍，而這時我們也是使用git add來更新這個進度。 所以說啦，如果今天我們新增一個檔案，且該檔案從未被加入“追蹤”清單中，那這個時候git commit -am 是不會對這個檔案起作用的！ 有一點請大家注意，-a 在這裡代表automatic，它會自動的更新”所有已經加入追蹤清單且有更改”的檔案！ 看完今天的分享，大家是不是對git有更進一步地瞭解了呢？ 我們明天見！","link":"/zh-tw/howToSkipGitAdd/"},{"title":"怎麼在Laravel中，利用AWS SES發郵件?","text":"申請AWS SES(simple Email Service)服務 建立一個使用者，並建立政策(SES full access)，取得Access key 跟Secret key 到AWS SES 主控台，左方Email Addresses，然後進去點選verify a new email address 進行驗證 Google AWS support center，提交‘移出沙盒’申請，約24小時內會解封。否則寄信數量跟頻率都會被很大程度上限制住，且任何收件人都必須要經過AWS驗證。 開立一個Laravel專案 輸入composer require guzzlehttp/guzzle，安裝套件 安裝AWS SDK composer require aws/aws-sdk-php 到config/mail.php中，將driver選項相對的env參數改成ses 到config/services.php中，進行以下配置 &apos;ses&apos; =&gt; [ &apos;key&apos; =&gt; &apos;your-ses-key&apos;, &apos;secret&apos; =&gt; &apos;your-ses-secret&apos;, &apos;region&apos; =&gt; &apos;ses-region&apos;, // e.g. us-east-1], 以上參數在env的配置，大概如下： MAIL_DRIVER=sesMAIL_FROM_ADDRESS=your-mail-addressMAIL_FROM_NAME=BuyBuyGoSES_KEY=your-ses-keySES_SECRET=your-ses-secretSES_REGION=us-west-2 建立Maiiables class，php artisan make:mail OrderCreated --markdown=emails.orders.created 到OrderCreated中，建立build檔案，大略如下: &lt;?phpnamespace App\\Mail;use Illuminate\\Bus\\Queueable;use Illuminate\\Mail\\Mailable;use Illuminate\\Queue\\SerializesModels;use Illuminate\\Contracts\\Queue\\ShouldQueue;class OrderShipped extends Mailable&#123; use Queueable, SerializesModels; protected $order; /** * Create a new message instance. * * @return void */ public function __construct($order) &#123; $this-&gt;order = $order; // &#125; /** * Build the message. * * @return $this */ public function build() &#123; return $this-&gt;markdown(&apos;emails.orders.created&apos;) -&gt;with([ &apos;buyer&apos; =&gt; $this-&gt;order-&gt;user-&gt;name, &apos;order&apos; =&gt; $this-&gt;order-&gt;name, &apos;item_name&apos; =&gt; $this-&gt;order-&gt;item_name, &apos;item_description&apos; =&gt; $this-&gt;order-&gt;item_description, &apos;quantity&apos; =&gt; $this-&gt;order-&gt;quantity, &apos;total_amount&apos; =&gt; $this-&gt;order-&gt;total_amount, &apos;unit_price&apos; =&gt; $this-&gt;order-&gt;unit_price, &apos;expiry_time&apos; =&gt; $this-&gt;order-&gt;expiry_time, ]); &#125;&#125; 到created.blade當中做版面客制，大略如下： @component(&apos;mail::message&apos;)# Dear &#123;&#123; $buyer &#125;&#125;Thanks for your patronage!- Order: &#123;&#123;$order&#125;&#125;- Item: &#123;&#123;$item_name&#125;&#125;- Item description: &#123;&#123;$item_description&#125;&#125;- Quantity: &#123;&#123;$quantity&#125;&#125;- Unit price: &#123;&#123;$unit_price&#125;&#125;- Amount: &#123;&#123;$total_amount&#125;&#125;## Kindly make this payment before &lt;span style=&quot;color: red&quot;&gt;&#123;&#123;$expiry_time&#125;&#125;&lt;/span&gt;&lt;hr&gt;&lt;br&gt;## If you have any question, feel free to contact us@component(&apos;mail::button&apos;, [&apos;url&apos; =&gt; &apos;https://tn710617.github.io/&apos;])Contact Us@endcomponentThanks,&lt;br&gt;&#123;&#123; config(&apos;app.name&apos;) &#125;&#125;@endcomponent 在任何你想要發這封mail的地方，使用mail來寄信，大略如下： Mail::to($buyer-&gt;email)-&gt;send(new OrderCreated($order)); 至此，應該可以成功寄信了！ 你以為結束了嗎？ 呵呵，是快結束了啦！ 不過呢，還有一件事情非常重要！上面的部分大概花了我一天，然後我遇到一個未解的謎題，又被搞了一天。身為一個backend programmer，如果遇到需要接金流的話，我都是用ngrok來測試。這次遇到的問題很奇怪，當我收到金流服務商的回饋時，我必須要去做一些事，自controller收到request之後所做的任何function都沒有問題，資料庫的CRUD也都正常，可偏偏只要執行到這一行寄mail的，就給我報錯！！ 錯誤訊息如下： &quot;message&quot;: &quot;Expected response code 250 but got code \\&quot;530\\&quot;, with message \\&quot;530 5.7.1 Authentication required\\r\\n\\&quot;&quot;,&quot;exception&quot;: &quot;Swift_TransportException&quot;,&quot;file&quot;: &quot;/Users/ray/code/FacebookOptimizedSellingSystem/vendor/swiftmailer/swiftmailer/lib/classes/Swift/Transport/AbstractSmtpTransport.php&quot;,&quot;line&quot;: 457,&quot;trace&quot;: [ 以下省略一千行… 在經過超級無敵疲勞的Debug之後，終於發現問題… 只要使用valet share，就不會有這個問題只要是用php artisan serve --port=yourPort，然後ngrok http yourPort，這樣就會遇到我說的這個問題。 雖然最後問題解決了，但說實在的我還是不知道為什麼… 如果有大大知道這是什麼原因，還請麻煩來信幫我解惑一下！感激不盡！","link":"/zh-tw/howToSendMailViaAWSSES/"},{"title":"如何使用 git checkout","text":"大家好，我是Ray! 還記得我們上次到了哪裡了嗎？看完上面的圖片有沒有讓你回想些什麼呢？ 沒錯，上次的git介紹我們從初始化開始，並且建立一個名為example1.html的檔案，然後完成了我們第一個存擋！ 如同之前提到的，我說git讓我們再存擋後，如果我們有需要的話，我們可以隨時地回到任何一個我們用git做的存擋點，今天我將跟大家分享如何回到存擋點，並且在存擋點之間自由的切換。 現在，讓我們在檔案內加入下面highlight的一段 &lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;First example&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;This is the first example&lt;/p&gt;&lt;p&gt;We add a new paragraph on the first example&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 然後我們到command line，輸入git status 你應該會看到如下圖，如下圖所示，git 顯示example1.html已經被修改過了。 如上一篇提到的，再做存擋之前，我們必須要先使用git add 來指定我們想要存擋的進度，所以 輸入git add example1.html 輸入git status 如上圖，我們已經指定了要存擋的進度 現在輸入git commit 並記錄訊息”New paragraph added in example1.html file” 完成後輸入git status確認一下狀態 然後git log 現在我們可以看到我們的第二個commit如下圖： 好啦，接下來我們來切換回第一個記錄點 git log 的功能是顯示我們所有記錄點的歷史，我們可以經由log裡面提供的資料自由的切換於不同的紀錄點。 輸入 git checkout b45934852da471efbbbc52b5a119e8723fb01866 這是我的版本，你們的版本會是一串不同的數字 如下圖所示，我們現在已經在一個第一個記錄點。 現在可以打開我editor查看，我們新增加的We add a new paragraph on the first example 已經不見了，此時版本恢復到我們第一個記錄點的狀態，不管我們是否有另外在editor做任何的紀錄。 那要如何回到我們的最新的紀錄點呢？ 輸入git checkout master 如上圖，我們現在已經回復到我們最新的紀錄點啦！ 現在打開我們的editor做確認，登登！ 原本消失的new paragraph 又出現啦！ 是不是很神奇呢？ 以上是今天的分享，希望可以讓大家對Git有更深的了解，我們明天見！","link":"/zh-tw/howToUseCheckout/"},{"title":"利用 Jenkins 在 AWS 上達到 CI","text":"前言以下為本篇記錄重點： 部署 jenkins 到 AWS EC2 的 Amazon Linux 2 AMI (HVM) 部署 jenkins 到 AWS EC2 的 Amazon Linux AMI 2018.03.0 (HVM) 當GitHub 上的進度有更新時，自動在 AWS EC2 執行 git pull 並與 GitHub 上的進度同步， 建立 EC2 instance 利用 SSH 連結到 AWS EC2 點擊 Connect ，並遵照指示操作 Amazon Linux 2 AMI (HVM)安裝sudo yum install java-1.8.0 sudo yum update –y sudo rpm --import https://pkg.jenkins.io/redhat/jenkins.io.key sudo yum install jenkins -y 設定sudo vim /etc/sysconfig/jenkins 並更改如右邊的參數 JENKINS_USER=&quot;root&quot; sudo service jenkins start sudo systemctl enable jenkins.service sudo vim /etc/sysconfig/jenkins 在瀏覽器設定 Jenkins 於瀏覽器輸入 http://yourPublicDNS:8080 於終端機輸入 sudo cat /var/lib/jenkins/secrets/initialAdminPassword 複製密碼以登入 安裝建議的插件 創立帳號 存檔並登入 到Jenkins管理頁面 安裝GitHub插件 開始一個自由專案 到設定的地方 輸入專案 url 選取 git , 並填入 git 資料夾的 url 勾選 GitHub hook trigger for GITScm polling 輸入客製化的shell script如果你的 jenkins 跟你的專案在同一台電腦的話 ssh -i /root/.ssh/yourKey.pem ec2-user@127.0.0.1 \"cd /var/www/html/yourProjectName;git reset @^ --hard;git pull;/usr/local/bin/composer install;php artisan migrate --force;\" 設定 GitHub 到 GitHub 的設定頁面 建立一個 webhook ，如下: Amazon Linux AMI 2018.03.0 (HVM)安裝sudo yum update –y sudo yum remove java-1.7.0-openjdk sudo yum install java-1.8.0 sudo wget -O /etc/yum.repos.d/jenkins.repo http://pkg.jenkins.io/redhat/jenkins.repo sudo rpm --import https://pkg.jenkins.io/redhat/jenkins.io.key sudo yum install jenkins -y 設定sudo vim /etc/sysconfig/jenkins 修改為 JENKINS_USER=&quot;root&quot; sudo service jenkins start 當 Server 重啟時，自動啟動 jenkinssudo chkconfig jenkins on 在瀏覽器設定 Jenkins 於瀏覽器輸入 http://yourPublicDNS:8080 於終端機輸入 sudo cat /var/lib/jenkins/secrets/initialAdminPassword 複製密碼以登入 安裝建議的插件 創立帳號 存檔並登入 到 Jenkins 管理頁面 安裝 GitHub 插件 開始一個自由專案 到設定的地方 輸入專案url 選取 git , 並填入 git 資料夾的 url 勾選 GitHub hook trigger for GITScm polling 輸入客製化的 shell script如果你的 jenkins 跟你的專案在同一台電腦的話 ssh -i /root/.ssh/yourKey.pem ec2-user@127.0.0.1 \"cd /var/www/html/yourProjectName;git reset @^ --hard;git pull;/usr/local/bin/composer install;php artisan migrate --force;\" 設定 GitHub 到 GitHub 的設定頁面 建立一個 webhook ，如下:","link":"/zh-tw/implementCIWithJenkinsOnAWS/"},{"title":"利用 Let's Encrypt 來自動簽署並更新 SSL 憑證","text":"前言本篇主要分享，如何利用 Let&#39;s Encrypt 的 cert bot 來自動簽署以及更新 SSL 憑證 參考網頁官網 環境 Server: NginX OS: Ubuntu 18.04DNS 設定先將 DNS 設定好, 建一個 A record, 將我們喜歡的 domain 指向我們的 IP 設定檔 這邊使用最簡單的設定, 反向代理 server 內的 9527 port, 若無反向代理需求，可以單純指向專案的 Document root 即可sudo vim /etc/nginx/sites-available/yourSiteName server &#123; listen 80; server_name yourDomainName; access_log /var/log/nginx/test_access_log; location / &#123; proxy_pass http://127.0.0.1:9527; &#125;&#125; 測試 syntax sudo nginx -t 啟用設定 sudo ln -s /etc/nginx/sites-available/yourSiteName /etc/nginx/sites-enabled/yourSiteName 設完之後，重啟 nginx sudo service nginx restart 測試設定設定好之後，如果我們 curl http://yourIPOrDomain/endpoint , 應該要可以存取服務 新增 cerbot PPA (Personal Package Archives)sudo apt-get update &amp;&amp; sudo apt-get install software-properties-common &amp;&amp; sudo add-apt-repository universe &amp;&amp; sudo add-apt-repository ppa:certbot/certbot 安裝 Let’s Encryptsudo apt-get install certbot python-certbot-nginx 運行 cerbot全自動模式如果你希望 cerbot 可以幫我們全自動完成設定，輸入sudo certbot --nginx 半自動模式如果你希望 cerbot 只幫我們拿到憑證，其他我們自己來的話，輸入sudo certbot certonly --nginx 測試自動更新到這裡，應該已經可以自動更新憑證了，輸入以下指令測試sudo certbot renew --dry-run cerbot 安裝在以下路徑之一: /etc/crontab/ /etc/cron.*/* systemctl list-timers 測試簽證是否成功測試網頁","link":"/zh-tw/letsencrypt/"},{"title":"如何將CSV檔，經由PHP導入MYSQL？","text":"大家好，我是Ray！我將跟大家分享如何使用PHP來將CSV檔案的內容導入MySQL資料庫。首先，一個CSV檔如下： 以下爲PHP腳本，請將csv的檔案跟腳本放在同一個資料夾內 &lt;?php// 連接資料庫$dbc = mysqli_connect('Your location', 'Your MySQL user_name', 'Your MySQL password', 'Your Database Name');// 設定編碼爲utf8mysqli_set_charset($dbc,\"utf8\");// 利用fopen功能讀取檔案$handle = fopen(\"The file name.csv\", \"r\");// 設定變數i，之後會用到$i=0;// 使用fgetcsv功能，配合while迴圈，可以拿到檔案內的每一行資料while (($data = fgetcsv($handle, 1000, ',')))&#123; //如圖片所示，第一行是行的名稱，我們不想要將這行導入資料庫，所以我們設定條件句， 當變數i爲0正是跑到第一行，進入條件句內，變數i變爲1，並且continue使迴圈將之後的code都跳掉， 直接回到迴圈的最上面在開始跑，此時變數i已經是1，所以將不會在進到條件句中。如此一來我們就完成我們的目標， 只跳掉第一行。 if($i == 0) &#123; $i++; continue; &#125; // 如csv的圖片所示，降雨量那一行中有出現非數字的NaN字串， // 但我們又想要將這一行的屬性設爲float或decimal方便之後若有需要用到計算。 // 要避免資料匯入出錯，我們必須將非數字的字串轉換爲數字， // 因此利用條件句，當$data array裏面的當三項爲NaN時，替換爲0 if($data[2] == 'NaN') &#123; $data[2] = 0; &#125; // 最後，將資料導入資料庫 $query = 'INSERT INTO rainfall (district, date, rainfall)VALUES (\"'.$data[0] . '\", \"' . $data[1] . '\", \"' . $data[2].'\")'; echo $query; $result = mysqli_query($dbc, $query); if ($result == false) &#123; echo 'Error description &lt;br/&gt;' . mysqli_error($dbc); &#125;&#125;?&gt; 最後，在終端機中執行該腳本，php -f 腳本名稱，完成！","link":"/zh-tw/importDataFromCSVIntoMySQLDatabaseViaPHP/"},{"title":"利用 PayPal 付款標準版 (PayPal Payment Standard) 以及 PayPal 即時付款通知 (PayPal IPN) 方式結帳付款","text":"前言有嘗試串接過 PayPal 的人都知道， PayPal 提供了好幾種方式供使用者串接使用。本篇記錄了： 如何使用 PayPal 付款標準版 (PayPal Payment Standard) 來付款結帳。 如用使用 PayPal 即時付款通知 (PayPal IPN) 來驗證付款結果。 如何在 PayPal 付款標準版 (PayPal Payment Standard) 中，自定義多個商品以及每個商品的明細，包含名稱、單價、數量。 在本文章中，我使用的是PHP的框架，Laravel因為此篇文章主要紀錄我這個專案大概的一個流程，雖說主題是金流部分，但難免會記錄到一些跟金流無關的部分。可以直接從’建金流訂單’的部分開始看即可。 驗證此節是整個流程的一個程序，跟金流較無關係，可以跳過。$toBeValidatedCondition = [ 'order_id' =&gt; 'required|array',];$failMessage = Helpers::validation($toBeValidatedCondition, $request);if ($failMessage) return Helpers::result(false, $failMessage, 400);if (!Helpers::checkIfIDExists($request, new Order(), 'order_id')) return Helpers::result(false, 'The orders doesn\\'t exist', 400);if (!Helpers::checkIfBelongToTheUser($request, new Order(), 'order_id')) return Helpers::result(false, 'The order doesn\\'t belong to this user', 400);$orders = Order::whereIn('id', $request-&gt;order_id)-&gt;get();if (Order::checkIfOrderPaid($orders)) return Helpers::result(false, 'The order has already been paid', 400);if (Order::checkIfOrderExpired($orders)) return Helpers::result(false, 'The order has expired', 400);if ($recipient-&gt;user_id !== User::getUserID($request)) return Helpers::result(false, 'The recipient doesn\\'t belong to the user', 400); 收集必要資訊因為我在做這個專案時，前端的時間比較吃緊一點，所以後端這邊決定除必要資訊之外，後端這邊將所有資訊搞定，盡量讓前端帶最少的資料，做最多的事。$toBeSavedInfo = [ 'total_amount' =&gt; Order::getTotalAmountForPayments($orders), 'orders_name' =&gt; Order::getOrdersNameForPayments($orders), 'merchant_trade_no' =&gt; time() . Helpers::createAUniqueNumber(), 'merchant_trade_date' =&gt; date('Y/m/d H:i:s'), 'trade_desc' =&gt; 'BuyBuyGo', 'quantity' =&gt; 1, 'user_id' =&gt; User::getUserID($request), 'payment_service' =&gt; $thirdPartyPaymentService, 'expiry_time' =&gt; (new Carbon())-&gt;now()-&gt;addDay(1)-&gt;toDateTimeString(), 'orders' =&gt; $orders, 'mc_currency' =&gt; 'TWD', 'ClintBackURL' =&gt; $request-&gt;ClintBackURL]; 分流點因為這個專案接了兩家金流，所以會需要一個地方來判定金流服務商switch ($thirdPartyPaymentService-&gt;id)&#123; case 1: $error = (new AllPay)-&gt;make($toBeSavedInfo, $request, $recipient); if($error) return Helpers::result(false, $error,400); return (new AllPay())-&gt;send($toBeSavedInfo, $request); break; case 2: $error = (new PayPal)-&gt;make($toBeSavedInfo, $request, $recipient); if($error) return Helpers::result(false, $error, 400); $url = (new PayPal)-&gt;send($toBeSavedInfo, $request, $recipient); return Helpers::result(true, $url, 200); break;&#125; 建金流訂單在使用者按下付款之後，一張臨時的金流訂單會被建立。此訂單只介於你與你與 PayPal 之間，使用者不會接觸到這張訂單。因為會一次性的寫入兩張 table ，所以這邊會特別使用 Laravel 的 Transaction 來將資料處理，如果對 Laravel Transaction 有興趣的，可以參考我在另外一篇文章中，有一小段針對 Laravel Transaction 的解說public function make(Array $toBeSavedInfo, Request $request, Recipient $recipient)&#123; DB::beginTransaction(); try &#123; $PayPal = new self(); $PayPal-&gt;user_id = $toBeSavedInfo['user_id']; $PayPal-&gt;payment_service_id = $toBeSavedInfo['payment_service']-&gt;id; $PayPal-&gt;expiry_time = $toBeSavedInfo['expiry_time']; $PayPal-&gt;merchant_trade_no = $toBeSavedInfo['merchant_trade_no']; $PayPal-&gt;total_amount = $toBeSavedInfo['total_amount']; $PayPal-&gt;trade_desc = $toBeSavedInfo['trade_desc']; $PayPal-&gt;item_name = $toBeSavedInfo['orders_name']; $PayPal-&gt;mc_currency = $toBeSavedInfo['mc_currency']; $PayPal-&gt;recipient_id = $recipient-&gt;id; $PayPal-&gt;save(); foreach ($toBeSavedInfo['orders'] as $order) &#123; $order_relations = new OrderRelations(); $order_relations-&gt;payment_service_id = $toBeSavedInfo['payment_service']-&gt;id; $order_relations-&gt;payment_service_order_id = $PayPal-&gt;id; $order_relations-&gt;order_id = $order-&gt;id; $order_relations-&gt;save(); &#125; &#125; catch (Exception $e) &#123; DB::rollBack(); return 'something went wrong with DB'; &#125; DB::commit();&#125; 建立提交付款申請的 URL這邊會用到很多 PayPal 付款標準版 (PayPal Payment Standard) 的 變量 (variable)，各種變量的使用可以參考這篇文章另外，因為 Ray 在做這個案子時，前端的時間上比較吃緊，所以 Ray 將所以非必要的資料全部由後端這邊處理，前端只帶入先前已建立的使用者訂單，後端從資料庫內調出所有的資料並提供給 PayPal public function send(Array $toBeSavedInfo, Request $request, Recipient $recipient)&#123; // 如果你是使用測試環境的話，請選 true $enableSandbox = env('PAYPAL_SANDBOX_ENABLESANDBOX'); $paypalUrl = $enableSandbox ? 'https://www.sandbox.paypal.com/cgi-bin/webscr' : 'https://www.paypal.com/cgi-bin/webscr'; $data = []; // 設定PayPal 帳號, 請先到以下網址申請測試者帳號，商家跟一般用戶都要申請，這邊填入的是商家的帳號，所以買家付款後，金額會直接匯入這個帳號 // https://developer.paypal.com/developer/accounts/ // Set the PayPal account $data['business'] = env('PAYPAL_SANDBOX_MAIL'); // 此數值為前端帶入，使用者完成付款後，將可以經由此URL返回原本的服務中 // Set the PayPal return addresses, after the transaction is completed, the user could be back via this URL. $data['return'] = $toBeSavedInfo['ClintBackURL']; // 在付款過程中，使用者可以選擇取消，並且經由此URL回到我們的服務 // During the transaction process on PayPal's site, the user could cancel the transaction and go back via this URL. $data['cancel_return'] = env('PAYPAL_SANDBOX_CANCEL_URL'); // 在使用者完成交易之後， PayPal 會發一封 IPN 到我們在這邊指定的 listener ，然後我們可以依據此 IPN 來判定付款是否成功，然後做相對應的事 // After the transaction is completed, PayPal will send IPN message to this URL. $data['notify_url'] = env('PAYPAL_SANDBOX_NOFITY_URL'); // 這邊我們指定了每一樣商品的明細，包含單價，名稱，數量。 這邊要將這些明細顯示在 PayPal 的付款頁面上 // Set the details about the products being purchased, including the price for every individual // and currency so that these aren't overridden by the form data. $i = 1; foreach ($toBeSavedInfo['orders'] as $order) &#123; $data[\"item_name_$i\"] = $order-&gt;item_name; $data[\"item_number_$i\"] = $order-&gt;quantity; $data[\"amount_$i\"] = $order-&gt;total_amount; $i++; &#125; // 這邊指定了幣別，細節部分可以參考官網資料 // https://developer.paypal.com/docs/classic/api/currency_codes/ $data['currency_code'] = $toBeSavedInfo['mc_currency']; // 這邊我們可以帶一個任何我們想要的值過去給 PayPal ，然後 PayPal 會再回傳 IPN 時一併帶回來，以本篇例子，我帶入的是我金流訂單的編號 // Add any custom fields for the query string. $data['custom'] = $toBeSavedInfo['merchant_trade_no']; // 這邊我指定了收件人，否則 PayPal 會顯示測試帳號上的假的收件人資料。 在這邊設定後，我們可以在 PayPal 上顯示任何我們想要的收件人資料 // Add recipient's information $data['address_override'] = 1; $data['country'] = $recipient-&gt;country_code; $data['city'] = $recipient-&gt;city; $data['address1'] = $recipient-&gt;others; $data['zip'] = $recipient-&gt;postcode; $data['first_name'] = $recipient-&gt;name; // 這邊的設定允許了我們上傳多個商品到 PayPal 的購物車裡面，所以可以分成多個商品並且一次性結帳。 // This setting allow to add multiple items with IPN method $data['upload'] = '1'; $data['cmd'] = \"_cart\"; // Add charset $data['charset'] = 'utf-8'; // 產生 query string // Build the query string from the data. $queryString = http_build_query($data); // 產生最終的要在 PayPal 建立付款請求的 URL，我們只需要將此URL回傳給前端，前端就可以直接利用這個 URL 將使用者導向付款頁面 // Build the URL to PayPal $url = $paypalUrl . '?' . $queryString; return $url; &#125; 使用者付款 使用者經由我們上面產出的 URL 到達 PayPal 付款頁面，這邊請先去申請測試帳號 到達付款頁面 這邊可以看到我們指定的商品明細，以及金額，選擇繼續 這邊可以看到我們指定的住址 交易成功，這邊可以看到全部的細節 驗證付款狀態使用者完成付款程序後， PayPal 會發一封 IPN 給我們，有關於 IPN 的規格可以參考官方文件 首先，我們先安裝 PayPal 的 官方 IPN CODE SAMPLES git clone https://github.com/paypal/ipn-code-samples 進到 php 的資料夾內 cd ipn-code-samples/php 接下來，我們複製PaypalIPN.php到我們的專案內， Ray 是把它放到 App 底下。 接著，在把 ipn-code-samples 裡頭的 cert 整個資料夾也放到 App 底下，大概如下圖 再來，我們到composer.json檔案中，在autoload-dev底下的files加入PaypalIPN.php這個檔案，如果沒有files的可能要自己建一個 \"autoload-dev\": &#123; \"psr-4\": &#123; \"Tests\\\\\": \"tests/\" &#125;, \"files\": [ \"app/Helpers.php\", \"app/AllPay.Payment.Integration.php\", \"app/PaypalIPN.php\" ]&#125;, 重新執行composer，在terminal的專案資料夾底下，執行 composer install 萬事俱備，只欠東風！ 接下來讓我們將example_usage_advanced.php的檔案裡頭的內容複製到你想要的地方，可以是你的Controller，也可以是你的某個class下面的一個function，如下：下面的 code 有點長，可以不必全看，除了我中文有特別解釋的地方之外，大概跟原本的sample一樣。 public function listen(Request $request) &#123; // 因為官方sample是去接 $_POST，所以這邊直接將Laravel的輸入轉成 POST ，想要自己改的人也可以哦 $_POST = $request-&gt;post(); // 這個資訊代表是否該交易已付款 $payment_status = $_POST['payment_status']; // 還記得我們之前帶過去的金流訂單號碼嗎？ $merchant_trade_no = $_POST['custom']; // 很重要，等等會用到 $txn_id = $_POST['txn_id']; $txn_type = $_POST['txn_type']; // 付款時間 $payment_date = Carbon::parse($_POST['payment_date'])-&gt;setTimezone('UTC'); // 總付款金額 $mc_gross = $_POST['mc_gross']; // 幣別 $mc_currency = $_POST['mc_currency']; $enable_sandbox = env('PAYPAL_SANDBOX_ENABLESANDBOX');// 這邊表示收款人的email，如果IPN裡頭的收款人不在這個清單裡面的話，驗證將會失敗// Use this to specify all of the email addresses that you have attached to paypal: $my_email_addresses = array(env('PAYPAL_SANDBOX_MAIL'));// Set this to true to send a confirmation email: $send_confirmation_email = env('PAYPAL_SANDBOX_SEND_CONFIRMATION_EMAIL'); $confirmation_email_address = \"buybuybuygogo@gmail.com\"; $from_email_address = \"test@gmail.com\";// 選true的話，會自動記log// Set this to true to save a log file: $save_log_file = env('PAYPAL_SANDBOX_SAVE_LOG_FILE'); $log_file_dir = storage_path() . \"/app/payment_logs\";// Here is some information on how to configure sendmail:// http://php.net/manual/en/function.mail.php#118210// 這邊就是主要驗證的function $ipn = new PaypalIPN(); if ($enable_sandbox) &#123; $ipn-&gt;useSandbox(); &#125; $verified = $ipn-&gt;verifyIPN(); $data_text = \"\"; foreach ($_POST as $key =&gt; $value) &#123; $data_text .= $key . \" = \" . $value . \"\\r\\n\"; &#125; $test_text = \"\"; if ($_POST[\"test_ipn\"] == 1) &#123; $test_text = \"Test \"; &#125;// 上面提到的mail，就在這邊確認// Check the receiver email to see if it matches your list of paypal email addresses $receiver_email_found = false; foreach ($my_email_addresses as $a) &#123; if (strtolower($_POST[\"receiver_email\"]) == strtolower($a)) &#123; $receiver_email_found = true; break; &#125; &#125; date_default_timezone_set(\"America/Los_Angeles\"); list($year, $month, $day, $hour, $minute, $second, $timezone) = explode(\":\", date(\"Y:m:d:H:i:s:T\")); $date = $year . \"-\" . $month . \"-\" . $day; $timestamp = $date . \" \" . $hour . \":\" . $minute . \":\" . $second . \" \" . $timezone; $dated_log_file_dir = $log_file_dir . \"/\" . $year . \"/\" . $month; $paypal_ipn_status = \"VERIFICATION FAILED\"; if ($verified) &#123; // 進到下面的if之後，表示已經驗證成功了，我們可以在驗證成功之後做一些該做的事 $paypal_ipn_status = \"RECEIVER EMAIL MISMATCH\"; if ($receiver_email_found) &#123; $paypal_ipn_status = \"Completed Successfully\"; $PayPal = (new PayPal())-&gt;where('merchant_trade_no', $merchant_trade_no)-&gt;first(); // 這邊檢查了幾項，大概如下： // 1. 檢查txn_id，為了避免這筆交易之前就已經有處理過。所以資料庫裡面如果已經有這個txn_id，將不予理會 // 2. 檢查mc_gross，總金額必須與我們金流訂單裡頭的金額相等 // 3. 檢查幣別，幣別必須與我們金流訂單裡頭的幣別相同 // 4. 檢查payment_status，該交易必需已經付款完成 if ((!PayPal::checkIfTxnIdExists($txn_id)) &amp;&amp; ($mc_gross == $PayPal-&gt;total_amount) &amp;&amp; ($mc_currency == $PayPal-&gt;mc_currency) &amp;&amp; ($payment_status == 'Completed')) &#123; // 將該txd_id新增到該金流訂單內，並更新該訂單數據，主要可被識別為已結單。 $PayPal-&gt;update(['txn_id' =&gt; $txn_id, 'txn_type' =&gt; $txn_type, 'payment_date' =&gt; $payment_date, 'status' =&gt; 1, 'expiry_time' =&gt; null]); $recipient = $PayPal-&gt;recipient; $orderRelations = $PayPal-&gt;orderRelations-&gt;where('payment_service_id', 2); // 更新完金流訂單後，根據該金流訂單取得相對應的使用者訂單，並更新使用者訂單狀態。 Order::updateStatus($orderRelations, $recipient); // 付款完成，寄mail通知使用者 Helpers::mailWhenPaid($PayPal, $orderRelations); &#125; &#125; &#125; elseif ($enable_sandbox) &#123; if ($_POST[\"test_ipn\"] != 1) &#123; $paypal_ipn_status = \"RECEIVED FROM LIVE WHILE SANDBOXED\"; &#125; &#125; elseif ($_POST[\"test_ipn\"] == 1) &#123; $paypal_ipn_status = \"RECEIVED FROM SANDBOX WHILE LIVE\"; &#125; if ($save_log_file) &#123; // Create log file directory if (!is_dir($dated_log_file_dir)) &#123; if (!file_exists($dated_log_file_dir)) &#123; mkdir($dated_log_file_dir, 0777, true); if (!is_dir($dated_log_file_dir)) &#123; $save_log_file = false; &#125; &#125; else &#123; $save_log_file = false; &#125; &#125; // Restrict web access to files in the log file directory $htaccess_body = \"RewriteEngine On\" . \"\\r\\n\" . \"RewriteRule .* - [L,R=404]\"; if ($save_log_file &amp;&amp; (!is_file($log_file_dir . \"/.htaccess\") || file_get_contents($log_file_dir . \"/.htaccess\") !== $htaccess_body)) &#123; if (!is_dir($log_file_dir . \"/.htaccess\")) &#123; file_put_contents($log_file_dir . \"/.htaccess\", $htaccess_body); if (!is_file($log_file_dir . \"/.htaccess\") || file_get_contents($log_file_dir . \"/.htaccess\") !== $htaccess_body) &#123; $save_log_file = false; &#125; &#125; else &#123; $save_log_file = false; &#125; &#125; if ($save_log_file) &#123; // Save data to text file file_put_contents($dated_log_file_dir . \"/\" . $test_text . \"paypal_ipn_\" . $date . \".txt\", \"paypal_ipn_status = \" . $paypal_ipn_status . \"\\r\\n\" . \"paypal_ipn_date = \" . $timestamp . \"\\r\\n\" . $data_text . \"\\r\\n\", FILE_APPEND); &#125; &#125; if ($send_confirmation_email) &#123; // Send confirmation email mail($confirmation_email_address, $test_text . \"PayPal IPN : \" . $paypal_ipn_status, \"paypal_ipn_status = \" . $paypal_ipn_status . \"\\r\\n\" . \"paypal_ipn_date = \" . $timestamp . \"\\r\\n\" . $data_text, \"From: \" . $from_email_address); &#125;// Reply with an empty 200 response to indicate to paypal the IPN was received correctly header(\"HTTP/1.1 200 OK\"); &#125; 結語以上大概就是整個利用 PayPal 付款標準版 (Payment Standard) 來付款 ，然後經由 IPN 驗證的流程，流程大概如下： 買家完成付款 PayPal 發送 IPN Message 到 Listener Listener 回饋 HTTP 200 Response 到 PayPal Listener 將剛剛收到的 IPN Message 原封不動的回傳到 PayPal PayPal 驗證無誤後，回傳 Verified ，若驗證失敗，回傳 Invalid","link":"/zh-tw/implementATransactionViaPayPalIPN/"},{"title":"My learning note on SSH","text":"前言本篇為未整理的個人學習紀錄 正文 建立一組公私鑰? ssh-keygen -t rsa -b 4096 -C \"Ray@gmail.com\" 如何將指定的 key 加到 ssh-agent? ssh-add keyFile 當 private_key 的名稱不是預設的 id_rsa 時，何解？將指定的 key 加到 ssh-agent 如何打開 ssh-agent? eval \"$(ssh-agent -s)\" 在 macOS 上，當我們想要將目前這組 key 刪掉，但是新的 key 要沿用相同的檔案名稱，可能會遇到什麼問題？macOS 的 keychain 將舊的 key 記住了，導致怎麼樣都驗不過，驗到人都覺得厭世了 承上，何解？ ssh-add -K keyFile 承上，在 GCP 上何解？ ssh-add -D &amp;&amp; ssh-add keyFile GCP 上，如何安裝 ssh client ? apt-get update -y &amp;&amp; apt-get install openssh-client -y 如果我已經將 key 加到 ssh-agent, 那我還需要將 key 的實體檔案放在 .ssh 的資料夾內嗎？不需要的哦！ 如何查詢指定 Server 的公鑰？ ssh-keyscan to-be-conneted-instance-ip # 127.0.0.1 SSH-2.0-OpenSSH_6.6.1 127.0.0.1 ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCWBZ3XrIajPmnd6R+g/wcUuOPOiRBMOYjAl4Dv8SfcZtgHqKTK6Zb1EeG3u/uzRYxqXMctG/2A4iXRDG9mvg9H9bimCWbA3xtR79NImPYg4m7BNuH9C+OXRYYJwoOGpjVMs0rGLXkq3/WVkXvQreBuhVD8NI2pEPnQsT1J5abdVbCHlwFYG6wVCJQqFY6jdntJJlxQv5EJu6w4/+Fd4LvdjysH+ngqArac6HMJUxqSxLQjzMdCRWEQKp3ySwmnRp9rHYVaJnnsXeYPfnMN1iMjdIQJPzc89Mepg4ip1q2bCMbMcx2XFO3I7YjYRdcOameFNafMGY0q5RHzhvgnNnal # 127.0.0.1 SSH- 2.0-OpenSSH_6.6.1 127.0.0.1 ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBCPWoEQ7iCCYDrpyb5KeMmCaQ8aOnSfehqmrplZRkbqqnkS9++PdSX/eSLJ0tkFd5902/C+HTCqbDgso4mCKpMo= # 127.0.0.2 SSH-2.0-OpenSSH_6.6.1127.0.0.2 ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCWBZ3XrIajPmnd6R+g/wcUuOPOiRBMOYjAl4Dv8SfcZtgHqKTK6Zb1EeG3u/uzRYxqXMctG/2A4iXRDG9mvg9H9bimCWbA3xtR79NImPYg4m7BNuH9C+OXRYYJwoOGpjVMs0rGLXkq3/WVkXvQreBuhVD8NI2pEPnQsT1J5abdVbCHlwFYG6wVCJQqFY6jdntJJlxQv5EJu6w4/+Fd4LvdjysH+ngqArac6HMJUxqSxLQjzMdCRWEQKp3ySwmnRp9rHYVaJnnsXeYPfnMN1iMjdIQJPzc89Mepg4ip1q2bCMbMcx2XFO3I7YjYRdcOameFNafMGY0q5RHzhvgnNnal # 127.0.0.2 SSH-2.0-OpenSSH_6.6.1 127.0.0.2 ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBCPWoEQ7iCCYDrpyb5KeMmCaQ8aOnSfehqmrplZRkbqqnkS9++PdSX/eSLJ0tkFd5902/ C+HTCqbDgso4mCKpMo= 取最短的那組即可，例如：127.0.0.2 ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBCPWoEQ7iCCYDrpyb5KeMmCaQ8aOnSfehqmrplZRkbqqnkS9++PdSX/eSLJ0tkFd5902/ C+HTCqbDgso4mCKpMo= 當我們初次從 a 電腦 經由 ssh 連到 b 電腦時，當 a 電腦要將 b 電腦的公鑰加到 known_host 檔案時，會跳出詢問視窗 yes/no, 如何避免掉這個視窗？ ssh -o StrictHostKeyChecking=no 如何在 GitHub 以及 Gitlab 上使用不同的 key # GitLabHost gitlab.com Preferredauthentications publickey IdentityFile ~/.ssh/gitlab # GitHubHost github.com Preferredauthentications publickey IdentityFile ~/.ssh/github scp利用 config 檔案來驗證scp -F SSHconfig sourceFile targetUser@targetIP:targetLocation 如果是要傳資料夾過去scp -F SSHconfig -r sourceFile targetUser@targetIP:targetLocation","link":"/zh-tw/ssh/"},{"title":"pm2 - 用法大全","text":"前言pm2 是什麼？ pm2 是一個 node 的程序管理器 pm2 解決什麼問題？ pm2 可以讓 node 服務 crash 掉之後，自動幫我們重啟 pm2 可以在 server 重啟之後，自動幫我們重啟 pm2 可利用 CPU 多核，開啟多程序，已達到類似負載平衡的效果 Graceful reload 可達成類似 rolling upgrade 的效果，0 downtime 升級 多程序多服務，可提升處理 request 的速度 可設定 cron 排程自動重啟時間 pm2 提供多項資訊，包含已重啟次數、 CPU 用量、 memory 用量, process id, 等等… pm2 可以在指定的條件下，自動幫我們重啟，條件可以是’up time’, ‘已使用多少 memory’, 等等…, pm2 可以幫我們整理 log, 讓 log 以我們想要的週期分割檔案，並保存我們想要的數量，若有超過，自動刪除。 pm2 提供簡單的部署方式，可一次性部署到多台 server pm2 可與 CD / CD 工具做結合， CI / CD 部署也沒有問題 好 pm2, 不用嗎？ 本篇將提到： 安裝 pm2 使用 CLI 啟動 pm2 使用 pm2 設定檔 ecosystem 啟動 pm2 使用 pm2 設定檔 ecosystem 部署 node 專案 使用 pm2 搭配 GitLab CI / CD Runner 部署 node 專案 安裝 全域安裝npm install pm2@latest -g pm2 with CLI可以使用 pm2 CLI 來啟動 node 專案, 範例如下：pm2 start location/fileName.js --name appName \\--watch true \\--max-memory-restart 500M \\--log ~/.pm2/logs/appName/ \\--time true \\--cron \"0 17 * * *\" \\--no-daemon true \\--merge-logs 以上範例中設定代表的意思，參考如下： 開始可以附加的參數 --name指定 app 一個名字 --watch檔案有變更時，會自動重新啟動 --max-memory-restartMemory 使用超過這個門檻時，會自動重啟 --log指定 log 的位址, 若要指定新位址，需將原本的 process 刪掉，再重新啟動指定 --output指定 output log 位址 --error指定 error log 位址 --log-date-format指定 log 的格式 --merge-logs同一個 app 跑多程序時，不要依據程序 id 去分割 log, 全部合在一起 --arg1 --arg2 --arg3指派額外的參數 --restart-delay自動重啟時，要 delay 多久 --time給 log 加上前綴 --no-autorestart不要自動重啟 --cron指定 cron 規律，強制重啟 --no-daemon無 daemon 模式， listen log 模式 叢集模式 pm2 自動偵測該機器的 CPU 數量，啟動最大能負荷的 process, 適用上面的選項, -i 後面接希望啟動 instance 的數量， 0 或 max 默認自動偵測 CPU 啟動最大值pm2 start app.js -i max 管理程序 直接 kill 掉 process, 再重新開始程序 pm2 restart app_name 如果是在 cluster mode, reload 會依序升級重啟每一個程序，達到 zero downtime 升級 pm2 reload app_name 停止服務 pm2 stop app_name 停止並刪除服務 pm2 delete app_name 除了 app_name 之外，你也可以指定all : 啟動所有程序id : 該程序 id 顯示管理程序狀態pm2 [list|ls|status] Logs 輸出 log pm2 logs 顯示指定行數 log (指定倒數 200 行) pm2 logs --lines 200 指定輸出程序 log pm2 logs id 指定輸出格式 pm2 logs --format pm2 logs --json 清空 log pm2 flush 取消 log可以利用指定 log 路徑為 /dev/null 來取消 log 輸出, log 參數用法請參考 ecosystem 範例 循環 log如果你看過 log 檔案超肥，幾年的 log 都寫在同一個檔案; 如果你打開 log 資料夾，發現裡面躺著幾百個 log 檔案; 如果你看過千奇百怪的 log 檔名; 如果你 du -h 發現 log 資料夾大的嚇死人如果你有以上的經驗，那恭喜你，你有救了 安裝pm2 install pm2-logrotate config 檔位置/home/user/.pm2/module_conf.json 參數 max_size (預設 10M):當 log 檔案達到多大時， logrotate module 會將它分割成另外一個檔案。 logrotate module 有可能在檢查檔案時，檔案已經超過指定的大小了，所以超過一些些是可能的。 單位可以自行指定, 10G, 10M, 10K retain (預設 30 個 log 檔案):預設最多保存的 log 數量，如果設定為 7 的話，將會保存目前的 log, 以及最多 7 個 log 檔案 compress (預設 false):壓縮所有循環 log 檔案 dateFormat (時間格式，預設 YYYY-MM-DD_HH-mm-ss) :檔案命名的時間格式 rotateModule (預設 true) :跟其他 apps 一樣，循環 pm2’s module workerInterval (預設 30 秒) :多久 logrotate 會檢查一次 log 檔案大小 rotateInterval (預設每天午夜循環, 範例 0 0 * ):除了設定檔案大小以外，我們也可以設定以時間為單位去循環，格式上採用 node-schedule TZ (預設為系統時間):檔案命名的時間會根據你所設定的時區而改變 圖示* * * * * *┬ ┬ ┬ ┬ ┬ ┬│ │ │ │ │ |│ │ │ │ │ └ day of week (0 - 7) (0 or 7 is Sun)│ │ │ │ └───── month (1 - 12)│ │ │ └────────── day of month (1 - 31)│ │ └─────────────── hour (0 - 23)│ └──────────────────── minute (0 - 59)└───────────────────────── second (0 - 59, OPTIONAL) terminal 監控面板pm2 monit pm2 ecosystemCLI 工具固然不錯，但只要是人難免手滑打錯或漏打參數。 pm2 ecosystem 解決了這個問題，只要好好的打上一次，以後除非設定有變更，否則啟動服務只需要短短幾個指令，而且 ecosystem 檔案還可以納入 git 控管，跟著專案跑 產生範例 ecosystem filepm2 ecosystem CLI跟前面介紹過的管理程序一樣，差別只是將 app.js 換成 ecosystem.js多個管理程序 CLI, 這邊就只列出 start, 其餘同上pm2 start ecosystem.config.js 從 ecosystem 中只啟動特定 app下面的 appName 為我們寫在 ecosystem.config.js 檔案中的 appNamepm2 start ecosystem.config.js --only yourApp 帶入參數拿下面的範例來說，如果我輸入 pm2 start ecosystem --only app1 --env production , 那麼 pm2 就會使用 NODE_ENV=production 這個環境變數 參數範例下面的參數有點多，我們肯定不會一次使用到這麼多的參數，所以可以視專案需求留下我們需要的參數即可module.exports = &#123; apps: [ // First application &#123; // App 名稱 name: 'app1', // 執行服務的入口檔案 script: './server.js', // 你的服務所在位置 cwd: 'var/www/yourApp/', // 分為 cluster 以及 fork 模式 exec_mode: 'cluster', // 只適用於 cluster 模式，程序啟動數量 instances: 0, // 適合開發時用，檔案一有變更就會自動重啟 watch: false, // 當佔用的 memory 達到 500M, 就自動重啟 max_memory_restart: '500M', // 可以指定要啟動服務的 node 版本 interpreter: '/root/.nvm/versions/node/v8.16.0/bin/node', // node 的額外參數 // 格式可以是 array, 像是 \"args\": [\"--toto=heya coco\", \"-d\", \"1\"], 或是 string, 像是 \"args\": \"--to='heya coco' -d 1\" interpreter_args: \"port=3001 sitename='first pm2 app'\", // 同上 node_args: \"port=3001 sitename='first pm2 app'\", // 'cron' 模式指定重啟時間，只支持 cluster 模式 cron_restart: \"0 17 * * *\", // log 顯示時間 time: true, // 可經由 CLI 帶入的參數 args: '-a 13 -b 12', // 想要被忽略的檔案或資料夾, 支援正則，指定的檔案或資料夾如果內容有變更，服務將不會重啟 // 格式可以是 array, 像是 \"args\": [\"--toto=heya coco\", \"-d\", \"1\"], 或是 string, 像是 \"args\": \"--to='heya coco' -d 1\" ignore_watch: [\"[\\/\\\\]\\./\", \"node_modules\"], // 支援 source_map, 預設 true, 細節可參考 // http://pm2.keymetrics.io/docs/usage/source-map-support/ // https://www.html5rocks.com/en/tutorials/developertools/sourcemaps/ source_map_support: true, // instance_var, 詳見以下連結 // http://pm2.keymetrics.io/docs/usage/environment/#specific-environment-variables instance_var: 'NODE_APP_INSTANCE', // log 的時間格式 log_date_format: 'YYYY-MM-DD HH:mm Z', // 錯誤 log 的指定位置 error_file: '/var/log', // 正常輸出 log 的指定位置 out_file: '/var/log', // 同一個 app 有多程序 id, 如果設定為 true 的話， 同 app 的 log 檔案將不會根據不同的程序 id 分割，會全部合在一起 combine_logs: true, // 同上 merge_logs: true, // pid file 指定位置, 預設 $HOME/.pm2/pid/app-pm_id.pid pid_file: 'user/.pm2/pid/app-pm_id.pid', // pm2 會根據此選項內的時間來判定程序是否有成功啟動 // 格式可使用 number 或 string, number 的話， 3000 代表 3000 ms。 string 的話, 可使用 '1h' 代表一個小時, '5m' 代表五分鐘, '10s' 代表十秒 min_uptime: '5', // 單位為 ms, 如果在該時間內 app 沒有聽 port 的話，強制重啟 listen_timeout: 8000, // 當執行 reload 時，因為 graceful reload 會等到服務都沒有被存取了才會斷開，如果超過這個時間，強制斷開重啟 // 細節可參考官方文件 http://pm2.keymetrics.io/docs/usage/signals-clean-restart/ kill_timeout: 1600, // 一般來說，服務等待 listen 事件觸發後，執行 reload, 若此選項為 true, 則等待 'ready' message // 細節可參考官方文件 http://pm2.keymetrics.io/docs/usage/signals-clean-restart/ wait_ready: false, // pm2 具有 crash 自動重啟的功能。 但若異常狀況重啟超過此選項的指定次數，則停止自動重啟功能。 異常與否的判定，預設為 1 秒，也就是說如果服務啟動不足一秒又立即重啟，則異常重啟次數 + 1。 若 min_uptime 選項有指定，則以 min_uptime 指定的最小正常啟動時間為標準來判斷是否為異常重啟 // 細節可參考官方文件 http://pm2.keymetrics.io/docs/usage/signals-clean-restart/ max_restarts: 10, // 單位為 ms, 預設為 0, 若有指定時間，則 app 會等待指定時間過後重啟 restart_delay: 4000, // 預設為 true, 若設為 false, pm2 將會關閉自動重啟功能, 也就是說 app crash 之後將不會自動重啟 autorestart: true, // 預設為 true, 預設執行 pm2 start app 時，只要 ssh key 沒問題， pm2 會自動比較 local 跟 remote, 看是否為最新的 commit，若否，會自動下載更新。 此功能有版本問題，需新版才支援 vizion: true, // 進階功能，當使用 Keymetrics 的 dashboard 執行 pull 或 update 操作後，可以觸發執行的一系列指令 post_update: [\"npm install\", \"echo launching the app\"], // defaults to false. if true, you can start the same script several times which is usually not allowed by PM2 // 預設為 false, 如果設定為 true, force: false, // 當不指定 env 時，會套用此 object 裡頭的環境變數, 例如 pm2 start ecosystem.js env: &#123; COMMON_VARIABLE: 'true', NODE_ENV: '', ID: '44' &#125;, // 當有指定 env 時，會套用此 object 裡頭的環境變數, 例如 pm2 start ecosystem.js --env production env_production: &#123; NODE_ENV: 'production', ID: '55' &#125;, // 同上 env_development: &#123; NODE_ENV: 'development' &#125; &#125;, // 第二個 app, 很多資訊上面有介紹過的就不再重複 &#123; name: 'app2', script: 'server.js', // 預設模式，可應用在其他語言, cluster 只可用在 node.js exec_mode: 'fork', instances: 0, watch: false, max_memory_restart: '500M', interpreter: '/root/.nvm/versions/node/v8.16.0/bin/node', time: true, env: &#123; COMMON_VARIABLE: 'true', NODE_ENV: '' &#125;, env_staging: &#123; NODE_ENV: 'staging' &#125;, env_test: &#123; NODE_ENV: 'test' &#125; &#125; ], // 這一個區塊是部署的部分 deploy: &#123; // production production: &#123; // 要登入執行 pm2 的 user user: 'root', // 支援多個 host 部署 host: ['host1', 'host2'], // remote 要檢查的 public key 的位置 key: 'path/to/some.pem', // 要部署的分支 ref: 'origin/master', // Git 倉庫位址 repo: 'git@gitlab.com:user/yourProject.git', // 要部署到 server 上的資料夾路徑 path: '/var/www/yourProjectName', // 如果 ssh 有設定好，從 local 連到 remote 端將不會再詢問是否將 remote 端的 public key 加到 known host \"ssh_options\": \"StrictHostKeyChecking=no\", // 在 pm2 要從 local 端連到 remote 端之前要執行的指令，可以多個指令，由 ; 分割，也可以指定 shell script 的檔案路徑 \"pre-setup\": 'apt update -y; apt install git -y', // 當 pm2 在 remote 機器上將專案 clone 下來之後會執行的指令，同上，可以多個指令，由 ; 分割，也可以指定 shell script 的檔案路徑 \"post-setup\": \"ls -la\", // 當 pm2 在 local 要連上 remote 部署之前 ，在 local 端所要執行的指令, 同上，可以多個指令，由 ; 分割，也可以指定 shell script 的檔案路徑 \"pre-deploy-local\" : \"echo 'This is a local executed command'\", // 部署完成後, 所要執行的指令 同上，可以多個指令，由 ; 分割，也可以指定 shell script 的檔案路徑 'post-deploy': 'sudo /root/.nvm/versions/node/v8.16.0/bin/npm install &amp;&amp; sudo /root/.nvm/versions/node/v8.16.0/bin/npm rebuild &amp;&amp; /root/.nvm/versions/node/v8.16.0/bin/pm2 reload ecosystem.config.js', env_production: &#123; NODE_ENV: 'production' &#125; &#125;, staging: &#123; user: 'root', host: ['host3', 'host4'], ref: 'origin/staging', repo: 'git@gitlab.com:user/yourProject.git', path: '/var/www/yourProjectName', \"ssh_options\": \"StrictHostKeyChecking=no\", \"pre-setup\": 'apt update -y; apt install git -y', \"post-setup\": \"ls -la\", \"pre-deploy-local\" : \"echo 'This is a local executed command'\", 'post-deploy': 'sudo /root/.nvm/versions/node/v8.16.0/bin/npm install &amp;&amp; sudo /root/.nvm/versions/node/v8.16.0/bin/npm rebuild &amp;&amp; /root/.nvm/versions/node/v8.16.0/bin/pm2 reload ecosystem.config.js', env_production: &#123; NODE_ENV: 'staging' &#125; &#125;, &#125;,&#125;; pm2 部署pm2 的部署功能，可以讓我們從本機直接部署到多台 server 上, 也可以結合 CI / CD 工具，在提交 commit 後自動部署 部署前的必要條件 首先要先確定，local 到 remote 端的 ssh key 有準備好了嗎？ local 到 remote server 的 ssh 連線是必要的哦！ 簡單來說，你需要在 local 放一把 private key, 然後在你的 remote server 放一把 public key, 這樣才能暢通無阻哦！ 這部分再麻煩 Google 一下哦！ 再來，因為 pm2 會 ssh 到 remote server 上，然後在 remote server 上從我們的專案處 GitHub 或 GitLab 將專案 clone 下來，所以務必確保 remote server 是可以從 GitHub 或 GitLab clone 我們的專案, 所以你要在 remote server 上放一把 clone 用的 private key, 然後將 public key 放在 GitLab 或 GitHub 上，這部分也是麻煩 Google 一下哦 由於首次 ssh 連線時會跳詢問是否將 public key 加入到 known host，這個 prompt 會讓 pm2 deploy 卡住，所以務必先將 remote server 設定好哦！ 可以先連線一次，也可以修改 ssh config, 取消這個 hostKey 的 確認功能。 echo -e \"Host *\\n\\tStrictHostKeyChecking no\\n\\n\" &gt; ~/.ssh/config 接下來，要將 ecosystem 設定檔寫好，這部分請參考上方的 deploy 範例 最後，請確認 remote server 的 ssh 通道 (預設 port 22) 不是關閉的哦！ 初始化遠端資料夾在部署之前, 先在 remote server 上初始化專案的資料夾, 可以帶入不同的參數讓 pm2 根據設定檔做相對應得部署pm2 deploy ecosystem.config.js production setup 部署 部署在初始化遠端資料夾之後，我們就可以使用 pm2 的部署功能了 pm2 deploy ecosystem.config.js production deploy 可使用的參數如下，也可使用 pm2 deploy help 查看 pm2 deploy &lt;configuration_file&gt; &lt;environment&gt; &lt;command&gt; Commands: setup 遠端初始化（第一次部署才會用到） update 更新到最新的 commit revert [n] 回復到上一次的 deployment curr[ent] 輸出目前上線中的 commit prev[ious] 輸出上一次部署的 commit exec|run &lt;cmd&gt; 執行指定的指令 list 列出包含目前，以及之前所部署的 commit [ref] 部署到指定的 ref 部署相關指令pm2 startOrRestart all.json # 重啟所有 apppm2 startOrReload all.json # 觸發 reload 強制重啟pm2 的部署，會要求 local 端先將變更推上 Git repository, 然後 pm2 會在 remote server 執行 git pull, 所以當 local 的變更尚未推上 Git 時，部署會失敗。這時候如果我們硬要部署，我們可以使用pm2 deploy ecosystem.json production --force CI / CD 部署 利用 GitLab 的 CI / CD Runner 配合 pm2 來跑自動部署, 以下為 gitlab.yml 檔案範例 # 使用輕量化 pm2 imageimage: keymetrics/pm2:latest-alpinestages:- deployDeploy: stage: deploy script: # 若 ssh-agent 未安裝，則安裝 - 'which ssh-agent || ( apk add --update openssh )' # 安裝 bash, 以執行 pm2 CLI 工具 - apk add --update bash # 安裝 git, pm2 要連過去時會用到 - apk add --update git # 執行 ssh agent - eval $(ssh-agent -s) # 將 ssh key 加到 ssh agent, 此 ssh key 為 GitLab 的 variable 選項 - echo \"$SSH_PRIVATE_KEY\" | ssh-add - # 執行 pm2 CLI - pm2 deploy ecosystem.config.js production update only: - master 設定好之後，只要 git push 到 master branch, 就會觸發 GitLab CI / CD Runner 自動完成 CI / CD 開機自動啟動 產生開機 script pm2 startup 取消開機自動重啟 pm2 unstartup 儲存下次重啟時，預設啟動的 process pm2 save 如果有更新 node 的版本，記得更新 script pm2 unstartup &amp;&amp; pm2 startup &amp;&amp; pm2 save 有變更時重啟監看該資料夾下的所有檔案，以及子資料夾，並且忽略 node_module 這個資料夾cd /path/to/my/apppm2 start env.js --watch --ignore-watch=\"node_modules\" 更新 PM2npm install pm2@latest -g &amp;&amp; pm2 update 常用指令# Fork 模式pm2 start app.js --name my-api # 指定程序名稱# Cluster 模式pm2 start app.js -i 0 # 會根據可用的 CPU 數量來啟動最大的程序數量，達到平衡負載的效果pm2 start app.js -i max # 跟上面一樣，但是廢除了pm2 scale app +3 # 增加三個 workerpm2 scale app 2 # 將 worker 更新成兩個# 狀態顯示pm2 list # 顯示所有程序狀態pm2 jlist # 將程序狀態使用 raw JSON 印出pm2 prettylist # 將程序狀態用美化的 JSON 印出pm2 describe 0 # 顯示特定程序的所有資訊pm2 monit # 監控所有程序# Logspm2 logs [--raw] # 以串流的方式顯示所有 logpm2 flush # 移除所有 log 檔案pm2 reloadLogs # 重新載入 logs# 操作pm2 stop all # 停止所有程序pm2 restart all # 重新開啟所有程序pm2 reload all # 重新載入服務pm2 stop 0 # 停止特定 id 的程序pm2 restart 0 # 重新啟動特定 id 程序pm2 delete 0 # 從 pm2 list 移除特定 id 程序, 但這並不會停止該程序pm2 delete all # 移除所有程序, 但這並不會停止這些程序# Miscpm2 reset &lt;process&gt; # 重置 meta datapm2 updatePM2 # 更新 pm2pm2 ping # Ensure pm2 daemon has been launchedpm2 sendSignal SIGUSR2 my-app # Send system signal to scriptpm2 start app.js --no-daemon # 不要背景執行pm2 start app.js --no-vizion # 不加這一行，預設執行 pm2 start app 時，只要 ssh key 沒問題， pm2 會自動比較 local 跟 remote, 看是否為最新的 commit，若否，會自動下載更新pm2 start app.js --no-autorestart # 不自動重啟 自動補齊 支援 pm2 指令可以打 tab 自動補齊pm2 completion install 疑難雜症遇到錯誤 Error: ENOENT: no such file or directory, uv_cwd意思是說， pm2 的工作目錄資料夾不存在，所謂的工作目錄資料夾就是我們第一次啟動 pm2 的位置。很可能是我們啟動之後，就不小心把它刪了，如果要尋找工作目錄資料夾在哪，可以使用下面的 command 找到 pm2 的 process id ps ax | grep PM2 然後查詢該 process 執行時所在的目錄（將上面得到的 process id 替換下面的 PM2_Process_ID ls -l /proc/PM2_Process_ID/cwd 公布結果 ls -l /proc/24016/cwd 結果應該會如下, 最後的 deleted 表示該目錄已經被刪除了lrwxrwxrwx 1 root root 0 Feb 4 17:04 /proc/24016/cwd -&gt; /home/nodejs/deploy(deleted) 現在知道原因了，那解決的方法呢？ 我們要先把目前的 process 砍掉，然後到一個安全一點的地方在開啟一次，以免下次又被誤刪了！ 殺掉 pm2 process id kill -9 processID 到一個安全不會再被意外砍掉的目錄再次啟動 pm2 cd ~ &amp;&amp; pm2 -v 參考資料pm2 官網pm2 logrotate","link":"/zh-tw/pm2/"},{"title":"在 PayPal 的 IPN 方式中，提交多個商品","text":"前言這篇文章將分享，當我們使用 PayPal 的 IPN 結帳方式時，如何提交多個商品，每個商品擁有各自的名稱，價格，以及數量。本文章是我從官網 複製下來的, 因為我不知道未來什麼時候會用到，而且我實在懶得再去找一次。 本文開始有些網站開發人員可能希望將PayPal付款處理集成到他們自己的第三方購物車上，而不是標準的PayPal購物車上。請使用以下說明為您的買家提供PayPal付款，以便他們在您的第三方購物車上添加購置物品後結賬時使用。 將您的第三方購物車與PayPal的付款流程集成目前有兩種方法。第一種方法是傳遞購物車付款總額，而不是單個物品金額。第二種方法是將所選物品詳情傳遞給PayPal，而不是總購物車數量。提示：按下述步驟粘貼必需的變量到PayPal時，可能需要在您的網站上執行某些腳本。 方法 1. 將總購物車數量傳遞給PayPal 方法 2. 將單個物品傳遞給PayPal 方法1. 將總購物車數量傳遞給PayPal如果願意，您可以累加整個購物車，將總數量傳遞給PayPal的立即購買按鈕代碼（也就是說，您需要粘貼整個購物車的單一名稱及其物品總價款，與購買單件物品一樣）。 該方法有一個不足之處，您的買家將無法查看其購物車中的單個物品。此外，您不能修改我們的變量名稱，也不能添加您自己的變量名稱。 查閱以下信息後如有其他技術問題，請訪問我們的 開發者服務網頁。欲知有關“立即購買”按鈕代碼或以下變量的附加信息，請查看網站付款標準版集成指南。 必需的變量向PayPal提交粘貼代碼時，應包括以下 4 個隱藏變量及一張圖片： 姓名 值 business 您的PayPal賬戶上的電子郵件地址 item_name 物品名稱（或購物車名稱） currency_code 定義幣種以標示貨幣變量（金額、運送費、運送費2、手續費、稅款）。值可以為”USD”、”EUR”、”GBP”、”CAD”、”JPY”。 amount 物品的價格（購物車中所有物品的總價格） image 按鈕圖片，您的買家按此按鈕開始PayPal付款程序。您可以將src 更換為圖片URL，以使用您自己的圖片 這就是說，您粘貼到PayPal的最短必需代碼應如下： &lt;form action=&quot;https://www.paypal.com/cgi-bin/webscr&quot; method=&quot;post&quot;&gt; &lt;input type=&quot;hidden&quot; name=&quot;cmd&quot; value=&quot;_xclick&quot;&gt; &lt;input type=&quot; hidden&quot; name=&quot;business&quot; value=&quot;you@youremail.com&quot;&gt; &lt;input type=&quot;hidden&quot; name=&quot;item_name&quot; value=&quot;Item Name&quot;&gt; &lt;input type=&quot;hidden&quot; name=&quot;currency_code&quot; value= &quot;USD&quot;&gt; &lt;input type=&quot;hidden&quot; name=&quot;amount&quot; value=&quot;0.00&quot;&gt; &lt;input type=&quot;image&quot; src=&quot;http://www.paypal.com/zh_XC/i/btn/x- click-but01.gif&quot; name=&quot;submit&quot; alt=&quot;Make payments with PayPal - it&apos;s fast, free and secure!&quot;&gt; &lt;/form&gt; PayPal提供附加變量，用於自定義您的Form Post。所有可用變量如下（變量名稱必須用小寫）： 可用變量 姓名 值 business 您的PayPal賬戶上的電子郵件地址 quantity 物品數量。大於1 時，會與金額相乘 item_name 物品名稱（或購物車名稱）。必須是字母數字字符，最多為127 個字符 item_number 用於跟踪付款的可選傳遞變量。必須是字母數字字符，最多為127 個字符 amount 物品的價格（購物車中所有物品的總價格） shipping 該物品的運送成本 shipping2 每增加一件物品所需的運送成本 handling 手續費 tax 基於交易的稅額。如果使用該變量，傳遞值將覆蓋所有用戶信息稅收設置（不管買家所在位置）。 no_shipping 送貨地址。如果設為”1”，則不會要求您的客戶提供送貨地址。該變量為可選項；如果省略或設為”0”，將提示您的客戶輸入送貨地址 cn 可選標籤，會在提示欄上顯示（最多40 個字符） no_note 為付款加入提示。如果設為”1”，則不會提示您的客戶輸入提示。該變量為可選項；如果省略或設為”0”，將提示您的客戶輸入提示。 on0 第一選項欄名稱。最多64 個字符 os0 第一組選項值。最多200 個字符。”on0” 必須定義，以便識別”os0”。 on1 第二選項欄名稱。最多64 個字符 os1 第二組選項值。最多200 個字符。”on1” 必須定義，以便識別”os1”。 custom 決不會向您的客戶顯示的可選轉遞變量。可用於跟踪庫存 invoice 決不會向您的客戶顯示的可選轉遞變量。可用於跟踪賬單號 notify_url 僅與IPN 一起使用。發送IPN Form Post 的互聯網URL return 您的客戶完成付款後將返回的互聯網URL cancel_return 您的客戶取消付款後將返回的互聯網URL image_url 您要用作圖標的圖片的互聯網URL，圖片大小為150 X 50 像素 cs 設置您的付款頁面的背景色。如果設為”1”，背景色將為黑色。該變量為可選項；如果省略或設為”0”，背景色將為白色 擴展變量 PayPal允許您粘貼擴展變量，條件是將改變以下”cmd”值： &lt;input type=&quot;hidden&quot; name=&quot;cmd&quot; value=&quot;_xclick&quot;&gt; 到： &lt;input type=&quot;hidden&quot; name=&quot;cmd&quot; value=&quot;_ext-enter&quot;&gt; &lt;input type=&quot;hidden&quot; name=&quot;redirect_cmd&quot; value=&quot;_xclick&quot;&gt; 通過上述”cmd” 值修改，您還可使用以下變量： 擴展變量 姓名 值 email 客戶的電子郵件地址 first_name 客戶的名。必須是字母數字字符，最多為32個字符 last_name 客戶的姓。必須是字母數字字符，最多為64個字符 address1 客戶地址所在國家或地區。必須是字母數字字符，最多為100個字符 address2 客戶地址第二行。必須是字母數字字符，最多為100 個字符 city 客戶地址所在城市。必須是字母數字字符，最多為100 個字符 state 客戶地址所在州。必須是正式的2 個字母縮寫 zip 客戶地址的郵政編碼 night_phone_a 客戶夜間聯繫電話號碼的區號 night_phone_b 客戶夜間聯繫電話號碼前三位 day_phone_a 客戶白天聯繫電話號碼的區號 day_phone_b 客戶白天聯繫電話號碼前三位 提示：若要更改“用戶信息”中的默認運費和手續費設置，請轉至您的用戶信息，編輯您的運費計算，然後點擊“允許採用基於交易的運費”複選框。 方法2. 將單個物品傳遞給PayPal如果您的第三方購物車可設置成向PayPal傳遞單個物品，有關物品的信息將加入買家和賣家的記錄日誌和系統通知中。要加入該物品的信息，您需要將HTML 格式元素粘貼至PayPal購物車流程的新版本。該過程與#1 節“將總購物車數量傳遞給PayPal”描述的非常相似，不同之處在於： 將”cmd”變量設置到”_cart”更換必要的HTML行 &lt;input type=&quot;hidden&quot; name=&quot;cmd&quot; value=&quot;_xclick&quot;&gt; 與&lt;input type=&quot;hidden&quot; name=&quot;cmd&quot; value=&quot;_cart&quot;&gt; 添加稱為”upload”的新變量 在&lt;表格&gt;和&lt;/表格&gt;標籤之間新增以下行： &lt;input type=&quot;hidden&quot; name=&quot;upload&quot; value=&quot;1&quot;&gt; 定義物品明細對於以下各特定物品參數，定義與通過您的合作商購物車購買的各物品對應的一組新值。將”_x”附加到變量名稱，其中x是物品號碼，從1開始，每加入一物品增加一。 姓名 值 item_name_x （物品#x 需要）購物車中物品#x 的名稱。必須是字母數字字符，最多為127 個字符 item_number_x 與購物車中物品#x 關聯的可選傳遞變量。必須是字母數字字符，最多為127 個字符 amount_x （物品#x 需要）物品#x 的價格 shipping_x 運送物品#x 的第一件（數量1）的成本 shipping2_x 每增加一件運送物品#x（數量2 或更多）所需的運送成本 handling_x 物品#x 的處理成本 on0_x 物品#x 的第一選項欄名稱。最多64 個字符 os0_x 物品#x 的第一組選項值。最多200 個字符。”on0_x” 必須定義，以便識別”os0_x”。 on1_x 物品#x 的第二選項欄名稱。最多64 個字符 os1_x 物品#x 的第二組選項值。最多200 個字符。”on1_x” 必須定義，以便識別”os1_x”。 為購物車中每件物品重複此設定為您的買家購物車中的各物品加入以上表格中的一組必需的變量和任何選項變量。購物車中的第一物品必須用以”_1”結束的參數定義，如”item_name_1”、”amount_1”等。同樣，第二物品應用變量”item_name_2”、”amount_2”等命名。提示：”_x”值必須以一為單位按序遞增，以便識別。如果從item #1跳到item #3而不定義item #2，則第三個物品會被忽略。要指定幣種：所有貨幣變量（金額、運費、運費2、手續費、稅款）將以粘貼在付款上的”currency_code”變量指定的幣種顯示。因為其不是隨物品不同的，無需向變量名稱附加”_x”。如果沒有粘貼”currency_code”變量，我們將假定所有貨幣變量值為美元。查閱以下信息後如有其他技術問題，請訪問我們的開發者支持網頁。欲知有關購物車代碼或以下變量的其他信息，請查看網站付款標準版集成指南。","link":"/zh-tw/submitMultipleItemsInPayPalIPNmethod/"},{"title":"使用Laravel任務排程","text":"打開排程檔案打開yourProjectName/app/Console/Kernel.php 輸入你的排程排程範例如下： protected function schedule(Schedule $schedule)&#123; $schedule-&gt;call(function () &#123; Token::where(&apos;expiry_time&apos;, &apos;&lt;&apos;, time())-&gt;delete(); PaymentServiceOrders::deleteExpiredOrders(); Order::where(&apos;expiry_time&apos;, &apos;&lt;&apos;, Carbon::now())-&gt;delete(); &#125;)-&gt;daily();&#125; 我設定的任務排程，是每天固定刪除資料庫裡過期的訂單。 將Laravel排程加入到Linux的crontab中 sudo vim /etc/crontab * * * * * apache cd /var/www/html/yourProjectName &amp;&amp; php artisan schedule:run &gt;&gt; /dev/null 2&gt;&amp;1 前面的 * 依序分別代表 分(0-59) 時(0-23) 每月的第幾天(1-31) 月份(1-12) 每週的第幾天(0-6) apache表示使用者，這關乎權限問題，當執行的schedule中出現錯誤，log會由此使用者而建立，若權限沒有設好，之後的使用者都將無法讀取log，會造成，若我們本身有額外記log的話，會因為此log檔無法被開啟而造成錯誤 cd ray cd /var/www/html/yourProjectName到該目錄底下 php artisan schedule:run &gt;&gt; /dev/null 2&gt;&amp;1執行Laravel的排程指令 以上，這樣應該就可以順利地跑起來了！","link":"/zh-tw/taskSchedulingInLaravel/"},{"title":"在 MacOS 及 AWS 上部署 supervisor","text":"部署 supervisor前言本篇重點如下： 在 Mac OS 上安裝並部署 Supervisor 在 AWS 上安裝並部署 Supervisor Supervisor是什麼？Supervisor 是一套程序管理系統。因為 Ray 的專案有使用到 Laravel 的 queue ，而 queue 必須要常駐在背景執行，那要是不小心失敗或中斷了怎麼辦呢？ supervisor 可以確保當 queue 失敗中斷時，自動地幫我們重啟。 Mac OS安裝 安裝 Supervisorbrew install supervisor 配置 進到預設設定檔 vim /usr/local/etc/supervisord.ini 更改預設 include 目錄，到最後一行，修改如下 [include]files = /usr/local/etc/supervisor.d/*.conf 新增客製化配置目錄及檔案 mkdir /usr/local/etc/supervisor.d;vim /usr/local/etc/supervisor.d/processNameYouLike.conf; 輸入下面的設定 [program:programNameYouLike]process_name=%(program_name)s_%(process_num)02dcommand=php absoluteAddressOfYourProject/artisan queue:work sqs --sleep=3 --tries=3 --daemonautostart=trueautorestart=trueuser=raynumprocs=8redirect_stderr=truestdout_logfile=/absoluteAddressOfLocationYouWouldLikeToPutTheLog/worker.log 啟動 啟動服務 sudo supervisord -c /usr/local/etc/supervisord.ini 進到控制台 sudo supervisorctl -c /usr/local/etc/supervisord.ini 更新配置 update 查看狀態 status 看起來如下： AWSAmazon Linux 2 AMI本篇記錄使用的AWS型號如下： Amazon Linux 2 AMI (HVM), SSD Volume Type - ami-0f9ae750e8274075b t2.micro (Variable ECUs, 1 vCPUs, 2.5 GHz, Intel Xeon Family, 1 GiB memory, EBS only) 安裝 安裝 supervisorsudo yum install -y supervisor 配置 到預設設定檔 sudo vim /etc/supervisord.conf 更改最後一行 include 的目錄 [include]files = supervisord.d/*.conf 新增配置檔，如果資料夾不存在就創建 sudo mkdir /etc/supervisord.d;sudo vim /etc/supervisord.d/projectFileNameYouLike.conf 新增配置 [program:laravel-worker]process_name=%(program_name)s_%(process_num)02dcommand=sudo php absoluteAddressOfYourProject/artisan queue:work sqs --sleep=3 --tries=3 --daemonautostart=trueautorestart=trueuser=rootnumprocs=8redirect_stderr=truestdout_logfile=absoluteAddressOfYourProject/worker.log 啟動 啟動 supervisor sudo supervisord -c /etc/supervisord.conf 套用新的配置檔並查看狀態 sudo supervisorctl update;sudo supervisorctl status 配置自動重啟 增加重啟配置檔 sudo vim /etc/init.d/supervisord 輸入以下配置 #! /bin/sh### BEGIN INIT INFO# Provides: supervisord# Required-Start: $remote_fs# Required-Stop: $remote_fs# Default-Start: 2 3 4 5# Default-Stop: 0 1 6# Short-Description: Example initscript# Description: This file should be used to construct scripts to be# placed in /etc/init.d.### END INIT INFO# Author: Dan MacKinlay &lt;danielm@phm.gov.au&gt;# Based on instructions by Bertrand Mathieu# http://zebert.blogspot.com/2009/05/installing-django-solr-varnish-and.html# Do NOT &quot;set -e&quot;# PATH should only include /usr/* if it runs after the mountnfs.sh scriptPATH=/sbin:/usr/sbin:/bin:/usr/binDESC=&quot;Description of the service&quot;NAME=supervisordDAEMON=/usr/local/bin/supervisordDAEMON_ARGS=&quot;&quot;PIDFILE=/var/run/$NAME.pidSCRIPTNAME=/etc/init.d/$NAME# Exit if the package is not installed[ -x &quot;$DAEMON&quot; ] || exit 0# Read configuration variable file if it is present[ -r /etc/default/$NAME ] &amp;&amp; . /etc/default/$NAME# Load the VERBOSE setting and other rcS variables. /lib/init/vars.sh# Define LSB log_* functions.# Depend on lsb-base (&gt;= 3.0-6) to ensure that this file is present.. /lib/lsb/init-functions## Function that starts the daemon/service#do_start()&#123; # Return # 0 if daemon has been started # 1 if daemon was already running # 2 if daemon could not be started start-stop-daemon --start --quiet --pidfile $PIDFILE --exec $DAEMON --test &gt; /dev/null \\ || return 1 start-stop-daemon --start --quiet --pidfile $PIDFILE --exec $DAEMON -- \\ $DAEMON_ARGS \\ || return 2 # Add code here, if necessary, that waits for the process to be ready # to handle requests from services started subsequently which depend # on this one. As a last resort, sleep for some time.&#125;## Function that stops the daemon/service#do_stop()&#123; # Return # 0 if daemon has been stopped # 1 if daemon was already stopped # 2 if daemon could not be stopped # other if a failure occurred start-stop-daemon --stop --quiet --retry=TERM/30/KILL/5 --pidfile $PIDFILE --name $NAME RETVAL=&quot;$?&quot; [ &quot;$RETVAL&quot; = 2 ] &amp;&amp; return 2 # Wait for children to finish too if this is a daemon that forks # and if the daemon is only ever run from this initscript. # If the above conditions are not satisfied then add some other code # that waits for the process to drop all resources that could be # needed by services started subsequently. A last resort is to # sleep for some time. start-stop-daemon --stop --quiet --oknodo --retry=0/30/KILL/5 --exec $DAEMON [ &quot;$?&quot; = 2 ] &amp;&amp; return 2 # Many daemons don&apos;t delete their pidfiles when they exit. rm -f $PIDFILE return &quot;$RETVAL&quot;&#125;## Function that sends a SIGHUP to the daemon/service#do_reload() &#123; # # If the daemon can reload its configuration without # restarting (for example, when it is sent a SIGHUP), # then implement that here. # start-stop-daemon --stop --signal 1 --quiet --pidfile $PIDFILE --name $NAME return 0&#125;case &quot;$1&quot; in start) [ &quot;$VERBOSE&quot; != no ] &amp;&amp; log_daemon_msg &quot;Starting $DESC&quot; &quot;$NAME&quot; do_start case &quot;$?&quot; in 0|1) [ &quot;$VERBOSE&quot; != no ] &amp;&amp; log_end_msg 0 ;; 2) [ &quot;$VERBOSE&quot; != no ] &amp;&amp; log_end_msg 1 ;; esac ;; stop) [ &quot;$VERBOSE&quot; != no ] &amp;&amp; log_daemon_msg &quot;Stopping $DESC&quot; &quot;$NAME&quot; do_stop case &quot;$?&quot; in 0|1) [ &quot;$VERBOSE&quot; != no ] &amp;&amp; log_end_msg 0 ;; 2) [ &quot;$VERBOSE&quot; != no ] &amp;&amp; log_end_msg 1 ;; esac ;; #reload|force-reload) # # If do_reload() is not implemented then leave this commented out # and leave &apos;force-reload&apos; as an alias for &apos;restart&apos;. # #log_daemon_msg &quot;Reloading $DESC&quot; &quot;$NAME&quot; #do_reload #log_end_msg $? #;; restart|force-reload) # # If the &quot;reload&quot; option is implemented then remove the # &apos;force-reload&apos; alias # log_daemon_msg &quot;Restarting $DESC&quot; &quot;$NAME&quot; do_stop case &quot;$?&quot; in 0|1) do_start case &quot;$?&quot; in 0) log_end_msg 0 ;; 1) log_end_msg 1 ;; # Old process is still running *) log_end_msg 1 ;; # Failed to start esac ;; *) # Failed to stop log_end_msg 1 ;; esac ;; *) #echo &quot;Usage: $SCRIPTNAME &#123;start|stop|restart|reload|force-reload&#125;&quot; &gt;&amp;2 echo &quot;Usage: $SCRIPTNAME &#123;start|stop|restart|force-reload&#125;&quot; &gt;&amp;2 exit 3 ;;esac: script來源 增加權限 sudo chmod +x /etc/init.d/supervisord 將新增的開機重啟配置檔加到系統 sudo chkconfig --add supervisord 打開自動重啟功能，並開始 sudo chkconfig supervisord on;sudo service supervisord start Amazon Linux 2 AMI型號： Amazon Linux AMI 2018.03.0 (HVM), SSD Volume Type - ami-00a5245b4816c38e6 安裝 安裝 supervisor sudo easy_install supervisor 將 /usr/local/bin 加到 sudo path sudo vim /etc/sudoers Defaults secure_path = /sbin:/bin:/usr/sbin:/usr/bin:/usr/local/bin 配置 建立設定檔 sudo su -sudo echo_supervisord_conf &gt; /etc/supervisord.conf;sudo vim /etc/supervisord.conf 更改最後一行 include 的目錄 [include]files = /etc/supervisord.d/*.conf 新增配置檔，如果資料夾不存在就創建 sudo mkdir /etc/supervisord.d;sudo vim /etc/supervisord.d/projectFileNameYouLike.conf 新增配置 [program:laravel-worker]process_name=%(program_name)s_%(process_num)02dcommand=php absoluteAddressOfYourProject/artisan queue:work sqs --sleep=3 --tries=3 --daemonautostart=trueautorestart=trueuser=apachenumprocs=8redirect_stderr=truestdout_logfile=absoluteAddressOfYourProject/worker.log 啟動 啟動 supervisor sudo supervisord -c /etc/supervisord.conf 套用新的配置檔並查看狀態 sudo supervisorctl update;sudo supervisorctl status 配置自動重啟 增加重啟配置檔 sudo vim /etc/init.d/supervisord 輸入以下配置 #!/bin/bash## supervisord Startup script for the Supervisor process control system## Author: Mike McGrath &lt;mmcgrath@redhat.com&gt; (based off yumupdatesd)# Jason Koppe &lt;jkoppe@indeed.com&gt; adjusted to read sysconfig,# use supervisord tools to start/stop, conditionally wait# for child processes to shutdown, and startup later# Erwan Queffelec &lt;erwan.queffelec@gmail.com&gt;# make script LSB-compliant## chkconfig: 345 83 04# description: Supervisor is a client/server system that allows \\# its users to monitor and control a number of processes on \\# UNIX-like operating systems.# processname: supervisord# config: /etc/supervisord.conf# config: /etc/sysconfig/supervisord# pidfile: /var/run/supervisord.pid#### BEGIN INIT INFO# Provides: supervisord# Required-Start: $all# Required-Stop: $all# Short-Description: start and stop Supervisor process control system# Description: Supervisor is a client/server system that allows# its users to monitor and control a number of processes on# UNIX-like operating systems.### END INIT INFO# Source function library. /etc/rc.d/init.d/functions# Source system settingsif [ -f /etc/sysconfig/supervisord ]; then . /etc/sysconfig/supervisordfi# Path to the supervisorctl script, server binary,# and short-form for messages.supervisorctl=/usr/local/bin/supervisorctlsupervisord=$&#123;SUPERVISORD-/usr/local/bin/supervisord&#125;prog=supervisordpidfile=$&#123;PIDFILE-/tmp/supervisord.pid&#125;lockfile=$&#123;LOCKFILE-/var/lock/subsys/supervisord&#125;STOP_TIMEOUT=$&#123;STOP_TIMEOUT-60&#125;OPTIONS=\"$&#123;OPTIONS--c /etc/supervisord.conf&#125;\"RETVAL=0start() &#123; echo -n $\"Starting $prog: \" daemon --pidfile=$&#123;pidfile&#125; $supervisord $OPTIONS RETVAL=$? echo if [ $RETVAL -eq 0 ]; then touch $&#123;lockfile&#125; $supervisorctl $OPTIONS status fi return $RETVAL&#125;stop() &#123; echo -n $\"Stopping $prog: \" killproc -p $&#123;pidfile&#125; -d $&#123;STOP_TIMEOUT&#125; $supervisord RETVAL=$? echo [ $RETVAL -eq 0 ] &amp;&amp; rm -rf $&#123;lockfile&#125; $&#123;pidfile&#125;&#125;reload() &#123; echo -n $\"Reloading $prog: \" LSB=1 killproc -p $pidfile $supervisord -HUP RETVAL=$? echo if [ $RETVAL -eq 7 ]; then failure $\"$prog reload\" else $supervisorctl $OPTIONS status fi&#125;restart() &#123; stop start&#125;case \"$1\" in start) start ;; stop) stop ;; status) status -p $&#123;pidfile&#125; $supervisord RETVAL=$? [ $RETVAL -eq 0 ] &amp;&amp; $supervisorctl $OPTIONS status ;; restart) restart ;; condrestart|try-restart) if status -p $&#123;pidfile&#125; $supervisord &gt;&amp;/dev/null; then stop start fi ;; force-reload|reload) reload ;; *) echo $\"Usage: $prog &#123;start|stop|restart|condrestart|try-restart|force-reload|reload&#125;\" RETVAL=2 esac exit $RETVAL script來源 增加權限 sudo chmod +x /etc/init.d/supervisord 將新增的開機重啟配置檔加到系統 sudo chkconfig --add supervisord 打開自動重啟功能，並開始 sudo chkconfig supervisord on;sudo service supervisord start 在設定好配置檔之前，如何關閉 supervisord ? ps -ef | grep supervisord kill -s SIGTERM 29646 結論完成設定後，每次 reboot ， AWS 就會自動地重啟 supervisor","link":"/zh-tw/supervisor/"},{"title":"使用MySQL- group by 來整理資料庫","text":"大家好，我是Ray! 昨天跟大家分享如何正確的導入中文的資訊到資料庫裡，今天呢，我將分享如何使用MySQL的group by 來整理資料庫！ 在上圖我們可以看到，所有資料都以不同的地區來做劃分。假設右手邊的欄位資料爲降雨量好了，如果我們今天想要取得全地區的平均降雨量，該怎麼作呢？我們可以使用MySQL的group by 來達到我們的目的。 輸入以下code:select date, avg(rainfall) rainfall from rainfall group by date; 上面的date代表我日期欄位的名稱，avg代表平均值，rainfall代表降雨量欄位的名稱，而在括號後面又出現一次rainfall代表顯示在取得的資料表上的欄位的名稱，最後一個rainfall則是我這個表格的名稱。由於我select的項目裡並沒有地區，而最後的group by 表示資料將以date下去做重新整理，如果有相同天數的欄位就會自動重整，並使用我前面下的avg平均化處理。 得出的結果如下圖：￼ 我們下次見。","link":"/zh-tw/useGroupByToOrganiseYourDatabase/"},{"title":"使用MySQL- group by 來整理資料庫 2","text":"哈囉大家好，我是Ray！ 今天想要跟大家分享group by 的更進一步的操作，如何使用group by 配合select 相對應的選項，新建一個表格，並在新表格內將資料重新整理爲我們需要的row and column。 首先，延續昨天的進度，如下圖所示，我們將降雨量根據天來做分類，那如果說今天我們需要月的降雨量，或者年雨量總和呢？￼ 請參考以下的code: &lt;?php// SELECT後面的year(date)以及month(date)表示SELECT這兩項資料，// 括號後的year以及month表示顯示出來的欄位名稱，sum表示加總括號內欄位資料的總和,// 括號內的rainfall爲欄位名稱，括號後的表示顯示出來的欄位名稱，一樣使用group by，// 使資料以月份以及年分來做顯示，order by 表示依照先後順序由先到後作排列。$selectQuery = &apos;SELECT year(date) year, month(date) month, sum(rainfall) rainfall from rainfall_by_date group by month(date), year(date) order by year(date) asc, month(date) asc;&apos;;// 向資料庫作select 請求$selectResult = mysqli_query($dbc, $selectQuery);// 使用迴圈來重複請求，直到拿出所有位於$selectResult物件中的所有arraywhile ($selectRow = mysqli_fetch_array($selectResult))&#123; // 將我們從rainfall_by_date取得的資料insert進新表格rainfall_by_month $insertQuery = &apos;INSERT INTO rainfall_by_month (year, month, rainfall) VALUES(&quot;&apos; . $selectRow[&apos;year&apos;] . &apos;&quot;, &quot;&apos; . $selectRow[&apos;month&apos;] . &apos;&quot;, &quot;&apos; . $selectRow[&apos;rainfall&apos;] . &apos;&quot;)&apos;; // 作insert請求 $insertResult = mysqli_query($dbc, $insertQuery);&#125; 執行以上的script之後，可以得到新的表格，如下：￼","link":"/zh-tw/useGroupByToOrganiseYourDatabasePart2/"},{"title":"Git log 裡面的東西是什麼？","text":"大家好，我是Ray! 今天想跟大家分享，git log 裡面的一些細節。 首先，我們先來看看下面的圖片： 我們可以看到，每一個commit後面都有一段非常長的隨機字串，那這是什麼呢？ 這是一串git 根據commit的內容，由SHA1生成的隨機驗證字串，也許你會問，什麼是SHA1? SHA1全名為security hash algorithm, 中文意思大概就是“安全加密演算法”。 諸如此類的演算法有好幾種，SHA系列的演算法是不可逆的，簡單來說，如果你拿到一串加密過的字串，就像上面那些驗證字串，你是沒有辦法透過將它逆轉回加密前的樣子。 有興趣的朋友可以google一下，這邊我們就不針對SHA多做討論！ 接下來介紹一個非常實用的指令，git log --oneline! 輸入git log --online 可以對照下圖，這是git log 與 git log --oneline的差別。 由上圖大家可以看到，git --oneline 拿掉了作者，日期相關資訊，並且只保留驗證字串的七碼！ 那我們之前提到的git checkout也可以使用這七碼來作切換嗎？ 輸入git checkout out cc92d2f (請輸入你電腦上的驗證字串，你的跟我的不一樣） 如上圖，我們已經成功的切換到前一個commit 輸入 git checkout master 輸入 git log --oneline 這樣就又切回來了！ 看完今天的文章，是不是對於git 有更深一層的理解了呢？ 我們明天見！","link":"/zh-tw/whatIsInGitLog/"},{"title":"為什麼我們要使用Git?","text":"大家好我是Ray! 今天要跟大家分享，為什麼要使用Git? 首先，你有沒有遇過，coding到一半忽然有急事要做（可能是你媽叫你，也可能是你忘記去接你女朋友） 然而很不巧的，當時你可能正在debug，又或者在開發一個新功能。 當你終於有空回去繼續coding時，靠！怎麼出錯啦～？ 滿滿的程式碼滿滿的邏輯不知道從何找起從何debug起～ 又或者，有時在開發新功能時，新功能不巧地影響到現有的功能，導致現有的功能也無法使用！ 當我們陷入一個無頭緒的狀態時，我們就想要回到還沒開始新功能的那一刻，很不巧的，我們早就已經養成定時存檔的良好習慣… 這些時候，就是Git出場的時候啦！ 當你在一些關鍵的時刻，又或者已經完成一個功能，而打算從這個功能為一個起點，開始一個新功能，這個時候你可以使用Git把它存檔起來，存檔後，你可以隨時回到你存擋的那一刻，這種回朔是跟你檔案本身存擋沒有關聯的，換句話說，就算你已經在編輯器或者是IDE上面存擋了，你也可以隨時地回到你使用Git設的存擋點！ 另外一個情況，除非你做的是一個人可以完成的小專案，否則只要是多人協作的專案都需要多人合作與配合，有沒有想過，當這麼多人來一起做一個案子甚至一個檔案，該如何有效地整合呢？畢竟coding是非常細緻的工作，就算你只錯了一個字也可以會造成整個功能無法使用啊！ 這個時候通常我們都會使用Git來整合，試想你的電腦上是一個你自己擁有的資料夾，當你在你的電腦上把你的部分完成之後，你把完成的部分上傳到一個公共的資料夾，而團隊內的其他成員也是用這種方式來上傳他們的部分，此時Git可以讓我們記錄所有人的部分並且將所有人的code合併已達到整合！ 所以對於一個coder來說，Git似乎是不可或缺的呢！","link":"/zh-tw/whyGitIsSoMuchRequired/"},{"title":"為什麼要使用VIM?","text":"哈囉大家好，我是Ray! 今天要來跟大家分享一款非常實用且歷史悠久的編輯器，它叫做Vim! 關於歷史來源背景，我這邊就不贅述了，在麻煩有興趣的讀者自行Google! Vim除了是一款專門爲coding而設計的編輯器之外，幾乎在所有有名的IDE，或者是Editor上，都可以找到Vim的插件，比如我所使用的PHPstorm，或者Subline。 在我們深入Vim之間，我們先來說說，爲什麼我們要使用Vim? 我個人在選擇成爲一名工程師之前，就已經使用標準指法，就是利用F以及J上的凸點來做定位而達到盲打，盲打就是蒙着眼睛也可以準確的打字哦！ 在開始寫程式之後，我最大的困擾並不是程式的語法或邏輯，而是我的手必須頻繁的在滑鼠、方向鍵、以及主鍵區之間作切換。 在我還未邂逅Vim之前，我一直在尋找可以自定義按鍵的鍵盤，因為我認為最理想的打字模式，就是我的手掌並不需要離開主鍵區而可以完成所有的操作。 理論上來說，如果兩個工程師有著同樣的經驗與邏輯，以及技術，打字速度較快的那個人肯定有著較高的輸出，意味著可以更快的完成任務。 如果你問我，那我沒事做那麼快做什麼？ 各位大大，時間就是金錢啊！！ 越快完成表示省下越多的時間，代表你可以運用的時間將越多！ 對於技術狂熱者，啊不對，是對技術有較高熱情的人來說，像是我，更多的時間表示可以學習更多的技術。 時間可以用來做非常多的事，說是比比特幣還珍貴也不為過！ 你可以用來陪家人、追劇、陪女朋友，阿～前提是你要先有女朋友，像我就沒有QQ。 Vim的最基本也最實用的功能，就是可以使用h, j, k, l四個鍵來當成上下左右，換言之，他已經解決我們最大的問題-需要在方向鍵區與主鍵區頻繁的移動。 Vim的功能區分為普通模式、輸入模式，以及選取模式，簡單來說，就是移動游標時會在普通模式，而輸入代碼時會在輸入模式，最後，當我們選取一整行要做複製或貼上甚至更複雜的動作時，會在選取模式。 看完以上的剖析，有沒有被Vim吸引到的感覺呢？ 今天的分享就到這裡，我們明天見！","link":"/zh-tw/whyWouldWeUseVIM/"}],"tags":[{"name":"GCP","slug":"GCP","link":"/zh-tw/tags/GCP/"},{"name":"QWIKLABS","slug":"QWIKLABS","link":"/zh-tw/tags/QWIKLABS/"},{"name":"Cloud Shell","slug":"Cloud-Shell","link":"/zh-tw/tags/Cloud-Shell/"},{"name":"gcloud","slug":"gcloud","link":"/zh-tw/tags/gcloud/"},{"name":"Apache","slug":"Apache","link":"/zh-tw/tags/Apache/"},{"name":"MySQL","slug":"MySQL","link":"/zh-tw/tags/MySQL/"},{"name":"Composer","slug":"Composer","link":"/zh-tw/tags/Composer/"},{"name":"Laravel","slug":"Laravel","link":"/zh-tw/tags/Laravel/"},{"name":"PHP","slug":"PHP","link":"/zh-tw/tags/PHP/"},{"name":"Laravel Transaction","slug":"Laravel-Transaction","link":"/zh-tw/tags/Laravel-Transaction/"},{"name":"Laravel Log","slug":"Laravel-Log","link":"/zh-tw/tags/Laravel-Log/"},{"name":"ngrok","slug":"ngrok","link":"/zh-tw/tags/ngrok/"},{"name":"Laravel Middleware","slug":"Laravel-Middleware","link":"/zh-tw/tags/Laravel-Middleware/"},{"name":"QUIKLABS","slug":"QUIKLABS","link":"/zh-tw/tags/QUIKLABS/"},{"name":"GCP-Marketplace","slug":"GCP-Marketplace","link":"/zh-tw/tags/GCP-Marketplace/"},{"name":"Kubernetes","slug":"Kubernetes","link":"/zh-tw/tags/Kubernetes/"},{"name":"Docker","slug":"Docker","link":"/zh-tw/tags/Docker/"},{"name":"Network Load Balancer","slug":"Network-Load-Balancer","link":"/zh-tw/tags/Network-Load-Balancer/"},{"name":"HTTP Load Balancer","slug":"HTTP-Load-Balancer","link":"/zh-tw/tags/HTTP-Load-Balancer/"},{"name":"AWS SQS","slug":"AWS-SQS","link":"/zh-tw/tags/AWS-SQS/"},{"name":"Laravel Queue","slug":"Laravel-Queue","link":"/zh-tw/tags/Laravel-Queue/"},{"name":"Linux","slug":"Linux","link":"/zh-tw/tags/Linux/"},{"name":"Stackdriver","slug":"Stackdriver","link":"/zh-tw/tags/Stackdriver/"},{"name":"Laravel blade","slug":"Laravel-blade","link":"/zh-tw/tags/Laravel-blade/"},{"name":"Laravel template","slug":"Laravel-template","link":"/zh-tw/tags/Laravel-template/"},{"name":"Laravel view","slug":"Laravel-view","link":"/zh-tw/tags/Laravel-view/"},{"name":"PayPal REST API","slug":"PayPal-REST-API","link":"/zh-tw/tags/PayPal-REST-API/"},{"name":"Hexo","slug":"Hexo","link":"/zh-tw/tags/Hexo/"},{"name":"minos","slug":"minos","link":"/zh-tw/tags/minos/"},{"name":"class","slug":"class","link":"/zh-tw/tags/class/"},{"name":"object","slug":"object","link":"/zh-tw/tags/object/"},{"name":"Node.js","slug":"Node-js","link":"/zh-tw/tags/Node-js/"},{"name":"Docker Image","slug":"Docker-Image","link":"/zh-tw/tags/Docker-Image/"},{"name":"Docker Container","slug":"Docker-Container","link":"/zh-tw/tags/Docker-Container/"},{"name":"Docker Swarm","slug":"Docker-Swarm","link":"/zh-tw/tags/Docker-Swarm/"},{"name":"Docker Multi Stage","slug":"Docker-Multi-Stage","link":"/zh-tw/tags/Docker-Multi-Stage/"},{"name":"Docker Compose","slug":"Docker-Compose","link":"/zh-tw/tags/Docker-Compose/"},{"name":"Docker Service","slug":"Docker-Service","link":"/zh-tw/tags/Docker-Service/"},{"name":"Docker Rolling Update","slug":"Docker-Rolling-Update","link":"/zh-tw/tags/Docker-Rolling-Update/"},{"name":"Docker Push","slug":"Docker-Push","link":"/zh-tw/tags/Docker-Push/"},{"name":"Docker Deployment","slug":"Docker-Deployment","link":"/zh-tw/tags/Docker-Deployment/"},{"name":"Laravel Image","slug":"Laravel-Image","link":"/zh-tw/tags/Laravel-Image/"},{"name":"Laravel package Intervention","slug":"Laravel-package-Intervention","link":"/zh-tw/tags/Laravel-package-Intervention/"},{"name":"gcloud shell","slug":"gcloud-shell","link":"/zh-tw/tags/gcloud-shell/"},{"name":"vsftpd","slug":"vsftpd","link":"/zh-tw/tags/vsftpd/"},{"name":"ftp","slug":"ftp","link":"/zh-tw/tags/ftp/"},{"name":"GCP persistent disk","slug":"GCP-persistent-disk","link":"/zh-tw/tags/GCP-persistent-disk/"},{"name":"GCP virtual machine","slug":"GCP-virtual-machine","link":"/zh-tw/tags/GCP-virtual-machine/"},{"name":"Facebook Graph API","slug":"Facebook-Graph-API","link":"/zh-tw/tags/Facebook-Graph-API/"},{"name":"git rebase -i","slug":"git-rebase-i","link":"/zh-tw/tags/git-rebase-i/"},{"name":"git rebase -i --onto","slug":"git-rebase-i-onto","link":"/zh-tw/tags/git-rebase-i-onto/"},{"name":"git reset --hard","slug":"git-reset-hard","link":"/zh-tw/tags/git-reset-hard/"},{"name":"git reset @^ --hard","slug":"git-reset-hard","link":"/zh-tw/tags/git-reset-hard/"},{"name":"git checkout -b","slug":"git-checkout-b","link":"/zh-tw/tags/git-checkout-b/"},{"name":"git flow","slug":"git-flow","link":"/zh-tw/tags/git-flow/"},{"name":"git init","slug":"git-init","link":"/zh-tw/tags/git-init/"},{"name":"git revert","slug":"git-revert","link":"/zh-tw/tags/git-revert/"},{"name":"git tag -a","slug":"git-tag-a","link":"/zh-tw/tags/git-tag-a/"},{"name":"git checkout","slug":"git-checkout","link":"/zh-tw/tags/git-checkout/"},{"name":"git log --oneline","slug":"git-log-oneline","link":"/zh-tw/tags/git-log-oneline/"},{"name":"Daemon","slug":"Daemon","link":"/zh-tw/tags/Daemon/"},{"name":"SSH","slug":"SSH","link":"/zh-tw/tags/SSH/"},{"name":"Gitlab pusher","slug":"Gitlab-pusher","link":"/zh-tw/tags/Gitlab-pusher/"},{"name":"garbles","slug":"garbles","link":"/zh-tw/tags/garbles/"},{"name":"AWS SES","slug":"AWS-SES","link":"/zh-tw/tags/AWS-SES/"},{"name":"Ngrok","slug":"Ngrok","link":"/zh-tw/tags/Ngrok/"},{"name":"Laravel Mail","slug":"Laravel-Mail","link":"/zh-tw/tags/Laravel-Mail/"},{"name":"git config","slug":"git-config","link":"/zh-tw/tags/git-config/"},{"name":"git config --global user.name","slug":"git-config-global-user-name","link":"/zh-tw/tags/git-config-global-user-name/"},{"name":"git config --global user.email","slug":"git-config-global-user-email","link":"/zh-tw/tags/git-config-global-user-email/"},{"name":"AWS","slug":"AWS","link":"/zh-tw/tags/AWS/"},{"name":"git add","slug":"git-add","link":"/zh-tw/tags/git-add/"},{"name":"git commit","slug":"git-commit","link":"/zh-tw/tags/git-commit/"},{"name":"git commit -a","slug":"git-commit-a","link":"/zh-tw/tags/git-commit-a/"},{"name":"Jenkins","slug":"Jenkins","link":"/zh-tw/tags/Jenkins/"},{"name":"CI/CD","slug":"CI-CD","link":"/zh-tw/tags/CI-CD/"},{"name":"Let's Encrypt","slug":"Let-s-Encrypt","link":"/zh-tw/tags/Let-s-Encrypt/"},{"name":"SSL","slug":"SSL","link":"/zh-tw/tags/SSL/"},{"name":"PayPal Payment Standard","slug":"PayPal-Payment-Standard","link":"/zh-tw/tags/PayPal-Payment-Standard/"},{"name":"PayPal IPN","slug":"PayPal-IPN","link":"/zh-tw/tags/PayPal-IPN/"},{"name":"CSV","slug":"CSV","link":"/zh-tw/tags/CSV/"},{"name":"pm2","slug":"pm2","link":"/zh-tw/tags/pm2/"},{"name":"GitLab CI / CD","slug":"GitLab-CI-CD","link":"/zh-tw/tags/GitLab-CI-CD/"},{"name":"Supervisor","slug":"Supervisor","link":"/zh-tw/tags/Supervisor/"},{"name":"MacOS","slug":"MacOS","link":"/zh-tw/tags/MacOS/"},{"name":"ssh-add","slug":"ssh-add","link":"/zh-tw/tags/ssh-add/"},{"name":"ssh-agent","slug":"ssh-agent","link":"/zh-tw/tags/ssh-agent/"},{"name":"Laravel Task Scheduling","slug":"Laravel-Task-Scheduling","link":"/zh-tw/tags/Laravel-Task-Scheduling/"},{"name":"Linux crontab","slug":"Linux-crontab","link":"/zh-tw/tags/Linux-crontab/"},{"name":"multiple items","slug":"multiple-items","link":"/zh-tw/tags/multiple-items/"},{"name":"variables","slug":"variables","link":"/zh-tw/tags/variables/"},{"name":"group by","slug":"group-by","link":"/zh-tw/tags/group-by/"},{"name":"git log","slug":"git-log","link":"/zh-tw/tags/git-log/"},{"name":"VIM","slug":"VIM","link":"/zh-tw/tags/VIM/"},{"name":"歐付寶","slug":"歐付寶","link":"/zh-tw/tags/歐付寶/"},{"name":"歐付寶 付款","slug":"歐付寶-付款","link":"/zh-tw/tags/歐付寶-付款/"},{"name":"歐付寶 退款","slug":"歐付寶-退款","link":"/zh-tw/tags/歐付寶-退款/"},{"name":"Facebook 長期權杖","slug":"Facebook-長期權杖","link":"/zh-tw/tags/Facebook-長期權杖/"},{"name":"Facebook 永不過期權杖","slug":"Facebook-永不過期權杖","link":"/zh-tw/tags/Facebook-永不過期權杖/"},{"name":"PayPal 退款","slug":"PayPal-退款","link":"/zh-tw/tags/PayPal-退款/"},{"name":"PayPal 授權","slug":"PayPal-授權","link":"/zh-tw/tags/PayPal-授權/"},{"name":"PayPal 請款","slug":"PayPal-請款","link":"/zh-tw/tags/PayPal-請款/"},{"name":"PayPal 取消授權","slug":"PayPal-取消授權","link":"/zh-tw/tags/PayPal-取消授權/"},{"name":"PayPal 建立授權訂單","slug":"PayPal-建立授權訂單","link":"/zh-tw/tags/PayPal-建立授權訂單/"},{"name":"PayPal 款項凍結","slug":"PayPal-款項凍結","link":"/zh-tw/tags/PayPal-款項凍結/"},{"name":"多語","slug":"多語","link":"/zh-tw/tags/多語/"},{"name":"多語系","slug":"多語系","link":"/zh-tw/tags/多語系/"},{"name":"雙語","slug":"雙語","link":"/zh-tw/tags/雙語/"},{"name":"部落格","slug":"部落格","link":"/zh-tw/tags/部落格/"}],"categories":[{"name":"Facebook","slug":"Facebook","link":"/zh-tw/categories/Facebook/"},{"name":"GCP","slug":"GCP","link":"/zh-tw/categories/GCP/"},{"name":"Laravel","slug":"Laravel","link":"/zh-tw/categories/Laravel/"},{"name":"Hexo","slug":"Hexo","link":"/zh-tw/categories/Hexo/"},{"name":"OOP","slug":"OOP","link":"/zh-tw/categories/OOP/"},{"name":"Node.js","slug":"Node-js","link":"/zh-tw/categories/Node-js/"},{"name":"Git","slug":"Git","link":"/zh-tw/categories/Git/"},{"name":"PHP","slug":"PHP","link":"/zh-tw/categories/PHP/"},{"name":"ssh","slug":"ssh","link":"/zh-tw/categories/ssh/"},{"name":"MySQL","slug":"MySQL","link":"/zh-tw/categories/MySQL/"},{"name":"VIM","slug":"VIM","link":"/zh-tw/categories/VIM/"},{"name":"部署","slug":"部署","link":"/zh-tw/categories/部署/"},{"name":"金流","slug":"金流","link":"/zh-tw/categories/金流/"}]}