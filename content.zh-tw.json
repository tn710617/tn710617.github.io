{"pages":[{"title":"About me","text":"我是一個後端工程師。 我對terminal的黑色視窗情有獨鍾，可能是因為在我看過的駭客電影中，厲害的駭客都是在小小的黑畫面中施展他們的妖術，印象中好像沒有看過施展妖術前還要開UI的駭客… 我曾是個職業軍人，天為被，地為枕，一個禮拜不洗澡，與弟兄們坐在野地上，相視一笑，仰望著深山沒有光害的星空，這是一種一輩子難忘但卻再也不想經歷的經驗。 我也曾是個國外業務，發現日本人對於SOP，以及猶太人對於數字，有著異常相似的執著！其實美國辦公室人員加班也是沒有加班費的啦！第一次接觸荷蘭人，還以為他們是巨人族的後裔。猶太人在戰場上，需要等敵人開槍才可以反擊，於是我說：”那如果敵人開槍你就掛了呢？”，猶太客戶回我說：”嗯，那就是你的命了”。 現在的我是個工程師，我很幸運，這輩子有幸跟coding邂逅。我喜歡任何形式的語言，當我想與人交流時，我說人類語言; 當我想獨處時，我說機器語言。機器語言的細膩與嚴謹深深的吸引我。日新月異的技術，在使我瞠目結舌之餘，不斷的充填我對知識永不枯竭的渴求。每天早晨，我不需要鬧鐘讓我起床，我的熱血喚醒我的身體，對新的一天的興奮感吹散我的睡意，因為今天的我，還可以思考，學習，並將我的邏輯，轉換成細緻而優美的機器語言。","link":"/zh-tw/about/index.html"},{"title":"categories","text":"","link":"/zh-tw/categories/index.html"},{"title":"Friends","text":"","link":"/zh-tw/friends/index.html"},{"title":"archives","text":"","link":"/zh-tw/archives/index.html"},{"title":"Schedule","text":"2019/9/24The target I set today Work: Figure out how to get data from Influxdb with Node.js Besides work: Linux English Japanese The result of today’s target Work: Figure out how to get data from Influxdb with Node.js Besides work: Linux English Japanese 2019/9/24The target I set today Task: Working on logParsing API Complete the Tool Linux English Japanese The result of today’s target Task: Working on logParsing API Complete the Tool Linux English Japanese 2019/9/23The target I set today Task: Working on logParsing API Renew a wildcard SSL certificate Linux English Japanese The result of today’s target Task: Working on logParsing API Renew a wildcard SSL certificate Linux English Japanese 2019/9/22The target I set today Task: Post an article Completed a documentation of Stackdriver Logging Linux English Japanese The result of today’s target Task: Post an article Completed a documentation of Stackdriver Logging Linux English Japanese 2019/9/21The target I set today Task: Linux English Japanese The result of today’s target Task: Linux English Japanese 2019/9/20The target I set today Task: Working on logParsing API Deploy to production machine Linux English Japanese The result of today’s target Task: Working on logParsing API Deploy to production machine Linux English Japanese 2019/9/19The target I set today Task: Working on logParsing API Linux English Japanese The result of today’s target Task: Working on logParsing API Linux English Japanese 2019/9/18The target I set today Task: Working on logParsing API Deploy first version of Flow API Linux English Japanese The result of today’s target Task: Working on logParsing API Deploy first version of Flow API Linux English Japanese 2019/9/17The target I set today Task: Working on logParsing API Linux English Japanese The result of today’s target Task: Working on logParsing API Linux English Japanese 2019/9/16The target I set today Task: Working on logParsing API Take a rest because you are having a cold. Linux English Japanese The result of today’s target Task: Working on logParsing API Take a rest because you are having a cold. Linux English Japanese 2019/9/15The target I set today Task: Working on logParsing API Take a rest because you are having a cold. Complete translated course so far Post an article Linux English Japanese The result of today’s target Task: Working on logParsing API Take a rest because you are having a cold. Complete translated course so far Post an article Linux English Japanese 2019/9/14The target I set today Task: Working on logParsing API Take a rest because you are having a cold. Post one article Linux English Japanese The result of today’s target Task: Working on logParsing API Take a rest because you are having a cold. Post one article Linux English Japanese 2019/9/13The target I set today Task: Working on logParsing API Take a rest because you are having a cold. Post one article Finish one Qwiklab course Make a Qwiklab lesson documentation Linux English Japanese The result of today’s target Task: Working on logParsing API Take a rest because you are having a cold. Post one article Finish one Qwiklab course Make a Qwiklab lesson documentation Linux English Japanese 2019/9/12The target I set today Task: Working on logParsing API Linux English Japanese The result of today’s target Task: Working on logParsing API Working on SSH issue Linux English Japanese 2019/9/11The target I set today Task: Working on logParsing API Linux English Japanese The result of today’s target Task: Working on logParsing API Linux English Japanese 2019/9/11the result of my target yesterday Task: Working on logParsing API Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on logParsing API Linux English Japanese 2019/9/10the result of my target yesterday Task: Working on logParsing API Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on logParsing API Linux English Japanese 2019/9/9the result of my target yesterday Task: Finish one course of GCP Post an article Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on logParsing API Linux English Japanese 2019/9/8the result of my target yesterday Task: Finish one course of GCP Post an article Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Finish one course of GCP Post an article Linux English Japanese 2019/9/7the result of my target yesterday Task: Working on logParsing Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Finish one course of GCP Post an article Linux English Japanese 2019/9/6the result of my target yesterday Task: Working on logParsing Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on logParsing Linux English Japanese 2019/9/5the result of my target yesterday Task: Working on logParsing Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on logParsing Linux English Japanese 2019/9/4the result of my target yesterday Task: Working on logParsing Still working on it Stackdriver Logging - Logging with Stackdriver on Kubernetes Engine No time for it Learn Node course 3 No time for it One interesting thing Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on logParsing Linux English Japanese 2019/9/3the result of my target yesterday Task: Working on logParsing Still working on it Stackdriver Logging - Logging with Stackdriver on Kubernetes Engine No time for it Learn Node course 3 No time for it One interesting thing No time for it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on logParsing Stackdriver Logging - Logging with Stackdriver on Kubernetes Engine Learn Node course 3 One interesting thing Linux English Japanese 2019/9/2the result of my target yesterday Task: Stackdriver Logging - Logging with Stackdriver on Kubernetes Engine Completed document Documentation building - Baseline: Infrastructure - Cloud IAM: Qwik Start Learn Node course 3 One interesting thing Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on logParsing Stackdriver Logging - Logging with Stackdriver on Kubernetes Engine Learn Node course 3 One interesting thing Linux English Japanese 2019/9/1the result of my target yesterday Task: Working on Stackdriver Logging - Using BigQuery and Stackdriver to Analyze BigQuery Usage Documentation building - Baseline: Infrastructure - Cloud IAM: Qwik Start Still working Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Stackdriver Logging - Logging with Stackdriver on Kubernetes Engine Documentation building - Baseline: Infrastructure - Cloud IAM: Qwik Start Learn Node course 3 One interesting thing Linux English Japanese History","link":"/zh-tw/schedule/index.html"},{"title":"tags","text":"","link":"/zh-tw/tags/index.html"},{"title":"History","text":"2019AugustJulyJuneMayAprilMarchFebruaryJanuary 2018DecemberNovember","link":"/zh-tw/schedule/History/index.html"},{"title":"November 2018","text":"2018/11/30The result of my target yesterday ‘The Wondering’ sharing was perfectily done. having learnt the purpose of $remote_addr and $proxy_add_x_forwarded_forAchieved except for set target yesterdayDescription Today’s target go deeper into apache and nginx config git linux 2018/11/29The result of my target yesterday having learnt how to use apache with php-fpmAchieved except for set target yesterday having completed backend challenge of second roundDescription Today’s target go deeper into apache and nginx config share git in ‘The Wondering’ 2018/11/28The result of my target yesterday backend challenge was completedAchieved except for set target yesterday DescriptionToday’s target go deeper into apache config 2018/11/27The result of my target yesterdayAchieved except for set target yesterdayDescriptionToday’s target aws ec2, eip, security group server default environment apache, nginx installation and config","link":"/zh-tw/schedule/2018/November/index.html"},{"title":"December 2018","text":"2018/12/31The result of my target yesterday [ ] linux: 鳥哥的linux基礎篇 i read some book not related to coding yesterday. i was guilty! [ ] git: pro git i read some book not related to coding yesterday. i was guilty! [x] challenge20181217 rewriting paymentdetail function getachievedachievement function getpossessions function profile function DescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git challenge20181217 rewriting deposit achievement 2018/12/30The result of my target yesterday [ ] linux: 鳥哥的linux基礎篇 i read some book not related to coding yesterday. i was guilty! [ ] git: pro git i read some book not related to coding yesterday. i was guilty! [x] challenge20181217 rewriting shop system function rewriting DescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git challenge20181217 rewriting getachievedachievement getachievedachievement function getpossessions function profile function 2018/12/29The result of my target yesterday [x] linux: 鳥哥的linux基礎篇 head -n number filename tail -f filename cat -n filename | tail -n [x] git: pro git how to revert a merged commit and undo all the changes introduced by the branch being merged?git revert -m 1 commitid if i reverted a merged commit and chose the parent, what if i want to merge it again?revert the reverted commit when merging, how to skip mamually resolving and just choose the side we choose? git merge branchname -xours or git merge branchname -xtheirs challenge20181217 rewriting shop system function rewriting went to a movie theater. DescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git challenge20181217 rewriting shop system function rewriting 2018/12/28The result of my target yesterday [x] linux: 鳥哥的linux基礎篇 nl -ba filename nl -bt filename nl -w filename nl -nln filename nl -nrn filename nl -nrz filename [x] git: pro git git merge -xignore-all-space git merge -xignore-space-change git log --oneline --left-right --merge -p (option) challenge20181217 rewriting readability of achievement function shop system function rewriting to be completed today DescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git challenge20181217 rewriting shop system function rewriting 2018/12/27The result of my target yesterday linux: 鳥哥的linux基礎篇 cat -a cat -b cat -e cat -n cat -t cat -v [x] git: pro git git filter-branch --subdirectory-filter directoryname head git filter-branch --commit-filter &apos; if [ &quot;$git_author_email&quot; = &quot;currentemail&quot; ] ; then git_author_name=&quot;newauthornameyouwanttobe&quot;; git_author_email=&quot;newemailyouwanttobe&quot;; git commit-tree &quot;$@&quot;; else git commit-tree &quot;$@&quot;; fi&apos; head rewrite challenge20181217 achievement function achievement function was completed, but need to improvie its readability Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git challenge20181217 rewriting readability of achievement function shop system function rewriting2018/12/26 The result of my target yesterday linux: 鳥哥的linux基礎篇 went to ktv instead git: pro git went to ktv instead rewrite challenge20181217 getachievementlist &amp; getitemlist api was completed Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git i think i need to focus on my challenge code rework until i finish it 2018/12/25The result of my target yesterday linux: 鳥哥的linux基礎篇辦事項 git: pro git git commit –amend –no-edit git commit filter-branch –tree-filter –all ‘rm -f file’ head laracast: the_php_practitioner recap 23 rameke my git presentation from keynote to hackmd (2/5) rewrite challenge20181217 redesign tables Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git i think i need to focus on my challenge code rework until i finish it 2018/12/24The result of my target yesterday linux: 鳥哥的linux基礎篇辦事項 git: pro git - git grep filename -n &amp; git grep filename -n laracast: the_php_practitioner recap 23 rameke my git presentation from keynote to hackmd (1/5) Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git laracast: the_php_practitioner recap 23 rameke my git presentation from keynote to hackmd (2/5) 2018/12/23The result of my target yesterday figure out how to use moment of js to covert the timezone from utc to where you are - not completed yet wondering presentation - completed Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git laracast: the_php_practitioner recap 23 rameke my git presentation from keynote to hackmd (1/5) 2018/12/22The result of my target yesterday challenge 20181221 passed figure out how to use moment of js to covert the timezone from utc to where you are - not completed yet Achieved except for set target yesterdayDescriptionToday’s target wondering presentation 2018/12/21The result of my target yesterday challenge 20181220 passed Achieved except for set target yesterdayDescriptionToday’s target don’t special game challenge 20181221 2018/12/20The result of my target yesterday challenge 20181219 passed Achieved except for set target yesterdayDescriptionToday’s target challenge 20181220 2018/12/19The result of my target yesterday challenge 20181218 passed Achieved except for set target yesterdayDescriptionToday’s target challenge 20181219 2018/12/18The result of my target yesterday challenge 20181217 passed Achieved except for set target yesterdayDescriptionToday’s target challenge 20181218 2018/12/17The result of my target yesterdaylaravel warming up laravel warm up Achieved except for set target yesterdayDescriptionToday’s target challenge 20181217 2018/12/16The result of my target yesterdaylaracast focus on laravel warming up first laravel warming up laravel_5.7_from_scratch series (9~12/36) linux: focus on laravel warming up first git git add -i revert git add -p git reset -p git stash apply –index git stash –keep-index git add -i update Achieved except for set target yesterdayDescriptionToday’s target laravel- warming up for challenge next week 2018/12/15The result of my target yesterdaylaracast recap the php practitioner series (22/25) laravel warming up laravel_5.7_from_scratch series (4~8/36) linux: what’s cp -s? waht’s cp -r? waht’s cp -u? waht’s cp –preserve=all? if there are two sources when placing cp command, what the destination should be? waht’s cp –preserve=all? git git log origin/master..head git log master..test git log ^master test git log test –not master git log test develop ^master git log test develop –not master Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git laracast: the_php_practitioner recap 23 laravel- warming up for challenge next week 2018/12/14The result of my target yesterdaylaracast recap the php practitioner series (21/25) laravel warming up laravel_5.7_from_scratch series (1~3/36) linux: what’s cp -a? what’s cp -d? what’s cp -f? what’s cp -i? what’s cp -l? what’s cp -p? git git rebase -i ‘wondering’ presentation perfectly done Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git laracast: the_php_practitioner recap 22 laravel- warming up for challenge next week 2018/12/13The result of my target yesterdaylaracast the php practitioner series (19~20/25) linux: what’s in /var/spool folder of linux? what’s ls -a? what’s ls -f? what’s ls -h? what’s ls -i? what’s ls -n? what’s ls -r? what’s ls -r? what’s ls -s? what’s ls -t? what’s ls –full-time? challenge 20181212 passed git git rebase -i Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git laracast: the_php_practitioner recap 21 ‘wondering’ presentation laravel- warming up for challenge next week 2018/12/12The result of my target yesterdaylaracast no time for it. linux: what’s in /var/spool folder of linux? what’s nfs in full name? what’s lsb in full name? how to show true path rather than link path when using pwd? how to create folders through multipal layers? how to give authority when creating a folder? how to show $path? how to add a folder into $path? what’s ls -a? challenge 20181211 passed adaptor make every single book an object how to pass outside variable into closure git github notification flicked through github api and github hooks Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git laracast: the_php_practitioner recap 18~? challenge 20181212 ‘wondering?’ rehersal 2018/12/11The result of my target yesterdaylaracast have completed recapping of 15~17 linux: what’s in /include folder of linux? what’s in /libexec folder of linux? what’s in /usr/src folder of linux? what’s in /var folder of linux? what’s in /var/cache folder of linux? what’s in /var/lib folder of linux? what’s in /var/lock folder of linux? what’s in /var/log folder of linux? what’s in /var/mail folder of linux? what’s in /usr folder of linux? what’s in /usr/bin folder of linux? challenge 20181210 passed git how to fetch all pull-requests without adding them as remotesfetch = +refs/pull//head:refs/remotes/origin/pr/ Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git laracast: the_php_practitioner recap 18~? challenge 20181211 2018/12/10The result of my target yesterdaylaracast the_php_practitioner series (25/25) was completed. have recapped the_php_practitioner 1~15. linux: what’s in /usr folder of linux? what’s in /usr/bin folder of linux? what’s in /usr/lib folder of linux? what’s in /usr/local folder of linux? what’s in /usr/sbin folder of linux? what’s in /usr/share folder of linux? what’s in /usr/games folder of linux? what’s in /home folder of linux? what’s in /lib qual folder of linux? what’s in /root qual folder of linux? what’s in /proc qual folder of linux? what’s in /sys folder of linux? git if you see something like pull request does not merge cleanly in github, what should you do?① add the original repository as a remote named “upstream”② fetch the newest work from that remote③ merge the main branch of that repository into your topic branch④ fix the conflict that occurred⑤ push back up to the same topic branch how could we reference issue or pull-request on github?## how to use task list on github? write the code write all the tests document the code Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git laracast: the_php_practitioner recap challenge 20181210 2018/12/9The result of my target yesterdaylaracast having completed episode 24, and will recap it again and push it to github linux: what’s in /home folder of linux? what’s in /lib qual folder of linux? what’s in /root folder of linux? what’s in /lost+found folder of linux? what’s in /proc folder of linux? what’s in /sys folder of linux? git what are the steps to create a pull-request on github?① clone our fork of the project locally② create a descriptive topic branch③ make our change to the code④ check that the change is good⑤ commit our change to the topic branch⑥ push our new topic branch back up to our github fork how to condense a whole feature branch into a single commit and push it to master branch as production branch. Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git laracast: the_php_practitioner (24/25) recap and (25/25) 2018/12/8The result of my target yesterdaylaracast having completed episode 23 and pushed it to github linux: what’s in /media folder of linux? what’s in /mnt folder of linux? what’s in /opt folder of linux? what’s in /run folder of linux? what’s in /sbin folder of linux? what’s in /srv folder of linux? what’s in /tmp folder of linux? The Wondering having completed presentation for ‘wondering’ next week. git i didn’t have time for it yesterday. Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git laracast: the_php_practitioner (24/25) 2018/12/7The result of my target yesterdaylaracast yesterday i didn’t watch it at all, my goodness. i must finish it today and move on! linux: what’s in /bin folder of linux? what’s in /boot folder of linux? what’s in /dev folder of linux? what’s in /etc folder of linux? what’s in /lib folder of linux? The Wondering both rehersal and presentation were perfectly done. Achieved except for set target yesterday sharing what i learnt from the deployment event at tuesday night with the whole backend team. DescriptionToday’s target presentation for The Wondering next week, or perhaps the week after that. linux: 鳥哥的linux基礎篇 git: pro git laracast: the php practitioner(23/25) recap, and push every step of it on github 2018/12/6The result of my target yesterdaylaracast finally, i finished episode (23/25) yesterday. i will try to recap it again and push each step on github linux: when installing package, why it shows 403 forbidden? the limit of length of the name of files and repositories in linux. fhs - filesystem hierarchy standard the purpose of fhs four types of repositories in linux explanation of four types of repositories - shareable, unshareable, static, variable three defaultly defined repositries by fhs The Wondering i have finished rehersal one time, and am going to do that again before presentation.Achieved except for set target yesterdayDescriptionToday’s target The Wondering rehersal before presentation linux: 鳥哥的linux基礎篇 laracast: the php practitioner(23/25) recap, and push every step of it on github 2018/12/5The result of my target yesterdaylaracast still stuck on the_php_practitioner episode 23. maybe bacause i stayed up late the night before last night with whole backend working server deployment, yesterday i was too groggy to figure it out. i have to finish it today!git: gpg security keys for git tag signituressl: having completed ssl hand-on experiment. linux: recap authority command with jett and soj. i was supposed to read linux book last night, however, i passed out as soon as i took a shower. Achieved except for set target yesterdayDescriptionToday’s target laracast: the php practitioner(23/25) The Wondering rehersal linux: 鳥哥的linux基礎篇 2018/12/4The result of my target yesterdaylaracast the php practitioner (23/25). i was scheduled to finish episode 23 yesterday. however, the whole backend team and i were working on server configuration and deployment all day long, and i will manage to finish it today. git: as above mentioned, i counldn’t manage any time for git yesterday. linux: what’s link file what’s data file what’s device file what are block and character of device file what’s socket file what’s fifo file Achieved except for set target yesterday ssl signature frontend and backend deployment on server with apache.DescriptionToday’s target laracast: the php practitioner(23/25) git: pro git linux: 鳥哥的linux基礎篇 ssl signature hand-on experiment.2018/12/3 The result of my target yesterdaylaracast the php practitioner (23/25), i’ve recapped the logic, and ready to go further. git: hand-on experiment on rerere function linux: chmod ugoa, +-=, rwx rules of authority for files and repositories regular file: ascii, data, binary how to read data file - last how to read ascii file - cat The Wondering completed Achieved except for set target yesterdayDescriptionToday’s target laracast: the php practitioner(23/25) git: pro git linux: 鳥哥的linux基礎篇2018/12/2 The result of my target yesterdaylaracast the php practitioner (23/25): i spent a lot of time recaping what i’d leart before backend challenge. i think i will need more time to retrive the logic before getting later episode. git: merging work flow large-merging workflow git config –global rerere.enabled true linux: chgrp [-r] groupname filename chown [-r] user:group filenameorrepositoryname chmod [-r] xyz filenameorrepositoryname docker: create a dockerfile build a dockerfile run a dockerfile push a dockerfile rough concept of docker Achieved except for set target yesterdayDescriptionToday’s target laracast: the php practitioner series git linux presentation of The Wondering for next week. 2018/12/1The result of my target yesterdayapache and nginx: having learnt how to use either apache or nginx as reverse proxy and proxy_pass to webserver with whatever headers that are required. git: create a branch based off another branch - git branch thebranchyouwant thebranchyouwouldliketobebasedoff will git reflog be pushed? - no can i pull from repositories that haven’t been added as remote? - yes how to pull from repositories that haven’t been saved as remote - git pull theurl, append –allow-unrelated-histories if not related. it shows only the work your current topic branch has introduced since its common ancestor with master - git diff master…meatlinux: drwxrwxrwx, what does d mean? -rwxrwxrwx, what does - mean? lrwxrwxrwx, what does l mean? brwxrwxrwx, what does b mean? crwxrwxrwx, what does c mean?DescriptionToday’s target laracast: the php practitioner series attending docker speech held on good idea studio git linux","link":"/zh-tw/schedule/2018/December/index.html"},{"title":"August 2019","text":"2019/8/31the result of my target yesterday Task: Working on logParsing and inserting project Still working on it Working on Stackdriver course 2 Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on Stackdriver Logging - Using BigQuery and Stackdriver to Analyze BigQuery Usage Documentation building - Baseline: Infrastructure - Cloud IAM: Qwik Start Linux English Japanese 2019/8/30the result of my target yesterday Task: Working on logParsing and inserting project Still working on it Working on Stackdriver course 2 Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on logParsing and inserting project Working on Stackdriver course 2 Linux English Japanese 2019/8/29the result of my target yesterday Task: Finish Netdata Finish Stackdriver course 1 Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on logParsing and inserting project Working on Stackdriver course 2 Linux English Japanese 2019/8/28the result of my target yesterday Task: Finish Netdata Still working on it Finish Stackdriver course 1 Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Finish Netdata Finish Stackdriver course 1 Linux English Japanese 2019/8/27the result of my target yesterday Task: Finish Netdata Still working on it Finish Stackdriver course 1 Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Finish Netdata Finish Stackdriver course 1 Linux English Japanese 2019/8/26the result of my target yesterday Task: Start a new Quest on QwikLab Finish Cloud FUnction document Not yet, do Stackdriver first. Finish Node course episode 2 Not yet, haven’t finished Stackdriver Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Finish Netdata Finish Stackdriver course 1 Linux English Japanese 2019/8/25the result of my target yesterday Task: Finish QwikLab Baseline: Infrastructure Finish The Wondering presentation next week Post at least an article of QwikLab Improve my resume Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Start a new Quest on QwikLab Finish Cloud FUnction document Finish Node course episode 2 Linux English Japanese 2019/8/24the result of my target yesterday Task: Working on Netdata and MongoDB Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Finish QwikLab Baseline: Infrastructure Finish The Wondering presentation next week Post at least an article of QwikLab Improve my resume Linux English Japanese 2019/8/23the result of my target yesterday Task: Working on customer-dashboard Was assigned to do another work Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on Netdata and MongoDB Linux English Japanese 2019/8/22the result of my target yesterday Task: Working on customer-dashboard Still working on it Finish GCP Cloud IAM: Qwik Start Still no time for it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on customer-dashboard Linux English Japanese 2019/8/21the result of my target yesterday Task: Working on customer-dashboard Still working on it Finish GCP Cloud IAM: Qwik Start Still no time for it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on customer-dashboard Finish GCP Cloud IAM: Qwik Start Linux English Japanese 2019/8/20the result of my target yesterday Task: Working on customer-dashboard Still working on it Finish GCP Cloud IAM: Qwik Start No time for it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on customer-dashboard Finish GCP Cloud IAM: Qwik Start Linux English Japanese 2019/8/19the result of my target yesterday Task: Post GCP Cloud Storage Qwiklab start: SDK/CLI Finish GCP Cloud IAM: Qwik Start Still haven’t finished yet Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on customer-dashboard Finish GCP Cloud IAM: Qwik Start Linux English Japanese 2019/8/18the result of my target yesterday Task: Post GCP Storage Qwiklab start: Console Finish GCP Storage Qwiklab start: SDK/CLI Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Post GCP Cloud Storage Qwiklab start: SDK/CLI Finish GCP Cloud IAM: Qwik Start Linux English Japanese 2019/8/17the result of my target yesterday Task: Release checkEdgeAlive asynchronous beta version Release checkEdgeAlive process-block-proof shell script Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Post GCP Storage Qwiklab start: Console Finish GCP Storage Qwiklab start: SDK/CLI Linux English Japanese 2019/8/16the result of my target yesterday Task: Build new site with SSL certificate Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Release checkEdgeAlive asynchronous beta version Release checkEdgeAlive process-block-proof shell script Linux English Japanese 2019/8/15the result of my target yesterday Task: Optimise checkEdgeAlive to reduce the Datastore read time Add a time response on DNS Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Build new site with SSL certificate Linux English Japanese 2019/8/14the result of my target yesterday Task: GCP QwikLab - Baseline: Infrastructure Optimise checkEdgeAlive to reduce the Datastore read time Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Optimise checkEdgeAlive to reduce the Datastore read time Add a time response on DNS Linux English Japanese 2019/8/13the result of my target yesterday Task: GCP QwikLab - Baseline: Infrastructure Still working on it Optimise checkEdgeAlive to reduce the Datastore read time Initially completed the cost part, and going to remove unnecessary code Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: GCP QwikLab - Baseline: Infrastructure Optimise checkEdgeAlive to reduce the Datastore read time Linux English Japanese 2019/8/12the result of my target yesterday Task: GCP QwikLab - Baseline: Infrastructure Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: GCP QwikLab - Baseline: Infrastructure Optimise checkEdgeAlive to reduce the Datastore read time Linux English Japanese 2019/8/11the result of my target yesterday Task: GCP QwikLab - Baseline: Infrastructure Not yet QQ Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: GCP QwikLab - Baseline: Infrastructure Linux English Japanese 2019/8/10the result of my target yesterday Task: Refactor checkEdgeAlive Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: GCP QwikLab - Baseline: Infrastructure Linux English Japanese 2019/8/9the result of my target yesterday Task: Figure out how logParser works Suspended temporarily Completed logrotate documentation Suspended temporarily Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Refactor checkEdgeAlive Linux English Japanese 2019/8/8the result of my target yesterday Task: Figure out how deploy works Will focus on logParser first Completed logrotate documentation No time for it yet Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Figure out how logParser works Completed logrotate documentation Linux English Japanese 2019/8/7the result of my target yesterday Task: Figure out what lerna is Completed Figure out what yarn workspace is Completed Completed logrotate documentation No time for it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Figure out how deploy works Completed logrotate documentation Linux English Japanese 2019/8/6the result of my target yesterday Task: Figure out what lerna is Still working on it Figure out what yarn workspace is Still working on it Completed logrotate documentation Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Figure out what lerna is Figure out what yarn workspace is Completed logrotate documentation Linux English Japanese 2019/8/5the result of my target yesterday Task: Figure out what lerna is Still working on it Figure out what yarn workspace is Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Figure out what lerna is Figure out what yarn workspace is Completed logrotate documentation Linux English Japanese 2019/8/4the result of my target yesterday Task: Organise GCP Load Balancer Finally completed it Figure out what lerna is Still working on it Figure out what yarn workspace is Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Figure out what lerna is Figure out what yarn workspace is Linux English Japanese 2019/8/3the result of my target yesterday Task: Organise GCP Load Balancer Still working on it Figure out what lerna is Still working on it Figure out what yarn workspace is Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Organise GCP Load Balancer Figure out what lerna is Figure out what yarn workspace is Linux English Japanese 2019/8/2the result of my target yesterday Task: Organise GCP Load Balancer Still working on it Figure out how to use logRotate Completed Figure out what lerna is Still working on it Figure out what yarn workspace is Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Organise GCP Load Balancer Figure out what lerna is Figure out what yarn workspace is Linux English Japanese 2019/8/1the result of my target yesterday Task: Organise GCP Load Balancer Still working on it Figure out how to use logRotate Teh result is to be seen Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Organise GCP Load Balancer Figure out how to use logRotate Figure out what lerna is Figure out what yarn workspace is Linux English Japanese","link":"/zh-tw/schedule/2019/August/index.html"},{"title":"February 2018","text":"2019/2/28The result of my target yesterday Write down how to use PayPal payment service One more section of my Git Course Optimize FB online selling project Make recipient information only required when a order is paid Achieved except for set target yesterday Solve the problem that the canvas-nest special effect doesn’t work properly on Schedule page DescriptionToday’s target Write down how to use PayPal payment service One more section of my Git Course Optimize FB online selling project Restructure WebSocket 2019/2/27The result of my target yesterday One more section of my Git course Write down an article - how to build a multilingual blog with Hexo Optimize FB online selling project Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service One more section of my Git Course Optimize FB online selling project Make recipient information only required when a order is paid 2019/2/26The result of my target yesterday My blog - improve the layout Achieved except for set target yesterdayDescriptionToday’s target One more section of my Git course Write down an article - how to build a multilingual blog with Hexo Optimize FB online selling project 2019/2/25The result of my target yesterday Working on the blog, I would like to make a bilingual version Achieved except for set target yesterdayDescriptionToday’s target My blog - improve the layout 2019/2/24The result of my target yesterday Fix the decoded garble problem of my blog Completed a bit, but still working on it Achieved except for set target yesterdayDescriptionToday’s target Working on the blog, I would like to make a bilingual version 2019/2/23The result of my target yesterday Challenge: Facebook optimized selling system - keep optimizing Git course: The presentation Finished first course Write down how to make PayPal payment service work Working on my blog instead Achieved except for set target yesterdayDescriptionToday’s target Fix the decoded garble problem of my blog 2019/2/22The result of my target yesterday Challenge: Facebook optimized selling system Optimize and debug Demo Achieved except for set target yesterdayDescriptionToday’s target Challenge: Facebook optimized selling system - keep optimizing Git course: The presentation Write down how to make PayPal payment service work 2019/2/21The result of my target yesterday Challenge: Facebook optimized selling system - Optimize and debug Optimize images upload function with Laravel way Reorganise and write down how to make PayPal payment service works Achieved except for set target yesterday Challenge: Facebook optimized selling system Added new function that when an order is paid, the buyer will receive a notification email DescriptionToday’s target Challenge: Facebook optimized selling system optimize and debug demo 2019/2/20The result of my target yesterday challenge: facebook optimized selling system - optimize and debug added email update function in update-user-info function Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system - optimize and debug optimize images upload function with laravel way reorganise and write down how to make paypal payment service works 2019/2/19The result of my target yesterday challenge: facebook optimized selling system - paypal payment service finally app site is able to use it Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system - optimize and debug 2019/2/18 gcp quiklab training course stackdriver: qwik start set up network and http load balancers The result of my target yesterdayAchieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system - paypal payment service 2019/2/17The result of my target yesterday gcp quiklab training course completed lessons 6 Achieved except for set target yesterdayDescriptionToday’s target gcp quiklab training course 2019/2/16The result of my target yesterday gcp quiklab training course completed lessons 1~5 Achieved except for set target yesterdayDescriptionToday’s target gcp quiklab training course 2019/2/15 challenge: facebook optimized selling system - paypal payment service completed paypal payment service function The result of my target yesterdayAchieved except for set target yesterdayDescriptionToday’s target gcp quiklab training course 2019/2/14 challenge: facebook optimized selling system - paypal payment service still working on it The result of my target yesterdayAchieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system - paypal payment service 2019/2/13 challenge: facebook optimized selling system - paypal payment service still working on it The result of my target yesterdayAchieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system - paypal payment service 2019/2/12 challenge: facebook optimized selling system paypal payment service The result of my target yesterdayAchieved except for set target yesterday api revise create new api- get user status DescriptionToday’s target challenge: facebook optimized selling system - paypal payment service 2019/2/11 challenge: facebook optimized selling system write an article about how to get user’s basic information via token got from fb paypal payment service still working on it. The result of my target yesterdayAchieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system paypal payment service 2019/2/10 challenge: facebook optimized selling system write an article about how to get user’s basic information via token got from fb paypal payment service still working on it The result of my target yesterdayAchieved except for set target yesterday challenge: facebook optimized selling system debug optimize DescriptionToday’s target challenge: facebook optimized selling system write an article about how to get user’s basic information via token got from fb paypal payment service 2019/2/9 challenge: facebook optimized selling system write an article about how to handle allpay payment service paypal payment service still working on it git pro 鳥哥的linux The result of my target yesterdayAchieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system write an article about how to get user’s basic information via token got from fb paypal payment service 2019/2/8The result of my target yesterday challenge: facebook optimized selling system write down how to use task scheduling of laravel with crontab to routinely delete expired orders the presentation of hackmd for ‘the wondering’ on 14 february 2019 paypal payment service git pro git object 鳥哥的linux Achieved except for set target yesterday adopted task scheduling of laravel with crontab to routinely delete expired orders DescriptionToday’s target challenge: facebook optimized selling system write an article about how to handle allpay payment service paypal payment service git pro 鳥哥的linux 2019/2/7The result of my target yesterday challenge: facebook optimized selling system write down how to use aws ses find out why ngrok doesn’t work with aws ses it’s caused by the port. Achieved except for set target yesterday adopted task scheduling of laravel with crontab to routinely delete expired orders DescriptionToday’s target challenge: facebook optimized selling system write down how to use task scheduling of laravel with crontab to routinely delete expired orders the presentation of hackmd for ‘the wondering’ on 14 february 2019 paypal payment service git pro 鳥哥的linux 2019/2/6The result of my target yesterday challenge: facebook optimized selling system mail notification system via ses and laravel Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system write down how to use aws ses find out why ngrok doesn’t work with aws ses 2019/2/5The result of my target yesterday challenge: facebook optimized selling system optimize order system for allpay payment service Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system mail notification system via ses and laravel 2019/2/4The result of my target yesterday challenge: facebook optimized selling system third party payment service, allpay Achieved except for set target yesterday git pro: git hash-object -w stdin git cat-file -p checksum DescriptionToday’s target challenge: facebook optimized selling system optimize order system for allpay payment service 2019/2/3The result of my target yesterday challenge: facebook optimized selling system still working on third party payment service, allpay git pro no time for it = = 鳥哥的linux no time for it = = Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system third party payment service, allpay 2019/2/2The result of my target yesterday challenge: facebook optimized selling system still working on it git pro no time for it 鳥哥的linux no time for it Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system third party payment service git pro 鳥哥的linux 2019/2/1The result of my target yesterday [ ] challenge: facebook optimized selling system ‘the wondering presentation’ instead [x] git pro step into plumbing’s world 鳥哥的linux no time for it Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system third party payment service git pro 鳥哥的linux","link":"/zh-tw/schedule/2019/February/index.html"},{"title":"January 2019","text":"2019/1/31The result of my target yesterday challenge: facebook optimized selling system revised api instead git pro prepared ‘the wondering’ rehearsal 鳥哥的linux prepared ‘the wondering’ rehearsal Achieved except for set target yesterday block chain knowledgeDescriptionToday’s target challenge: facebook optimized selling system third party payment service git pro 鳥哥的linux 2019/1/30The result of my target yesterday challenge: facebook optimized selling system completed api (26/26) git course outline provided to howard Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system third party payment service git pro 鳥哥的linux2019/1/29 The result of my target yesterday challenge: facebook optimized selling system commpleted api (23/25) git pro prepared git course outline instead 鳥哥的linux prepared git course outline instead Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system git course outline 2019/1/28The result of my target yesterday challenge: facebook optimized selling system commpleted api (22/25) introduction of my blog Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system git pro 鳥哥的linux2019/1/27 The result of my target yesterday ‘the wondering’ presentation next week challenge: facebook optimized selling system completed 3 api Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system introduction of my blog 2019/1/26The result of my target yesterday challenge: facebook optimized selling system working on my blog and linkedin instead. Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system ‘the wondering’ presentation next week 2019/1/25The result of my target yesterday challenge: facebook optimized selling system working on ci with jenkins instead Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system 2019/1/24The result of my target yesterday challenge: facebook optimized selling system completed three apis Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system 2019/1/23The result of my target yesterday challenge: facebook optimized selling system completed three apis Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system 2019/1/22The result of my target yesterday challenge: facebook optimized selling system completed three apis Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system 2019/1/21The result of my target yesterday challenge: facebook optimized selling system completed six apis Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system 2019/1/20The result of my target yesterday challenge: facebook optimized selling system completed three api Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system 2019/1/19The result of my target yesterday challenge: facebook optimized selling system initially completed api document Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system 2019/1/18The result of my target yesterday challenge: facebook optimized selling system intially confirmed the specification Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system2019/1/17 The result of my target yesterday challenge: facebook optimized selling system initially discussed the feature Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system 2019/1/16The result of my target yesterdayAchieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system 2019/1/15The result of my target yesterday linux: 鳥哥的linux基礎篇 git: pro git build my own blog in github with hexo almost complete personal configuration Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system 2019/1/14The result of my target yesterday [x] linux: 鳥哥的linux基礎篇 suid full name suid’s function and limit [x] git: pro git how to configure your git to save your credentials? what are three level of git configurations? where is the configuration file that git looks for when it comes to system level configuration? where is the configuration file that git looks for when it comes to global level configuration? how to ignore files globaly in git? [x] build my own blog in github with hexo i’m still working on it, still some issues to be solved. Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git build my own blog in github with hexo 2019/1/13The result of my target yesterday iron man award ceremony Achieved except for set target yesterday completed presentation for ‘the wondering’ on 17 january 2019DescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git reorganize those presentations i’ve made from keynote to hackmd the first commit 沒遇到這些事之前，我也覺得我git超屌 episode 1 沒遇到這些事之前，我也覺得我git超屌 episode 2 沒遇到這些事之前，我也覺得我git超屌 episode 3 沒遇到這些事之前，我也覺得我git超屌 episode 4 2019/1/12The result of my target yesterday challenge20181217 rewriting optimize readme the wondering organize git presentation that i’ve shared in ‘the wondering’ presentation for ‘the wondering’ next week 鳥哥的Linux基礎篇 git: pro git Achieved except for set target yesterday build opendata project on aws and so my team members could use it for their interviews in the future.DescriptionToday’s target iron man award ceremony 2018/1/11The result of my target yesterday challenge20181217 rewriting add status code to all the functions revise api document accordingly to restful api. Achieved except for set target yesterday git: if you create a new branch, add a submodule there, and then switch back to a branch without that submodule, what will happen?DescriptionToday’s target challenge20181217 rewriting optimize readme the wondering organize git presentation that i’ve shared in ‘the wondering’ presentation for ‘the wondering’ next week linux: 鳥哥的linux基礎篇 git: pro git 2019/1/10The result of my target yesterday linux: 鳥哥的linux基礎篇 working on swagger api [ ] git: pro git working on swagger api [x] challenge20181217 rewriting added customized status code on register, login, and get profile api revise api document accordingly to restful api Achieved except for set target yesterdayDescriptionToday’s target challenge20181217 rewriting add status code to all the functions revise api document accordingly to restful api.2019/1/9 The result of my target yesterday linux: 鳥哥的linux基礎篇 working on swagger api [ ] git: pro git working on swagger api [x] challenge20181217 rewriting complete register and login function api with swagger Achieved except for set target yesterdayDescriptionToday’s target challenge20181217 rewriting make api document with swagger2019/1/8 The result of my target yesterday linux: 鳥哥的linux基礎篇 working on challenge20190107 - how to upload a file to aws-s3 via a pre-signed url instead. [x] git: pro git how to stash all the work in all our submodules? how to create a new branch and switch to it in all our submodules? how to use ‘git diff’ in your main project and all your submodules? [ ] challenge20181217 rewriting working on challenge20190107 - how to upload a file to aws-s3 via a pre-signed url instead. Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git challenge20181217 rewriting revise api document learn how to use swagger 2019/1/7The result of my target yesterday had a wonderful getaway yesterday.Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git challenge20181217 rewriting revise api document 2019/1/6The result of my target yesterday [ ] linux: 鳥哥的linux基礎篇 [x] git: pro git practice submodule [x] challenge20181217 rewriting complete transferring to restful apiAchieved except for set target yesterdayDescriptionToday’s target have a getaway today. 2019/1/5The result of my target yesterday [ ] linux: 鳥哥的linux基礎篇 [x] git: pro git practice submodule [x] challenge20181217 rewriting publish api document on github page, and sign ssl certificateAchieved except for set target yesterday how to build a blog with hexo DescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git challenge20181217 rewriting optimize api to restful api 2019/1/4The result of my target yesterday [x] linux: 鳥哥的linux基礎篇 what’s chattr [+-=] [asacdistu] how to search placed command in lunux? [x] git: pro git how to check if we find a bug after a lot of commits made, and we have no idea when and where the code went wrong? how to revise submodule url? what does 160000 mode means when commit a submodule? how to make a submodule? a better diff for submodule? [x] challenge20181217 rewriting complete ‘aws deployment’ DescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git challenge20181217 rewriting publish the api document on github page 2019/1/3The result of my target yesterday [x] linux: 鳥哥的linux基礎篇 how to execute cat command with value got previously in linux? [x] git: pro git what’s the progress of cloning project with submodule in? if, in master branch, i reset with a sha1 from develop branch, what would happen? how to specify lines with git blame? how to show where it’s originally copied from with git blame? [x] challenge20181217 rewriting complete ‘optimizing payment controller’ DescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git challenge20181217 rewriting deploy on aws2019/1/2 The result of my target yesterday [ ] linux: 鳥哥的linux基礎篇 ‘wondering’ rehearsal instead [ ] git: pro git ‘wondering’ rehearsal instead [x] challenge20181217 rewriting complete ‘deposit common achievement’ DescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git challenge20181217 rewriting optimize payment controller2019/1/1 The result of my target yesterday [x] linux: 鳥哥的linux基礎篇 what’s default authority when creating a file? what’s the default umask? so what’s the final default authority? how to see default umask? how to set umask? what’s the correct way of calculating final authority after deducting umask? [ ] git: pro git challenge20181217 rewriting do a linebot challenge held by howard instead DescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git challenge20181217 rewriting deposit achievement","link":"/zh-tw/schedule/2019/January/index.html"},{"title":"April 2019","text":"2019/4/30The result of my target yesterday node.js Implementing MVC on Express.js docker English Japanese achieved except for set target yesterdaydescriptiontoday’s target node.js docker English Japanese 2019/4/29The result of my target yesterday English docker Japanese Node.js Working on documentation of GCP Mountain hiking achieved except for set target yesterdaydescriptiontoday’s target node.js docker English Japanese 2019/4/28The result of my target yesterday English docker Japanese Node.js Working on documentation of GCP IWD worker achieved except for set target yesterdaydescriptiontoday’s target node.js docker English Japanese 2019/4/27The result of my target yesterday English docker Japanese Node.js Build an app server with express.js achieved except for set target yesterdaydescriptiontoday’s target node.js docker English Japanese 2019/4/26The result of my target yesterday English Japanese Node.js Go deeper into event loop What’s event loop Every phase in event loop timers I/O callbacks idle, prepare poll check close callbacks achieved except for set target yesterdaydescriptiontoday’s target node.js docker English Japanese 2019/4/25The result of my target yesterday English Japanese Node.js Parsing request bodies Understanding the concept of event driven Blocking and Non-Blocking Code Roughly reading through event loop achieved except for set target yesterdaydescriptiontoday’s target node.js docker English Japanese 2019/4/24The result of my target yesterday English Japanese Node.js module create a rudimentary server end a loop get information we want from request define response rudimentary request routing achieved except for set target yesterdaydescriptiontoday’s target node.js docker English Japanese 2019/4/23The result of my target yesterday English Japanese Get deeper into Docker Write down current progressAchieved except for set target yesterdayDescriptionToday’s target English Japanese Node.js 2019/4/22The result of my target yesterday English Japanese Get deeper into Docker Completed my first image made by Docker commitAchieved except for set target yesterdayDescriptionToday’s target English Japanese Get deeper into Docker 2019/4/21The result of my target yesterday English Japanese Get deeper into Docker Docker commit Achieved except for set target yesterdayDescriptionToday’s target English Japanese Get deeper into Docker 2019/4/20The result of my target yesterday English Japanese Get deeper into Docker docker tag, docker push, docker volume, docker save Achieved except for set target yesterdayDescriptionToday’s target English Japanese Get deeper into Docker 2019/4/19The result of my target yesterday English Japanese Finish Inboxer project Get deeper into Docker Create a MySQL container and connect to it while another MySQL is installed locally. That is, I could connect to two MySQLs in the server. Achieved except for set target yesterdayDescriptionToday’s target English Japanese Get deeper into Docker 2019/4/18The result of my target yesterday English Japanese Finish Inboxer project Still wait for DNS to update for SSL signature Achieved except for set target yesterdayDescriptionToday’s target English Japanese Finish Inboxer project Get deeper into Docker 2019/4/17The result of my target yesterday English Japanese Complete CentOS document with Docker Achieved except for set target yesterdayDescriptionToday’s target English Japanese Finish Inboxer project 2019/4/16The result of my target yesterday English Japanese Inboxer project Quote the translation feeAchieved except for set target yesterdayDescriptionToday’s target English Japanese Complete CentOS document with Docker 2019/4/15The result of my target yesterday English Japanese Inboxer project Initially completed deploying and send-mail function Achieved except for set target yesterdayDescriptionToday’s target English Japanese Inboxer project Quote the translation fee 2019/4/14The result of my target yesterday English Japanese GCP event Achieved except for set target yesterdayDescriptionToday’s target English Japanese Inboxer project 2019/4/13The result of my target yesterday English Japanese GCP Essentials review Working on docker-compose Achieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Event 2019/4/12The result of my target yesterday English Japanese GCP Essentials review Working on docker-compose Achieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Essentials review Kubernetes and Load Balance 2019/4/11The result of my target yesterday English Japanese GCP Essentials review Working on docker-compose Achieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Essentials review Go deeper into Docker 2019/4/10The result of my target yesterday English Japanese GCP Essentials review Go deeper into docker-compose Achieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Essentials review Go deeper into Docker 2019/4/9The result of my target yesterday English Japanese GCP Essentials review Docker-compose Achieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Essentials review Go deeper into Docker 2019/4/8The result of my target yesterday English Japanese GCP Essentials review Go deeper into Docker - Overlay Network Achieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Essentials review Go deeper into Docker 2019/4/7The result of my target yesterday English Japanese GCP Essentials review Go deeper into Docker - Swarm and Service Achieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Essentials review Go deeper into Docker 2019/4/6The result of my target yesterday English Japanese GCP Essentials review Docker - containerAchieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Essentials review Go deeper into Docker 2019/4/5The result of my target yesterday English Japanese GCP Essentials review Docker - image Achieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Essentials review Go deeper into Docker 2019/4/4The result of my target yesterday English Japanese GCP Essentials review Go deeper into Docker Achieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Essentials review Go deeper into Docker 2019/4/3The result of my target yesterday English Japanese GCP Essentials review Achieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Essentials review Go deeper into Docker 2019/4/2The result of my target yesterday English Japanese GCP Essentials review 1~3 Laracasts-Laravel_5.7_From_Scratch No time for it Achieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Essentials review 2019/4/1The result of my target yesterday English Japanese GCP Essentials - Kubernetes Quick Start Laracasts-Laravel_5.7_From_Scratch Achieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Essentials review Laracasts-Laravel_5.7_From_Scratch","link":"/zh-tw/schedule/2019/April/index.html"},{"title":"July 2019","text":"2019/7/31the result of my target yesterday Task: Organise GCP Load Balancer Completed testing, and going to write a documentation Figure out how to use logRotate No time for it Optimise CICD on api-server project Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Organise GCP Load Balancer Figure out how to use logRotate Linux English Japanese 2019/7/30the result of my target yesterday Task: Organise GCP Load Balancer Still working on it Work on CostDown Initially completed Figure out how to use logRotate No time for it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Organise GCP Load Balancer Figure out how to use logRotate Optimise CICD on api-server project Linux English Japanese 2019/7/29the result of my target yesterday Task: Organise GCP Load Balancer Still working on it Work on CostDown Still working on it Figure out how to use logRotate No time for it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Organise GCP Load Balancer Work on CostDown Figure out how to use logRotate Linux English Japanese 2019/7/28the result of my target yesterday Task: Organise GCP Load Balancer Still working on it Work on CostDown Still working on it Figure out how to use logRotate No time for it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Organise GCP Load Balancer Work on CostDown Figure out how to use logRotate Linux English Japanese 2019/7/27the result of my target yesterday Task: Organise GCP Load Balancer Still working on it Work on CostDown Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Organise GCP Load Balancer Work on CostDown Figure out how to use logRotate Linux English Japanese 2019/7/26the result of my target yesterday Task: Organise GCP Load Balancer Still working on it Work on CostDown Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Organise GCP Load Balancer Work on CostDown Linux English Japanese 2019/7/25the result of my target yesterday Task: Organise GCP Load Balancer Still working on it Work on CostDown We’ve got some progress Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Organise GCP Load Balancer Work on CostDown Linux English Japanese 2019/7/24the result of my target yesterday Task: Build new sites Organise pm2 config Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Organise GCP Load Balancer Work on CostDown Linux English Japanese 2019/7/23the result of my target yesterday Task: Trace edgeOnline API Initially found the issue, going to test it Organise pm2 config No time for it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Build new sites Organise pm2 config Linux English Japanese 2019/7/22the result of my target yesterday Task: Organise GCP Load Balance No time for it Organise pm2 config Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Trace edgeOnline API Organise pm2 config Linux English Japanese 2019/7/21the result of my target yesterday Task: Organise GCP Load Balance No time for it Organise pm2 config Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Organise GCP Load Balance Organise pm2 config Linux English Japanese 2019/7/20the result of my target yesterday Task: Observe new LB, and if every thing goes well, delete all previous VMs Build CICD for all of the projects Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Organise GCP Load Balance Organise pm2 config Linux English Japanese 2019/7/19the result of my target yesterday Task: Optimise the number of VM instance from 8 VMs to 2 VMs Initially completed, and going to observe it further Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Observe new LB, and if every thing goes well, delete all previous VMs Build CICD for all of the projects Linux English Japanese 2019/7/18the result of my target yesterday Task: Optimise the number of VM instance from 8 VMs to 2 VMs Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Optimise the number of VM instance from 8 VMs to 2 VMs Linux English Japanese 2019/7/17the result of my target yesterday Task: Optimise the number of VM instance from 8 VMs to 2 VMs Still working on it Shutdown qcdn-job and move the job to another VM Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Optimise the number of VM instance from 8 VMs to 2 VMs Linux English Japanese 2019/7/16the result of my target yesterday Task: Optimise the number of VM instance from 8 VMs to 2 VMs still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Optimise the number of VM instance from 8 VMs to 2 VMs Shutdown qcdn-job and move the job to another VM Linux English Japanese 2019/7/15the result of my target yesterday Task: Optimise the number of VM instance from 8 VMs to 2 VMs Still working on it Fix eon_v3 DNS issue Initially completed, but still have something to discuss with Raymond before closing this issue Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Optimise the number of VM instance from 8 VMs to 2 VMs Fix eon_v3 DNS issue Linux English Japanese 2019/7/14the result of my target yesterday Task: Optimise the number of VM instance from 8 VMs to 2 VMs Still working on it Fix eon_v3 DNS issue Initially fixed it, but still have some problems to discuss Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Optimise the number of VM instance from 8 VMs to 2 VMs Fix eon_v3 DNS issue Linux English Japanese 2019/7/13the result of my target yesterday Task: Optimise the number of VM instance from 8 VMs to 2 VMs Still working on it Fix eon_v3 DNS issue Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Optimise the number of VM instance from 8 VMs to 2 VMs Fix eon_v3 DNS issue Linux English Japanese 2019/7/12the result of my target yesterday Task: Optimise the number of VM instance from 8 VMs to 2 VMs Still working on it Added a feature sending event notification to Slack channel Completed Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Optimise the number of VM instance from 8 VMs to 2 VMs Linux English Japanese 2019/7/11the result of my target yesterday Task: Trace customer-api code to find out what might cause huge Datastore read It seems that either cloud-api and cloud-customer-api is not the cause of this issue. Optimise the number of VM instance from 8 VMs to 2 VMs Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Optimise the number of VM instance from 8 VMs to 2 VMs Linux English Japanese 2019/7/10the result of my target yesterday Task: Trace customer-api code to find out what might cause huge Datastore read Still working on it Optimise the number of VM instance from 8 VMs to 2 VMs Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Trace customer-api code to find out what might cause huge Datastore read Optimise the number of VM instance from 8 VMs to 2 VMs Linux English Japanese 2019/7/9the result of my target yesterday Task: Optimise CI with pm2 Still working on it Publish my article regarding pm2 Still working on it Trace customer-api code to find out what might cause huge Datastore read still tracing Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Trace customer-api code to find out what might cause huge Datastore read Optimise the number of VM instance from 8 VMs to 2 VMs Linux English Japanese 2019/7/8the result of my target yesterday Task: Optimise CI with pm2 Still working on it Publish my article regarding pm2 Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Optimise CI with pm2 Publish my article regarding pm2 Trace customer-api code to find out what might cause huge Datastore read Linux English Japanese 2019/7/7the result of my target yesterday Task: Change CI with pm2 Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Optimise CI with pm2 Publish my article regarding pm2 Linux English Japanese 2019/7/6the result of my target yesterday Task: Change CI with pm2 Still working on it Turn off loadAccessLog, bandwidthUsage, and emptyGzLogRemover API Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Change CI with pm2 Linux English Japanese 2019/7/5the result of my target yesterday Task: Change CI with pm2 Still working on it Keep off checkEdgeAlive API until 10 pm, and check the bill tomorrow Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Change CI with pm2 Turn off loadAccessLog, bandwidthUsage, and emptyGzLogRemover API Linux English Japanese 2019/7/4the result of my target yesterday Task: Change CI with pm2 Analyse the bill Keep off checkEdgeAlive API until 10 pm, and check the bill tomorrow Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Change CI with pm2 Keep off checkEdgeAlive API until 10 pm, and check the bill tomorrow Linux English Japanese 2019/7/3the result of my target yesterday Task: Configure ShadowSocks client setting Change CI with pm2 Make ShadowSocks automatically restart after reboot and shutdown the instance Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Change CI with pm2 Analyse the bill Keep off checkEdgeAlive API until 10 pm, and check the bill tomorrow Linux English Japanese 2019/7/2the result of my target yesterday Task: Configure ShadowSocks sever setting Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Configure ShadowSocks client setting Change CI with pm2 Make ShadowSocks automatically restart after reboot and shutdown the instance Linux English Japanese 2019/7/1the result of my target yesterday Task: Make a pm2 document Still working on it Make a Let’s Encrypt document and publish it Linux English Japanese JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: TBD Linux English Japanese","link":"/zh-tw/schedule/2019/July/index.html"},{"title":"June 2019","text":"2019/6/30the result of my target yesterday Task: Complete FTP server document and publish it Linux English Japanese JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: Make a pm2 document Make a Let’s Encrypt document and publish it Linux English Japanese JavaScript 2019/6/29the result of my target yesterday Task: Make PM2 document, and optimise every VM Still working on it Made a FTP server for internal deployment Linux English Japanese JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: Complete FTP server document and publish it Linux English Japanese JavaScript 2019/6/28the result of my target yesterday Task: Auto sign three sites with Let&#39;s Encrypt Linux English Japanese JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: Make PM2 document, and optimise every VM Linux English Japanese JavaScript 2019/6/27the result of my target yesterday Task: Figure out how pm2 works and optimise VMs with pm2 Partially Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Auto sign three sites with Let&#39;s Encrypt Linux English Japanese JavaScript 2019/6/26the result of my target yesterday Task: Understand how Cloud Function works Linux English Japanese JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: Figure out how pm2 works and optimise VMs with pm2 Linux English Japanese JavaScript 2019/6/25the result of my target yesterday Task: Optimise VMs Re-purged failed edges Linux English Japanese JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: Understand how Cloud Function works Linux English Japanese JavaScript 2019/6/24the result of my target yesterday Task: Linux English Japanese JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: TBD Linux English Japanese JavaScript 2019/6/23the result of my target yesterday Task: Linux English Japanese JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: Linux English Japanese JavaScript 2019/6/22the result of my target yesterday Task: Made eov_v3 work Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Linux English Japanese JavaScript 2019/6/21the result of my target yesterday Task: Working on EON_V3 Make domain column accepts array Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: TBD Linux English Japanese 2019/6/20the result of my target yesterday Task: Working on EON_V3 Completed CI Completed revising, the service is working now. Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on EON_V3 Make domain column accepts array Linux English Japanese 2019/6/19the result of my target yesterday Task: The handover of the work with Eddie I was told to work on project EON_V3 first Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on EON_V3 Linux English Japanese 2019/6/18the result of my target yesterday Task: The handover of the work with Eddie Linux English Japanese JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: The handover of the work with Eddie Linux English Japanese 2019/6/17the result of my target yesterday Task: Linux English Japanese JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: TBD Linux English Japanese JavaScript 2019/6/16the result of my target yesterday Task: Linux English Japanese JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: Linux English Japanese JavaScript 2019/6/15the result of my target yesterday Task: Edge and Site API Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Linux English Japanese JavaScript 2019/6/14the result of my target yesterday Task: Working on DNS function Completed Working on Site and Edge API Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Edge and Site API Linux English Japanese 2019/6/13the result of my target yesterday Task: Working on DNS function Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on DNS function Linux English Japanese 2019/6/12the result of my target yesterday Task: Working on DNS function Finished GCP Cloud DNS Service part Linux English Japanese JavaScript No time for it achieved except for set target yesterdaydescriptiontoday’s target Task: Working on DNS function Linux English Japanese 2019/6/11the result of my target yesterday Task: Have a meeting with ST, Raymond, and OY Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on DNS function Linux English Japanese JavaScript 2019/6/10the result of my target yesterday Task: Figured out how to add a Load-Balancing with gcloud Got stuck on SSH issue instead. However, I learnt something from it. Linux English Japanese JavaScript The Principles of Object-Oriented JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: Have a meeting with ST, Raymond, and OY Linux English Japanese 2019/6/9the result of my target yesterday Task: Figured out how to add a Load-Balancing with gcloud Linux English Japanese JavaScript The Principles of Object-Oriented JavaScript Today I will go out with friends for dinner, I hope that I will still finish my schedule achieved except for set target yesterdaydescriptiontoday’s target Task: Figured out how to add a Load-Balancing with gcloud Linux English Japanese JavaScript The Principles of Object-Oriented JavaScript 2019/6/8the result of my target yesterday Task: Transfer the drawing from HackMD to Draw.io Figured out how to add a Load-Balancing with gcloud Linux English Japanese JavaScript The Principles of Object-Oriented JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: Figured out how to add a Load-Balancing with gcloud Linux English Japanese JavaScript The Principles of Object-Oriented JavaScript Today I will go out with friends for dinner, I hope that I will still finish my schedule 2019/6/7the result of my target yesterday Task: Discuss with Raymond to finalize initial version, and discuss with ST Linux English Japanese JavaScript The Principles of Object-Oriented JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: Transfer the drawing from HackMD to Draw.io Figured out how to add a Load-Balancing with gcloud Linux English Japanese JavaScript The Principles of Object-Oriented JavaScript 2019/6/6the result of my target yesterday Task: Discuss with Raymond to finalize initial version of programming process drawing and make it with draw.io Raymond pointed out some errors, to be revised and resubmitted Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Discuss with Raymond to finalize initial version, and discuss with ST Linux English Japanese JavaScript The Principles of Object-Oriented JavaScript 2019/6/5the result of my target yesterday Task: Revised the data path according to the discussion yesterday. Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Discuss with Raymond to finalize initial version of programming process drawing and make it with draw.io Linux English Japanese 2019/6/4the result of my target yesterday Task: Completed logic part and compare with ST’s data path Completed first version of scratch, and had a discussion with Raymond Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Revised the data path according to the discussion yesterday. Linux English Japanese 2019/6/3the result of my target yesterday Task: Add new Japanese vocabulary card Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Completed logic part and compare with ST’s data path Linux English Japanese 2019/6/2the result of my target yesterday task: add new japanese vocabulary card Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Add new Japanese vocabulary card Linux English Japanese 2019/6/1the result of my target yesterday Task: Working on architecture of Cloud API Initially finished Ready Pool and Bootstrap Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: add new japanese vocabulary card Linux English Japanese","link":"/zh-tw/schedule/2019/June/index.html"},{"title":"November 2018","text":"2019/3/31The result of my target yesterday Deploy jenkins for openData Laracasts-Laravel_5.7_From_Scratch Achieved except for set target yesterdayDescriptionToday’s target GCP Essentials - Kubernetes Laracasts-Laravel_5.7_From_Scratch 2019/3/30The result of my target yesterday Write down how to do jenkins deployment Deploy ‘backendOfMobileGames’ and ‘openData’ Achieved except for set target yesterdayDescriptionToday’s target Deploy jenkins for openData Laracasts-Laravel_5.7_From_Scratch 2019/3/29The result of my target yesterday AWS Deployment: jenkins deployment Achieved except for set target yesterdayDescriptionToday’s target Write down how to do jenkins deployment Deploy ‘backendOfMobileGames’ and ‘openData’ 2019/3/28The result of my target yesterday AWS Deployment Completed supervisor and queue setting Achieved except for set target yesterdayDescriptionToday’s target AWS Deployment: jenkins deployment 2019/3/27The result of my target yesterday AWS Deployment Still working on it Achieved except for set target yesterdayDescriptionToday’s target AWS Deployment 2019/3/26The result of my target yesterday Laracasts-Laravel_5.7_From_Scratch Episode 6-11 Achieved except for set target yesterdayDescriptionToday’s target AWS Deployment 2019/3/25The result of my target yesterday Laracasts-Laravel_5.7_From_Scratch Episode 1~5 Achieved except for set target yesterdayDescriptionToday’s target Laracasts-Laravel_5.7_From_Scratch 2019/3/24The result of my target yesterday Write down how to use queue with sqs Prepare interview tonight Well, the interview was rescheduled because the interviewer was indisposed. Achieved except for set target yesterdayDescriptionToday’s target Laracasts-Laravel_5.7_From_Scratch 2019/3/23The result of my target yesterday Write down how to use Supervisor to manage queue work with sqs Completed Supervisor part, and will work on sqs part today. Prepare interview tonight The interview time was changed to tonight. Achieved except for set target yesterdayDescriptionToday’s target Write down how to use queue with sqs Prepare interview tonight 2019/3/22The result of my target yesterday Figure out how to use Supervisor to manage queue work Write down how to use Supervisor to manage queue work ‘The Wondering’ presentation Achieved except for set target yesterdayDescriptionToday’s target Write down how to use Supervisor to manage queue work with sqs Prepare interview tonight 2019/3/21The result of my target yesterday Figure out how to use SQS to send email Recap GCP Essentials Achieved except for set target yesterdayDescriptionToday’s target Figure out how to use Supervisor to manage queue work Write down how to use Supervisor to manage queue work ‘The Wondering’ presentation 2019/3/20The result of my target yesterday Complete FB selling side project’s ReadMe Recap GCP Essentials Achieved except for set target yesterdayDescriptionToday’s target Figure out how to use SQS to send email Recap GCP Essentials 2019/3/19The result of my target yesterday Write down Ray’s git flow Complete FB selling side project’s ReadMe Not yet completed, but working on it. Achieved except for set target yesterdayDescriptionToday’s target Complete FB selling side project’s ReadMe Recap GCP Essentials 2019/3/18The result of my target yesterday The Wondering presentation. Optimize FB online selling project Achieved except for set target yesterdayDescriptionToday’s target Write down Ray’s git flow Complete FB selling side project’s ReadMe 2019/3/17The result of my target yesterday The Wondering presentation. Optimize FB online selling project Phone validation and address validation Mail system Achieved except for set target yesterdayDescriptionToday’s target The Wondering presentation. Optimize FB online selling project 2019/3/16The result of my target yesterday Optimize FB online selling project Still working on the mail system for refund Achieved except for set target yesterdayDescriptionToday’s target The Wondering presentation. Optimize FB online selling project Phone validation and address validation Mail system 2019/3/15The result of my target yesterday Write down how to use PayPal payment service I’ve done it! Optimize FB online selling project If possible, I will go validation today! Achieved except for set target yesterdayDescriptionToday’s target Optimize FB online selling project Phone validation and address validation 2019/3/14The result of my target yesterday Write down how to use PayPal payment service I’m working on it! Optimize FB online selling project Have added refund function on both PayPal and AllPay Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service Finish it! Optimize FB online selling project If possible, I will go validation today! 2019/3/13The result of my target yesterday Write down how to use PayPal payment service Finished the refund function of PayPal. Optimize FB online selling project Finished the refund function of PayPal. Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service Will start to write this article after AllPay system refund function is completed. Optimize FB online selling project Finish refund function of AllPay 2019/3/12The result of my target yesterday Write down how to use PayPal payment service Almost finished refund function Optimize FB online selling project Almost finished PayPal refund function Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service Optimize FB online selling project 2019/3/11The result of my target yesterday Write down how to use PayPal payment service Completed capture authorization function. Optimize FB online selling project Completed capture authorization function. Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service Optimize FB online selling project 2019/3/10The result of my target yesterday Write down how to use PayPal payment service Nearly finished a basic transaction with REST API of PayPal Optimize FB online selling project Nearly finished a basic transaction with REST API of PayPal Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service Optimize FB online selling project 2019/3/9The result of my target yesterday Write down how to use PayPal payment service Still working on new features Optimize FB online selling project Working on refund feature Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service Optimize FB online selling project 2019/3/8The result of my target yesterday Write down how to use PayPal payment service Still working on new features Optimize FB online selling project Working on refund feature Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service Optimize FB online selling project 2019/3/7The result of my target yesterday Write down how to use PayPal payment service Already figured out how to use REST API, and now working on how to integrate it into my system Optimize FB online selling project Restructure Currently working on refund function WebSocket Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service Optimize FB online selling project Restructure WebSocket 2019/3/6The result of my target yesterday Write down how to use PayPal payment service still working on figuring out how rest API works Optimize FB online selling project Restructure WebSocket Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service Optimize FB online selling project Restructure WebSocket 2019/3/5The result of my target yesterday Write down how to use PayPal payment service Completed Payment Standard and IPN Message method Optimize FB online selling project Refine payment service Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service Optimize FB online selling project Restructure WebSocket 2019/3/4The result of my target yesterday Write down how to use PayPal payment service Still working on it, it’s a epic task! Optimize FB online selling project Restructure Make PayPal page show items and recipient in detail WebSocket Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service Optimize FB online selling project Restructure WebSocket 2019/3/3The result of my target yesterday Write down how to get long-lived and forever token from FB One more section of my Git Course Basically, it’s completed Optimize FB online selling project Restructure WebSocket Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service Optimize FB online selling project Restructure WebSocket 2019/3/2The result of my target yesterday Write down how to use PayPal payment service One more section of my Git Course Optimize FB online selling project Added long-lived token function Achieved except for set target yesterdayDescriptionToday’s target Write down how to get long-lived and forever token from FB One more section of my Git Course Optimize FB online selling project Restructure WebSocket 2019/3/1The result of my target yesterday Write down how to use PayPal payment service One more section of my Git Course Optimize FB online selling project- Restructure - WebSocket Achieved except for set target yesterdayDescription Went to help 日安 carry the new counter she bought Went to KTV with Lester Today’s target Write down how to use PayPal payment service One more section of my Git Course Optimize FB online selling project- Restructure - WebSocket","link":"/zh-tw/schedule/2019/March/index.html"},{"title":"May 2019","text":"2019/5/31the result of my target yesterday Task: Working on architecture of Cloud API Started working on Discover Service Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on architecture of Cloud API Linux English Japanese 2019/5/30the result of my target yesterday Task: Working on architecture of Cloud API Initially completed Ready Pool and Bootstrap Help Raymond to check edge condition Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on architecture of Cloud API Linux English Japanese 2019/5/29the result of my target yesterday Task: A meeting in Hsinchu Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on architecture of Cloud API Linux English Japanese 2019/5/28the result of my target yesterday Task: Completed edge-ip-revising API Still working on GCP Cloud DNS documentation Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: A meeting in Hsinchu Linux English Japanese 2019/5/27the result of my target yesterday Task: Completed a course in Qwiklab Watch Game of Thrones instead, I was guilty! Fix my windows computer Containerise HX-API Watch Game of Thrones instead, I was guilty! Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Completed edge-ip-revising API Linux English Japanese 2019/5/26the result of my target yesterday Task add getting new ip feature to monitor api Organising what I have learnt those weeks English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task Completed a course in Qwiklab Fix my windows computer Containerise HX-API Linux English Japanese 2019/5/25the result of my target yesterday Task review merge request of monitor api add getting new ip feature to monitor api working on onedgeipchange api English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task add getting new ip feature to monitor api Organising what I have learnt those weeks English Japanese 2019/5/24the result of my target yesterday Task figured out how edge dns works English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task review merge request of monitor api add getting new ip feature to monitor api working on onedgeipchange api English Japanese 2019/5/23The result of my target yesterday Task Comment issue 302~310 Have a meeting with Raymond English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task Working on API developing and refactoring. English Japanese 2019/5/22The result of my target yesterday Task Added new feature into monitor API English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task Comment issue 302~310 Have a meeting with Raymond English Japanese 2019/5/21The result of my target yesterday Task English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task Added new feature into monitor API English Japanese 2019/5/20The result of my target yesterday Task English Japanese achieved except for set target yesterdaydescriptiontoday’s target Organise what I learnt those weeks English Japanese 2019/5/19The result of my target yesterday Organise what I learnt those weeks Completed gitlac CI/CD on GCP virtual machine document organisation English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task Figure out checkEdgeAlive API Complete issue 302~310 English Japanese 2019/5/18The result of my target yesterday Organise what I learnt those weeks Organised Gitlab CI/CD English Japanese achieved except for set target yesterdaydescriptiontoday’s target Organise what I learnt those weeks English Japanese 2019/5/17The result of my target yesterday Task I would like to complete API support feature of the healthCheck function, however, it depends on the task English Japanese achieved except for set target yesterdaydescriptiontoday’s target Organise what I learnt those weeks English Japanese 2019/5/16The result of my target yesterday Task Understand the logic of checkEdgeAlive API - Then, we optimise the healthCheck function instead. English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task I would like to complete API support feature of the healthCheck function, however, it depends on the task English Japanese 2019/5/15The result of my target yesterday Task Come out with a solution for checkEdgeAlive issue: Completed a health check program to check the health per 10 minutes for temporary solution. English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task Understand the logic of checkEdgeAlive API English Japanese 2019/5/15The result of my target yesterday Task Initially fixed issue from 302 to 310 English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task Come out with a solution for checkEdgeAlive issue English Japanese 2019/5/14The result of my target yesterday Task Understand the logic of API implementation of QCDN. English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task Solve issue 302~310 English Japanese 2019/5/13The result of my target yesterday Task Understand the logic of API implementation of QCDN. Deploy Node.js project on Google App Engine English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task Understand the logic of API implementation of QCDN. English Japanese 2019/5/12The result of my target yesterday Task Figured out how to use breakpoint feature in PHPStorm. English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task Understand the logic of API implementation of QCDN. English Japanese 2019/5/11The result of my target yesterday Task Have initially completed the database organising, however, still have to change the logic of API implementation. English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task Figure out how to use IDE breakpoint feature English Japanese 2019/5/10The result of my target yesterday Task Have figured out the logic, still working on it. English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task Fix siteEdge unmatched data issue English Japanese 2019/5/9The result of my target yesterday English Japanese Task Got siteEdge.host unmatched from either site.host or site.cname Learnt how to build a site achieved except for set target yesterdaydescriptiontoday’s target Task Fix siteEdge unmatched data issue English Japanese 2019/5/8The result of my target yesterday English Japanese node.js How to insert data into datastore achieved except for set target yesterdaydescriptiontoday’s target Task English Japanese 2019/5/7The result of my target yesterday English Japanese A go over with Eddie and Raymond achieved except for set target yesterdaydescriptiontoday’s target node.js English Japanese 2019/5/6The result of my target yesterday English Japanese Gitlab CI Load Balance achieved except for set target yesterdaydescriptiontoday’s target node.js English Japanese 2019/5/5The result of my target yesterday English Japanese Gitlab CI Load Balance achieved except for set target yesterdaydescriptiontoday’s target node.js English Japanese 2019/5/4The result of my target yesterday node.js English Japanese Gitlab CI achieved except for set target yesterdaydescriptiontoday’s target node.js English Japanese 2019/5/3The result of my target yesterday node.js English Japanese Gitlab CI achieved except for set target yesterdaydescriptiontoday’s target node.js English Japanese 2019/5/2The result of my target yesterday node.js add a new route in Express.js make different routes with different prefixes in Express.js send status code in Express.js docker English Japanese achieved except for set target yesterdaydescriptiontoday’s target node.js docker English Japanese Gitlab CI 2019/5/1The result of my target yesterday node.js Implementing mass delete and get function in GCP Datastore docker English Japanese achieved except for set target yesterdaydescriptiontoday’s target node.js docker English Japanese","link":"/zh-tw/schedule/2019/May/index.html"}],"posts":[{"title":"GCP-Essentials","text":"前言此篇為我在QWIKLABS上學習GCP-Essentials系列課程所做的學習筆記目錄，以下為每堂課的學習筆記連結： Create a Virtual Machine / 建立一台虛擬機https://tn710617.github.io/zh-tw/createAVirtualMachineInGCP/ Getting Started with Cloud Shell &amp; gcloud / 讓我們從Cloud Shell 以及 gloud開始吧https://tn710617.github.io/zh-tw/CloudShellAndgcloud/ Provision Services with GCP Marketplace / 利用GCP Marketplace來提供服務https://tn710617.github.io/zh-tw/GCPMarketplace/ Creating a Persistent Disk / 建立一個Persistent Diskhttps://tn710617.github.io/zh-tw/createAPersistentDisk/ Kubernetes - Quick Start / Kubernetes - 快速開始https://tn710617.github.io/zh-tw/KubernetesEngineQuickStart/ Hello Node Kubernetes / 你好，Kubernetes!https://tn710617.github.io/zh-tw/Kubernetes/ Stackdriver - Quick Start / Stackdriver - 快速開始https://tn710617.github.io/zh-tw/Stackdriver/ Set Up Network and HTTP Load Balancers / 設定Network 以及 HTTP 平衡負載器https://tn710617.github.io/zh-tw/HTTPAndNetworkLoadBalancer/","link":"/zh-tw/GCP-Essentials/"},{"title":"讓我們開始Cloud Shell及gcloud吧！","text":"前言本篇主要是利用Google的Qwiklab平台學習的同時，做的一份學習筆記原文可參閱:官方連結 本篇將會做什麼？ 練習使用gcloud指令 連結到Google Cloud Platform的儲存裝置 設定及要求 Qwiklabs setup在你按下 Start Lab 按鈕之前 詳讀所有的教學。Labs 是有時間限制的，而且你不可以停止時間倒數。倒數計時器在你按下 Start Lab 按鈕後開始倒數，上面顯示的時間為你還能使用 Cloud 資源的時間。 Quiklabs 的手把手環境，讓你可以在真實環境中來操作進行 Quiclabs 上提供的課程，而不是在一個模擬或是展示的環境。我們透過提供你一個全新的、暫時的帳號密碼，在計時器歸零之前，你可以用來登入並存取 Google Cloud Platform。 你需要什麼？ 要完成這個 lab ，你需要: 一個一般的網路瀏覽器（推薦 Chrome） 完成這個 lab 的時間 備註： 如果你已經有你自己的個人 GCP 帳號或專案，請不要使用在這一個 lab 現在你已經開始你的 lab, 你將會登入 Google Cloud Shell 主控台，然後開啟命令列工具 如何開始你的 lab ，然後登入 Console? 按下 Start Lab 按鈕。如果你需要付費，會有一個彈出視窗來讓你選擇付費的方式。在左方你會看到一個面板，上面有暫時的帳號密碼，你必須使用這些帳號密碼在此次 lab 複製 username , 然後點擊 Open Google Console。 Lab 會開啟另外一個視窗，顯示選擇帳號的頁面 tip: 開啟一個全新的視窗，然後跟原本的頁面並排 在選擇帳號頁面, 點擊 Use Another Account 登入頁面開啟，貼上之前複製的 username 以及 password ，然後貼上 重要：必須使用之前於 Connection Details 面板 取得的帳號密碼，不要使用你自己的 Qwiklabs 帳號密碼。 如果你有自己的 GCP 帳號，請不要用在這裡（避免產生費用） 點擊並通過接下來的頁面: 接受terms以及conditions 不要增加recovery optoins 或 two factor authentication (因為這只是一個臨時帳號) 不要註冊免費體驗 稍待一些時候， GCP 控制台將會在這個視窗開啟。 注意：按下左上方位於Google Cloud Platform 隔壁的 Navigation menu ，你可以瀏覽選單，裡面有一系列的 GCP 產品以及服務 啟動 Google Cloud ShellGoogle Cloud Shell 是載有開發工具的虛擬機器。它提供了5GB的 home 資料夾，並且運行在 Google Cloud 上。 Google Cloud Shell 讓你可以利用 command-line 存取 GCP 資源 在 GCP 控制台 ，右上的工具列，點擊 Open Cloud Shell 按鈕 在打開的對話框裡，按下 START CLOUD SHELL: 你可以立即按下 START CLOUD SHELL 當對話視窗打開。 連結並提供環境會需要一點時間。當你連結成功，這代表你已成功獲得授權，且此專案已被設為你的專案ID，例如： gcloud 是 Google Cloud Platform 的 command-line 工具，他已事先被安裝在 Cloud Shell 並且支援自動補齊 使用這個 command ,你可以列出有效帳戶名稱: gcloud auth list 輸出: Credentialed accounts: - &lt;myaccount&gt;@&lt;mydomain&gt;.com (active) 範例輸出: Credentialed accounts: - google1623327_student@qwiklabs.net 你可以使用以下 command 來列出專案 ID gcloud config list project 輸出： [core]project = &lt;project_ID&gt; 範例輸出： [core]project = qwiklabs-gcp-44776a13dea667a6 gcloud 的完整文件可以參閱 Google Cloud gcloud Overview 理解Regions 和 Zones 特定的Compute Engine 資源位於特定的regions或zones. Region表示一個特定的地理位置，而你的資源就跑在那邊。 每個region都有一個或多個zones，舉例來說，us-central1 region位於Central United States，並且下面有us-central1-a, us-central1-b, us-central1-c, us-central1-f這些zones 位於zone的資源算是zonal資源。 Virtual machine instance還有persistent disk都位於zone, 如果要在一個virtual machine上加一個persistent disk，那兩者必須位於同一個zone 相同的，如果你要分配一個static IP位址到一個instance，這個instance必須要跟這個static IP同一個region 使用終端機 點擊位於GCP主控台右上角的圖案來開始一個新的Cloud Shell視窗，如下圖： 在Cloud Shell成功開啟後，我們可以使用終端機來下達Cloud SDK gcloud，或任何其他vurtual machine instance有提供的指令。 我們也可以在不同的專案，或著Cloud Shell，把檔案儲存在persistent disk的HOME資料夾。 HOME資料夾只屬於你個人，任何其他USER將無法存取。 gcloud提供使用指南，只要在指令的後面加上-h，試試下面的指令: gcloud -h 或者，你也可以打長一點 gcloud config --help gcloud help config 使用你的Home資料夾現在，讓我們來試試Home資料夾。就算你結束或者重開你的virtual machine，Cloud Shell Home 資料夾內的內容也會繼續存在，不同的專案或者Cloud Shell都可以存取。 改變目前的工作資料夾 cd $HOME 使用vim打開.bashrc設定檔 vim .bashrc 使用gcloud指令 讓我們來檢視一下我們環境內的設定列表 gcloud config list 檢視其他的property是怎麼被設定的 gcloud config list --all 管理Cloud儲存資料 建立一個Cloud Storage bucket, bucket 的名字必須獨一無二，所以請給一個名稱來取代下面的unique-namegsutil mb gs://unique-name 現在，我們可以建立一些資料，並上傳的我們的bucket 建立一個test檔案 vim test.dat 加一些資料進去 welcome to gcloud! 存檔 :wq 現在，上傳一些檔案到我們建立的bucket，請使用我們之前給的名字來取代下面的unique-name gsutil cp test.dat gs://unique-name 如果想看一下我們建立的bucket，以及我們上傳的檔案，可以打開Navigation menu &gt; Storage &gt; Browser，然後點擊bucket，應該可以看到test.dat檔案，如下圖： 考考你！ Three basic ways to interact with the GCP services and resources: Command-line interface Client libraries GLib GStreamer GCP Console Which tool in cloud shell helps to manage Cloud Storage resources? gcloud gsutil compute bq","link":"/zh-tw/CloudShellAndgcloud/"},{"title":"gcloud shell","text":"前言本篇記錄 gcloud shell 用法 computeinstance 建立一台虛擬機 gcloud compute instances create example-instance-1 \\--image-project=ubuntu-os-cloud \\--image-family=ubuntu-1804-lts \\--boot-disk-size=10GB \\--boot-disk-type=pd-standard \\--machine-type=f1-micro \\--tags=example-instance-1,http-server,https-server \\--zone=asia-east1-c 由自己建立的 image 建一台 VM gcloud compute instances create example-instance-1 \\--image-project=yourProject \\--image=yourImage \\--boot-disk-size=10GB \\--boot-disk-type=pd-standard \\--machine-type=f1-micro \\--tags=example-instance-1,http-server,https-server \\--zone=asia-east1-c 停止 instance gcloud compute instances stop instanceName1 instanceName2 instanceName3 啟動 instance gcloud compute instances start instanceName1 instancesName2 instanceName3 刪除 instance gcloud compute instances delete instanceName 列出 instances 列表 gcloud compute instances list 列出特定 instance 細節資料 gcloud compute instances describe instanceName 查詢執行個體的 ssh 金鑰 gcloud compute instances describe instanceName | grep -A 5 ssh-keys 移除或新增執行個體 ssh 金鑰 gcloud compute instances add-metadata instanceName --metadata-from-file ssh-keys=fileName 指令如上，以下是 fileName 的格式[USERNAME_2]:ssh-rsa [EXISTING_KEY_VALUE_2] [USERNAME_2][USERNAME_3]:ssh-rsa [NEW_KEY_VALUE] [USERNAME_3] 為 instance 增加 tags gcloud compute instances add-tags instanceName \\--tags tag1,tag2,tag3... 封鎖全專案公開 SSH 金鑰 gcloud compute instances add-metadata [INSTANCE_NAME] --metadata block-project-ssh-keys=TRUE 允許全專案公開 SSH 金鑰 gcloud compute instances add-metadata [INSTANCE_NAME] --metadata block-project-ssh-keys=FALSE firewall-rules 增加防火牆規則gcloud compute firewall-rules create firewallRuleName --allow tcp:50005,port2,port3 --target-tags targetTags 文件連結 images 查詢可用的 images 相關資訊 gcloud compute images list 從現有的 disk 創立 image gcloud compute images create shadowsocks \\--source-disk test-shadowsock \\--source-disk-zone asia-east1-a \\--family ubuntu-1804-lts project 查詢全專案公開 ssh 金鑰並且顯示 5 行資料 gcloud compute project-info describe | grep -A 5 ssh-keys 移除或新增全專案公開 ssh 金鑰 gcloud compute project-info add-metadata --metadata-from-file ssh-keys=fileName 指令如上，以下是 fileName 的格式[USERNAME_2]:ssh-rsa [EXISTING_KEY_VALUE_2] [USERNAME_2][USERNAME_3]:ssh-rsa [NEW_KEY_VALUE] [USERNAME_3] addresses 將現有 VM 使用的 IP 轉為靜態 gcloud compute addresses create addressName \\--addresses IP \\--region regionName 列出 IP gcloud compute addresses list 刪除 IP gcloud compute addresses delete ip1 ip2 ip3 regions 取得 regions 列表gcloud compute regions list backend-service 更新 draining-time-outgcloud compute backend-services update [BACKEND_SERVICE] \\ --connection-draining-timeout [CONNECTION_TIMEOUT_SECS] DNSrecord-sets顯示區域的當前 DNS 紀錄gcloud dns record-sets list --zone=\"myzonename\" 此指令會以含有前 100 筆記錄的資源記錄集，輸出 JSON 回應。您可以指定下列額外參數： limit：要列出的記錄集數目上限。 name：只列出含有這個確切網域名稱的記錄集。 type：只列出這個類型的記錄。如果有這類記錄，則必須同時使用 –name 參數。 新增 A record 開始 transaction gcloud dns record-sets transaction start --z zoneName 增加 A 紀錄 gcloud dns record-sets transaction add 'ip' --name 'domainName' --ttl 5 --type A --zone 'zoneName' 增加 cname 紀錄 gcloud dns record-sets transaction add -z=zoneName --type=CNAME --name=\"www.ray.com\" --ttl 5 \"ray.com.\" 增加 MX 紀錄 gcloud dns record-sets transaction add --z=zoneName --name=\"ray.com\" --ttl 5 --type MX \"10 mail1.ray.com.\" \"20 mail2.ray.com.\" 執行 gcloud dns record-sets transaction execute -z 'zoneName' managed-zones列出所有 zone 列表gcloud dns managed-zones list config切斷 projectgcloud config set projectID projects取得 project listgcloud projects list gsutilCloud Storage mb建立儲存區, 命名規格請參考gsutil mb gs://YOUR-BUCKET-NAME cp上傳檔案gsutil cp ada.jpg gs://YOUR-BUCKET-NAME 下載檔案gsutil cp -r ada.jpg gs://YOUR-BUCKET-NAME -r: recursive 複製檔案gsutil cp gs://YOUR-BUCKET-NAME/ada.jpg gs://YOUR-BUCKET-NAME/image-folder/ ls列出物件gsutil ls gs://YOUR-BUCKET-NAME 列出物件細節gsutil ls -l gs://YOUR-BUCKET-NAME/ada.jpg -l: list acl增加公開存取權限gsutil acl ch -u AllUsers:R gs://YOUR-BUCKET-NAME/fileName 移除公開存取權限gsutil acl ch -d AllUsers gs://YOUR-BUCKET-NAME/fileName rm刪除物件gsutil rm gs://YOUR-BUCKET-NAME/fileName","link":"/zh-tw/GCP/"},{"title":"利用GCP Marketplace來提供服務","text":"前言本篇主要是利用 Google 的 Qwiklab 平台學習的同時，做的一份學習筆記 概述GCP Marketplace 讓我們可以透過簡單的幾下點擊就可以在 Google Compute Engine 部署一些常見的套裝軟體。 許多網頁框架，資料庫，客戶管理系統以及客戶關係管理系統都有支援。 這是最快速的方法之一，來讓我們的服務運行在 Google Cloud Platform. 在這個手把手教程中，你將會學習如何在 Google Cloud Platform 開始並設置一個 Marketplace 服務 本篇將會做什麼？ 使用 Marketplace 來建立一套網路工具包 核對部署 設定及要求 Qwiklabs setup在你按下 Start Lab 按鈕之前 詳讀所有的教學。Labs 是有時間限制的，而且你不可以停止時間倒數。倒數計時器在你按下 Start Lab 按鈕後開始倒數，上面顯示的時間為你還能使用 Cloud 資源的時間。 Quiklabs 的手把手環境，讓你可以在真實環境中來操作進行 Quiclabs 上提供的課程，而不是在一個模擬或是展示的環境。我們透過提供你一個全新的、暫時的帳號密碼，在計時器歸零之前，你可以用來登入並存取 Google Cloud Platform。 你需要什麼？ 要完成這個 lab ，你需要: 一個一般的網路瀏覽器（推薦 Chrome） 完成這個 lab 的時間 備註： 如果你已經有你自己的個人 GCP 帳號或專案，請不要使用在這一個 lab 現在你已經開始你的 lab, 你將會登入 Google Cloud Shell 主控台，然後開啟命令列工具 如何開始你的 lab ，然後登入 Console? 按下 Start Lab 按鈕。如果你需要付費，會有一個彈出視窗來讓你選擇付費的方式。在左方你會看到一個面板，上面有暫時的帳號密碼，你必須使用這些帳號密碼在此次 lab 複製 username , 然後點擊 Open Google Console。 Lab 會開啟另外一個視窗，顯示選擇帳號的頁面 tip: 開啟一個全新的視窗，然後跟原本的頁面並排 在選擇帳號頁面, 點擊 Use Another Account 登入頁面開啟，貼上之前複製的 username 以及 password ，然後貼上 重要：必須使用之前於 Connection Details 面板 取得的帳號密碼，不要使用你自己的 Qwiklabs 帳號密碼。 如果你有自己的 GCP 帳號，請不要用在這裡（避免產生費用） 點擊並通過接下來的頁面: 接受terms以及conditions 不要增加recovery optoins 或 two factor authentication (因為這只是一個臨時帳號) 不要註冊免費體驗 稍待一些時候， GCP 控制台將會在這個視窗開啟。 注意：按下左上方位於Google Cloud Platform 隔壁的 Navigation menu ，你可以瀏覽選單，裡面有一系列的 GCP 產品以及服務 啟動 Google Cloud ShellGoogle Cloud Shell 是載有開發工具的虛擬機器。它提供了5GB的 home 資料夾，並且運行在 Google Cloud 上。 Google Cloud Shell 讓你可以利用 command-line 存取 GCP 資源 在 GCP 控制台 ，右上的工具列，點擊 Open Cloud Shell 按鈕 在打開的對話框裡，按下 START CLOUD SHELL: 你可以立即按下 START CLOUD SHELL 當對話視窗打開。 連結並提供環境會需要一點時間。當你連結成功，這代表你已成功獲得授權，且此專案已被設為你的專案ID，例如： gcloud 是 Google Cloud Platform 的 command-line 工具，他已事先被安裝在 Cloud Shell 並且支援自動補齊 使用這個 command ,你可以列出有效帳戶名稱: gcloud auth list 輸出: Credentialed accounts: - &lt;myaccount&gt;@&lt;mydomain&gt;.com (active) 範例輸出: Credentialed accounts: - google1623327_student@qwiklabs.net 你可以使用以下 command 來列出專案 ID gcloud config list project 輸出： [core]project = &lt;project_ID&gt; 範例輸出： [core]project = qwiklabs-gcp-44776a13dea667a6 gcloud 的完整文件可以參閱 Google Cloud gcloud Overview 導覽到 Marketplace 在 Google Cloud Console ，找到 Marketplace 如下： 然後應該可以看到 Marketplace 首頁 選擇 Nginx 在搜尋欄輸入 Nginx, 然後選擇 Nginx Certified by Bitnami 的版本 建立 Nginx 工具組VM instance 設定一旦專案建立了，我們將會被帶到位於 Cloud 主控台，新的 Nginx 部署頁面來設定我們的 Nginx instance 為 instance 取名，例如， nginxstack-1 選擇 zone 以下保持預設值 Machine type: micro(1-shared vCPU)0.6GB memory Boot Disk: 10 GB SSD “Allow HTTP Traffic” 以及 “Allow HTTPS Traffic” 需要被勾選 請接受 GCP Marketplace Terms of Service ，在頁面的下方 點擊 Deploy 來建立我們的Nginx 工具組 核對部署 當 Cloud 主控台回報，我們的 Nginx 套組已經部署完畢，我們可以核實一下，是否所有東西都正常運行，我們的畫面看起來應該如下圖： 核對網頁 點擊上圖的藍色按鈕 Visit the site ，我們可以存取部署好的 Nginx 套組，看起來如下圖： 核對 SSH 我們也可以點擊 SSH 連結來打開一個新的 VM instance 視窗。我們可以使用 Unix 指令，像是 ps 來看看 Nginx 是否正常的運行在我們的 instanceps aux | grep nginx 考考你！！ Does Google Cloud Platform Marketplace allow you to deply a software package now, and scale that deployment later when your application require additional capacity without updating the software that you have already deployed true false","link":"/zh-tw/GCPMarketplace/"},{"title":"手把手教你理解並建立 GCP 平衡負載","text":"前言為什麼要使用 Load Balancer? 可以分攤流量, 利用多台機器跑多個服務 當一台機器掛了，你還有另外一台 當負載到達一定程度，可以啟動 auto scaling (本篇不會使用到) 配合適當的 CI / CD, 以及健康檢查，可達到 rolling upgrade 的效果 本篇重點 本篇分享最簡單易設的 unmanaged Load Balancer 為避免混淆，本篇對於有意義的元件術語，將維持原文，不會特別翻譯 詳解每個元件行為 簡單的概念圖如下 (圖片來源： Google )： IPv4 以及 IPv6 的使用者，對我們的服務發請求 我們設定的 IPv4 以及 IPv6 Forwading rules，會將使用者導向我們設定好的 HTTP(S) proxy 到了 HTTP(S) proxy 的 request, 會根據我們設定好的 url-map 規則，導向相對應的backend-service, 例如說， 透過 domain name 為 ‘test1’ 的 request, 導向backend-service 1, 而 ‘test2’ 的 request 導向 backend-service 2 backend-service 由 instance group 組成，舉例來說，我們可以指定， backend-service A 導向 instance group A 的 port 8000 , 而 backend-service B 導向 instance group B 的 port 6000 instance group, 顧名思義，由 instance 所組成，當我們在 instance group 中設定好特定的 port, 並且設定好 backend-service, 那麼 request 將會經由 backend-service, 再到 instance group 指定的 port, 最後到依照 instance 本身的負載狀況, 將 request 導向適合服務的 instance 每個 backend-service 都可以設定一個 health-check, health-check 會根據指定的頻率向指定的 port 探測並取得回應，如果回應的速度低於我們設立的門檻，那麼該 instance 就會被判定為不健康。 request 不會導向已被判定為不健康的 instance 如果有 SSL 需求，可建立 SSL certificate, 並且掛在 HTTPS proxy 以下我們就開始來實作吧! 安裝 Google Cloud SDK本篇所有的指令都會使用到 Google Cloud SDK 的指令, 所有在我們開始之前，先安裝它哦！根據你的作業系統的不同，安裝方法也不一樣哦，請參考官方文件 建立 instance 建立兩個 instances gcloud compute instances create test-01 \\--image-project=ubuntu-os-cloud \\--image-family=ubuntu-1804-lts \\--boot-disk-size=30GB \\--boot-disk-type=pd-standard \\--machine-type=f1-micro \\--tags=test-01,http-server,https-server \\--zone=asia-east1-c gcloud compute instances create test-02 \\--image-project=ubuntu-os-cloud \\--image-family=ubuntu-1804-lts \\--boot-disk-size=30GB \\--boot-disk-type=pd-standard \\--machine-type=f1-micro \\--tags=test-02,http-server,https-server \\--zone=asia-east1-c 建立二台機器, 叫做 test-01, test-02 開機碟的空間為 30GB 從 ubuntu-os-cloud, 來 pull 我們需要的 image 我們使用 ubuntu-1804-lts 的 image 版本, 這會自動使用這個版本的最新版 硬碟類型為 pd-standard, 不知道類型可以跑 gcloud compute disk-types list 來看看 機器型號為 f1-micro, 不知道類型可以跑 gcloud compute machine-types list 來看看 tags 用來當作該 instance 的一個識別，等等開防火牆的時候會用到 zone 指定該 instance 的地區, 有些資源只有相同 zone 或者 region 可以取用，要注意 可參考官方文件 instance 環境建置以下為 instance 上的環境建置範例，與本篇主題較無關係，可跳過 apt-get update -y &amp;&amp; apt-get install curl -y &amp;&amp; curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.34.0/install.sh | bash &amp;&amp; export NVM_DIR=\"$HOME/.nvm\" &amp;&amp; [ -s \"$NVM_DIR/nvm.sh\" ] &amp;&amp; \\. \"$NVM_DIR/nvm.sh\" &amp;&amp; [ -s \"$NVM_DIR/bash_completion\" ] &amp;&amp; \\. \"$NVM_DIR/bash_completion\" &amp;&amp; nvm install yourNodeVersion &amp;&amp; apt-get install npm -y &amp;&amp; npm install pm2 -g &amp;&amp; pm2 update &amp;&amp; apt-get install git -y &amp;&amp; apt-get install build-essential 開啟防火牆看服務跑在哪一個 port, 我們需要將防火牆打開，這樣 instance group 才能將 request 從 Load Balancer 經由 backend-service 導向相對應的 port, 可參考官方文件 gcloud compute firewall-rules create test-01 --allow tcp:123,tcp:456,tcp:789 --target-tags test-01 gcloud compute firewall-rules create test-02 --allow tcp:123,tcp:456,tcp:789 --target-tags test-02 外部靜態 IP這邊建立一個 IPv4 的靜態 IP , 之後會用到, 可參考官方文件 gcloud compute addresses create lb-test \\ --ip-version=IPV4 \\ --global Instance groupInstance group 可由多個 instance 所組成，為組成 backend-service 的主體, 可參考官方文件 建立 instance group, 之後 Load Balancer 可以用它來建立不同的 backend-service gcloud compute instance-groups unmanaged create test --description 'run test project' --zone asia-east1-c 設定 named port, 所以不同的 backend-service 可以指定要用哪一個 port gcloud compute instance-groups unmanaged set-named-ports test --named-ports port1:3000,port2:6000,port3:9000,port4:12000,port5:15000 --zone asia-east1-c 將現有的 instance 加到 instance group gcloud compute instance-groups unmanaged add-instances test \\ --instances test-01,test-02 \\ --zone asia-east1-c Health checkhealth-check , 可根據我們指定的頻率，探測指定的 port, 如果該 port 無回應， health-check 將判定這個 port 不健康， backend-service 不會將 request 送往不健康的 instance 可參考官方文件 gcloud compute health-checks create tcp test-tcp-3000 \\ --description='test tcp 3000'\\ --port=3000 gcloud compute health-checks create tcp test-tcp-6000 \\ --description='test tcp 6000'\\ --port=6000 gcloud compute health-checks create tcp test-tcp-9000 \\ --description='test tcp 9000'\\ --port=9000 gcloud compute health-checks create tcp test-tcp-12000 \\ --description='test tcp 12000'\\ --port=12000 gcloud compute health-checks create tcp test-tcp-15000 \\ --description='test tcp 15000'\\ --port=15000 Backend service這邊的 --port-name, 就是上面我們在 instance-group 中，建立的 port, 在此範例中，不同的 backend-service 會將 request 導向不同的 port, 這邊看起來沒有提到 instance group ? 別緊張，下一步我們就會把 instance group 加到 backend-service 當中。 同理， health-check 也是掛在 backend-service 上的, 因為 backend-service 將決定要將 request 導向哪一個 instance。可參考官方文件 建立後端服務 gcloud compute backend-services create backend-service-port1 \\ --protocol http \\ --port-name port1 \\ --health-checks test-tcp-3000 \\ --global gcloud compute backend-services create backend-service-port2 \\ --protocol http \\ --port-name port2 \\ --health-checks test-tcp-6000 \\ --global gcloud compute backend-services create backend-service-port3 \\ --protocol http \\ --port-name port3 \\ --health-checks test-tcp-9000 \\ --global gcloud compute backend-services create backend-service-port4 \\ --protocol http \\ --port-name port4 \\ --health-checks test-tcp-12000 \\ --global gcloud compute backend-services create backend-service-port5 \\ --protocol http \\ --port-name port5 \\ --health-checks test-tcp-15000 \\ --global 接下來，我們將 instance group 加到我們剛剛建立的 backend-service, 因為我們在建立 backend-service 時就已指定了 port, 所以 backend-service 會將 request 導向所屬的 instance group 中已指定的 port, 嗯, 聽起來有點饒舌, 不過的確是這樣。 除了設定導向的 port 之外，這邊也會設定 instance 的負載門檻。 設定 UTILIZATION 表示使用率，當使用到 80 % 時， backend-service 便會停止將 request 導向這個 instance capacity-scaler 表示， 1 * 0.8, 所以說，如果你有多個 backend-service 使用這個 instance-group, 那你希望多保留一些 instance-group 的可使用率，給其他 backend-service 使用，那就可以將 capacity-scaler 調低，如此一來，當這個 backend-service 已使用了 capacity-scaler * max-utilization 的 CPU 時，來自於該 backend-service 的請求就不會導向該 instance-group, 可以很大程度地保留該 instance-group 服務其他 backend-service 的可用性。 下面範例，可參考官方文件 將 instance group 加到 backend-service gcloud compute backend-services add-backend backend-service-port1 \\ --balancing-mode UTILIZATION \\ --max-utilization 0.8 \\ --capacity-scaler 1 \\ --instance-group test \\ --instance-group-zone asia-east1-c \\ --global gcloud compute backend-services add-backend backend-service-port2 \\ --balancing-mode UTILIZATION \\ --max-utilization 0.8 \\ --capacity-scaler 1 \\ --instance-group test \\ --instance-group-zone asia-east1-c \\ --global gcloud compute backend-services add-backend backend-service-port3 \\ --balancing-mode UTILIZATION \\ --max-utilization 0.8 \\ --capacity-scaler 1 \\ --instance-group test \\ --instance-group-zone asia-east1-c \\ --global gcloud compute backend-services add-backend backend-service-port4 \\ --balancing-mode UTILIZATION \\ --max-utilization 0.8 \\ --capacity-scaler 1 \\ --instance-group test \\ --instance-group-zone asia-east1-c \\ --global gcloud compute backend-services add-backend backend-service-port5 \\ --balancing-mode UTILIZATION \\ --max-utilization 0.8 \\ --capacity-scaler 1 \\ --instance-group test \\ --instance-group-zone asia-east1-c \\ --global URL map前面介紹完了 backend-service, 那這個 url-map, 就是將 request 導向 backend-service 的元件。 首先，我們要先建立一個 url-map, 並且給予一個默認的 backend-service, 意思就是說，如果沒有特別指定的話，收到的 request 要導向哪一個 backend-service 下面範例，可參考官方文件 建立 URL-map gcloud compute url-maps create web-map \\ --default-service backend-service-port1 上面建立了 url-map, 並且指定了一個默認的 backend-service, 現在我們可以定義怎麼樣的 request 該導向哪一個 backend-service。 路徑的指定，我們需要使用 path-matcher, 範例如下： path-matcher: 建立一個 path-matcher, 並給予指定的路徑規則 new-hosts: 當 request 是對 host sunday.com.tw 發請求時，會套用此規則 所以就是說, 當 request 的 host 為 sunday.com.tw 時，會導向 backend-service-port1 以下為範例，可參考官方文件 新增 path-matcher gcloud compute url-maps add-path-matcher web-map \\ --default-service backend-service-port1 \\ --path-matcher-name pathmap-port1 \\ --new-hosts=sunday.com.tw 這邊可以看到比上面多了一個新的元件，叫做 path-rules 當 request 的 host 為 monday.com.tw, 默認路徑如 / 會導向 backend-service-port2 當 request 的路徑為 happy, 如 monday.com.tw/happy, 會導向 backend-service-port1 當 request 的路徑為 unhappy, 如 monday.com.tw/unhappy, 會導向 backend-service-port2 當 request 的路徑為 sad, 如 monday.com.tw/sad, 會導向 backend-service-port3 gcloud compute url-maps add-path-matcher web-map \\ --default-service backend-service-port2 \\ --path-matcher-name pathmap-port2 \\ --path-rules=/happy=backend-service-port1,/unhappy=backend-service-port2,/sad=backend-service-port3 \\ --new-hosts=monday.com.tw 以下範例同上，當 request 為 tuesday.com.tw 時，導向 backend-service-port3 gcloud compute url-maps add-path-matcher web-map \\ --default-service backend-service-port3 \\ --path-matcher-name pathmap-port3 \\ --new-hosts=tuesday.com.tw 建立 SSL 憑證要讓我們的服務支援 HTTPS, 我們需要建立 ssl-certificates, ssl-certificates 分成 self-managed, 以及 google-managed。 self-managed 顧名思義就是你提供你自己的 ssl 簽證，以下範例採用 google-managed 可參考官方文件 gcloud beta compute ssl-certificates create www-ssl-cert \\ --domains sunday.com.tw,monday.com.tw,tuesday.com.tw HTTP proxy所有來自 HTTP 的請求，都會先到這裡，再經由我們剛剛建立的 url-map 導向指定的 backend-service 可參考官方文件 建立 HTTP proxy gcloud compute target-http-proxies create http-lb-proxy \\ --url-map web-map HTTPS proxy所有來自 HTTPS 的請求，都會先到這裡，再經由我們剛剛建立的 url-map 導向指定的 backend-service 並且，我們剛剛建立的 ssl-certificates 也要掛在這, 這樣 target-https-proxies 才能支援 HTTPS 可參考官方文件 建立 HTTPS proxy gcloud compute target-https-proxies create https-lb-proxy \\--url-map web-map \\--ssl-certificates www-ssl-cert 查看外部靜態 IP 清單列出我們一開始建立的 addresses 可參考官方文件 gcloud compute addresses list 轉發規則當 request 的 address 以及 port 符合 forwarding-rules, 導向指定的 target-http-proxy 下面範例的 [LB_IP_ADDRESS] 請替換為上面建立的靜態 IP 可參考官方文件 建立 HTTP forwarding-rules gcloud compute forwarding-rules create http-content-rule \\ --address [LB_IP_ADDRESS] \\ --global \\ --target-http-proxy http-lb-proxy \\ --ports 80 當 request 的 address 以及 port 符合 forwarding-rules, 導向指定的 target-https-proxy 下面範例的 [LB_IP_ADDRESS] 請替換為上面建立的靜態 IP 可參考官方文件 建立 HTTPS forwarding-rules gcloud compute forwarding-rules create https-content-rule \\ --address [LB_IP_ADDRESS] \\ --global \\ --target-https-proxy https-lb-proxy \\ --ports 443 總結以上便是 GCP Load Balancer 的 gcloud 各元件順序流程，順序如下：request =&gt; forwarding-rules =&gt; target-http(s)-proxy =&gt; url-map =&gt; backend-service =&gt; instance-group =&gt; instance 照著以上範例跑完之後，只要在 instance 跑服務，並且跑在範例上指定的 port 號，那 request 應會照著上面的順序到達我們的服務。 我花了不少時間來寫這篇文章，希望有幫到需要的人，如果你已經看到這裡，很感謝你把它看完了！ 最後，如果你覺得這篇文章有幫到你，或者你覺得寫得不錯，你的掌聲將是對我最大的鼓勵！ 如果有發現任何錯誤，還請不吝指教哦！","link":"/zh-tw/GCPLoadBalancer/"},{"title":"在 Server 上部署 Laravel 專案","text":"前言本篇紀錄如何在 AWS EC2 上部署 Laravel 專案主要有以下重點： LAMP 部署 Composer 部署 Laravel 部署 規格 Amazon Linux AMI 2018.03.0 (HVM), SSD Volume Type LAMPPHP 安裝 PHP sudo yum install php72;php -v 安裝 PHP Extension sudo yum install php72-mbstring sudo yum install php72-bcmath sudo yum install php72-pdo sudo yum install php72-mysqlnd sudo yum install php72-gd.x86_64 Apache 安裝 Apache sudo yum install httpd24 啟動 Apache sudo service httpd start 設定開機自動重啟 Apache sudo chkconfig httpd on 確認 httpd 已啟用 chkconfig --list httpd 設定 AWS security inbound 測試 Apache 運作，拜訪 IP 安裝 SSL module sudo yum install mod24_ssl MySQL 安裝 MySQL sudo yum install mysql57-server 啟動 MySQL sudo service mysqld start 設定 MySQL 於 Reboot 時自動重啟 sudo chkconfig mysqld on 執行 mysql_secure_installation sudo mysql_secure_installation 設定MySQL支援Sequel Pro 遠端連接 CREATE USER 'root'@'%' IDENTIFIED BY '';GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' WITH GRANT OPTION;FLUSH PRIVILEGES; 設定檔案許可 將您的使用者 (在此案例中為 ec2-user) 新增至 apache 群組 sudo usermod -a -G apache ec2-user 登出並重新登入，以取得新的群組並驗證您的成員資格。 登出 (使用 exit 命令或關閉終端機視窗)： exit 若要在 apache 群組中驗證您的會員資格，請重新連線至您的執行個體，然後執行下列命令： groups 將 /var/www 的群組所有權及其內容變更為 apache 群組。 sudo chown -R ec2-user:apache /var/www 若要新增群組寫入許可並在將來的子目錄上設定群組 ID，請變更 /var/www 及其子目錄的目錄許可。 sudo chmod 2775 /var/wwwfind /var/www -type d -exec sudo chmod 2775 &#123;&#125; \\; 若要新增群組寫入許可，請以遞迴方式變更 /var/www 及其子目錄的檔案許可： find /var/www -type f -exec sudo chmod 0664 &#123;&#125; \\; 測試您的 LAMP Web 伺服器 在 Apache 文件根資料夾中建立 PHP 檔案。 echo \"&lt;?php phpinfo(); ?&gt;\" &gt; /var/www/html/phpinfo.php 在 Web 瀏覽器中，輸入您剛才建立的檔案 URL。此 URL 為您執行個體的公有 DNS 地址，其後跟隨斜線和檔案名稱。例如： http://my.public.dns.amazonaws.com/phpinfo.php 刪除 phpinfo.php 檔案。雖然這可能是有用的資訊，但基於安全因素，您不應將其廣播至網際網路。rm /var/www/html/phpinfo.php Composer 安裝 Composer php -r \"copy('https://getcomposer.org/installer', 'composer-setup.php');\"php -r \"if (hash_file('sha384', 'composer-setup.php') === '48e3236262b34d30969dca3c37281b3b4bbe3221bda826ac6a9a62d6444cdb0dcd0615698a5cbe587c3f0fe57a54d8f5') &#123; echo 'Installer verified'; &#125; else &#123; echo 'Installer corrupt'; unlink('composer-setup.php'); &#125; echo PHP_EOL;\"php composer-setup.phpphp -r \"unlink('composer-setup.php');\" 讓 Composer 可被 Global 使用 sudo mv composer.phar /usr/local/bin/composer Git 安裝 Gitsudo yum install -y git 部署專案 Clone 專案 git clone repositoryAddress 部署 .env 檔 cp .env.example .env 安裝 Composer composer install 產生 key php artisan key:generate 建立資料庫 mysql -urootcreate database databaseName; 建立表格 php artisan migrate 若記憶體不足，可劃分磁碟為替代記憶體 sudo dd if=/dev/zero of=/swapfile bs=1M count=2000;sudo chmod 600 /swapfile;sudo mkswap /swapfile;sudo swapon /swapfile;swapon -s;sudo vim /etc/fstab; 加入以下 code/swapfile swap swap defaults 0 0 更改 Apache 的預設讀取資料夾位置sudo vim /etc/httpd/conf/httpd.conf &lt;Direction \"/var/www/html\"&gt; Allow Override All&lt;/Direction&gt; 以上為正規流程，以下為懶人版 懶人版sudo yum install -y php72;sudo yum install -y php72-mbstring;sudo yum install -y php72-bcmath;sudo yum install -y php72-pdo;sudo yum install -y php72-mysqlnd;sudo yum install -y httpd24;sudo yum install -y sudo yum install php72-gd.x86_64sudo service httpd start;sudo chkconfig httpd on;sudo yum install -y mod24_ssl;sudo yum install -y mysql57-server;sudo service mysqld start;sudo chkconfig mysqld on;sudo usermod -a -G apache ec2-user;sudo chown -R ec2-user:apache /var/www;sudo chmod 2775 /var/wwwfind /var/www -type d -exec sudo chmod 2775 &#123;&#125; \\;find /var/www -type f -exec sudo chmod 0664 &#123;&#125; \\;php -r \"copy('https://getcomposer.org/installer', 'composer-setup.php');\"php -r \"if (hash_file('sha384', 'composer-setup.php') === '48e3236262b34d30969dca3c37281b3b4bbe3221bda826ac6a9a62d6444cdb0dcd0615698a5cbe587c3f0fe57a54d8f5') &#123; echo 'Installer verified'; &#125; else &#123; echo 'Installer corrupt'; unlink('composer-setup.php'); &#125; echo PHP_EOL;\"php composer-setup.php;php -r \"unlink('composer-setup.php');\";sudo mv composer.phar /usr/local/bin/composer;sudo yum install -y git;sudo php -v 設定 AWS security inbound 測試 Apache 運作，拜訪 IP 執行 mysql_secure_installation sudo mysql_secure_installation 設定MySQL支援Sequel Pro 遠端連接 CREATE USER 'root'@'%' IDENTIFIED BY '';GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' WITH GRANT OPTION;FLUSH PRIVILEGES; 登出並重新登入，以取得新的群組並驗證您的成員資格。 登出 (使用 exit 命令或關閉終端機視窗)： exit 若要在 apache 群組中驗證您的會員資格，請重新連線至您的執行個體，然後執行下列命令： groups 在 Apache 文件根資料夾中建立 PHP 檔案。 echo \"&lt;?php phpinfo(); ?&gt;\" &gt; /var/www/html/phpinfo.php 在 Web 瀏覽器中，輸入您剛才建立的檔案 URL。此 URL 為您執行個體的公有 DNS 地址，其後跟隨斜線和檔案名稱。例如： http://my.public.dns.amazonaws.com/phpinfo.php 刪除 phpinfo.php 檔案。雖然這可能是有用的資訊，但基於安全因素，您不應將其廣播至網際網路。 rm /var/www/html/phpinfo.php Clone 專案 git clone repositoryAddress 部署 .env 檔 cp .env.example .env 安裝 Composer composer install 產生 key php artisan key:generate 建立資料庫 mysql -urootcreate database databaseName; 建立表格 php artisan migrate 若記憶體不足，可劃分磁碟為替代記憶體 sudo dd if=/dev/zero of=/swapfile bs=1M count=2000;sudo chmod 600 /swapfile;sudo mkswap /swapfile;sudo swapon /swapfile;swapon -s;sudo vim /etc/fstab; 加入以下 code/swapfile swap swap defaults 0 0 更改 Apache 的預設讀取資料夾位置sudo vim /etc/httpd/conf/httpd.conf &lt;Direction \"/var/www/html\"&gt; Allow Override All&lt;/Direction&gt; 重啟 Apachesudo service httpd restart 規格 GCP- CentOS 7 LAMPPHP 更新鏡像站 yum install epel-release;rpm -Uvh http://rpms.famillecollet.com/enterprise/remi-release-7.rpm 安裝 PHP sudo apt-get install php72;php -v 安裝 PHP Extension sudo apt-get install php7.2-mbstring sudo apt-get install php7.2-bcmath sudo apt-get install php7.2-mysqlnd sudo apt-get install php7.2-gd sudo apt-get install php-simplexml sudo apt-get install php7.2-zip sudo apt-get install php7.2-curl sudo apt install zip;sudo apt install unzip Apache 安裝 Apache sudo apt install apache2 啟動 Apache sudo service apache2 start 設定開機自動重啟 Apache sudo systemctl enable apache2 確認 Apache 已啟用 sudo systemctl is-enabled apache2 設定 AWS security inbound 測試 Apache 運作，拜訪 IP 啟動 SSL module sudo a2enmod ssl;sudo service apache2 restart MySQL 安裝 MySQL sudo apt install mysql-server 啟動 MySQL sudo systemctl start mysql 設定 MySQL 於 Reboot 時自動重啟 sudo systemctl is-enabled mysql 執行 mysql_secure_installation sudo mysql_secure_installation 設定MySQL支援Sequel Pro 遠端連接 CREATE USER 'root'@'%' IDENTIFIED BY 'yourPassword';GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' WITH GRANT OPTION;FLUSH PRIVILEGES; GCP 要特別開權限 LOCAL_IP=$(curl http://metadata.google.internal/computeMetadata/v1/instance/network-interfaces/0/ip \\ -H \"Metadata-Flavor: Google\")sudo sed -i \"s|bind-address.*|bind-address = $LOCAL_IP|\" /etc/mysql/mysql.conf.d/mysqld.cnf 更多設定可參考官方文件 設定檔案許可 將您的使用者 (在此案例中為 ec2-user) 新增至 apache 群組 sudo usermod -a -G www-data yourUserName 登出並重新登入，以取得新的群組並驗證您的成員資格。 登出 (使用 exit 命令或關閉終端機視窗)： exit 若要在 apache 群組中驗證您的會員資格，請重新連線至您的執行個體，然後執行下列命令： groups 將 /var/www 的群組所有權及其內容變更為 apache 群組。 sudo chown -R yourUserName:www-data /var/www 若要新增群組寫入許可並在將來的子目錄上設定群組 ID，請變更 /var/www 及其子目錄的目錄許可。 sudo chmod 2775 /var/wwwfind /var/www -type d -exec sudo chmod 2775 &#123;&#125; \\; 若要新增群組寫入許可，請以遞迴方式變更 /var/www 及其子目錄的檔案許可： find /var/www -type f -exec sudo chmod 0664 &#123;&#125; \\; 測試您的 LAMP Web 伺服器 在 Apache 文件根資料夾中建立 PHP 檔案。 echo \"&lt;?php phpinfo(); ?&gt;\" &gt; /var/www/html/phpinfo.php 在 Web 瀏覽器中，輸入您剛才建立的檔案 URL。此 URL 為您執行個體的公有 DNS 地址，其後跟隨斜線和檔案名稱。例如： http://my.public.dns.amazonaws.com/phpinfo.php 刪除 phpinfo.php 檔案。雖然這可能是有用的資訊，但基於安全因素，您不應將其廣播至網際網路。rm /var/www/html/phpinfo.php Composer 安裝 Composer php -r \"copy('https://getcomposer.org/installer', 'composer-setup.php');\"php -r \"if (hash_file('sha384', 'composer-setup.php') === '48e3236262b34d30969dca3c37281b3b4bbe3221bda826ac6a9a62d6444cdb0dcd0615698a5cbe587c3f0fe57a54d8f5') &#123; echo 'Installer verified'; &#125; else &#123; echo 'Installer corrupt'; unlink('composer-setup.php'); &#125; echo PHP_EOL;\"php composer-setup.phpphp -r \"unlink('composer-setup.php');\" 讓 Composer 可被 Global 使用 sudo mv composer.phar /usr/local/bin/composer Git 安裝 Gitsudo apt install -y git 部署專案 Clone 專案 git clone repositoryAddress 部署 .env 檔 cp .env.example .env 安裝 Composer composer install 產生 key php artisan key:generate 確認 MySQL root 登入方式 SELECT user, plugin, host FROM mysql.user; 更改登入 root 的方式 ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'yourPassword';FLUSH PRIVILEGES 建立資料庫 mysql -urootcreate database databaseName; 建立表格 php artisan migrate 若記憶體不足，可劃分磁碟為替代記憶體 sudo dd if=/dev/zero of=/swapfile bs=1M count=2000;sudo chmod 600 /swapfile;sudo mkswap /swapfile;sudo swapon /swapfile;swapon -s;sudo vim /etc/fstab; 加入以下 code/swapfile swap swap defaults 0 0 更改 Apache 的預設讀取資料夾位置sudo vim /etc/httpd/conf/httpd.conf &lt;Direction \"/var/www/html\"&gt; Allow Override All&lt;/Direction&gt; 以上為正規流程，以下為懶人版 懶人版sudo yum install -y php72;sudo yum install -y php72-mbstring;sudo yum install -y php72-bcmath;sudo yum install -y php72-pdo;sudo yum install -y php72-mysqlnd;sudo yum install -y httpd24;sudo yum install php72-gd.x86_64sudo service httpd start;sudo chkconfig httpd on;sudo yum install -y mod24_ssl;sudo yum install -y mysql57-server;sudo service mysqld start;sudo chkconfig mysqld on;sudo usermod -a -G apache ec2-user;sudo chown -R ec2-user:apache /var/www;sudo chmod 2775 /var/wwwfind /var/www -type d -exec sudo chmod 2775 &#123;&#125; \\;find /var/www -type f -exec sudo chmod 0664 &#123;&#125; \\;php -r \"copy('https://getcomposer.org/installer', 'composer-setup.php');\"php -r \"if (hash_file('sha384', 'composer-setup.php') === '48e3236262b34d30969dca3c37281b3b4bbe3221bda826ac6a9a62d6444cdb0dcd0615698a5cbe587c3f0fe57a54d8f5') &#123; echo 'Installer verified'; &#125; else &#123; echo 'Installer corrupt'; unlink('composer-setup.php'); &#125; echo PHP_EOL;\"php composer-setup.php;php -r \"unlink('composer-setup.php');\";sudo mv composer.phar /usr/local/bin/composer;sudo yum install -y git;sudo php -v 設定 AWS security inbound 測試 Apache 運作，拜訪 IP 執行 mysql_secure_installation sudo mysql_secure_installation 設定MySQL支援Sequel Pro 遠端連接 CREATE USER 'root'@'%' IDENTIFIED BY '';GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' WITH GRANT OPTION;FLUSH PRIVILEGES; 登出並重新登入，以取得新的群組並驗證您的成員資格。 登出 (使用 exit 命令或關閉終端機視窗)： exit 若要在 apache 群組中驗證您的會員資格，請重新連線至您的執行個體，然後執行下列命令： groups 在 Apache 文件根資料夾中建立 PHP 檔案。 echo \"&lt;?php phpinfo(); ?&gt;\" &gt; /var/www/html/phpinfo.php 在 Web 瀏覽器中，輸入您剛才建立的檔案 URL。此 URL 為您執行個體的公有 DNS 地址，其後跟隨斜線和檔案名稱。例如： http://my.public.dns.amazonaws.com/phpinfo.php 刪除 phpinfo.php 檔案。雖然這可能是有用的資訊，但基於安全因素，您不應將其廣播至網際網路。 rm /var/www/html/phpinfo.php Clone 專案 git clone repositoryAddress 部署 .env 檔 cp .env.example .env 安裝 Composer composer install 產生 key php artisan key:generate 建立資料庫 mysql -urootcreate database databaseName; 建立表格 php artisan migrate 若記憶體不足，可劃分磁碟為替代記憶體 sudo dd if=/dev/zero of=/swapfile bs=1M count=2000;sudo chmod 600 /swapfile;sudo mkswap /swapfile;sudo swapon /swapfile;swapon -s;sudo vim /etc/fstab; 加入以下 code/swapfile swap swap defaults 0 0 更改 Apache 的預設讀取資料夾位置sudo vim /etc/httpd/conf/httpd.conf &lt;Direction \"/var/www/html\"&gt; Allow Override All&lt;/Direction&gt; 重啟 Apachesudo service httpd restart 確認 OS 種類以及版本 使用 lsb_release ， 如果沒安裝的話，安裝它 sudo apt-get install lsb-release 查詢用法 lsb_release --help 輸出如下：-h, --help show this help message and exit-v, --version show LSB modules this system supports-i, --id show distributor ID-d, --description show description of this distribution-r, --release show release number of this distribution-c, --codename show code name of this distribution-a, --all show all of the above information-s, --short show requested information in short format 根據上面的資訊，想查詢明細的話 lsb_release -a 只想知道 Kernel 版本的話 uname -r","link":"/zh-tw/AWSLaravelDeployment/"},{"title":"取得 Facebook 長期權杖 (long lived token)，以及 永不過期權杖 (never expired token)","text":"前言本篇將分享如何利用 Facebook 的圖形 API 測試工具，以及 PHP 來取得長期權杖 (long lived token)，以及永不過期權杖 (never expired token)目前正在做一個 Facebook 的直播拍賣優化系統的後端，發現前端的短期 (short lived token) 權杖有效時間只有不到兩個小時，相較於 Android 的三個月，以及 iOS 的兩個月，實在是有夠短。雖然說 code 寫好之後其實也無所謂，但是就想來研究一下如何拿到長期的權杖 (long lived token) Facebook 的圖形 API 測試工具長期權杖 (long lived token)首先，讓我們先用 Facebook 的圖形 API 來拿長期權杖 (long lived token) 測試帳號 取得測試測試帳號權杖 圖形 API 測試工具 輸入剛剛獲得的權杖 按下’提交’ 按下權杖左邊的驚嘆號，並選擇，以存取權杖工具開啟 點擊左下方的，延伸存取權杖 得到兩個月的長期權杖 (long lived token) 永不過期的粉絲專頁權杖接下來，讓我們使用 Facebook 的圖形 API 測試工具來取得永不過期的權杖 (never expired token) 首先，讓我們登入測試帳號，並申請一個粉絲團 跟上面的流程完全一模一樣，我們就可以拿到永不過期的權杖 (never expired token) PHP長期權杖 (long lived token)現在讓我們使用 PHP 來透過呼叫 Facebook 的 API 來取得長期權杖 (long lived token) 使用 PHP 的 function file_get_contents來呼叫 Facebook 的 API public static function getLongLivedToken($token)&#123; $url = 'https://graph.facebook.com/oauth/access_token?grant_type=fb_exchange_token&amp;client_id=yourClientID&amp;client_secret=yourClientSecret&amp;fb_exchange_token=shortLivedToken; return json_decode(file_get_contents($url), true);&#125; 會得到以下資訊: &#123; \"result\": true, \"response\": &#123; \"access_token\": \"EAAEpKfFACZA8BAGyTFU29VFIlEjhDaUe66eliyWdGQDfVTBUUdFZBZAGeZBEgTEwxgthvdABuzECYi1ahqm8ZCYNRSV9YMnegq7XxCouP1sR8kXMdnNFysGb2IHZBhSB3KENeTZCBzHrFSJ9BJLt9k6xkuWkJsVHnG0KahmFmybKTG6pVaFoZATN\", \"expires_in\": 5182393 &#125;&#125; 結語至於如何利用 PHP 來取得永不過期的粉絲專頁權杖 (never expired token)，似乎需要提升 APP 的權限，這方面需要審查，所以我就暫時無法測試啦。","link":"/zh-tw/FacebookLongLivedToken/"},{"title":"設定 Network 以及 HTTP 平衡負載器","text":"前言本篇主要是利用 Google 的 Qwiklab 平台學習的同時，做的一份學習筆記 概述在這個教程中，你將會學習 network load balance 與 HTTP load balance 之間的不同，以及如何正確地根據你的應用來設定，讓你的應用在 Google Compute Engine VM 上運行平衡負載的功能。有好幾種方法可以在Google Cloud Platform 上實施平衡負載。 本教程會帶你走過以下兩種負載器的設定： L3 Network Load Balancer L7 HTTP(s) Load Balancer 學生們會建議自己輸入指令，這對學習核心概念有幫助。 很多教程中，都會有代碼區塊，可以直接複製需要的代碼，你可以很簡單的從代碼區塊複製貼上這些指令到教程中適當的位置。 你將會做什麼 設定一個網路平衡負載器 設定一個 HTTP(S) 平衡負載器 通過實作，學習兩者之間的不同之處 設定及要求 在你按下 Start Lab 按鈕之前 詳讀所有的教學。Labs 是有時間限制的，而且你不可以停止時間倒數。倒數計時器在你按下 Start Lab 按鈕後開始倒數，上面顯示的時間為你還能使用 Cloud 資源的時間。 Qwiklabs 的手把手環境，讓你可以在真實環境中來操作進行 Qwiklabs 上提供的課程，而不是在一個模擬或是展示的環境。我們透過提供你一個全新的、暫時的帳號密碼，在計時器歸零之前，你可以用來登入並存取 Google Cloud Platform。 你需要什麼？ 要完成這個 lab ，你需要: 一個一般的網路瀏覽器（推薦 Chrome） 完成這個 lab 的時間 備註： 如果你已經有你自己的個人 GCP 帳號或專案，請不要使用在這一個 lab 現在你已經開始你的 lab, 你將會登入 Google Cloud Shell 主控台，然後開啟命令列工具 如何開始你的 lab ，然後登入 Console? 按下 Start Lab 按鈕。如果你需要付費，會有一個彈出視窗來讓你選擇付費的方式。在左方你會看到一個面板，上面有暫時的帳號密碼，你必須使用這些帳號密碼在此次 lab 複製 username , 然後點擊 Open Google Console。 Lab 會開啟另外一個視窗，顯示選擇帳號的頁面 tip: 開啟一個全新的視窗，然後跟原本的頁面並排 在選擇帳號頁面, 點擊 Use Another Account 登入頁面開啟，貼上之前複製的 username 以及 password ，然後貼上 重要：必須使用之前於 Connection Details 面板 取得的帳號密碼，不要使用你自己的 Qwiklabs 帳號密碼。 如果你有自己的 GCP 帳號，請不要用在這裡（避免產生費用） 點擊並通過接下來的頁面: 接受terms以及conditions 不要增加recovery optoins 或 two factor authentication (因為這只是一個臨時帳號) 不要註冊免費體驗 稍待一些時候， GCP 控制台將會在這個視窗開啟。 注意：按下左上方位於Google Cloud Platform 隔壁的 Navigation menu ，你可以瀏覽選單，裡面有一系列的 GCP 產品以及服務 啟動 Google Cloud ShellGoogle Cloud Shell 是載有開發工具的虛擬機器。它提供了5GB的 home 資料夾，並且運行在 Google Cloud 上。 Google Cloud Shell 讓你可以利用 command-line 存取 GCP 資源 在 GCP 控制台 ，右上的工具列，點擊 Open Cloud Shell 按鈕 在打開的對話框裡，按下 START CLOUD SHELL: 你可以立即按下 START CLOUD SHELL 當對話視窗打開。 連結並提供環境會需要一點時間。當你連結成功，這代表你已成功獲得授權，且此專案已被設為你的專案ID，例如： gcloud 是 Google Cloud Platform 的 command-line 工具，他已事先被安裝在 Cloud Shell 並且支援自動補齊 使用這個 command ,你可以列出有效帳戶名稱: gcloud auth list 輸出: Credentialed accounts: - &lt;myaccount&gt;@&lt;mydomain&gt;.com (active) 範例輸出: Credentialed accounts: - google1623327_student@qwiklabs.net 你可以使用以下 command 來列出專案 ID gcloud config list project 輸出： [core]project = &lt;project_ID&gt; 範例輸出： [core]project = qwiklabs-gcp-44776a13dea667a6 gcloud 的完整文件可以參閱 Google Cloud gcloud Overview 為你的資源設定預設的 region 以及 zone 在 Cloud Shell ，設定預設 zone gcloud config set compute/zone us-central1-a 在 Cloud Shell ，設定預設 region gcloud config set compute/region us-central1 建立多個 web server instance為了模擬使用一個群組的機器來服務，我們可以利用 Instance Template 以及 Managed Instance Groups 來創建一個群集的 Nginx web servers 用以服務靜態的內容。 Instance Template 定義了在這個群組中的 virtual machine 的規格（ disk, CPUs, memory, 等等）。 Managed Instance Groups 可以初始化多台使用 Instance Template 定義的 virtual machine 要建立一個 Nginx web server 服務群，建立以下事物: 一份用來設定所有 virtual machine 上的 Nginx server 的 script 一份 instance template 來使用上述的 script 一個 target pool 一個使用 instance template 的 managed instance group 在 Cloud Shell 中，建立一個使用在所有 VM 上的 startup script。 這個腳本會在一開始時設定 Nginx servercat &lt;&lt; EOF &gt; startup.sh#! /bin/bashapt-get updateapt-get install -y nginxservice nginx startsed -i -- 's/nginx/Google Cloud Platform - '\"\\$HOSTNAME\"'/' /var/www/html/index.nginx-debian.htmlEOF 建立使用 startup script 的 instance template gcloud compute instance-templates create nginx-template \\ --metadata-from-file startup-script=startup.sh (輸出)Created [...].NAME MACHINE_TYPE PREEMPTIBLE CREATION_TIMESTAMPnginx-template n1-standard-1 2015-11-09T08:44:59.007-08:00 建立 target pool 。一個 target pool 將針對所有的群組內的 instance 提供一個存取點，且在之後的平衡負載步驟，這是必須的。gcloud compute target-pools create nginx-pool (輸出)Created [...].NAME REGION SESSION_AFFINITY BACKUP HEALTH_CHECKSnginx-pool us-central1 建立一個使用 instance template 的 managed instance group gcloud compute instance-groups managed create nginx-group \\ --base-instance-name nginx \\ --size 2 \\ --template nginx-template \\ --target-pool nginx-pool (輸出)Created [...].NAME LOCATION SCOPE BASE_INSTANCE_NAME SIZE TARGET_SIZE INSTANCE_TEMPLATE AUTOSCALEDnginx-group us-central1-a zone nginx 0 2 nginx-template no 這將會建立兩個擁有相同前綴名稱 nginx-的vurtual machine ，需要幾分鐘。 檢視所有已建立的 instancesgcloud compute instances list (輸出)NAME ZONE MACHINE_TYPE PREEMPTIBLE INTERNAL_IP EXTERNAL_IP STATUSnginx-7wvi us-central1-a n1-standard-1 10.240.X.X X.X.X.X RUNNINGnginx-9mwd us-central1-a n1-standard-1 10.240.X.X X.X.X.X RUNNING 現在設定防火牆，所以我們可以經由 port 80，EXTERNAL_IP 位址來連接我們的機器 gcloud compute firewall-rules create www-firewall --allow tcp:80 現在我們應該要可以經由上述的 external IP 位址連接到任何一台的 instance 測試進度點擊 Check my progress 來確認目前的進度。如果你已經完成目前的進度，你將獲得一個評價分數。 建立Network Load BalancerNetwork Load Balancing 允許我們依據收到的 IP 協議資料，像是位址， port 號，還有協議類型，來平衡負載我們的系統。我們還可以取得一些 HTTP(S) load balancing 沒有提供的選項，例如說，基於 TCP/UDP 的協議, 像是 SMTP traffic ，且如果你的應用對 TCP 連結相關的特性感興趣的話， Network Load Balacing 也允許你的 app 去檢查封包，這是 HTTP(S) Load Balancing 沒有提供的。 更多資訊，可以參考Setting Up Network Load Balancing 針對我們的 instance ，建立一個 L3 network load balancer gcloud compute forwarding-rules create nginx-lb \\ --region us-central1 \\ --ports=80 \\ --target-pool nginx-pool (輸出)Created [https://www.googleapis.com/compute/v1/projects/...]. 列出所有 Google Compute Engine 轉發的規則 gcloud compute forwarding-rules list (輸出)NAME REGION IP_ADDRESS IP_PROTOCOL TARGETnginx-lb us-central1 X.X.X.X TCP us-central1/targetPools/nginx-pool 經由瀏覽器來拜訪 load balancerhttp://IP_ADDRESS/IP_ADDRESS 可從上一個指令輸出中找到 測試進度點擊 Check my progress 來確認目前的進度。如果你已經完成目前的進度，你將獲得一個評價分數。 建立一個 HTTP(S) Load BalancerHTTP(S) Load Balancing 提供全球性的所有對我們的 instance 所做的請求。我們可以設定 URL 規則來將某些 URL 導向一些 instance ，而將另一些 URL 導向另外一些 instance 。正常下，請求將會被導向離使用者最近的 instance ，以確保該群組的 instance 有足夠的資源可以提供給使用者。如果被導向的 instance 沒有足夠的資源，那請求將會被導向離使用者最近的並且有足夠資源的 instance 更多資訊可以參考 HTTP(s) Load Balancer in the documentation 首先，建立一個 health check 。 Health check 可以核實 instance 有針對 HTTP 或 HTTPS 通道做回應 gcloud compute http-health-checks create http-basic-check (輸出)Created [https://www.googleapis.com/compute/v1/projects/...].NAME HOST PORT REQUEST_PATHhttp-basic-check 80 / 定義一個 HTTP 服務，並且給予我們 instance 使用的 port 號, 現在平衡負載服務已經將流量轉發到指定的 portgcloud compute instance-groups managed \\ set-named-ports nginx-group \\ --named-ports http:80 (輸出)Updated [https://www.googleapis.com/compute/v1/projects/...]. 建立 後端服務gcloud compute backend-services create nginx-backend \\ --protocol HTTP --http-health-checks http-basic-check --global (輸出)Created [https://www.googleapis.com/compute/v1/projects/...].NAME BACKENDS PROTOCOLnginx-backend HTTP 將我們的 instance 群組加到後端服務:gcloud compute backend-services add-backend nginx-backend \\ --instance-group nginx-group \\ --instance-group-zone us-central1-a \\ --global (輸出)Updated [https://www.googleapis.com/compute/v1/projects/...]. 建立一個預設的 URL 指定，他將會把所有收到的請求導向我們的 instancegcloud compute url-maps create web-map \\ --default-service nginx-backend (輸出)Created [https://www.googleapis.com/compute/v1/projects/...].NAME DEFAULT_SERVICEWeb-map nginx-backend 若要直接將流量基於請求的 URL 不同，導向不同的 instance, 請參考 content-based routing 建立一個 target HTTP proxy 來將請求導向我們的 URL mapgcloud compute target-http-proxies create http-lb-proxy \\ --url-map web-map (輸出)Created [https://www.googleapis.com/compute/v1/projects/...].NAME URL_MAPhttp-lb-proxy web-map 建立一個全球轉發規則來處理導向所有收到的請求。一個轉發規則將流量送到指定的 HTTP 或 HTTPS 代理根據請求的 IP 位址， IP 協議，或特定的 port 號。全球轉發規則不支援多個 port gcloud compute forwarding-rules create http-content-rule \\ --global \\ --target-http-proxy http-lb-proxy \\ --ports 80 (輸出)Created [https://www.googleapis.com/compute/v1/projects/...]. 全球轉發規則建立之後，需要幾分鐘時間生效gcloud compute forwarding-rules list (輸出)NAME REGION IP_ADDRESS IP_PROTOCOL TARGEThttp-content-rule X.X.X.X TCP http-lb-proxynginx-lb us-central1 X.X.X.X TCP us-central1/.... 我們現在應該要可以從瀏覽器經由http://IP_ADDRESS/來連接，這可能會需要幾分鐘生效。如果無法連接，多等一些時間，重新整理瀏覽器。 測試進度點擊 Check my progress 來確認目前的進度。如果你已經完成目前的進度，你將獲得一個評價分數。 測試你的理解下面有多重選擇的問題來鞏固你對本教程概念的理解，盡你所能的回答吧： 答案是 true 恭喜你已經完成本教程","link":"/zh-tw/HTTPAndNetworkLoadBalancer/"},{"title":"Laravel串接歐付寶第三方金流支付","text":"建立Laravel專案Laravel new AllPay 一開始先Git，這幾乎是一定要的啊！git init 下載歐付寶SDK，本篇使用PHP SDKgit clone https://github.com/o-pay/Payment_PHP 將SDK移到Laravel裡頭的app底下 cp Payment_PHP/sdk/AllPay.Payment.Integration.php AllPay/app/ 建立等等測試用的Controllerphp artisan make:controller PaymentsController 從剛剛的SDK包裡面，複製example到我們的controller裡，本篇使用All的example，如下：/****/ //載入SDK(路徑可依系統規劃自行調整) include('AllPay.Payment.Integration.php'); try &#123; $obj = new AllInOne(); //服務參數 $obj-&gt;ServiceURL = \"https://payment-stage.opay.tw/Cashier/AioCheckOut/V5\"; //服務位置 $obj-&gt;HashKey = '5294y06JbISpM5x9' ; //測試用Hashkey，請自行帶入AllPay提供的HashKey $obj-&gt;HashIV = 'v77hoKGq4kWxNNIS' ; //測試用HashIV，請自行帶入AllPay提供的HashIV $obj-&gt;MerchantID = '2000132'; //測試用MerchantID，請自行帶入AllPay提供的MerchantID $obj-&gt;EncryptType = EncryptType::ENC_SHA256; //CheckMacValue加密類型，請固定填入1，使用SHA256加密 //基本參數(請依系統規劃自行調整) $MerchantTradeNo = \"Test\".time(); $obj-&gt;Send['ReturnURL'] = 'http://localhost/simple_ServerReplyPaymentStatus.php' ; //付款完成通知回傳的網址 $obj-&gt;Send['ReturnURL'] = 'http://gw.grazia.tw/sdk/op_sdk/op_payment/example/simple_ServerReplyPaymentStatus.php' ; //付款完成通知回傳的網址 $obj-&gt;Send['MerchantTradeNo'] = $MerchantTradeNo; //訂單編號 $obj-&gt;Send['MerchantTradeDate'] = date('Y/m/d H:i:s'); //交易時間 $obj-&gt;Send['TotalAmount'] = 2000; //交易金額 $obj-&gt;Send['TradeDesc'] = \"good to drink\"; //交易描述 $obj-&gt;Send['ChoosePayment'] = PaymentMethod::ALL; //付款方式:全功能 //訂單的商品資料 array_push($obj-&gt;Send['Items'], array('Name' =&gt; \"歐付寶黑芝麻豆漿\", 'Price' =&gt; (int)\"2000\", 'Currency' =&gt; \"元\", 'Quantity' =&gt; (int) \"1\", 'URL' =&gt; \"dedwed\")); # 電子發票參數 /* $obj-&gt;Send['InvoiceMark'] = InvoiceState::Yes; $obj-&gt;SendExtend['RelateNumber'] = $MerchantTradeNo; $obj-&gt;SendExtend['CustomerEmail'] = 'test@opay.tw'; $obj-&gt;SendExtend['CustomerPhone'] = '0911222333'; $obj-&gt;SendExtend['TaxType'] = TaxType::Dutiable; $obj-&gt;SendExtend['CustomerAddr'] = '台北市南港區三重路19-2號5樓D棟'; $obj-&gt;SendExtend['InvoiceItems'] = array(); // 將商品加入電子發票商品列表陣列 foreach ($obj-&gt;Send['Items'] as $info) &#123; array_push($obj-&gt;SendExtend['InvoiceItems'],array('Name' =&gt; $info['Name'],'Count' =&gt; $info['Quantity'],'Word' =&gt; '個','Price' =&gt; $info['Price'],'TaxType' =&gt; TaxType::Dutiable)); &#125; $obj-&gt;SendExtend['InvoiceRemark'] = '測試發票備註'; $obj-&gt;SendExtend['DelayDay'] = '0'; $obj-&gt;SendExtend['InvType'] = InvType::General; */ //產生訂單(auto submit至AllPay) $obj-&gt;CheckOut(); &#125; catch (Exception $e) &#123; echo $e-&gt;getMessage(); &#125; 我們將上面一些機敏資訊，移到Laravel的.env檔裡面，如下://服務位置$obj-&gt;HashKey = env('HASHKEY'); //測試用Hashkey，請自行帶入AllPay提供的HashKey$obj-&gt;HashIV = env('HASHIV'); //測試用HashIV，請自行帶入AllPay提供的HashIV$obj-&gt;MerchantID = env('MERCHANTID'); //測試用MerchantID，請自行帶入AllPay提供的MerchantID$obj-&gt;Send['ReturnURL'] = env('ALLPAYRETURNURL');//付款完成通知回傳的網址$obj-&gt;Send['ClientBackURL'] = $request-&gt;ClintBackURL;//付款完成後，於第三方頁面顯示回到我們服務的網址 .env檔內如下：ALLPAYRETURNURL=https://163be100.ngrok.io/api/paymentsResponseHASHKEY=5294y06JbISpM5x9HASHIV=v77hoKGq4kWxNNISMERCHANTID=2000132 使用use代替include 刪除 //載入SDK(路徑可依系統規劃自行調整)include('AllPay.Payment.Integration.php'); 新增AllPay.Payment.Integration.php到composer.json file \"autoload-dev\": &#123; \"psr-4\": &#123; \"Tests\\\\\": \"tests/\" &#125;, \"files\": [ \"app/Helpers.php\", \"app/AllPay.Payment.Integration.php\" ] 在terminal下達 composer dump-autoload` 在controller檔案裡，use新的class namespace App\\Http\\Controllers;use AllInOne;use EncryptType;use Exception;use Illuminate\\Http\\Request;use PaymentMethod; 建立金流訂單 (這部分屬個人表格設計，帶入參數每個人都不同)因為會一次性的寫入兩張表格，所以這邊會使用 Laravel 的 transaction 來寫入資料//總金額$totalAmount = Order::getTotalAmountForPayments($orders);//商品訂單編號$ordersName = Order::getOrdersNameForPayments($orders);//金流訂單編號$MerchantTradeNo = time() . Helpers::createAUniqueNumber();//金流訂單建立時間$MerchantTradeDate = date(&apos;Y/m/d H:i:s&apos;);//金流訂單敘述$TradeDesc = &apos;BuyBuyGo&apos;;//數量$quantity = 1;//因為同時建立兩張表格，這邊使用Laravel的transaction功能來防止資料庫資料不一//transaction開始DB::beginTransaction();//以下動作需全部完成無錯誤，否則終止並回朔try&#123; $payment_service_order = new PaymentServiceOrders(); $payment_service_order-&gt;user_id = User::getUserID($request); //金流服務商ID $payment_service_order-&gt;payment_service_id = $thirdPartyPaymentService-&gt;id; $payment_service_order-&gt;expiry_time = (new Carbon())-&gt;now()-&gt;addDay(1)-&gt;toDateTimeString(); $payment_service_order-&gt;MerchantID = env(&apos;MERCHANTID&apos;); $payment_service_order-&gt;MerchantTradeNo = $MerchantTradeNo; $payment_service_order-&gt;MerchantTradeDate = $MerchantTradeDate; $payment_service_order-&gt;TotalAmount = $totalAmount; $payment_service_order-&gt;TradeDesc = $TradeDesc; //商品訂單的編號 $payment_service_order-&gt;ItemName = $ordersName; $payment_service_order-&gt;save(); foreach ($orders as $order) &#123; $order_relations = new OrderRelations(); $order_relations-&gt;payment_service_id = $thirdPartyPaymentService-&gt;id; $order_relations-&gt;payment_service_order_id = $payment_service_order-&gt;id; $order_relations-&gt;order_id = $order-&gt;id; $order_relations-&gt;save(); &#125; //若有錯誤，則停止並回朔，回報自訂錯誤訊息&#125; catch (Exception $e)&#123; DB::rollBack(); return Helpers::result(&apos;false&apos;, &apos;Something went wrong with DB&apos;, 400);&#125;//若無錯誤，則寫入資料庫DB::commit(); 為PaymentsController建立一支API 到routes資料夾底下的api.php 增加routeRoute::post(&apos;pay&apos;, &apos;PaymentsController@pay&apos;); 建立一頁最簡單的的html 直接更改Laravel內建welcome.blade的內容，如下：&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Facebook Login JavaScript Example&lt;/title&gt; &lt;meta charset=&quot;UTF-8&quot;&gt;&lt;/head&gt;&lt;body&gt;// 這邊需輸入PaymentsController的API&lt;form action=&quot;/api/pay&quot; method=&quot;POST&quot;&gt; @csrf() &lt;input type=&quot;checkbox&quot; value=&quot;1&quot; name=&quot;order_id[]&quot;&gt; &lt;input type=&quot;checkbox&quot; value=&quot;2&quot; name=&quot;order_id[]&quot;&gt; &lt;input type=&quot;checkbox&quot; value=&quot;3&quot; name=&quot;order_id[]&quot;&gt; &lt;input type=&quot;hidden&quot; value=&quot;https://64b30ea0.ngrok.io/&quot; name=&quot;ClintBackURL&quot;&gt; &lt;button type=&quot;submit&quot;&gt;Submit&lt;/button&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 簡單傳送測試 到Laravel首頁，此時此頁面應已經變更為我們剛剛建立的簡單form頁面 什麼都不要勾選，點選submit 成功到了歐付寶的付款頁面 建立Log 為了要知道當我們成功付款之後，歐付寶會回傳什麼給我們，我們需要用Log來看看回傳的東西 有沒有一個地方，是所有的請求跟回饋都一定會進出通過，而且可以讓我們控制的？ 這似乎是個完美記log的地方 我們可以建立一個middleware，然後在middleware裏頭使用Laravel的Log功能，將所有進來的請求跟我們回饋的東西全都記下來 建立middleware 於terminal頁面php artisan make:middleware TestLog 註冊middleware 到/app/Http/Kernel.php檔案裡頭，加上我們剛剛建立的middleware protected $middleware = [ \\App\\Http\\Middleware\\CheckForMaintenanceMode::class, \\Illuminate\\Foundation\\Http\\Middleware\\ValidatePostSize::class, \\App\\Http\\Middleware\\TrimStrings::class, \\Illuminate\\Foundation\\Http\\Middleware\\ConvertEmptyStringsToNull::class, \\App\\Http\\Middleware\\TrustProxies::class, \\App\\Http\\Middleware\\TestLog::class,]; 建立Log 到我們剛剛建立的TestLog檔案裡頭，新增： $response = $next($request);log::info([$request-&gt;header(),$request-&gt;getMethod(),$request-&gt;getRequestUri(),$request-&gt;all(),$response-&gt;getStatusCode(),$response-&gt;getContent()]);return $response; 實際上，Log要記些什麼視乎每個人的需求 建立public url 我們要取得第三方回傳的資訊，所以我們必須要有一個public url來接收第三方的response 我們可以使用ngrok來取得public url 至ngrok官網安裝ngrok 將ngrok變更為可全域執行 mv ngrok /usr/local/bin 先取得public url，在terminal中 ngrok http 8000 在terminal中，位於AllPay專案資料夾內，開啟本機通道 php artisan serve 8000` 複製ngrok產生的public https url 建立接收的function 我們準備要來接歐付寶回傳的訊息了，我們需要建立一個function，並且接到之後，可以在裡面做我們想做的事 在PaymentsController裡頭，我們先建一個function receive，如下：public function receive()&#123; &#125; 針對此function，建立一個API Route::post(&apos;pay&apos;, &apos;PaymentsController@pay&apos;);Route::post(&apos;receive&apos;, &apos;PaymentsController@receive&apos;); 設定ReturnURL 於.env檔內，如有照之前步驟，應有以下參數，將複製的public url 貼上 ALLPAYRETURNURL=https://163be100.ngrok.io/api/recevie 你的連結跟我的不一樣哦，別貼我的 付款測試 再次連到歐付寶付款頁面 登入歐付寶提供的買家測試帳號 帳號： stageuser001 密碼： test1234 使用歐付寶提供的測試信用卡付款 卡號： 4311-9522-2222-2222 有效期限：請大於目前月/年，例：12 / 20 末三碼：222 付款後，我們到log去看一下有沒有收到歐付寶的回饋，於terminal，位於AllPay的資料夾內 cat storage/logs/laravel-2019-02-08.log` 咦，有收到歐付寶的回饋了！ &apos;MerchantID&apos; =&gt; &apos;2000132&apos;, &apos;MerchantTradeNo&apos; =&gt; &apos;Test1549597724&apos;, &apos;PayAmt&apos; =&gt; &apos;2000&apos;, &apos;PaymentDate&apos; =&gt; &apos;2019/02/08 11:49:03&apos;, &apos;PaymentType&apos; =&gt; &apos;Credit_CreditCard&apos;, &apos;PaymentTypeChargeFee&apos; =&gt; &apos;20&apos;, &apos;RedeemAmt&apos; =&gt; &apos;0&apos;, &apos;RtnCode&apos; =&gt; &apos;1&apos;, &apos;RtnMsg&apos; =&gt; &apos;交易成功&apos;, &apos;SimulatePaid&apos; =&gt; &apos;0&apos;, &apos;TradeAmt&apos; =&gt; &apos;2000&apos;, &apos;TradeDate&apos; =&gt; &apos;2019/02/08 11:48:44&apos;, &apos;TradeNo&apos; =&gt; &apos;1902081148440800&apos;, &apos;CheckMacValue&apos; =&gt; &apos;5B1EE24B0E9D600C65578DD82D3168E2ED56799453577E17E1EBEFC536BD7EAF&apos;, 驗證 試想，如果有人不小心知道了你的API，然後對方也是開發者，他如果跑到你的服務購買商品，然後呼叫你的API結帳，你如何辨別？ 所以說，第三方跟廠商會有一套只有雙方身份對了，驗證才能通過的機制 驗證機制大概就是，所以你傳出去的資料，每一項欄位，會經過一套只有雙方適用的公式下去計算，最後會得出一串CheckMacValue，眼尖的朋友應該已經看到，在我們收到的訊息最下面一個欄位帶的就是這串資料。 詳細的公式各位朋友可參照官方網站。 由於本篇使用官方的SDK，所以本篇將教大家如何使用官方SDK來驗證收到的資訊 首先，我們到官方SDK的檔案中app/AllPay.Payment.Integration.php，搜尋名為CheckMacValue的class CheckMacValue class裡頭，有一個名為generate的function，大家可以看一下它是怎麼寫的，這就是產生這串CheckMacValue的公式。 所以說，我們只要通過這套公式，驗證我們收到的訊息之中，除了CheckMacValue這個欄位的資訊，那理應得到跟回傳的CheckMacValue一模一樣的值 先取得回傳資訊中，除了CheckMacValue之外的所有資訊，我們可以使用以下的code $parameters = $paymentResponse-&gt;except(&apos;CheckMacValue&apos;); 再來，取得歐付寶回傳的CheckMacValue $receivedCheckMacValue = $paymentResponse-&gt;CheckMacValue; 接下來，使用官方的generate function，帶入我們收到的資訊，來產出正確的CheckMacValue $calculatedCheckMacValue = CheckMacValue::generate($parameters, env(&apos;HASHKEY&apos;), env(&apos;HASHIV&apos;), EncryptType::ENC_SHA256); 最後，比較兩者的值是否一樣？如果一樣，表示這則訊息的確來自歐付寶，如果不同，那此資訊沒有可信度 if($receivedCheckMacValue == $calculatedCheckMacValue) return true;return false; 驗證之後呢？ 確認資訊來源正確之後，我們就可以依據收到的資訊下去做事了！ 比方說，付款了做些什麼，付款失敗又做些什麼 本篇範例為收到付款之後，將資料庫內訂單標記付款，並發email通知買家，如下： if (PaymentServiceOrders::checkIfCheckMacValueCorrect($request) &amp;&amp; PaymentServiceOrders::checkIfPaymentPaid($request-&gt;RtnCode))&#123; $paymentServiceOrder = (new PaymentServiceOrders)-&gt;where(&apos;MerchantTradeNo&apos;, $request-&gt;MerchantTradeNo)-&gt;first(); $paymentServiceOrder-&gt;update([&apos;status&apos; =&gt; 1, &apos;expiry_time&apos; =&gt; null]); $orderRelations = $paymentServiceOrder-&gt;where(&apos;MerchantTradeNo&apos;, $request-&gt;MerchantTradeNo)-&gt;first()-&gt;orderRelations; Order::updateStatus($orderRelations); $payerEmail = $paymentServiceOrder-&gt;user-&gt;email; if ($payerEmail !== null) Mail::to($payerEmail)-&gt;send(new PaymentReceived($paymentServiceOrder, $orderRelations)); return &apos;1|OK&apos;;&#125; 最後記得別忘記return ‘1|OK’, 通知歐付寶我們已經收到付款囉！ 一些沒說到的事 歐付寶測試帳號中，除了信用卡之外，也支援多種其他方式付款哦！可於登入買家測試帳號之後使用。 超商或轉帳付款方式，需特別登入歐付寶提供的後台測試帳號，方可達到模擬付款！ 帳號： StageTest 密碼： test1234 退款 退款範例如下： public static function refund($order, $paymentServiceInstance, $orderRelation)&#123; try &#123; $obj = new AllInOne(); $obj-&gt;ServiceURL = &quot;https://payment-stage.opay.tw/Cashier/AioChargeback&quot;; // 服務位置 $obj-&gt;HashKey = env(&apos;HASHKEY&apos;); // 測試用Hashkey，請自行帶入AllPay提供的HashKey $obj-&gt;HashIV = env(&apos;HASHIV&apos;); // 測試用HashIV，請自行帶入AllPay提供的HashIV $obj-&gt;MerchantID = env(&apos;MERCHANTID&apos;); // 測試用MerchantID，請自行帶入AllPay提供的MerchantID $obj-&gt;EncryptType = EncryptType::ENC_SHA256; // CheckMacValue加密類型，請固定填入1，使用SHA256加密 $obj-&gt;ChargeBack[&apos;MerchantTradeNo&apos;] = $paymentServiceInstance-&gt;MerchantTradeNo; // 當初訂單成立時，提供的訂單號碼 $obj-&gt;ChargeBack[&apos;TradeNo&apos;] = $paymentServiceInstance-&gt;TradeNo; // AllPay提供的訂單號碼 $obj-&gt;ChargeBack[&apos;ChargeBackTotalAmount&apos;] = $order-&gt;total_amount; // 退款金額 $obj-&gt;AioChargeback(); &#125; catch (Exception $e) &#123; // 若錯誤，return return Helpers::result(true, &apos;Something wrong happened&apos;, 200); // Debug模式，印出錯誤 echo $e-&gt;getMessage(); &#125;&#125; 帶入參數可參考官方文件，選項12，會員通知退款。","link":"/zh-tw/AllPayPaymentService/"},{"title":"你好！Kubernetes","text":"前言本篇主要是利用Google的Qwiklab平台學習的同時，做的一份學習筆記原文連結如下：Refer to QWIKLABS official website 本篇將會做什麼？ 建立一個 Node.js server 建立一個 Docker container image 建立一個 container cluster 建立一個 Kubernetes pod 擴大服務 設定及要求需熟悉Linux內建的編輯器，像是vim, emacs, 或是nanoQwiklabs setup在你按下 Start Lab 按鈕之前詳讀所有的教學。Labs 是有時間限制的，而且你不可以停止時間倒數。倒數計時器在你按下 Start Lab 按鈕後開始倒數，上面顯示的時間為你還能使用 Cloud 資源的時間。 Quiklabs 的手把手環境，讓你可以在真實環境中來操作進行 Quiclabs 上提供的課程，而不是在一個模擬或是展示的環境。我們透過提供你一個全新的、暫時的帳號密碼，在計時器歸零之前，你可以用來登入並存取 Google Cloud Platform。 你需要什麼？要完成這個 lab ，你需要: 一個一般的網路瀏覽器（推薦 Chrome） 完成這個 lab 的時間 備註： 如果你已經有你自己的個人 GCP 帳號或專案，請不要使用在這一個 lab Google Cloud Platform Console如何開始你的 lab ，然後登入 Console? 按下 Start Lab 按鈕。如果你需要付費，會有一個彈出視窗來讓你選擇付費的方式。在左方你會看到一個面板，上面有暫時的帳號密碼，你必須使用這些帳號密碼在此次 lab 複製 username , 然後點擊 Open Google Console。 Lab 會開啟另外一個視窗，顯示選擇帳號的頁面 tip: 開啟一個全新的視窗，然後跟原本的頁面並排 在選擇帳號頁面, 點擊 Use Another Account 登入頁面開啟，貼上之前複製的 username 以及 password ，然後貼上 重要：必須使用之前於 Connection Details 面板 取得的帳號密碼，不要使用你自己的 Qwiklabs 帳號密碼。 如果你有自己的 GCP 帳號，請不要用在這裡（避免產生費用） 點擊並通過接下來的頁面: 接受terms以及conditions 不要增加recovery optoins 或 two factor authentication (因為這只是一個臨時帳號) 不要註冊免費體驗 稍待一些時候， GCP 控制台將會在這個視窗開啟。 注意：按下左上方位於Google Cloud Platform 隔壁的 Navigation menu ，你可以瀏覽選單，裡面有一系列的 GCP 產品以及服務 Cloud Shell啟動 Google Cloud ShellGoogle Cloud Shell 是載有開發工具的虛擬機器。它提供了5GB的 home 資料夾，並且運行在 Google Cloud 上。 Google Cloud Shell 讓你可以利用 command-line 存取 GCP 資源 在 GCP 控制台 ，右上的工具列，點擊 Open Cloud Shell 按鈕 在打開的對話框裡，按下 START CLOUD SHELL: 你可以立即按下 START CLOUD SHELL 當對話視窗打開。 連結並提供環境會需要一點時間。當你連結成功，這代表你已成功獲得授權，且此專案已被設為你的專案ID，例如： gcloud 是 Google Cloud Platform 的 command-line 工具，他已事先被安裝在 Cloud Shell 並且支援自動補齊 使用這個 command ,你可以列出有效帳戶名稱:gcloud auth list 輸出:Credentialed accounts: - &lt;myaccount&gt;@&lt;mydomain&gt;.com (active) 範例輸出:Credentialed accounts: - google1623327_student@qwiklabs.net 你可以使用以下 command 來列出專案 IDgcloud config list project 輸出：[core]project = &lt;project_ID&gt; 範例輸出：[core]project = qwiklabs-gcp-44776a13dea667a6 gcloud 的完整文件可以參閱 Google Cloud gcloud Overview 建立Node.js 應用 建立server.js檔案 vim server.js 在檔案內新增以下代碼 var http = require('http');var handleRequest = function(request, response) &#123; response.writeHead(200); response.end(\"Hello World!\");&#125;var www = http.createServer(handleRequest);www.listen(8080); Cloud Shell以內建node，直接執行node server node server.js 使用Cloud Shell內建的Web預覽功能，開一個新的視窗並發請求到port 8080，如下圖： 結果如下： 在更進一步之前，讓我們先到Cloud Shell按下Ctrl+c停止正在運行中的node server，我們將打包這個運用，並置於Docker container內 建立一個Docker container image 接下來，建立一個Dockerfile來敘述我們想要建立的image，Docker container images可以是已經存在image的延伸，所以我們將從已經存在的Node image來延伸 vim Dockerfile 增加以下內容FROM node:6.9.2EXPOSE 8080COPY server.js .CMD node server.js 上面的內容將： 從Docker hub中開始一個找到的node image 開啟port 8080 複製server.js檔案到此docker image 如之前操作般，手動開始node server 輸入以下的指令以建立image，將下面的PROJECT_ID替換成你的GCP Project ID，可以從主控台以及Connection Details區找到 docker build -t gcr.io/PROJECT_ID/hello-node:v1 . 接下來會花一些時間來下載以及擷取需要的東西，但你可以從進度條看到image建立的進度 完成之後，於本地端使用下面的指令測試一下這個image，這個指令會從剛新建立的container image中，將Docker container以常駐的方式跑在port 8080，(將下面的PROJECT_ID替換成你的GCP Project ID，可以從主控台以及Connection Details區找到) docker run -d -p 8080:8080 gcr.io/PROJECT_ID/hello-node:v1 結果大概如下 325301e6b2bffd1d0049c621866831316d653c0b25a496d04ce0ec6854cb7998 可使用Web預覽功能 或在Cloud Shell中使用curlkcurl http://localhost:8080 停止Docker container 尋找Docker container ID docker ps 結果大概如下 CONTAINER ID IMAGE COMMAND2c66d0efcbd4 gcr.io/PROJECT_ID/hello-node:v1 &quot;/bin/sh -c &apos;node 關閉docker container docker stop containerID 結果會輸出你的container ID，如下： 2c66d0efcbd4 現在，image如我們預期般的運作著，接下來我們將它推到Google Container Registry，一個可倍Google Cloud Projects存取的Docker image私人資料夾, 執行下面的指令(將下面的PROJECT_ID替換成你的GCP Project ID，可以從主控台以及Connection Details區找到) gcloud docker -- push gcr.io/PROJECT_ID/hello-node:v1 Container image將會被列在主控台中，可從Navigation menu &gt; Container Registry找到 現在我們擁有project-wide的Docker image，可供Kubernetes存取以及編排 建立cluster 現在我們已經準備好可以建立Kubernetes Engine cluster。一個cluster內，有由Google的Kubernetes master API server，以及一組worker nodes。Woker nodes是Compute Engine virtual machines. 確保我們已經使用gcould來設定我們的專案(將下面的PROJECT_ID替換成你的GCP Project ID，可以從主控台以及Connection Details區找到) gcloud config set project PROJECT_ID 使用兩個n1-standard-1 nodes來建立cluster(將會耗費幾分鐘) gcloud container clusters create hello-world \\ --num-nodes 2 \\ --machine-type n1-standard-1 \\ --zone us-central1-a 你也可以透過主控台來建立cluster: Kubernetes Engine &gt; Kubernetes cluster &gt; Create cluster cluster建立的區域，建議跟container registry使用的儲存區的所在區域一樣 Vavigation menu &gt; Kubernetes Engine 可以看到，現在有一個由Kubernetes Engine驅動的完全運作的Kubernetes clsuter 接下來，是時候將我們容器化的application部署到Kubernetes cluster，從現在開始，我們將使用kubectl命令行（在Cloud Shell環境中，這已經被設定完畢） 建立pod Kubernetes pod由多個container組成，用於管理以及連結。它可以容納單一或多個containers。這邊我們將會使用儲存於私人的container registry，由Node.js image 建立的container。內容將會用在8080 port 使用kubectl run 指令來建立一個pod(將下面的PROJECT_ID替換成你的GCP Project ID，可以從主控台以及Connection Details區找到) kubectl run hello-node \\--image=gcr.io/PROJECT_ID/hello-node:v1 \\--port=8080 可以看到，我們已經建立一個deployment物件。Deployments是建立跟擴大pods推薦的方法。這邊，一個新的deployment管理一個執行hello-node:v1 image的pod 允許外部連結 在預設中，pod只可被cluster內部的ip存取。為了要讓hello-node container可倍Kubernetes virtual network之外的來源存取，我們必須設定pod成可被存取的Kubernates的服務 在Cloud Shell，透過使用kubectl expose指令，並結合--type=&quot;LoadBalancer&quot; flag, 我們可以讓pod可被公用網路存取。要建立一個外部存取IP，這個flag是必須的。kubectl expose deployment hello-node --type=\"LoadBalancer\" 這個flag指定我們將使用underlying infrostructure提供的load-balancer (在此範例中，為Compute Engine load balancer)。需注意我們是使deployment可視化，並非直接暴露pod。這代表，產生的服務將會讀取所有由此depolyment管理的pod(於此範例中，為一個pod，但我們之後可以增加) 此Kubernetes master建立了load balancer，相關的Compute Engline 轉發規格，target pools，以及防火牆規則， 所以服務可被Google Cloud Platform之外的來源所存取 若要找公開可存取IP，可要求kubectl列出所有的cluster服務 kubectl get services 結果如下： NAME CLUSTER-IP EXTERNAL-IP PORT(S) AGEhello-node 10.3.250.149 104.154.90.147 8080/TCP 1mkubernetes 10.3.240.1 &lt;none&gt; 443/TCP 5m 上圖可以看到，hello-node service有兩組IP，兩組都使用port 8080，CLUSTER-IP 是內部IP，只可被內部cloud vertial network所見，EXTERNAL-IP為外部load-balanced IP 外部IP可能需要幾分鐘生效 通過輸入IP來存取 http://&lt;EXTERNAL_IP&gt;:8080 擴充服務 通過指令來擴充服務kubectl scale deployment hello-node --replicas=4 查看deployment kubectl get deployment 查看所有pod kubectl get pods 以下圖示顯示Kubernetes的大概運作方式: 升級服務 某些時候，已經被部署的應用需要debug或增加新的功能。Kubernetes幫我們部署新的版本，並且不影響使用者 首先，修改應用，編輯server.js vim server.js 更新回覆訊息 response.end(&quot;Hello Kubernetes World!&quot;); 現在，我們可以透過往上增加的版本號，建立以及發布一個新的container image到registry。 使用以下指令(將下面的PROJECT_ID替換成你的GCP Project ID，可以從主控台以及Connection Details區找到) docker build -t gcr.io/PROJECT_ID/hello-node:v2 . gcloud docker -- push gcr.io/PROJECT_ID/hello-node:v2 編輯已經存在的hello-node deployment以及將image由gcr.io/PROJECT_ID/hello-node:v1變更為gcr.io/PROJECT_ID/hello-node:v2 kubectl edit deployment hello-node 修改如下：# Please edit the object below. Lines beginning with a '#' will be ignored,# and an empty file will abort the edit. If an error occurs while saving this file will be# reopened with the relevant failures.#apiVersion: extensions/v1beta1kind: Deploymentmetadata: annotations: deployment.kubernetes.io/revision: \"1\" creationTimestamp: 2016-03-24T17:55:28Z generation: 3 labels: run: hello-node name: hello-node namespace: default resourceVersion: \"151017\" selfLink: /apis/extensions/v1beta1/namespaces/default/deployments/hello-node uid: 981fe302-f1e9-11e5-9a78-42010af00005spec: replicas: 4 selector: matchLabels: run: hello-node strategy: rollingUpdate: maxSurge: 1 maxUnavailable: 1 type: RollingUpdate template: metadata: creationTimestamp: null labels: run: hello-node spec: containers: - image: gcr.io/PROJECT_ID/hello-node:v1 ## Update this line ## imagePullPolicy: IfNotPresent name: hello-node ports: - containerPort: 8080 protocol: TCP resources: &#123;&#125; terminationMessagePath: /dev/termination-log dnsPolicy: ClusterFirst restartPolicy: Always securityContext: &#123;&#125; terminationGracePeriodSeconds: 30 更新新的image到deployment，新的pods將被建立，舊的將被刪除kubectl get deployments Kubernetes圖形化面板 (optional) 取得cluster層級權限 kubectl create clusterrolebinding cluster-admin-binding --clusterrole=cluster-admin --user=$(gcloud config get-value account) 權限已經取得，建立新的面板服務 kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml 編輯面板服務的表面形式 kubectl -n kube-system edit service kubernetes-dashboard 將type: ClusterIP改成type: NodePort 要登入Kubernetes面板，需要經過token驗證，產生token如下： kubectl -n kube-system describe $(kubectl -n kube-system \\get secret -n kube-system -o name | grep namespace) | grep token: 打開連線 kubectl proxy --port 8081 使用Cloud Shell Web 預覽功能來改變port到8081 我們將收到一串API endpoint，要連結到面板，將/?authuser=0移除，然後加上下面的url: /api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/#!/overview?namespace=default 然後你會被帶到一個網頁預覽 點選Token radio，然後貼上剛剛拿到的token，然後Sign in 你可以從主控台存取面板服務，Navigation menu &gt; Kubernetes Engine，然後選擇Connect按鈕連接到我們想要連接的cluster 習題測驗 which of the following are features of the Kubernetes Engine? Identity and Access Management Integrated Logging and Monitoring None of these Stateful Application Support 非必要指令 如果想要檢視這個deployment，可以使用以下指令： kubectl get deployments 若想檢視由deployment建立的pod，可以使用以下指令: kubectl get pods 以下也是一些有趣的kubectl指令： kubectl cluster-info kubectl config view kubectl get events kubectl logs podName","link":"/zh-tw/Kubernetes/"},{"title":"Kubernetes Engine 從 Qwiklab 開始","text":"前言本篇為 GCP Kubernetes Engine 的學習筆記 概述Google Kubernetes Engine (GKE) 提供了一個 Google 管理的環境，這個環境可使用 Google 的基礎設施來部署，管理容器化應用，以及調整容器化應用的規模大小。 Kubernetes Engine 環境包含了多台的機器(這邊專指為 Google Compute Engine 的實例)，形成一個容器的叢集。在這個課程中，你將可以實際操作練習如何建立一個容器，以及在 GKE 上部署你的應用。 Kubernetes Engine 的叢集管理Kunernetes Engine 叢集器由 Kunernetes 開源叢集管理系統所提供。Kubernetes 提供與你的容器叢集互動的機制。使用Kebernetes的指令以及資源來部署、管理你的應用，執行管理任務、制訂政策，以及監控部屬工作量的健康度。 Kubernetes 使用了與目前運行在 Google 熱門服務相同的設計原則，並提供相同的優勢:自動管理, 應用容器的監控以及健康檢查, 自動擴展, 滾動升級, 以及更多…當你在一個容器叢集中運行你的應用, 相當於你使用了 Google 這10幾年正式在容器內上線的經驗來運行你的應用。 Kubernetes on Google Cloud Platform當你使用Kubernetes Engine 叢集，你同時也得到了 Google Cloud Platform 提供的優勢以及進階的叢集管理功能, 如下： Compute Engine 實例的平衡負載 節點池：在叢集內分配子集節點以提升靈活度 叢集節點實例數量的自動擴展 叢集節點軟體的自動升級 節點自動修復:保持節點的健康度以及可用性 使用 Stackdriver 來紀錄與監控，讓您可以掌握叢集的狀態 現在你已經對 Kubernetes 有基本的認識，你將在30分鐘內，學習如何使用 Kubernetes Engine 來部署你的容器化應用。繼續往下看並遵照每一個步驟來設定你的Lab環境。 設定及要求 在你按下 Start Lab 按鈕之前 詳讀所有的教學。Labs 是有時間限制的，而且你不可以停止時間倒數。倒數計時器在你按下 Start Lab 按鈕後開始倒數，上面顯示的時間為你還能使用 Cloud 資源的時間。 Qwiklabs 的手把手環境，讓你可以在真實環境中來操作進行 Qwiklabs 上提供的課程，而不是在一個模擬或是展示的環境。我們透過提供你一個全新的、暫時的帳號密碼，在計時器歸零之前，你可以用來登入並存取 Google Cloud Platform。 你需要什麼？ 要完成這個 lab ，你需要: 一個一般的網路瀏覽器（推薦 Chrome） 完成這個 lab 的時間 備註： 如果你已經有你自己的個人 GCP 帳號或專案，請不要使用在這一個 lab 現在你已經開始你的 lab, 你將會登入 Google Cloud Shell 主控台，然後開啟命令列工具 如何開始你的 lab ，然後登入 Console? 按下 Start Lab 按鈕。如果你需要付費，會有一個彈出視窗來讓你選擇付費的方式。在左方你會看到一個面板，上面有暫時的帳號密碼，你必須使用這些帳號密碼在此次 lab 複製 username , 然後點擊 Open Google Console。 Lab 會開啟另外一個視窗，顯示選擇帳號的頁面 tip: 開啟一個全新的視窗，然後跟原本的頁面並排 在選擇帳號頁面, 點擊 Use Another Account 登入頁面開啟，貼上之前複製的 username 以及 password ，然後貼上 重要：必須使用之前於 Connection Details 面板 取得的帳號密碼，不要使用你自己的 Qwiklabs 帳號密碼。 如果你有自己的 GCP 帳號，請不要用在這裡（避免產生費用） 點擊並通過接下來的頁面: 接受terms以及conditions 不要增加recovery optoins 或 two factor authentication (因為這只是一個臨時帳號) 不要註冊免費體驗 稍待一些時候， GCP 控制台將會在這個視窗開啟。 注意：按下左上方位於Google Cloud Platform 隔壁的 Navigation menu ，你可以瀏覽選單，裡面有一系列的 GCP 產品以及服務 啟動 Google Cloud ShellGoogle Cloud Shell 是載有開發工具的虛擬機器。它提供了5GB的 home 資料夾，並且運行在 Google Cloud 上。 Google Cloud Shell 讓你可以利用 command-line 存取 GCP 資源 在 GCP 控制台 ，右上的工具列，點擊 Open Cloud Shell 按鈕 在打開的對話框裡，按下 START CLOUD SHELL: 你可以立即按下 START CLOUD SHELL 當對話視窗打開。 連結並提供環境會需要一點時間。當你連結成功，這代表你已成功獲得授權，且此專案已被設為你的專案ID，例如： gcloud 是 Google Cloud Platform 的 command-line 工具，他已事先被安裝在 Cloud Shell 並且支援自動補齊 使用這個 command ,你可以列出有效帳戶名稱: gcloud auth list 輸出: Credentialed accounts: - &lt;myaccount&gt;@&lt;mydomain&gt;.com (active) 範例輸出: Credentialed accounts: - google1623327_student@qwiklabs.net 你可以使用以下 command 來列出專案 ID gcloud config list project 輸出： [core]project = &lt;project_ID&gt; 範例輸出： [core]project = qwiklabs-gcp-44776a13dea667a6 gcloud 的完整文件可以參閱 Google Cloud gcloud Overview 設定一個預設的 compute zone你的 [compute zone] 是一個你的叢集以及其資源大概所在的一個位置。 例如說， us-central1-a 是一個位於 us-central1 region 的 zone 在 Cloud Shell 開始一個新的區塊，並且依照下面的指令來將你的預設 compute zone 設定為 us-central1-a gcloud config set compute/zone us-central1-a 你將會收到以下的輸出Updated property [compute/zone]. 建立一個 Kubernetes Engine 叢集一個叢集包含至少一個叢集主要機器，以及多台工作機器，稱為 nodes (節點)。 Nodes 是 Compute Engine 虛擬機器實例，運行著 Kubernetes 的必要程序，使他們成為叢集的一部分。 執行以下的 command 來建立一個叢集。以你喜歡的叢集名稱(例如： my-cluster )來取代 command 中的 CLUSTER-NAME 。叢集的名稱必須由一個字母開始，並且需同時包含字母以及數字，且長度不可超過40個字。gcloud container clusters create [CLUSTER-NAME] 你可以無視輸出裡的任何警告。建立叢集會需要一些時間，很快的你將會收到類似下面的輸出：NAME LOCATION ... NODE_VERSION NUM_NODES STATUSmy-cluster us-central1-a ... 1.10.9-gke.5 3 RUNNING 點擊 Check my progress 來確認目前的進度。 取得叢集的授權證明在建立叢集之後，你需要取得授權證明來進行對叢集的進一步操作執行下面的 command 來授權叢集，並用你自己的叢集名稱取代 command 裡面的 CLUSTER-NAMEgcloud container clusters get-credentials [CLUSTER-NAME] 你將會收到類似下面的輸出：Fetching cluster endpoint and auth data.kubeconfig entry generated for my-cluster. 部署應用到叢集上現在你已經建立了一個叢集，你可以部署一個容器化的應用到這上面。在這個 Lab ，你將會部署 hello-app 到你的叢集上 Kubernetes Engine 使用 Kubernetes 物件來建立以及管理你的叢集資源。 Kubernetes 提供 部署 物件來部署無狀態的應用，像是 web server。服務物件定義了從網路上存取你應用的規則，以及負載平衡。 在 Cloud Shell 執行下面的 [kubectl run] 指令，從 hello-app 容器鏡像建立一個新的部署 hello-serverkubectl run hello-server --image=gcr.io/google-samples/hello-app:1.0 --port 8080 你應該會收到以下的輸出:deployment.apps \"hello-server\" created 這一個 Kubernetes 的指令，建立了一個代表 hello-app 的部署物件，在此指令中： --image 指定了一個容器鏡像來部署，在此範例中，這個指令從Google Container Registry儲存區裡，拉下一個範例鏡像。gcr.io/google-samples/hello-app:1.0 表示一個特定的鏡像。如果版本沒有明確標示，最新的版本將會被使用。 --port 指定容器暴露的 port 號 執行以下的 kubectl 暴露指令，建立一個 Kubernetes 的服務，一個 Kubernetes 的資源，讓你暴露你的應用到外部。 kubectl expose deployment hello-server --type=\"LoadBalancer\" 你應該會收到以下的輸出：service \"hello-server\" exposed 點擊 Check my progress 來確認目前的進度。 帶入參數 type=&quot;LoadBalancer&quot; ，在容器中建立一個 Compute Engine 平衡負載 執行 kubectl get 來檢查 hello-server 服務kubectl get service hello-server 你應該會收到類似以下的輸出： NAME TYPE ... EXTERNAL-IP PORT(S) AGEhello-server LoadBalancer ... 35.184.112.169 8080:30840/TCP 2m 備註：外部IP位址的產生，可能需要1分鐘。如果外部IP一直在沒有產生，你可以在執行一次上面的指令 從這個指令的輸出，從 `EXTERNAL-IP 欄位，複製服務的外部 IP 位址。 從瀏覽器，經由外部 IP 還有對應的 port 號來拜訪我們的應用 http://[EXTERNAL-IP]:8080 你的頁面應該看起來如下： 點擊 Check my progress 來確認目前的進度。 清除執行下面的指令來清除叢集gcloud container clusters delete [CLUSTER-NAME] 當選項跳出，輸入 Y 確認。清除叢集將會花費一些時間。你可以參閱 文件 來獲得更多刪除 Google Kubernetes Engine 叢集 的資訊 恭喜你已經完成本教程","link":"/zh-tw/KubernetesEngineQuickStart/"},{"title":"My learning note of MongoDB","text":"前言一份未整理的 MongoDB 學習筆記 環境GCP Linux Ubuntu 19.04 安裝參考 官方文件 重啟sudo service mongod restart 登入無建立使用者mongo 有建立使用者mongo -u user -p password 設定檔位置vim /etc/mongod.conf vim /lib/systemd/system/mongod.service 說明書mongo --help 一般指令 顯示 database show databases 顯示 collections show collections 顯示使用者 use adminshow users 使用資料庫 use databaseName 刪除 user db.dropUser('User') 變更密碼 db.changeUserPassword('user', 'updatedPassword') 建立需驗證的 user參考文件 登入 mongo --host &lt;HOSTNAME&gt; --port &lt;PORT&gt; 切換到 admin 資料庫 use admin 建立 user db.createUser( &#123; user: \"superuser\", pwd: \"changeMeToAStrongPassword\", roles: [ \"root\" ] &#125;) 驗證 user 是否成功建立 show users 關閉 MongoDB server db.shutdownServer() 離開 exit 如果是用套件安裝，需要先更改設定。 編輯設定檔，並新增 uncomment security 欄位 vim /etc/mongod.conf security: authorization: enabled 重新啟動 MongoDB Server, dbPath 可以在設定檔裡面看到vim /etc/mongod.conf 如下位置# Where and how to store data.storage: dbPath: /var/lib/mongodb journal: enabled: true 執行下面指令重新啟動mongod --dbpath &lt;path to data directory&gt; --auth &amp; 讓外面可以連到資料庫 更改 IP 如下# network interfacesnet: port: 27017 bindIp: 0.0.0.0","link":"/zh-tw/MongoDB/"},{"title":"My learning journey in Node.js","text":"前言這是一份未整理的 Node.js 學習筆記 正文安裝 在 CentOS 7 上安裝 Node.js 和 NPMNodeSource 是一家致力於提供企業級Node 支持的公司，他們為Linux 發行版維護一致更新的Node.js 軟件倉庫。要從CentOS 7 系統上的NodeSource 軟件倉庫安裝Node.js 和npm ，請按照下列步驟操作： 添加NodeSource yum 軟件倉庫Node.js 的當前LTS 版本是10.x 版。如果你想安裝的版本8 只吧下面的命令中setup_10.x 更改為setup_8.x 。運行以下curl命令將NodeSource yum軟件倉庫添加到您的系統： curl -sL https://rpm.nodesource.com/setup_10.x | bash - 安裝Node.js 和npm啟用NodeSource 軟件倉庫後，通過以下命令安裝Node.js 和npm ： yum install nodejs 驗證Node.js 和npm 安裝 node -v npm -v 如何使用NVM 安裝Node.js 和npmNVM （Node 版本管理器）是一個bash 腳本，用於管理多個活動的Node.js 版本。NVM 允許我們安裝和卸載任何特定的Node.js 版本，這意味著我們可以擁有任何數量的Node.js 版本供我們使用或測試。curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.34.0/install.sh | bash &amp;&amp; export NVM_DIR=\"$HOME/.nvm\" &amp;&amp; [ -s \"$NVM_DIR/nvm.sh\" ] &amp;&amp; \\. \"$NVM_DIR/nvm.sh\" &amp;&amp; [ -s \"$NVM_DIR/bash_completion\" ] &amp;&amp; \\. \"$NVM_DIR/bash_completion\" 參考資料來源 要在CentOS 系統上使用NVM 安裝Node.js 和npm ，請按照下列步驟操作： 使用 fs module fs.writeFileSyncconst fs = require(&#39;fs);在 Node.js 裏頭，如果要引用一個 module ，要用一個變數引用，然後之後就可以使用它例如fs.writeFileSync('hello.txt', 'Hello fromNode.js'); 上面的 function ，是將 Hello fromNode.js 寫進 hello.txt 這個檔案### 建立一個最簡單的 server首先，我們先引用 `http` module，當我們要調用本地 module 時，我們可以指定路徑，像是 `./http` ，但我們要調用 global 的 module 時，我們不加任何路徑， 如下```javascriptconst http = require(&apos;http&apos;); 接下來，我們利用剛剛引用的 http module 來建立一個 server ，如下：const server = http.createServer((req, res) =&gt; &#123; console.log(req);&#125;); orconst server = http.createServer(function(req, res)&#123; console.log(req);&#125;); or function rqListener(req, res) &#123; console.log(req);&#125;const server = http.createServer(rqListener); 最後，我們雖然已經建立了 server ，但是我們還沒有指定它的位址。 我們指定 3000 port 給這個 server ，如下：server.listen(3000); 此時，我們可以從瀏覽器，輸入 localhost:3000 來拜訪這個 server 停止這個 loopconst http = require('http');const server = http.createServer((req, res) =&gt; &#123; console.log(req); process.exit();&#125;);server.listen(3000); 從 request 中取得我們想要的資訊舉例來說，我們要取得 url , method , 以及 header 三項資訊，如下：const http = require('http');const server = http.createServer((req, res) =&gt; &#123; console.log(req.url, req.method, req.header); // process.exit();&#125;);server.listen(3000); 下圖，我們可以看到我們特別指定的三項資訊: 設定 response我們可以在 server 中，指定 response ，如下：const http = require('http');const server = http.createServer((req, res) =&gt; &#123; console.log(req.url, req.method, req.header); // process.exit(); res.setHeader('Content-Type', 'text/html'); res.write('&lt;html&gt;'); res.write('&lt;head&gt;&lt;title&gt;My First Page&lt;/title&gt;&lt;/head&gt;'); res.write('&lt;body&gt;&lt;ht&gt;Hello from my NOde.js Server&lt;/ht&gt;&lt;/body&gt;'); res.write('&lt;/html&gt;'); res.end();&#125;);server.listen(3000); 然後打開開發者工具，我們可以看到我們剛剛設定的 header 然後 response 的地方可以看到我們剛剛設定的 response 簡易的 request routing我們可以指定觸發特定 response 的 url ，當 client 呼叫這個 url 時，就會觸發我們指定的 response ，反之，則觸發另外的 response const http = require('http');const server = http.createServer((req, res) =&gt; &#123; const url = req.url; if (url === '/') &#123; res.write('&lt;html&gt;'); res.write('&lt;head&gt;&lt;title&gt;Enter Message&lt;/title&gt;&lt;/head&gt;'); res.write('&lt;body&gt;&lt;form action=\"/message\" method=\"post\"&gt;&lt;input type=\"text\" name=\"message\"&gt;&lt;button type=\"submit\"&gt;Send&lt;/button&gt;&lt;/form&gt;&lt;/body&gt;'); res.write('&lt;/html&gt;'); return res.end(); &#125; res.setHeader('Content-Type', 'text/html'); res.write('&lt;html&gt;'); res.write('&lt;head&gt;&lt;title&gt;My First Page&lt;/title&gt;&lt;/head&gt;'); res.write('&lt;body&gt;&lt;ht&gt;Hello from my NOde.js Server&lt;/ht&gt;&lt;/body&gt;'); res.write('&lt;/html&gt;'); res.end();&#125;);server.listen(3000); 由上面的 code 可以看到，我們指定 req.url 必須要絕對等於 / 才會觸發條件內，我們指定的 response 如下： 當我們按下 send ，會執行 post method, action /message ，如下： 因為 action 的關係，會嘗試拜訪 message url ，而因為這個 url 並不符合我們設定的條件，所以會執行預設 response 簡單的 redirect request現在，我們要簡易的 redirect 我們的 request ，如下：const http = require('http');const fs = require('fs');const server = http.createServer((req, res) =&gt; &#123; const url = req.url; const method = req.method; if (url === '/') &#123; res.write('&lt;html&gt;'); res.write('&lt;head&gt;&lt;title&gt;Enter Message&lt;/title&gt;&lt;/head&gt;'); res.write('&lt;body&gt;&lt;form action=\"/message\" method=\"post\"&gt;&lt;input type=\"text\" name=\"message\"&gt;&lt;button type=\"submit\"&gt;Send&lt;/button&gt;&lt;/form&gt;&lt;/body&gt;'); res.write('&lt;/html&gt;'); return res.end(); &#125; if (url === '/message' &amp;&amp; method === 'POST') &#123; fs.writeFileSync('message.txt', 'DUMMY'); res.statusCode = 302; res.setHeader('Location', '/'); return res.end(); &#125; res.setHeader('Content-Type', 'text/html'); res.write('&lt;html&gt;'); res.write('&lt;head&gt;&lt;title&gt;My First Page&lt;/title&gt;&lt;/head&gt;'); res.write('&lt;body&gt;&lt;ht&gt;Hello from my NOde.js Server&lt;/ht&gt;&lt;/body&gt;'); res.write('&lt;/html&gt;'); res.end();&#125;);server.listen(3000); 從上面的 code 可以看到，我們新增了第二個 if statement。如果 url 等於 //message 以及 method 等於 post ，雙重條件都符合之下，就會觸發我們設定的條件我們使用了之前我們曾經使用的 fs module ，如果條件觸發，我們就會將 DUMMY 寫入一個叫做 message.txt 的檔案接著回傳 status code 302最後回導到 /在 res.end() 之後，我們不可以在 define 新的 res ，否則就會出現錯誤，因為這邊我們要使用 return ，後續的代碼就不會再執行 Parsing request bodies本章節，我們將解析 request 裡頭的 body 資料並且初次接觸到了 stream 以及 buffer 的概念。首先，我們先設定一個事件。 當接收到 data 時，觸發一個 function 並且帶入 chunk ， chunk 是資料的最小單位。接著我們使用了 console.log 來把 chunk 印出來！同時，我們建立一個 body 常數 array ，並且將每一次觸發 data 事件時，我們都將 chunk 丟到這個 array 裏頭， 代碼如下：const body = [];req.on('data', (chunk) =&gt; &#123; console.log(chunk); body.push(chunk);&#125;); 接著，我們在建立一個事件，當 request 接收完成，我們在定義一個常數，叫做 parsedBody ， 至於這個常數的內容，我們使用 buffer 物件，來將 body array 裡頭的 chunk 都串起來，然後轉換成 string 。最後，我們使用 console.log 把常數 parsedBody 印出來，代碼如下：req.on('end', () =&gt; &#123; const parsedBody = Buffer.concat(body).toString(); console.log(parsedBody);&#125;); 結果如下： 接下來，我們在定義一個常數 message ，它的內容是用 ‘=’ 來將常數 parsedBody 分隔，變成一個 array ，然後我們取 [1] ，就是 array 中的第二項資料。然後，我們將這個常數 message 一方面利用 console.log 印出來，一方面利用 fs module 來寫到一個叫做 message.txt 的檔案中。代碼如下：req.on('end', () =&gt; &#123; const parsedBody = Buffer.concat(body).toString(); const message = parsedBody.split('=')[1]; console.log(message); fs.writeFileSync('message.txt', message);&#125;); 至此, 此 episode 告一段落，最後全部的 code 如下：const http = require('http');const fs = require('fs');const server = http.createServer((req, res) =&gt; &#123; const url = req.url; const method = req.method; if (url === '/') &#123; res.write('&lt;html&gt;'); res.write('&lt;head&gt;&lt;title&gt;Enter Message&lt;/title&gt;&lt;/head&gt;'); res.write('&lt;body&gt;&lt;form action=\"/message\" method=\"post\"&gt;&lt;input type=\"text\" name=\"message\"&gt;&lt;button type=\"submit\"&gt;Send&lt;/button&gt;&lt;/form&gt;&lt;/body&gt;'); res.write('&lt;/html&gt;'); return res.end(); &#125; if (url === '/message' &amp;&amp; method === 'POST') &#123; const body = []; req.on('data', (chunk) =&gt; &#123; console.log(chunk); body.push(chunk); &#125;); req.on('end', () =&gt; &#123; const parsedBody = Buffer.concat(body).toString(); const message = parsedBody.split('=')[1]; console.log(message); fs.writeFileSync('message.txt', message); &#125;); res.statusCode = 302; res.setHeader('Location', '/'); return res.end(); &#125; res.setHeader('Content-Type', 'text/html'); res.write('&lt;html&gt;'); res.write('&lt;head&gt;&lt;title&gt;My First Page&lt;/title&gt;&lt;/head&gt;'); res.write('&lt;body&gt;&lt;ht&gt;Hello from my NOde.js Server&lt;/ht&gt;&lt;/body&gt;'); res.write('&lt;/html&gt;'); res.end();&#125;);server.listen(3000); 了解事件驅動代碼的執行本章節介紹了事件驅動代碼的執行規則以及順序舉例來說，如果我們對目前的代碼做了一些調整，如下:req.on('end', () =&gt; &#123; const parsedBody = Buffer.concat(body).toString(); const message = parsedBody.split('=')[1]; fs.writeFileSync('message.txt', message); res.statusCode = 302; res.setHeader('Location', '/'); return res.end();&#125;); 首先，在一開始我們就引用了 http module 以及 fs module ，然後我們利用 http module 來建立一個 server ，並且讓這個 server 聽 3000 port 。當有任何 requets 呼叫這個 server 時，都會觸發這個 server 。我們帶入 request 以及 response ， 在 server 內可以用。首先，我們定義發請求的 url 為常數 url ， 再來，我們定義發請求的方法為常數 method如果常數 url 等於 / 時，會觸發一系列的 response ，並且 return res.end(); 做結束。如果常數 url 等於 /message 且常數 method 等於 POST 的話，定義常數 body 為 array。接下來進入事件驅動, 當開始解析 request 時，我們帶入 chunk ，印出 chunk ，並且將 chunk 放入一個叫做 body 的 array 常數另外一個事件，當 request 解析完成後， 定義一個常數叫做 parsedBody ，它是利用 buffer 物件來將在常數 body 內的所有 chunk 串連起來，然後變成 string在定義一個常數叫做 message ， 首先， 常數 parsedBody 是一個 string ，我們將這個 string 用 = 為分隔點，將這個 string 變成 array 之後，取 [1] ，就是這個 array 的第二項資料，這個就是常數 message 的值接下來，我們利用一開始引用的 fs module ， 將常數 message 的內容寫入一個叫做 message.txt 的檔案。接下來，定義 response 的 status code 為 302定義 response 跳轉的 location 為 /最後， return res.end(); 出了事件驅動之後，是定義 header ，然後定義另外一些 html 的 response ， 最後是 res.end(); Server 內的執行部分到此做一個結尾。 由於 js 的事件驅動屬性，事件 end 並不會先被執行，反之，後面的代碼會先被執行。所以這個更動會造成一個錯誤，那就是當 res.end(); 已經被執行了，才開始執行 end 事件內的 setHeader 以及 statusCode ，這樣就會造成如下的錯誤 如果，我們在 end 事件之下加了 return ，那錯誤就不會出現 ， 修改代碼如下：req.on('end', () =&gt; &#123; const parsedBody = Buffer.concat(body).toString(); const message = parsedBody.split('=')[1]; fs.writeFileSync('message.txt', message); res.statusCode = 302; res.setHeader('Location', '/'); return res.end();&#125;);return; 因為 end 事件之下的 res.setHeader(&#39;Content-Type&#39;, &#39;text/html&#39;); 就不會被執行了。注意！ 在 return 的當下，其實 end 的監聽事件是還沒有被執行的，但是當 server 裡頭的動作執行完畢之後， request 被解析完成，觸發了 end 的監聽事件，然後才開始執行這個事件裡頭的動作。 至此，此 Episode 告一段落，截至目前的完整程式碼如下：const http = require('http');const fs = require('fs');const server = http.createServer((req, res) =&gt; &#123; const url = req.url; const method = req.method; if (url === '/') &#123; res.write('&lt;html&gt;'); res.write('&lt;head&gt;&lt;title&gt;Enter Message&lt;/title&gt;&lt;/head&gt;'); res.write('&lt;body&gt;&lt;form action=\"/message\" method=\"post\"&gt;&lt;input type=\"text\" name=\"message\"&gt;&lt;button type=\"submit\"&gt;Send&lt;/button&gt;&lt;/form&gt;&lt;/body&gt;'); res.write('&lt;/html&gt;'); return res.end(); &#125; if (url === '/message' &amp;&amp; method === 'POST') &#123; const body = []; req.on('data', (chunk) =&gt; &#123; console.log(chunk); body.push(chunk); &#125;); req.on('end', () =&gt; &#123; const parsedBody = Buffer.concat(body).toString(); const message = parsedBody.split('=')[1]; fs.writeFileSync('message.txt', message); res.statusCode = 302; res.setHeader('Location', '/'); return res.end(); &#125;); return; &#125; res.setHeader('Content-Type', 'text/html'); res.write('&lt;html&gt;'); res.write('&lt;head&gt;&lt;title&gt;My First Page&lt;/title&gt;&lt;/head&gt;'); res.write('&lt;body&gt;&lt;ht&gt;Hello from my NOde.js Server&lt;/ht&gt;&lt;/body&gt;'); res.write('&lt;/html&gt;'); res.end();&#125;);server.listen(3000); Blocking and Non-Blocking Code所以，fs.writeFile 跟 fs.writeFileSync 差在哪？fs.writeFileSync 會待這個檔案寫入的任務完成之後，才會繼續向後執行，而 fs.writeFIle 會異步執行，儘管檔案寫入的任務還沒完成，程式一樣會繼續向後執行，並且，我們可以在任務完成時執行一項 callback ，修改代碼如下： req.on('end', () =&gt; &#123; const parsedBody = Buffer.concat(body).toString(); const message = parsedBody.split('=')[1]; fs.writeFile('message.txt', message, (err)=&gt;&#123; res.statusCode = 302; res.setHeader('Location', '/'); return res.end(); &#125;);&#125;); 從以上的代碼來看，當程式執行到寫入檔案那一行， fs.writeFile ，程式不會停下來等待 fs.writeFile 執行完畢，反之，程式會繼續往下跑 ， 而當 fs.writeFile 執行完畢後，會觸發我們設定的 callback ，進而執行以下的代碼res.statusCode = 302;res.setHeader('Location', '/');return res.end(); 簡述事件迴圈本章節主要參閱官方文件 ， 以及這位大大的文章 。在本章節中，主要是搞懂 Node.js 中事件迴圈的概念。 Node.js 的架構圖 上圖可以看到，除了 V8 Engine ， Node.js 使用了 libuv 來處理 I/O 的部分，提供了 asynchronous 以及 Non-Blocking API 以及事件迴圈 ， 下面提到的事件迴圈，主要與 libuv 有關。 什麼是事件迴圈？事件迴圈，藉由將工作量分擔給 Kernel 來處理，使 Node.js 得以做非阻塞 I/O 的操作，儘管 JsvaScript 是單線程的。 因為目前新型的 Kernel 都是多線程的，它們可以在背景運行多個程序。當其中一個程序完成了， Kernel 會通知 Node.js ，所以 Node.js 會調整將適合的 callback 加到 poll 階段的 queue 當中 ，這些 callback 最終將會被執行。 深談事件迴圈以下是事件迴圈各個階段圖，以及運行順序 每個階段都有自己的 先進先出 的要被執行的 callback queue 。每個階段都有自己特別的運行方式，一般來說，當事件迴圈跑到一個特定的階段，事件迴圈將會執行這個特定階段裡頭的操作，然後執行它的 callback ，這個執行的動作會重複，直到該階段內的 callback 都被執行完畢了，或者已經達到最大的執行數量。當 queue 裡頭的工作都被處理完了，或者已達最大執行數量限制，事件迴圈會進入下一個階段，反覆循環。 因為上述提到的這些程序很有可能排定更多的程序，且由 poll 階段處理的事件將被 kernel 佇列著 ， 所以 poll 事件可以在被佇列的同時也被執行。 造成的結果是，一個耗時較長的 callback ， 會允許 poll 階段執行的久一點，甚至讓 timer 階段的工作等待。 各階段概述 timers: 這個階段主要處理 setTimeout() 以及 setInterval() 排程的 callback I/O callbacks: 除了 timers, setImmediate(), close 之外的多數類型 idle, prepare: 只供內部使用 poll: 取回新的 I/O 事件; 某些情況， node 將會阻塞在這裡 check: setImmediate() callbacks 將會在這階段被觸發 close callbacks: socket, on … libuv 各階段詳述timers:簡單來說， timers 階段將處理 setTimeout() 以及 setInterval() 的工作。 timers 並不保證可以準確地在給予的時間點執行 callback ， 反之 ，給予的時間更像是一個最低的門檻，唯有過了這個給予的時間點， callback 才會被執行，這視乎當時的工作狀態。 系統的排程或者是其他 callback 的運行都可能會延遲 timers 執行的確切時間。總而言之，過了指定的時間點之後， timers 會盡可能地盡快執行排程的 callback可以看看以下的範例： var fs = require('fs');function someAsyncOperation (callback) &#123; // Assume this takes 0 ms to complete fs.readFile('/path/to/file', callback);&#125;function anotherAsyncOperation (callback) &#123; // Assume this takes 0 ms to complete fs.readFile('/path/to/file', callback);&#125;var timeoutScheduled = Date.now();setTimeout(function () &#123; var delay = Date.now() - timeoutScheduled; console.log(delay + \"ms have passed since I was scheduled\");&#125;, 100);// do someAsyncOperation which takes 200 ms to completesomeAsyncOperation(function () &#123; var startCallback = Date.now(); // do something that will take 10ms... while (Date.now() - startCallback &lt; 200) &#123; ; // do nothing &#125;&#125;);// do anotherSyncOperation which takes 200 ms to completeanotherAsyncOperation(function () &#123; var startCallback = Date.now(); // do something that will take 10ms... while (Date.now() - startCallback &lt; 200) &#123; ; // do nothing &#125;&#125;); 從上面的範例中可以看到， setTimeout 任務原定 100 ms 之後被執行，但是 someAsyncOperation 任務花了 0 + 200 ms ，當執行這個任務時，事件迴圈正處在 poll 階段，所以在一個循環中, 需等待 poll 階段中的任務完全處理完畢，或者達到最大處理數量限制。所以在上面的範例中，需等待 poll 階段的任務 someSyncOperation 以及 anotherSyncOperation 被執行完畢，總共花費 400 ms 左右， 之後才會執行 setTimeout() 的任務。 I/O callbacks這個階段主要執行系統端操作的 callbacks, 像是 TCP 錯誤。舉例來說，當試圖連接時，如果一個 TCP socket 接收到 ECONNREFUSED, 某個 *nix 系統想要等待並回報錯誤，這些都會在 I/O callbacks 階段被佇列。 pollpoll 階段有兩種主要功能: 替時間點已經到的 timers 執行腳本 處理 poll queue 當中的事件 當事件進入 poll 階段，且沒有 timers 排程事件 ， 下面兩件事中，其中一件會發生: 如果 poll 階段不為空，事件迴圈將會執行佇列中的所有 callbacks ，又或者達到最大 callbacks 處理上限 如果 poll 階段為空，以下兩件事中，其中一件會發生： 如果腳本已經被 setImmediate() 排程，事件迴圈將會結束 poll 階段，並且繼續進入到 check 階段來處理該佇列中的排程 如果腳本沒有 setImmediate() 的排程，那事件迴圈將會等待新的事件被加入到佇列，然後立即處理他們 一旦 poll 循環為空，事件迴圈將會檢查 timer 中有沒有可以執行的 callback。 如果有一個或多個可以執行了, 事件迴圈會回去執行 timer 階段的 callback check這個階段允許在 poll 階段完成後，立即執行 callback。如果 poll 階段處於空轉，或者已經有 setImmediate() 的排程，事件迴圈將會繼續進入到 check 階段，而不會等待。 setImmediate() 事實上，是一個很特別的 timer 階段，它跟 timer 在事件迴圈內跑在不同的階段。 它使用 libuv API ，這個 API 排程 callback 使之在 poll 階段結束後被執行 通常，事件迴圈會停在 poll 階段等待新的 request 或 connection ，但是當 setImmediate() 有排程，且 poll 階段處於空轉, 那事件迴圈將會結束 poll 階段，並且進入 check 階段 close callbacks如果一個 socket 或 handle 忽然被關閉， close 事件將會被置於這個階段，除非我們指定 process.nextTick 來執行它 setImmediate() vs setTimeout()setImmediate() 和 setTimeout() 很類似，但根據被呼叫的時機不一樣，行為也不同。 setImmediate() 被設計為，一旦 poll 階段結束時執行 setTimeout() 排程任務，在特定的時間之後執行 兩者之間執行的順序，根據被呼叫時的情況而有所不同。如果兩者都在主模組的時候被呼叫，那順序將由當時的程序的表現所決定，意思就是說，順序無法預測。範例如下：// timeout_vs_immediate.jssetTimeout(function timeout () &#123; console.log('timeout');&#125;,0);setImmediate(function immediate () &#123; console.log('immediate');&#125;); 然而，如果兩者是在 I/O cycle 中被呼叫，那 sedImmediate() 將會優先於 setTimeout() // timeout_vs_immediate.jsvar fs = require('fs')fs.readFile(__filename, () =&gt; &#123; setTimeout(() =&gt; &#123; console.log('timeout') &#125;, 0) setImmediate(() =&gt; &#123; console.log('immediate') &#125;)&#125;) 對比 setTimeout() , 使用 setImmediate() 的主要優勢為，如果在 I/O cycle 中， setImmediate() 將會被優先執行，不管 setTimeout() 有幾個 process.nextTick()理解 process.nextTick()你可能已經注意到， process.nextTick() 並沒有被顯示在圖表上，儘管它也是 asynchronous API 的一部分。 這是因為 process.nextTick() 技術上來說不算是事件迴圈的一部分。 nextTickQueue 將會在目前操作完成後，立即被執行，不管目前是在事件迴圈內的哪一個循環。 看看我們的圖表，不管在什麼時候，只要你在特定的階段呼叫 process.nextTick() ， 所以經由 process.nextTick() 送出的 callbacks 將會在事件迴圈啟動下一個階段之前全部都處理完畢。 這樣的模式可能會造成一些不好的情況發生，因為如果你遞迴的使用 process.nextTick() callback ，就會造成所謂的 I/O 飢餓 ，事件迴圈將會無法進入 poll 階段 為什麼這樣的行為會被容許？你可能會想，為什麼這樣的行為在 Node.js 終會被容許？ Node.js 部分的設計哲學是， API 總是異步的，不管是否必要，可以參考以下範例:// this has an asynchronous signature, but calls callback synchronouslyfunction someAsyncApiCall (callback) &#123; callback(); &#125;;// the callback is called before `someAsyncApiCall` completes.someAsyncApiCall(() =&gt; &#123; // since someAsyncApiCall has completed, bar hasn't been assigned any value console.log('bar', bar); // undefined&#125;);var bar = 1; 如果我們執行上面的代碼，會出現輸出如下： 因為 someAsyncApiCall 並沒有做任何異步的動作，照同步的流程跑到 console.log 時， bar 還沒有被定義 如果我們將代碼改成以下：function someAsyncApiCall (callback) &#123; process.nextTick(callback);&#125;;someAsyncApiCall(() =&gt; &#123; console.log('bar', bar); // 1&#125;);var bar = 1; 可以得到以下的輸出： 如上所述， process.nextTick() 的執行時間，是在當前的階段內所有的工作都完成了，在進入下個階段之前，會將所有的 process.nextTick() 處理完畢。在上面的例子中， process.nextTick() 會等到所有在此階段的代碼都被執行完畢，也就是待 var bar = 1 執行後，才去執行這個 callback ，所以不會出現 undefined 的情況。請注意！這沒有最大處理數量限制，所以如果利用 process.nextTick() 指派遞迴任務，那就會造成 I/O 飢餓 情況， 事件迴圈將無法接收到新的 request 一個 tick 到底是多長？一個 tick 的時間長度，是 Event Loop 繞完一圈，把所有 queues 中的 callbacks 依序且同步地執行完，所消耗的總時間。因此，一個 tick 的值是不固定的。可能很長，可能很短，但我們希望它能盡量地短。 process.nextTick() vs setImmediate()千萬不要被這兩個階段的命名搞混了！ process.nextTick():在當前階段結束前執行完畢 setImmediate():在下一個階段，或者下一個事件迴圈的 tick 中執行 基本上，這兩個命名應該是要互換。 process.nextTick() 比 setImmediate() 更快地被觸發。這算是一個很難更動的部分，因為當初命名錯誤之後，隨時時間的推移，越來越多 npm 的 package 都是使用這樣的命名，所以一旦這命名變更了，影響會非常的大。 官方文件上建議開發者，在任何情況中，都使用 setImmediate() ，因為它可以更簡單的被邏輯思考，然後在不同的環境上，有著更廣的相容性。 Promise從下面的原始碼可以看到 Promise ， 或者又稱為 microtasks 的執行優先順序依照原始碼的執行順序來看，在一個階段結束之前，process.nextTick() 會先被執行，緊接著, 執行 Promise 。 startup.processNextTick = function() &#123; var nextTickQueue = []; // Callbacks 會排進這個 queue!! var pendingUnhandledRejections = []; var microtasksScheduled = false; var _runMicrotasks = &#123;&#125;; // ... 略 process.nextTick = nextTick; // nextTick 函式在下面 // ... 略 // process._setupNextTick 在 node.cc 中, 我認為意思到了, 就不用再挖下去了 const tickInfo = process._setupNextTick(_tickCallback, _runMicrotasks); _runMicrotasks = _runMicrotasks.runMicrotasks; // ... 略 function _tickCallback() &#123; var callback, args, tock; do &#123; while (tickInfo[kIndex] &lt; tickInfo[kLength]) &#123; // callbacks 從 queue 中一個一個被挖出來執行 tock = nextTickQueue[tickInfo[kIndex]++]; callback = tock.callback; args = tock.args; if (args === undefined) &#123; nextTickCallbackWith0Args(callback); &#125; else &#123; switch (args.length) &#123; case 1: nextTickCallbackWith1Arg(callback, args[0]); // ... &#125; &#125; if (1e4 &lt; tickInfo[kIndex]) tickDone(); &#125; tickDone(); // process.nextTick 的 callbacks 跑完, 接著跑 Promise 的 microtasks _runMicrotasks(); emitPendingUnhandledRejections(); &#125; while (tickInfo[kLength] !== 0); &#125; // ...略 function nextTick(callback) &#123; var args; if (arguments.length &gt; 1) &#123; args = []; for (var i = 1; i &lt; arguments.length; i++) args.push(arguments[i]); &#125; // 將 callback 連它的 arguments 用一個物件存起來推進 queue nextTickQueue.push(new TickObject(callback, args)); tickInfo[kLength]++; &#125; // ... &#125;; 事件迴圈總結 順序:timers &rarr; I/O callbacks &rarr; idle, pare &rarr; poll &rarr; check &rarr; close callbacks &rarr; timers … 往復循環 順序細節 timers 設定的時間過了之後，才會被’盡快’的執行。如果 poll 階段內還有工作還沒做完，會先做完，才會執行 timers 的工作，所以可能會延遲 當處於 I/O 程序中，比如說， fs 模組中， setImmediate() 順序一定大於 setTimeout() ，因為 check 階段緊接在 poll 階段之後 當處於主要模組中， setImmediate() 以及 setTimeout 的優先順序，取決於運行狀況，這個狀態下，次序無法確定 process.nextTick() 將在當前階段的工作結束前，在進入下一個階段之前執行, 所以他的優先性是第一名的 promise 的執行次序緊接在 process.nextTick() 之後，也是在當前階段結束前執行完畢 Express.js建立一個 app server npm install --save 2.npm install --save express npm install --save-dev nodemon Set script as nodemon fileName.js 指定 status coderes.status (statusCode); Promise以下的範例中， function test 中，我們 return 了一個 Promise ，如果帶入 test function 中的 argument 是 1 ，那就走 resolve 路線 ， 而除了 1 之外所有的 argument, 都走 reject 路線。在 function main 中, 我們使用了 function test, 並帶入 argument 1, Ray 個人覺得這有點像是 PHP 當中的 ternary 用法。當 argument 等於我們在 promise 當中指定的 1 時，走 resolve 路線, 而 then 就是當 promise 為 resolve 路線時該做的事。當 argument 等於是除了 1 之外的任何數，也就是會走 promise 當中的 reject 路線, 此時將會執行 catch 的動作。我們在 promise 當中指定，當走 resolve 路線時，輸出為字串 Success, 所以在 then 的 closure 當中，被帶入的 argument 就是 Success反之，當走 reject 路線時，輸出字串為 Error, 所以在 catch 的 closure 當中，被帶入的 argument 則為 Errorfunction test(number) &#123; return new Promise((resolve, reject) =&gt; &#123; if (number === 1) &#123; resolve(\"Success\") &#125; else &#123; reject(\"Failed\") &#125; &#125;)&#125;function main() &#123; test(1).then((result) =&gt; &#123; // result === \"Success\" console.log(result) &#125;).catch((error) =&gt; &#123; // 不會被執行, 因為狀態是成功 &#125;) test(2).then((result) =&gt; &#123; // 不會被執行, 因為狀態是成功 console.log(result) &#125;).catch((error) =&gt; &#123; // error === \"Failed\" console.log(error) &#125;)&#125; 建立 Datastore Model// 從 google SDK 引用 Datastore functionconst &#123;Datastore&#125; = require('@google-cloud/datastore');// 輸入 project_idconst projectId = 'balmy-sanctuary-238903';// 初始一個 Datastore instanceconst datastore = new Datastore(&#123; projectId: projectId,&#125;);// 匯出這個 modulemodule.exports = datastore; 建立一個 Controller// 匯出這個 functionexports.test = function (req, res) &#123; async function quickStart() &#123; // The kind for the new entity const kind = 'abc'; // The name/ID for the new entity const name = 'sampletask1'; // The Cloud Datastore key for the new entity const taskKey = datastore.key([kind, name]); // Prepares the new entity const task = &#123; key: taskKey, data: &#123; description: 'Buy milk', &#125;, &#125;; console.log(datastore.key(['name', 'kind'])); // Saves the entity await datastore.save(task); console.log(`Saved $&#123;task.key.name&#125;: $&#123;task.data.description&#125;`); res.send(`Saved $&#123;task.key.name&#125;: $&#123;task.data.description&#125;`); &#125; quickStart().catch(console.error);&#125;; Routevar express = require('express');var router = express.Router();// 導入 controller 模組, 並給予名稱var datastore = require('../controllers/datastoreController');/* GET home page. */router.get('/', function(req, res, next) &#123; res.render('index', &#123; title: 'Express' &#125;);&#125;);// 建一個 router, 並且導向 datastoreController 裡頭的 test functionrouter.get('/test', datastore.test);module.exports = router; Root address// 找一個地方新增一個檔案，輸入以下的 code// 之後我們就可以在任何一個檔案中，透過 require 這個檔案來 const rootDirconst path = require('path');module.exports = path.dirname('/Users/ray/code/datastore/app.js'); 若我們 console.log 上面 exports 的值，可以得到該專案下的 root 位址 Path利用 path module 來指定路徑// p 會等於專案根目錄下, data 資料夾之下的一個叫做 `products.json` 的檔案// 專案根目錄請參考 `root address` 章節const p = path.join(rootDir, 'data', 'products.json') object.assign 可用來複製或覆蓋目標物件let exampleObject = &#123;a:1, b:2, c:3, c:4&#125;;let copy = object.assign(&#123;&#125;, exampleObject, &#123;a:4, b:4, c:4, d:4&#125;); test 用來確認該 string 是否符合該 regex pattenvar str = \"Hello world!\";// look for \"Hello\"var patt = /Hello/g;var result = patt.test(str);// result = true 時間var moment = require('moment-timezone');var test = moment(createdDate).tz(\"Asia/Taipei\").format('YYYY-MM-DD HH:MM:SS');console.log(test); // 2019-05-21 08:05:44 同時異步發多請求，並待全部有結果後繼續// 需安裝兩個套件 `request-promise` 以及 `p-limit`const request = require('request-promise');const pLimit = require('p-limit');class HealthCheckService &#123; static async getHealthCheckResults(sites) &#123;// 指定 limit 同時最多發十個 request const limit = pLimit(10);// 利用 map 從 sites 中拿到我們要發請求的 url// 然後利用套件 `limit` 來限制同時發請求的數量，再來使用 `request-promise` 套件來對上面拿到的 url 發請求 let promises = sites.map((site) =&gt; &#123; let url = `https://yourAPI?host=$&#123;site.host&#125;&amp;cname=$&#123;site.cname&#125;`; return limit(() =&gt; request(url)); &#125;);// 上面的每一個 promises, 都是一個請求。 現在我們利用 `Promise.all`, 待所有的結果都回來之後，在 return return await Promise.all(promises); &#125;&#125;","link":"/zh-tw/Node-js/"},{"title":"使用 Laravel Queue 以及 AWS SQS","text":"前言本篇重點如下： 使用 Laravel queue 完成寄 Email 功能 使用 AWS SQS 為什麼要使用 queue 呢？當我們執行一些耗時較久的工作時，像是發送 Email ， 或是上傳圖片或是影片，讓使用者等到工作執行完畢才進行下一個動作的話，是不太現實的。所以當使用者發出一些需要較長時間執行的請求時，我們要使用 queue 來幫我們隊列，在背景慢慢執行，然後讓使用者可以立即執行下一個動作。 申請 AWS SQS 服務 首先，你要有 AWS 帳號 到 AWS 上申請 SQS 服務 這邊可以參考 AWS教學，完成設定。 記住下面的資料，後面會用到 到右上角，選擇帳戶的地方，選擇My Security Credentials 到左邊選擇 Users 建立新的 User 輸入 user 名稱，打勾 Programmatic access ，然後下一步 然後 Create group ，如下圖 再來把剛剛建立的 user 加到這個新建的 group 接下來 Add tags 是選填，不一定要填 然後就可以獲得 Access key ID 以及 Secret access key ，如果怕忘記的話，可以下載下來哦！ 這個 Secret access key 只會出現一次哦，如果不小心忘記或沒有記下來的話，就要重新產生哦！ 實作 Laravel queue配置 AWS SQS 以下操作均參考官方文件 安裝 AWS 官方 SDK ，參照官方文件 ，在專案資料夾底下： composer require aws/aws-sdk-php 在.env檔案中，做以下配置 QUEUE_CONNECTION=sqsSQS_KEY=上面拿到的 keySQS_SECRET=上面拿到的 secretSQS_QUEUE=testSQSSQS_REGION=ap-northeast-1SQS_PREFIX=依照上面的URL去掉queue名稱後填入 建立 jobsphp artisan make:job ProcessPodcast job 範本如下&lt;?phpnamespace App\\Jobs;use App\\Helpers;use Illuminate\\Bus\\Queueable;use Illuminate\\Queue\\SerializesModels;use Illuminate\\Queue\\InteractsWithQueue;use Illuminate\\Contracts\\Queue\\ShouldQueue;use Illuminate\\Foundation\\Bus\\Dispatchable;class SendMailWhenOrderPlaced implements ShouldQueue&#123; use Dispatchable, InteractsWithQueue, Queueable, SerializesModels; protected $job; // 嘗試執行最高次數 public $tries = 5; /** * Create a new job instance. * * @return void */ public function __construct($order, $FB_email, $Local_email) &#123; $this-&gt;order = $order; $this-&gt;FB_email = $FB_email; $this-&gt;Local_email = $Local_email; $this-&gt;job = Helpers::mailWhenOrderPlaced($order, $FB_email, $Local_email); &#125; /** * Execute the job. * * @return void */ public function handle() &#123; return $this-&gt;job; &#125;&#125; 上面的範例，是使用 queue 來執行 Ray 專案裡頭的一個寄送 Email 的功能，叫做 mailWhenOrderPlaced。 使用 dispatch 在我們想要執行這一個job的地方，使用dispatch，就可以囉！SendMailWhenOrderPlaced::dispatch($order, $FB_email, $Local_email); 執行 queue 在專案底下，執行php artisan queue:work 測試 這個時候，當程式執行到 dispatch 那行時，就會使用 queue 來執行哦！ 總結是不是很簡單啊？另外，因為我們使用了 queue ，所以必須要確保 queue 的運作是正常的。以這個例子來說的話，如果 queue 不幸失效了，那這個發 Email 的功能就會失效哦！為了確保 queue 在失敗後重新自動執行，我們需要 Supervisor 來幫我們監控並管理程序！關於 Supervisor ，可以參考 Ray 的另外一篇文章哦！如果想知道如何用 Laravel Mail 以及 AWS SES 來發送 mail ，也可以參考 Ray 的另外一篇文章","link":"/zh-tw/LaravelQueueWithSQS/"},{"title":"使用 `Laravel` `template` 與 `blade`","text":"前言本篇為Laravel 的學習筆記，主要紀錄 Laravel blade 的用法，重點如下： 建立並重複使用 template 使用 yield 及 section 將值傳到 view {{ }} 幫我們做了什麼？ 建立 template 建立 template ，名為 layout ，如下&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; // 使用 yield 設定 title 的範圍，並將 Laracasts 設為預設值，若在頁面中沒有特別指定 title 的值時，會自訂套用預設 &lt;title&gt;@yield('title', 'Laracasts')&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;ul&gt; &lt;li&gt;&lt;a href=\"/\"&gt;Welcome&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=\"/about\"&gt;About&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=\"/contact\"&gt;contact&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;// 使用 yield 設定區塊的範圍，範圍名稱為 content@yield('content')&lt;/body&gt;&lt;/html&gt; 使用 section 上面已經建立好了 template ，所以我們可以在新的頁面直接套用 template// 下面我們直接套用名為 layout 的 template@extends('layout')// 使用 section ， 在 template 中已經設定好的區塊，插入我們想要的元素。在 title 區塊插入新的值@section('title', 'Welcome Page')// 使用 section ， 在 content 區塊插入值@section('content') &lt;h1&gt;Welcome here&lt;/h1&gt;// 使用 endsection 來明確範圍@endsection 重複上面的操作，在多個新頁面上套用 template 將值傳到 view 要將值帶到 view 其實也很多種做法，以下列舉四種 1. Route::get(&apos;/&apos;, function () &#123; $task = [ &apos;Go to the school&apos;, &apos;Go to the market&apos;, &apos;Go to work&apos; ]; return view(&apos;welcome&apos;, compact(&apos;task&apos;) );&#125;); 2. Route::get(&apos;/&apos;, function () &#123; $task = [ &apos;Go to the school&apos;, &apos;Go to the market&apos;, &apos;Go to work&apos; ]; return view(&apos;welcome&apos;, [&apos;tasks&apos; =&gt; $task] ); Route::get(&apos;/&apos;, function () &#123; return view(&apos;welcome&apos;, [&apos;tasks&apos; =&gt; [ &apos;Go to the school&apos;, &apos;Go to the market&apos;, &apos;Go to work&apos; ]]);&#125;); Route::get(&apos;/&apos;, function () &#123; return view(&apos;welcome&apos;)-&gt;withTasks([ &apos;Go to the school&apos;, &apos;Go to the market&apos;, &apos;Go to work&apos; ]);&#125;); 以上四種做法， Ray 比較常用第一種。 在 view 接值 在 view 把剛剛傳過來的值取出，並顯示 @extends(&apos;layout&apos;)@section(&apos;title&apos;, &apos;Welcome Page&apos;)@section(&apos;content&apos;) &lt;h1&gt;Welcome here&lt;/h1&gt; &lt;ul&gt; @foreach ($tasks as $task) &lt;li&gt; &#123;&#123; $task &#125;&#125; &lt;/li&gt; @endforeach &lt;/ul&gt;@endsection 在Laravel 的 blade 檔案中，可以在 {{ }} 中使用變數 畫面如下： blade {{ }} 幫我們做了什麼？ {{ }} 除了可讓我們取得傳過來的變數之外，還自動執行了 PHP的 function htmlspecialchars ，防止有心人 XSS 攻擊。 做個實驗，使用blade:Route::get(&apos;/&apos;, function () &#123; $test = &apos;&lt;script&gt;alert(&quot;test&quot;)&lt;/script&gt;&apos;; return view(&apos;welcome&apos;)-&gt;withTasks([ &apos;Go to the school&apos;, &apos;Go to the market&apos;, &apos;Go to work&apos; ])-&gt;withTest($test);&#125;); @extends(&apos;layout&apos;)@section(&apos;title&apos;, &apos;Welcome Page&apos;)@section(&apos;content&apos;) &lt;h1&gt;&#123;&#123; $test &#125;&#125;&lt;/h1&gt; &lt;ul&gt; @foreach ($tasks as $task) &lt;li&gt; &#123;&#123; $task &#125;&#125; &lt;/li&gt; @endforeach &lt;/ul&gt;@endsection 如上面的 code ，我們傳了有著 script tag 的 變數過去經由瀏覽器渲染出來後，如下： 再做個實驗，我們可以使用{!! !!} 來取消htmlspecialchars，慎用！@extends(&apos;layout&apos;)@section(&apos;title&apos;, &apos;Welcome Page&apos;)@section(&apos;content&apos;) &lt;h1&gt;&#123;!! $test !!&#125;&lt;/h1&gt; &lt;ul&gt; @foreach ($tasks as $task) &lt;li&gt; &#123;&#123; $task &#125;&#125; &lt;/li&gt; @endforeach &lt;/ul&gt;@endsection 瀏覽器渲染出來後，如下： 可以看到，該 script 真的被執行了 總結有關於blade的應用還有很多，之後會繼續更新。","link":"/zh-tw/LaravelView/"},{"title":"Stackdriver 快速開始","text":"前言本篇主要是利用Google的Qwiklab平台學習的同時，做的一份學習筆記原文連結如下： Refer to QWIKLABS official website 概述？本篇實作將告訴你如何利用Stackdriver來監看Google Compute Engine virtual machine instance，你也將安裝監看以及紀錄的服務在你的VM上，他們可以從你的instance上收集更多的資訊 設定及要求Qwiklabs setup在你按下 Start Lab 按鈕之前 詳讀所有的教學。Labs 是有時間限制的，而且你不可以停止時間倒數。倒數計時器在你按下 Start Lab 按鈕後開始倒數，上面顯示的時間為你還能使用 Cloud 資源的時間。 Quiklabs 的手把手環境，讓你可以在真實環境中來操作進行 Quiclabs 上提供的課程，而不是在一個模擬或是展示的環境。我們透過提供你一個全新的、暫時的帳號密碼，在計時器歸零之前，你可以用來登入並存取 Google Cloud Platform。 你需要什麼？ 要完成這個 lab ，你需要: 一個一般的網路瀏覽器（推薦 Chrome） 完成這個 lab 的時間 備註： 如果你已經有你自己的個人 GCP 帳號或專案，請不要使用在這一個 lab 現在你已經開始你的 lab, 你將會登入 Google Cloud Shell 主控台，然後開啟命令列工具 如何開始你的 lab ，然後登入 Console? 按下 Start Lab 按鈕。如果你需要付費，會有一個彈出視窗來讓你選擇付費的方式。在左方你會看到一個面板，上面有暫時的帳號密碼，你必須使用這些帳號密碼在此次 lab 複製 username , 然後點擊 Open Google Console。 Lab 會開啟另外一個視窗，顯示選擇帳號的頁面 tip: 開啟一個全新的視窗，然後跟原本的頁面並排 在選擇帳號頁面, 點擊 Use Another Account 登入頁面開啟，貼上之前複製的 username 以及 password ，然後貼上 重要：必須使用之前於 Connection Details 面板 取得的帳號密碼，不要使用你自己的 Qwiklabs 帳號密碼。 如果你有自己的 GCP 帳號，請不要用在這裡（避免產生費用） 點擊並通過接下來的頁面: 接受terms以及conditions 不要增加recovery optoins 或 two factor authentication (因為這只是一個臨時帳號) 不要註冊免費體驗 稍待一些時候， GCP 控制台將會在這個視窗開啟。 注意：按下左上方位於Google Cloud Platform 隔壁的 Navigation menu ，你可以瀏覽選單，裡面有一系列的 GCP 產品以及服務 啟動 Google Cloud ShellGoogle Cloud Shell 是載有開發工具的虛擬機器。它提供了5GB的 home 資料夾，並且運行在 Google Cloud 上。 Google Cloud Shell 讓你可以利用 command-line 存取 GCP 資源 在 GCP 控制台 ，右上的工具列，點擊 Open Cloud Shell 按鈕 在打開的對話框裡，按下 START CLOUD SHELL: 你可以立即按下 START CLOUD SHELL 當對話視窗打開。 連結並提供環境會需要一點時間。當你連結成功，這代表你已成功獲得授權，且此專案已被設為你的專案ID，例如： gcloud 是 Google Cloud Platform 的 command-line 工具，他已事先被安裝在 Cloud Shell 並且支援自動補齊 使用這個 command ,你可以列出有效帳戶名稱: gcloud auth list 輸出: Credentialed accounts: - &lt;myaccount&gt;@&lt;mydomain&gt;.com (active) 範例輸出: Credentialed accounts: - google1623327_student@qwiklabs.net 你可以使用以下 command 來列出專案 ID gcloud config list project 輸出： [core]project = &lt;project_ID&gt; 範例輸出： [core]project = qwiklabs-gcp-44776a13dea667a6 gcloud 的完整文件可以參閱 Google Cloud gcloud Overview 建立一個Compute Engline Instance 在GCP主控台的控制面板， Navigation menu &gt; Compute Engine &gt; VM instance，然後點擊 Create￼ 照下面的資訊填入相對應的空格，無提到的空格內請保持預設值 Name: lamp-1-vm Region: us-central1 (Iowa)` Zone: us-central1-a Machine type: small (1 shared vCPU) Firewall: Select Allow HTTP traffic 點擊Create 安裝Apache2 Server 在主控台，點擊SSH來開啟一個連接此instance的terminal 在SSH視窗中，執行下面的指令來設定Apache2 sudo apt-get update sudo apt-get install apache2 php7.0 當詢問是否繼續y 如果你無法安裝php7.0，裝php5 sudo service apache2 restart 回到主控台，在VM instance的頁面，點選External IP處以連接到Apache2預設頁面 建立Stackdriver帳號 要使用Stackdriver，你的專案必須要在一個Stackdriver 帳號內，接下的步驟將建立一個有試用期的Stackdriver帳號 (1) 在GCP主控台，點擊Navigation menu &gt; Monitoring - 這將在一個新視窗開啟Stackdriver，並顯示你的Qwiklabs專案。 點擊Create workspace ![](https://i.imgur.com/0wwazU5.png) (2) 在接下來的頁面: - 加入GCP專案到monitor，你將看到你的專案顯示已勾選 ![](https://i.imgur.com/97vi3ch.png) - 點擊Continue - 監看AWS帳號 - 略過設定 - 安裝Stackdriver監看代理 curl -sSO https://dl.google.com/cloudagents/install-monitoring-agent.sh` sudo bash install-monitoring-agent.sh 安裝Stachdriver記錄代理curl -sSO https://dl.google.com/cloudagents/install-logging-agent.sh sudo bash install-logging-agent.sh 點擊Continue 點擊Launch monitoring 建立運行時間確認Uptime check用以確認資源總是可以被存取，在此範例中，我們將建立一個uptime check來確認Google網頁正常運行中- 在Stackdriver console主控台，在控制面板上，點擊Create an Uptime Check按鈕。你也可以從左邊到menu中，找到Uptime Checks &gt; Uptime Checks Overview，然後點擊 Create an Uptime Check- 編輯New Uptime Check，加入以下資訊 - Title: Lamp Uptime Check - Check type: HTTP - Resource Type: Instacne - Applies to: Single, lamp-1-vm - Path: leave at default - Check every: 1 min如果instance沒有自動載入在我們寫則”single”之後，取消這次的uptime check，重新整理Stackdriver頁面，然後重新試一遍 點擊Test來確認我們的uptime check可以連結到資源 點擊save，當顯示所有的資源都已經可以連接 點擊No thanks來為這個uptime check 建立一個警告政策 Uptime Check的設置將會需要一些時間生效，我們繼續我們的進度，等等我們再來確認結果。讓我們先來建立一個警告政策。 建立一個警告政策利用Stackdriver來建立一個或多個的alerting policies.從左邊的選單，點擊Alerting &gt; Create a Policy，然後設置Conditions, Notifications, and Documentation 條件： 點擊Add Condition 依照下面的資訊來設置空格處，如果沒有提到，請保留為默認值 Target: Resource Type: GCE VM Instance (gce_instance)Metric: Type &quot;network&quot; then select Network traffic ConfigurationCondition: is aboveThreshold: 500 bytesFor: 1 minute 點擊Save Notifications: 選擇Email Address，然後輸入你的個人信箱地址 Documentation: 點擊Add Documentation然後新增一個訊息，這個訊息將會被包含在郵件警告中 Name this policy: Inbound Traffic Alert 點擊save 我們已經建立一個警告了！在等待系統觸發警告的同時，建立一個控制面板和圖表，然後看一下紀錄 建立控制面板和圖表 左邊選單，Dashboards &gt; Create Dashboard 螢幕右上方，點擊Add Chart 在Find resource type and metric區域，輸入CPU，然後選擇 CPU Load(1m). GCE VM instance根據資源類型自動被選擇，圖表名稱自動命名，但如果你想要的話，你可以自訂命名 點擊save 現在建立第二個圖表 在新的控制面板右上方的選單，選擇Add Chart Find resource type and metric欄位內輸入Network，選擇Received Packets，其餘欄位保持預設值，你可以在預覽區域看到圖表資料 點擊save 重新命名新的控制面板，從Untitled Dashboard改成Stackdriver LAMP Qwik Start Dashboard 檢視紀錄Stackdriver Monitoring 和 Stackdriver Logging緊密地互相整合著 在Stackdriver 左手邊選單，點擊Logging來檢視紀錄 選擇GCE VM instance &gt; lamp-1-vm在第一個下拉選單 從第二個下拉選單選擇syslog，然後點擊OK 其餘欄位保留預設 選擇Start streaming logs 圖案 可以看到這個VM instance的logs 現在來看看，當我們開始跟結束時，會發生什麼事 點擊並拖曳Logs Viewer brower視窗，所以Compute Engine console 和 Stackdriver Logging console會並排 在主控台內，VM instance視窗，點擊lamp-1-vm instance 在VM instance details 視窗，於螢幕上方點擊Stop，然後確認停止instance，這會需要幾分鐘，我們來看log messages 我們可以看著Logs View 視窗，然後看VM什麼時候被結束 在VM instance detail 視窗，在螢幕最上方點擊Start，然後確認。這會需要幾分鐘的時間，我們可以檢視log訊息 確認uptime check結果以及警告觸發 在Stackdriver左邊區域，點擊Uptime Checks &gt; Lamp Uptime Check。這將顯示uptime check的細節，包含等待時間，uptime 百分比，區域結果以及設定檢查。如果你看到的Location result 是 “No checks have run yet”，那請等待幾分鐘，然後重新整理頁面 左方區域點擊Uptime Checks &gt; Uptime Checks Overview，這將提供所有運行中的uptime checks，包含網站在不同區域的狀態 確認警報是否有觸發 在StackDriver 主控台，左方頁面點擊Alerting &gt; Incidents，如果你沒有看到開啟的事件，請確定一下你在看的是RESOLVED頁面 依然在Stackdriver 主控台，點擊Alerting &gt; Events，你應該會看到一個事件列表 確認一下我們的email帳號，應該會收到警報 習題測試 Stackdriver supports which of the following cloud platforms (1) [x] Google Cloud Platform (2) [ ] Azure (3) [x] Amazon Web Services","link":"/zh-tw/Stackdriver/"},{"title":"OOP-Class and Object","text":"大家好，我是Ray! 今天想跟大家分享，什麼是Ｃlass，以及什麼是Object，還有他們之間的關係！ 講到class就不得不講到object，而要解釋object就離不開class，這也常常是讓許多人感到困惑與不解的地方。 簡單來說，class算是一用來創造object的code模板。 廢話不多說，讓我們來創一個class先： 我們可以自訂我們喜歡的class的名稱，class的名稱可以是數字與字母的組成，但開頭的第一個字不可以是數字，如下面的code：class ＭyAccessories&#123; // class body&#125; 雖然上面的東西看起來沒什麼用，但是這已經是一個符合標準的class 如上所述，我們說class是產出object的一個模板，現在讓我們來產出幾個object，如以下的code:$accessory1 = MyAccessories();$accessory2 = MyAccessories(); 以上我們使用MyAccessories class 造出了兩個object，由於這兩個object是由同樣的class造出來的，所以他們有著相同的功能與類型。 那你會問，他們一樣嗎？ 答案是，不。 或許在功能以及類型上它們是一樣的，但他們的確是不同的object。 我知道你可能還有疑惑，讓我們把他們印出來看看！新增以下的code:var_dump($accessory1);var_dump($accessory2); 沒有意外的話，你應該會印出下面的東西。#後面的編號代表著他們的獨特性。或許你會說，啊～這會不會是照順序來顯示＃後面數字啊？object(MyAccessories)#1 (0) &#123;&#125;object(MyAccessories)#2 (0) &#123;&#125; 那我們再來做一個實驗 我們將var_dump內的object名稱互換，如果說＃後面的數字只是照順序來顯示的話，照理說印出來的東西應該不會變，是吧？var_dump($accessory2);var_dump($accessory1); 你應該會印出下面的東西： object(MyAccessories)#2 (0) &#123;&#125;object(MyAccessories)#1 (0) &#123;&#125; ＃後面的數字變了！ 這代表一個事實，那就是每個object，儘管他們是由同一個class所產出的，都會有屬於自己的一組編號，代表他們的獨特性，所以每一個object都會是不同的。 如果你還有些困惑，讓我再來舉個例子： Class就像是生產鑄件的模具，而object就像是被壓出來的鑄件，可以是一個鍵帽，或是一個同型號的耳機。外觀看來他們都是一模一樣的，但是他們確實是不同的獨立個體。你或許可以在上面看到生產流水編號，那就相當於上面印出來的#後面的數字。 看完以上的文章，各位是否對class以及object有更深一層的認識了呢？","link":"/zh-tw/OOP-ClassAndObject/"},{"title":"Cloud Functions:Qwik Start - Console","text":"前言本篇主要是利用 Google 的 Qwiklab 平台學習的同時，做的一份學習筆記為避免翻譯誤解，專業術語在本篇將不會被翻譯，保留原文 概述Google Cloud Functions 是一個用來建立以及連結雲端服務的無伺服器執行環境。 你可以利用 Cloud Functions 來寫簡單，單一用途的 functions, 這些 functions 被附加到雲端基礎設施以及服務的事件上。 當監聽的事件被觸發， Cloud Function 也會被觸發。 你的代碼將在一個完全自動化管理的環境中被執行。 你完全不需要提供任何的基礎設施或管理任何的伺服器。 Cloud Functions 由 Javascript 所編寫，並且執行在 Google Cloud Platform 的 Node.js 環境。 你可以讓你的 Cloud Functions 運行在任何的 Node.js 執行階段上，這不只攜帶輕便，而且更讓本地測試非常簡單。 連結並且延伸雲端服務Cloud Functions 提供一個邏輯的連結層，它可以讓你在上面寫代碼來連接並且延伸雲端服務。 監聽並且回應 Cloud Storage 的檔案上傳事件，一個紀錄改變事件，或是 Cloud Pub/Sub 的訊息觸發事件。 Cloud Functions 擴大已經存在的雲端服務，並且允許使用客制的程式邏輯來處理越來越多的使用情境。 Cloud Functions 擁有 Google Service Account credential 的存取權，因此可以無縫的大部分的 Google Cloud Platform 服務接軌，像是 Datastore, Cloud Spanner, Cloud Translation API, Cloud Vision API, 以及很多很多其他的服務。 並且，很多的 Node.js client libraries 都有支援 Cloud Functions, 這更是簡化了這些服務之間的整合。 事件以及觸發 (Events and Triggers)雲端事件是發生在雲端環境的事。 像是資料庫的資料有所改變，檔案被上傳到儲存區，或是一台新的虛擬機背建立。 不管你是否選擇回應，事件都會發生。 你可以使用 trigger 來建立對一個事件的回應。 Trigger 是一個宣告，對那些你有興趣的特定的或是一連串事件的宣告。 將一個 function 連結到 trigger 讓我們可以捕捉，並且隨著事件的發生有所動作。 更多有關建立 trigger 並且將它與 function 關聯的資訊，請參考 Events and Triggers 無伺服器Cloud Functions 幫我們拿掉了這些工作，像是伺服器管理，軟體設置，框架更新，作業系統更新。 你只需要專注在代碼的部分，因為 Google 完全地幫你管理軟體以及基礎設施的部分。 再者，資源會隨著事件的回應自動地被提供。 這代表說，你完全不需要做任何事就可以讓一個 function 從一天幾次的調用，到一天好幾百萬次的調用。 使用情境異步的工作量像是輕量化的 ETL, 或是雲端自動化像是應用被觸發而自動建立，不再需要獨立的伺服器以及開發者的維護。 你只要簡單的部署 Cloud Function 並且和你想要的事件做連結。 Cloud Functions 的這些細緻的，立即提供的特質讓它非常適合輕量化的 API 以及 webhooks。 再者，當你部署一個 HTTP Function，該 HTTP endpoints 將會自動地被提供，這代表你不再需要像其他服務的複雜設置。 下面的表格列出了一些額外的常用 Cloud Function 的使用情境： 使用情境 敘述 Data Processing / ETL 監聽並且回應 Cloud Storage 事件像是當一個檔案被建立，被改變，或是被移除了。 處理圖片，影片編譯，資料驗證及轉換，以及從 Cloud Functions 上觸發任何網路上的服務。 Webhooks 經由簡單的 HTTP trigger, 回應那些來自第三方的事件，像是 GitHub, Slack, Stripe, 或是任何可以發 HTTP requests 的來源。 輕量化 APIs 使用輕量化、不緊密相依、快速建立，以及立即可調整大小的邏輯來建構你的應用。 你的 functions 可以被事件驅動或者是直接通過 HTTP/S 觸發 可攜式後端 使用 Google 專為 App 開發者的可攜式平台, Firebase, 以及在 Cloud Functions 建構你自己的移動後端。 監聽以及回應來自於 Firebase Analytics, Realtime Database, Authentication, 以及 Storage 的事件。 IoT 想像一個數以萬計的裝置串流資料到 Cloud Pub/Sub, 然後啟動 Cloud Functions 來處理，轉換，並且儲存資料。 Cloud Functions 讓你使用完全無伺服器的方式來做到這些事。 這個手把手的教程將會教你如何使用 Google Cloud 主控台來建立，部署，並且測試 Cloud Function 你將會做什麼？ 建立一個 cloud function 部署並且測試這個 function 檢視紀錄 設定及要求 在你按下 Start Lab 按鈕之前 詳讀所有的教學。Labs 是有時間限制的，而且你不可以停止時間倒數。倒數計時器在你按下 Start Lab 按鈕後開始倒數，上面顯示的時間為你還能使用 Cloud 資源的時間。 Quiklabs 的手把手環境，讓你可以在真實環境中來操作進行 Quiclabs 上提供的課程，而不是在一個模擬或是展示的環境。我們透過提供你一個全新的、暫時的帳號密碼，在計時器歸零之前，你可以用來登入並存取 Google Cloud Platform。 你需要什麼？ 要完成這個 lab ，你需要: 一個一般的網路瀏覽器（推薦 Chrome） 完成這個 lab 的時間 備註： 如果你已經有你自己的個人 GCP 帳號或專案，請不要使用在這一個 lab 現在你已經開始你的 lab, 你將會登入 Google Cloud Shell 主控台，然後開啟命令列工具 如何開始你的 lab ，然後登入 Console? 按下 Start Lab 按鈕。如果你需要付費，會有一個彈出視窗來讓你選擇付費的方式。在左方你會看到一個面板，上面有暫時的帳號密碼，你必須使用這些帳號密碼在此次 lab 複製 username , 然後點擊 Open Google Console。 Lab 會開啟另外一個視窗，顯示選擇帳號的頁面 tip: 開啟一個全新的視窗，然後跟原本的頁面並排 在選擇帳號頁面, 點擊 Use Another Account 登入頁面開啟，貼上之前複製的 username 以及 password ，然後貼上 重要：必須使用之前於 Connection Details 面板 取得的帳號密碼，不要使用你自己的 Qwiklabs 帳號密碼。 如果你有自己的 GCP 帳號，請不要用在這裡（避免產生費用） 點擊並通過接下來的頁面: 接受terms以及conditions 不要增加recovery optoins 或 two factor authentication (因為這只是一個臨時帳號) 不要註冊免費體驗 稍待一些時候， GCP 控制台將會在這個視窗開啟。 注意：按下左上方位於Google Cloud Platform 隔壁的 Navigation menu ，你可以瀏覽選單，裡面有一系列的 GCP 產品以及服務 建立一個 function在這個步驟，你將使用主控台建立一個 cloud function 在主控台，點擊 Navigation menu &gt; Cloud Functions 點擊 Create function 在 Create function 對話框，輸入以下的值欄位 | 值— |Name | GCFunctionMemory allocated | DefaultTrigger | HPPT triggerSource code | Inline editor (使用預設被提供給 index.js 的 **helloWorld function 實作) 在下個章節部署 function 部署 function還是在 Create function 對話框，在底部點擊 Create 來部署 function 在你點擊 Create 後，主控台會重導向 Cloud Functions Overview 頁面 當 function 正被部署時，旁邊的小圖案會顯示轉圈圈，當部署完畢，會變成一個打勾的圖案 測試進度點擊 Check my progress 來確認目前的進度。如果你已經完成目前的進度，你將獲得一個評價分數。 測試 function測試這個被部署上去的 function 在 Cloud Functions Overview 頁面，從右邊三個小點的選單處點擊 Test function 在 Triggering event 欄位，在大括號 {} 之間輸入以下代碼並且點擊 Test the function \"message\":\"Hello World!\" 在 output 欄位，你應該可以看到一段訊息 Success: Hello World! 在 Logs 欄位，一段狀態碼 200 顯示成功。 (紀錄出現可能會需要幾分鐘的時間) View logs (檢視紀錄)從 Cloud Functions Overview 頁面檢視紀錄 點擊藍色箭頭來回到 Cloud Functions Overview 頁面 在 Cloud Functions Overview 頁面，從右邊三個小點的選單處點擊 View logs 紀錄歷史範例如下： 你的應用已經被部署，被測試，而且你已經可以檢視它的紀錄 測試你的理解下面有多重選擇的問題來鞏固你對本教程概念的理解，盡你所能的回答吧： true HTTP 恭喜你已經完成本教程","link":"/zh-tw/cloudFunctionsQwikStartConsole/"},{"title":"PayPal REST API 串接金流好簡單","text":"前言本篇將會分享，如何使用 PayPal REST API，來做到以下的動作： 建立授權訂單 授權 請款 退款 部分款項凍結 本篇屬於個人學習筆記，所以可能會參雜一些個人的專案內容，請選擇性參考。 安裝 PayPal REST API 官方 SDK本篇使用的為目前 PayPal 最新釋出的 SDK 版本 安裝composer require paypal/paypal-checkout-sdk 設定個人設定 安裝完成之後，可在 SDK 的資料夾底下，找到範例，如下圖： 設定 PayPalClient.php 檔案，如下: 申請開發者帳號並登入 建立一個App 取得 Client ID 以及 Secret 將取得的 Client ID 以及 Secret 填入， Ray 是設在環境變數 public static function environment()&#123; $clientId = env('PAYPAL_SANDBOX_API_ClientID'); $clientSecret = env('PAYPAL_SANDBOX_API_SECRET'); return new SandboxEnvironment($clientId, $clientSecret);&#125; 開始在上面提到的範例資料夾中，可以找到幾乎所有會用到的範例。這邊可以根據每個人的需求不同來客制，以下是 Ray 自己的版本任何疑惑，請參考 sample 裡頭的範例，以及官方文件如下:orderpayment order 跟 payment 的差異主要的差異如下： order： 只支援 PayPal 的會員。可以延後付款，並且視乎貨物的狀態做部分的請款 payment: 可以延後付款，但不可以分批請款。 詳細的介紹可以參考原文解說 建立訂單 ( order )public function createOrder($toBeSavedInfo, Recipient $recipient, $debug = false)&#123; // 引用SDK $request = new OrdersCreateRequest(); $request-&gt;headers[\"prefer\"] = \"return=representation\"; // 這邊的RequestBody等等會貼在下面 $request-&gt;body = self::buildRequestBody($toBeSavedInfo, $recipient); // 這邊引用剛剛設定好的 PayPalClient $client = PayPalClient::client(); $response = $client-&gt;execute($request); if ($debug) &#123; print \"Status Code: &#123;$response-&gt;statusCode&#125;\\n\"; print \"Status: &#123;$response-&gt;result-&gt;status&#125;\\n\"; print \"Order ID: &#123;$response-&gt;result-&gt;id&#125;\\n\"; print \"Intent: &#123;$response-&gt;result-&gt;intent&#125;\\n\"; print \"Links:\\n\"; foreach ($response-&gt;result-&gt;links as $link) &#123; print \"\\t&#123;$link-&gt;rel&#125;: &#123;$link-&gt;href&#125;\\tCall Type: &#123;$link-&gt;method&#125;\\n\"; &#125; // To toggle printing the whole response body comment/uncomment below line echo json_encode($response-&gt;result, JSON_PRETTY_PRINT), \"\\n\"; &#125; // 建立建立完成後，我只取讓使用者用來確認的連結，預設 PayPal 提供了很多的連結，但是其他的我們都可以靠 API 來達成。 foreach (($response-&gt;result-&gt;links) as $link) &#123; if ($link-&gt;rel === 'approve') &#123; $linkForApproval = $link-&gt;href; break; &#125; &#125; // 這邊取得建立訂單之後的一些會用到的資訊，然後 return $toBeSavedInfo['payment_id'] = $response-&gt;result-&gt;id; $toBeSavedInfo['statusCode'] = $response-&gt;statusCode; $toBeSavedInfo['custom_id'] = $response-&gt;result-&gt;purchase_units[0]-&gt;custom_id; $toBeSavedInfo['PayPal_total_amount'] = $response-&gt;result-&gt;purchase_units[0]-&gt;amount-&gt;value; $toBeSavedInfo['orderStatus'] = $response-&gt;result-&gt;status; $toBeSavedInfo['linkForApproval'] = $linkForApproval; return $toBeSavedInfo;&#125; 下面是建立訂單功能會用到的 RequestBodypublic static function buildRequestBody($toBeSavedInfo, Recipient $recipient)&#123; // 這邊的設定，使得我們可以在 PayPal 的付款頁面，看到多個商品的明細 $item = []; $i = 1; foreach ($toBeSavedInfo['orders'] as $order) &#123; $item[] = [ 'name' =&gt; $order-&gt;item_name, 'description' =&gt; $order-&gt;item_description, 'sku' =&gt; $i, 'unit_amount' =&gt; [ 'currency_code' =&gt; $toBeSavedInfo['mc_currency'], 'value' =&gt; $order-&gt;unit_price, ], 'quantity' =&gt; $order-&gt;quantity, ]; $i ++; &#125; // 這邊我們指定 intent ，我設在環境變數， return [ 'intent' =&gt; env('PAYPAL_SANDBOX_INTENT_OF_CREATED_ORDERS'), 'application_context' =&gt; [ 'return_url' =&gt; env('PAYPAL_SANDBOX_RETURN_URL'), 'cancel_url' =&gt; env('PAYPAL_SANDBOX_CANCEL_URL'), 'brand_name' =&gt; env('APP_NAME'), 'locale' =&gt; env('PAYPAL_SANDBOX_LOCALE'), 'landing_page' =&gt; env('PAYPAL_SANDBOX_LANDING_PAGE'), 'shipping_preferences' =&gt; env('PAYPAL_SANDBOX_SHIPPING_PREFERENCES'), 'user_action' =&gt; env('PAYPAL_SANDBOX_USER_ACTION'), ], // 這邊可以設定 purchase_unit ，一個 purchase_unit 裡面可以設定税、運費、等等，這邊省略 'purchase_units' =&gt; [ [ 'custom_id' =&gt; $toBeSavedInfo['merchant_trade_no'], 'amount' =&gt; [ 'currency_code' =&gt; $toBeSavedInfo['mc_currency'], 'value' =&gt; $toBeSavedInfo['total_amount'], 'breakdown' =&gt; [ 'item_total' =&gt; [ 'currency_code' =&gt; $toBeSavedInfo['mc_currency'], 'value' =&gt; $toBeSavedInfo['total_amount'], ], ], ], 'items' =&gt; $item, // 這邊可以指定收件人 'shipping' =&gt; array( 'name' =&gt; array( 'full_name' =&gt; $recipient-&gt;name, ), 'address' =&gt; array( 'address_line_1' =&gt; $recipient-&gt;others, 'admin_area_2' =&gt; $recipient-&gt;district, 'admin_area_1' =&gt; $recipient-&gt;city, 'postal_code' =&gt; $recipient-&gt;postcode, 'country_code' =&gt; $recipient-&gt;country_code, ), ), ], ], ];&#125; 授權 ( authorization )接下來，我們要使用 REST API 中的特別功能， Authorization 。 授權之後，我們有29天的時間可以使用 capture 來從使用者的帳戶裡面扣錢。 不過呢，雖然有效期限是29天，但是 PayPal 只能保證給予單次授權開始計算的三天內，使用者的帳戶裡頭會有足夠的金額。 意思就是說呢，在 authorization 開始計算的三天， PayPal 會暫時性的在付款方的 PayPal 帳戶中，凍結申請的款項，記住只有三天哦！ 這三天稱為 honor period 。 在首次的 authorization 之後，我們可以申請多次，最多10次的 authorization ，稱為 reauthorize 。如果你覺得這樣次數還是太少，可以通過跟 PayPal 客服聯絡的方式，將次數提升到最多99次！ 其實只要將時間算好，10次的授權應該很夠用了。平均三天授權一次，10次也一個月了，海運都到了！ 授權可以更改金額，最高可以授權115% 或 不超過 75 USD 的金額，如果運費或者稅務方面，或是其他原因造成費用有些許變動的話，可以透過重新授權來更改費用。 細節可以參考官方文件 授權的範例如下:記住這是 Ray 自己的版本，大家可以參考官方的範例，再依照自己的需求作更改，或者乾脆取SDK裡面的功能自己寫一個！ 這才是我認為的最佳解！ /** * This function can be used to perform authorization on the approved order. * Valid Approved order id should be passed as an argument. */ // 這邊我們可以變更授權的金額，根據你的需求public static function authorizeOrder($orderId, $amount = null, $debug = false)&#123; $request = new OrdersAuthorizeRequest($orderId); // RequestBody 跟上面提到的差不多，可以參考官方的範例！ $request-&gt;body = self::buildRequestBodyForAuthorizeOrder($amount); $client = PayPalClient::client(); $response = $client-&gt;execute($request); if ($debug) &#123; print \"Status Code: &#123;$response-&gt;statusCode&#125;\\n\"; print \"Status: &#123;$response-&gt;result-&gt;status&#125;\\n\"; print \"Order ID: &#123;$response-&gt;result-&gt;id&#125;\\n\"; print \"Authorization ID: &#123;$response-&gt;result-&gt;purchase_units[0]-&gt;payments-&gt;authorizations[0]-&gt;id&#125;\\n\"; print \"Links:\\n\"; foreach ($response-&gt;result-&gt;links as $link) &#123; print \"\\t&#123;$link-&gt;rel&#125;: &#123;$link-&gt;href&#125;\\tCall Type: &#123;$link-&gt;method&#125;\\n\"; &#125; print \"Authorization Links:\\n\"; foreach ($response-&gt;result-&gt;purchase_units[0]-&gt;payments-&gt;authorizations[0]-&gt;links as $link) &#123; print \"\\t&#123;$link-&gt;rel&#125;: &#123;$link-&gt;href&#125;\\tCall Type: &#123;$link-&gt;method&#125;\\n\"; &#125; // To toggle printing the whole response body comment/uncomment below line echo json_encode($response-&gt;result, JSON_PRETTY_PRINT), \"\\n\"; &#125; return $response;&#125; 授權之後呢，我們需要驗證授權是否成功，所以我利用回傳的response，寫一個驗證的 function，如下：public static function checkIfAuthorizedSuccessfully($response)&#123; $newPayPal = (new NewPayPal())-&gt;where('payment_id', request()-&gt;token)-&gt;first(); // 確認授權是否完成 if (($response-&gt;result-&gt;status) !== 'COMPLETED') return 'Authorization isn\\'t completed'; // 確認授權是否已開始 if (($response-&gt;result-&gt;purchase_units[0]-&gt;payments-&gt;authorizations[0]-&gt;status) !== 'CREATED') return 'Authorization was not created'; // 確認幣別是否一致 if (($response-&gt;result-&gt;purchase_units[0]-&gt;payments-&gt;authorizations[0]-&gt;amount-&gt;currency_code) !== ($newPayPal-&gt;mc_currency)) return 'The currency is mismatched'; // 確認授權金額是否正確。這邊是我自己的版本，有需要變動授權金額的話，這邊可以變一下。 if (intval($response-&gt;result-&gt;purchase_units[0]-&gt;payments-&gt;authorizations[0]-&gt;amount-&gt;value) !== ($newPayPal-&gt;total_amount)) return 'The total amount is not correct';&#125; 提款 ( capture ) 就像上面提到的，成功授權之後，我們可以在29天內隨時向買家請款。 不過 PayPal 只有保證三天買家帳戶裡頭會有足夠的金額，又稱 honor period 一般來說，我們只要把時間算好，可以透過 授權 以及 再次授權 ，將 這筆金額臨時凍結30天。 以下是提款 ( capture ) 的範例：public static function captureAuthorization(NewPayPal $newPayPal, $final_capture = false, $debug = false)&#123; $NewPayPal = (new NewPayPal)-&gt;where('merchant_trade_no', $newPayPal-&gt;merchant_trade_no)-&gt;first(); // 提款功能，需要帶入授權id $request = new AuthorizationsCaptureRequest($newPayPal-&gt;authorization_id); // 這邊帶入要提款的金額，如上所敘，提款金額是可以分批次的！ Final_capture 如果設定為true的話，會結束此次授權，此次授權之後無法再進行提款，若要提款需要再重新授權。 $request-&gt;body = self::buildRequestBodyForCaptureAuthorization($NewPayPal-&gt;to_be_captured_amount, $final_capture, $newPayPal-&gt;mc_currency); $client = PayPalClient::client(); $response = $client-&gt;execute($request); if ($debug) &#123; print \"Status Code: &#123;$response-&gt;statusCode&#125;\\n\"; print \"Status: &#123;$response-&gt;result-&gt;status&#125;\\n\"; print \"Capture ID: &#123;$response-&gt;result-&gt;id&#125;\\n\"; print \"Links:\\n\"; foreach ($response-&gt;result-&gt;links as $link) &#123; print \"\\t&#123;$link-&gt;rel&#125;: &#123;$link-&gt;href&#125;\\tCall Type: &#123;$link-&gt;method&#125;\\n\"; &#125; // To toggle printing the whole response body comment/uncomment below line echo json_encode($response-&gt;result, JSON_PRETTY_PRINT), \"\\n\"; &#125; return $response;&#125; 以下是提款 ( capture ) 的 RequestBodypublic static function buildRequestBodyForCaptureAuthorization($amount = null, $final_capture = false, $currency = 'USD')&#123; if ($amount != null) &#123; // 指定提款的金額與幣別，需要跟授權的一致 return [ \"amount\" =&gt; [ 'currency_code' =&gt; $currency, 'value' =&gt; $amount, ], 'final_capture' =&gt; $final_capture ]; &#125; return \"&#123;&#125;\";&#125; 以下是提款的邏輯Ray 的邏輯是設定一個提款期限來決定什麼時候提款，因為每次退款都會扣掉手續費，所以 Ray 的想法是利用金額凍結取代退款，在提款期限之前，如果買家申請退款的話， Ray 這邊只需要去更改要提款的最終數字，這樣就可以避免掉手續費的部分。 Ray 自己設定的容許退款期限為七天，所以 Ray 會將這筆金額凍結七天，在七天後等到一切都確定了再依照最終的提款金額一次提款。所以下面的function每天都會跑一次，如果已經過了提款期限就會真正執行提款，並更新該訂單在所有資料庫裡頭相對應的狀態。public static function dailyCaptureAuthorization()&#123; $toBeCapturedPayments = NewPayPal::whereNotNull(&apos;authorization_id&apos;)-&gt;whereNull(&apos;capture_id&apos;)-&gt;where(&apos;to_be_captured_date&apos;, &apos;&lt;&apos;, Carbon::now()-&gt;toDateTimeString())-&gt;get(); foreach ($toBeCapturedPayments as $toBeCapturedPayment) &#123; $response = NewPayPal::captureAuthorization($toBeCapturedPayment); if (($response-&gt;result-&gt;status) === &apos;COMPLETED&apos;) &#123; $toBeCapturedPayment-&gt;update([&apos;capture_id&apos; =&gt; $response-&gt;result-&gt;id, &apos;status&apos; =&gt; 7]); foreach ($toBeCapturedPayment-&gt;orderRelations as $orderRelation) &#123; if (($orderRelation-&gt;status == 5) || ($orderRelation-&gt;status == 6)) &#123; $orderRelation-&gt;order-&gt;update([&apos;status&apos; =&gt; 7]); $orderRelation-&gt;update([&apos;status&apos; =&gt; 7]); &#125; &#125; &#125; &#125;&#125; 退款 ( refund ) 退款的規則是，可以針對特定授權，進行一次性或者分批次的退款。 若屬於分批次，可以指定退款金額 若想要一次性，可以將整個 RequestBody 留空，像官方範例那樣public static function refundOrder($captureId, $amount, $currency, $debug = false)&#123; $request = new CapturesRefundRequest($captureId); // 這邊帶入指定的退款金額以及幣別，幣別必須要跟授權的一樣哦 $request-&gt;body = self::buildRequestBodyForRefundOrder($amount, $currency); $client = PayPalClient::client(); $response = $client-&gt;execute($request); if ($debug) &#123; print \"Status Code: &#123;$response-&gt;statusCode&#125;\\n\"; print \"Status: &#123;$response-&gt;result-&gt;status&#125;\\n\"; print \"Order ID: &#123;$response-&gt;result-&gt;id&#125;\\n\"; print \"Links:\\n\"; foreach ($response-&gt;result-&gt;links as $link) &#123; print \"\\t&#123;$link-&gt;rel&#125;: &#123;$link-&gt;href&#125;\\tCall Type: &#123;$link-&gt;method&#125;\\n\"; &#125; // To toggle printing the whole response body comment/uncomment below line echo json_encode($response-&gt;result, JSON_PRETTY_PRINT), \"\\n\"; &#125; return $response;&#125; 以下是退款的 RequestBodypublic static function buildRequestBodyForRefundOrder($amount = null, $currency = 'USD', $final_capture = false)&#123; // 若金額有指定就為指定值，若無指定便為預設格式 if ($amount != null) &#123; return [ \"amount\" =&gt; [ 'currency_code' =&gt; $currency, 'value' =&gt; $amount, ], 'final_capture' =&gt; $final_capture ]; &#125; return \"&#123;&#125;\";&#125; 退款的邏輯 相對應提款時所做的操作，在商家真正對買家做出提款之前，買家所申請的退款請求都只是去更改資料庫的數字。 如果過了七天，但實屬特殊案例，買家也還是可以申請退款，不過到時候就會有手續費產生 以上邏輯只適用於 PayPal ，因為本專案整合兩家金流，所以上面的邏輯並不適用於歐付寶，不過總體來說，對買家來說都是沒有影響的。public static function refund(Order $order, NewPayPal $paymentServiceInstance, OrderRelations $orderRelation)&#123; // 當該申請訂單為已授權，但尚未請款 if (($paymentServiceInstance-&gt;capture_id === null) &amp;&amp; ($paymentServiceInstance-&gt;authorization_id !== null)) &#123; // 如上所敘，我們只更新資料庫的請款金額 $paymentServiceInstance-&gt;update([ &apos;to_be_captured_amount&apos; =&gt; $paymentServiceInstance-&gt;to_be_captured_amount - $order-&gt;total_amount, &apos;total_amount&apos; =&gt; $paymentServiceInstance-&gt;total_amount - $order-&gt;total_amount ]); $order-&gt;update([&apos;status&apos; =&gt; 4]); $orderRelation-&gt;update([&apos;status&apos; =&gt; 4]); &#125; // 當該訂單已經請款了 if ($paymentServiceInstance-&gt;capture_id !== null) &#123; // 真正執行退款 API ，將款項退給買家 $response = self::refundOrder($paymentServiceInstance-&gt;capture_id, $order-&gt;total_amount, $paymentServiceInstance-&gt;mc_currency); // 如果退款確定成功，更新訂單狀態 if ($response-&gt;result-&gt;status == &apos;COMPLETED&apos;) &#123; $order-&gt;update([&apos;status&apos; =&gt; 4]); $orderRelation-&gt;update([&apos;status&apos; =&gt; 4]); $paymentServiceInstance-&gt;update([ &apos;total_amount&apos; =&gt; $paymentServiceInstance-&gt;total_amount - $order-&gt;total_amount ]); &#125; &#125;&#125; 取消授權取消方法非常簡單，只要使用官方範例，並且依照格式帶入授權的id就可以，這邊就不特別舉例！授權id在你成功授權的時候會回傳，在那時記得把它存起來！ 取得授權資料取得授權方法非常簡單，只要使用官方範例，並且依照格式帶入授權的id就可以，這邊就不特別舉例！授權id在你成功授權的時候會回傳，在那時記得把它存起來！ 取得提款資料取得提款方法非常簡單，只要使用官方範例，並且依照格式帶入提款的id就可以，這邊就不特別舉例！提款id在你成功提款的時候會回傳，在那時記得把它存起來！ 總結依照官方文件， PayPal REST API 是可以搭配 JavaScript 的 Smart Button 一起使用的，不過 Ray 負責的是後端的角色，所以這一部分就沒有深究。看起來還蠻有趣的！有興趣的可以花時間研究一下！PayPal 不愧是國際的金流系統，各項的支援都十分全面以及功能也十分多樣，可惜已經退出台灣了！不過據了解應該是因為相關法令的關係，退出在另一個角度來說也是在捍衛台灣的稅法，未嘗不是一件好事，這邊就不多做評論。這陣子算是針對 PayPal 的金流深入的研究了一下，當然還有許多比較細緻的功能因為時間的關係還沒有去接觸到，待之後有時間有機會再來好好研究，再把心得過程都記錄下來分享給大家！ 歡迎轉載，但麻煩請註明出處，感謝！","link":"/zh-tw/PayPalRestAPI/"},{"title":"Cloud IAM:從 Qwik 開始","text":"前言本篇主要是利用 Google 的 Qwiklab 平台學習的同時，做的一份學習筆記為避免翻譯誤解，專業術語在本篇將不會被翻譯，保留原文 概述Google Cloud 身份與存取權管理 (IAM)，提供了為 GCP 資源建立且管理權限。 Cloud IAM 統一 GCP 眾多服務的存取權限控制，且提供一致性的操作。 在本教程中，你將會學到如何賦予使用者角色權限，或是移除 IAM 相關角色權限。 更確切的說，在此教程中登入兩組帳密來體驗權限的允許與廢除在 GCP Owner 與 Viewer 上是如何運作的。 必要條件這是入門級的教程，如果你對 Cloud IAM 沒有經驗，或只有一點點經驗的話，這個教程會蠻適合你的。 如果你有 Cloud Storage 的經驗，會可能會讓你比較容易完成這個教程，但是如果沒有也沒關係，因為這不是必須的。 要完成本教程，你必須要可以建立 .txt 檔，或者 .html 檔。 如果你在找更進階一點的 Cloud IAM 課程，一定不要錯下面這個： IAM Custom Roles 設定兩個使用者如同早先提到的，本教程提供兩組帳號密碼來模擬 IAM 政策以及特定的角色有什麼樣的權限 在教程頁面的左方，你可以看到帳號密碼列表，代表如下： 注意到，有兩組帳號密碼: Username1 還有 Username2。 分別代表 不同的 Cloud IAM，每一個 IAM 都有各自被分配到的存取權限。 這些 GCP “roles” 根據被分配的權限限制哪些資源你可以存取，哪一些不行 用第一個 user 登入 GCP 主控台 點擊 Open Google Console 按鈕。 這會打開一個新的瀏覽視窗。 如果你被要求 Choose an account, 點擊 Use another account 打開 GCP 登入頁面，複製代表 `googlexxxxxx_student@qwiklabs.net` 的第一使用者帳號，然後貼到 “Email or phone” 欄位 從 “Connection Details” 複製密碼，然後貼到 Google 登入密碼欄位 點擊 Next 然後 Accept 服務條款。 Google Cloud Platform 主控台開啟。 Agree 服務條款，以及在 Email updates 處勾選 No 用第二個使用者登入 GCP 主控台 再次點擊 Open Google Console 按鈕。 這會打開一個新的瀏覽視窗。 如果你被要求 Choose an account, 點擊 Use another account 打開 GCP 登入頁面，複製代表 `googlexxxxxx_student@qwiklabs.net` 的第二使用者帳號，然後貼到 “Email or phone” 欄位 從 “Connection Details” 複製密碼，然後貼到 Google 登入密碼欄位 點擊 Next 然後 Accept 服務條款。 Google Cloud Platform 主控台開啟。 Agree 服務條款，以及在 Email updates 處勾選 No 現在你應該要有兩個 GCP Console 視窗是在你的瀏覽器打開的，一個是使用者 1, 一個是使用者 2 在瀏覽視窗重置或者檢視使用者有時候，一個使用者可能會被另一個使用者覆蓋掉，這時候可能會讓你很疑惑目前登入的使用者是哪一個 要知道目前確切登入的使用者是誰，將滑鼠停在大頭貼處，你就可以看到目前的 username 如果你要重置目前登入的使用者 點擊你的 Avatar, 然後點擊 Sign out 來登出 在 Connection Details 面板處，點擊 Open Google Console, 然後再用對的帳號密碼登入一次 IAM 主控台以及專案等級角色 到 Username 1 的 GCP 主控台頁面 選擇 Navigation menu &gt; IAM &amp; admin &gt; IAM 。你現在已經在 “IAM &amp; admin” 主控台 在頁面上方點擊 +ADD 按鈕, 從下拉選單探索與專案相關的角色 你應該會看到 Browser (瀏覽者), Editor (編輯者), Owner (擁有者), 還有 Viewer (檢視者) 角色。 這四種在 GCP 被熟知為 原始角色 (primitive roles) 。 原始角色設定專案等級的權限，並且，除非有特別指定，否則他們的存取管理權限範圍涵蓋所有的 GCP 服務 下面表格中的角色從 GCP roles documentation 提取定義，給予瀏覽者，編輯者，擁有者，以及檢視者權限的簡單概述 角色名稱 權限 角色/檢視者 擁有不影響狀態的 只讀 權限，例如檢視 (但不可修改) 已存在的資源或檔案 角色/編輯者 擁有檢視者的所有權限，外加修改的權限，例如可以改變已存在的資源 角色/擁有者 擁有編輯者的所有權限，外加以下的權限 管理專案內所有角色的權限設定專案的帳單 角色/瀏覽者 (beta) 擁有可以瀏覽專案階層關係的權限，包含資料夾，組織，以及 Cloud IAM 政策。 但此角色不包含檢視專案內資源的權限 因為我們可以管理這個專案的角色以及全縣，所以 Username 1 有專案擁有者的權限 點擊 CANCEL 離開 “Add member” 面板 探索編輯者角色現在切換到 Username 2 主控台 移動到 IAM &amp; admin 主控台，選擇 Navigation menu &gt; IAM &amp; admin &gt; IAM 在表格內搜尋一下 Username 1 以及 Username 2, 然後看一下他們被賦予的角色，你應該可以看到如下圖: 你應該會看到: Username 2 有 “檢視者” 的角色 頁面上方的 +ADD 按鈕是反灰的 - 如果你試圖點擊它，你會看到以下的訊息 這是一個範例，展示了 IAM 角色影響決定了你在 GCP 專案中哪些可以做，哪些不能做 下一步，我們切換到 Username 1 主控台 準備一個資源來測試存取確定你在 Username 1 的主控台 建立一個儲存區 建立一個 GCS 儲存區，給予一個獨特的名字。 從主控台，選擇 Navigation menu &gt; Storage &gt; Browser 點擊 Create bucket 注意: 如果出現一個儲存區建立的權限錯誤，先登出再使用 Username 1 登入 更新以下的欄位，沒提到的留為預設 注意儲存區的名字，之後會用到 點擊 Create 注意: 如果出現一個儲存區建立的權限錯誤，先登出再使用 Username 1 登入 上傳一個範例檔案 在儲存區的細節頁面，點擊 Upload files 按鈕 瀏覽你的電腦，找一個可以使用的檔案，任何 text 或 html 檔都可以 在檔案那一行的行末，點擊三個小點的圖案，然後點擊 Rename 更新檔名為 sample.txt 點擊 Rename 點擊 Check my progress 來核對目前進度 核對專案檢視者存取權限現在切換到 Username 2 主控台 從主控台： 選擇 Navigation menu &gt; Storage &gt; Browser 。 核對這個使用者可以看到這個儲存區 Username 2 被賦予 “檢視者” 角色，這個角色有不影響狀態的 “只讀” 權限。 這個範例說明了這個功能 - 在權限範圍內的 GCP 專案，他們可以檢視 Cloud Storage 儲存區，以及檔案 移除專案存取權限現在切換到 Username 1 主控台 移除 Username 2 的專案檢視權限 選擇 Navigation menu &gt; IAM &amp; admin &gt; IAM , 然後點擊 Username2 旁的鉛筆圖案 你可以要將螢幕變寬來看到鉛筆圖案 點擊角色名稱旁邊的垃圾桶圖案來移除 Username 2 的檢視者權限, 然後點擊 SAVE 注意到這個使用者已經從清單上消失了，這個使用者現在已經沒有存取權了 備註: 這個動作要完全生效到所有的服務，可能會需要最多 80 秒的時間，更多資訊請參考這裏 核對 Username 2 已經沒有存取權了 切換到 Username 2 主控台。 確認一下目前是 Username 2 登入狀態，而且 Username 2 在生效之後還沒被登出, 如果登出了，在登入一次。 選擇 Navigation menu &gt; Home 點擊 Navigation menu &gt; Storage &gt; Browser 來移動到 Cloud Storage 你應該會看到錯誤如下： 備註： 如同之前提到的，變更生效大概需要最多 80 秒。 如果你沒有收到權限錯誤，等兩分鐘之後再重整一下頁面 點擊 Check my progress 來和對目前進度都有完成 增加儲存權限 從 “Connection Details” 面板複製 Username 2 切換到 Username 1 主控台。 確認一下目前是 Username 2 登入狀態，而且 Username 2 在生效之後還沒被登出, 如果登出了，在登入一次。 選擇 Navigation menu &gt; IAM &amp; admin &gt; IAM 點擊 +ADD 然後貼上 Username 2 的名字到 member field 在角色欄位，從下拉選單選擇 Storage &gt; Storage Object Viewer 點擊 SAVE 核對存取權 切換到 Username 2 主控台Username 2 沒有專案檢視者的角色，所以使用者不能在主控台看到專案或者任何專案的資源。但是，這個使用者對 Cloud Storage 有特別的存取權，讓我們來驗證一下 點擊 Activate Cloud Shell 圖案來打開 Cloud Shell 命令列 打開 Cloud Shell 視窗，輸入以下的指令，記得用我們一開始建立的儲存區名字來將指令中的 [YOUR_BUCKET_NAME] 取代掉 gsutil ls gs://[YOUR_BUCKET_NAME] 你應該會收到類似下面的輸出 gs://[YOUR_BUCKET_NAME]/sample.txt 如你所見，你已經給了 Username 2 Cloud Storage 儲存區的檢視權限 點擊 Check my progress 來和對目前進度都有完成 恭喜你已經完成本教程！","link":"/zh-tw/cloudIAMQwikStart/"},{"title":"使用Laravel儲存並重新縮放圖片大小","text":"前言本篇為實際上使用Laravel，以及套件Intervention來儲存及重新修改圖片尺寸的學習筆記。 安裝套件Intervention安裝流程請參照InterventionGitHub官網composer require intervention/image 打開config/app.php, 在array $providers 裏頭加上Intervention\\Image\\ImageServiceProvider::class 在array aliases裏頭加上&apos;Image&apos; =&gt; Intervention\\Image\\Facades\\Image::class 建立上傳資料夾與storage資料夾的連結 依照官網說明建立連結 在terminal輸入 php artisan storage:link 連結之後，project/storage/app/public 會跟 project/public/storage這兩個資料夾就回相連。 如果你是要儲存檔案，請儲存到project/storage/app/public/(anySubdirectoryYouWant) 如果你是要提供外部存取的URL，請使用project/public/storage/(anySubdirectoryYouWant)/fileName，因為對外部來說，預設可存取資料夾為public，所以直接使用asset(&#39;storage/(anySubdirectoryYouWant/fileName)&#39;) 驗證圖片是否有被帶進來// 因為我們不需要太多的東西，只需要request array裡頭的東西$parameters = request()-&gt;all();if (request()-&gt;hasFile('image'))&#123; // 檔案存在，所以存到project/storage/app/public，並拿到url，此範例會拿到public/fileName $imageURL = request()-&gt;file('image')-&gt;store('public'); // 因為我們只想要將純粹的檔名存到資料庫，所以特別做處理 $parameters['image'] = substr($imageURL, 7);&#125; 重新縮放圖片大小 要縮放大小，所以會需要使用到套件intervention 在namespace下加上use Intervention\\Image\\ImageManagerStatic as Image; // 拿到剛剛存進DB的item實例$item = Item::update($parameters);// 設定driverImage::configure(array('driver' =&gt; 'gd'));// 如果我們dd (storage_phth)，我們將會得到'project/storage/'，但這不是我們要的// 所以我們在後面加上'app/public/，如上所敘，這是內部儲存的資料夾位址// 請注意，當我們重新縮放圖片大小，目標都是我們的內部資料夾// 並且，再重新縮放之後，也是要存到同樣的地方Image::make(storage_path('app/public/' . $item-&gt;image))-&gt;resize(300, 300)-&gt;save(storage_path('app/public/' . $item-&gt;image)); 刪除圖片(如果使用者要求)if ($request-&gt;imageDelete == true)&#123; Storage::delete($item-&gt;images); $item-&gt;update(['images' =&gt; null]);&#125; 產出可存取資源的URL// 當產出公開存取的URL，它必須要是外部存取位址return asset(&apos;storage/&apos; . $parameters[&apos;image&apos;]);","link":"/zh-tw/UploadAndResizeImagesWithLaravel/"},{"title":"利用 Hexo 來建立一個 多語系 部落格","text":"前言這幾天為了建立一個個人部落格，真是沒少折騰了！個人除了對程式分享有熱愛之外，對語言也很有愛，像是英日語等等，所以一直以來，就想建一個多語系的部落格，除了可以讓分享的受眾更廣之外，另一方面也可以強制練習自己的語言！在請教 Google 大神無數次之後，大概歸納出以下三種可行的方法：利用i18n，再透過修改源碼的方式建兩個站點，一個中文，一個英文利用Hexo的minos主題在花了一些時間研究之後，毅然決然的選擇第三種，原因如下：原本我是使用 Hexo 的 Next 主題，可惜該主題在這方面並沒有支援，需要特別去修改源碼。這代表，維護成本會相當可觀，每修改一個地方，就需要修改兩份檔案，看你有幾種語言就得修改幾份檔案所以，本篇會針對 Hexo 的 minos 主題來做分享 安裝Hexo 安裝 NodeJS ，會連帶安裝 npm 套件管理器 brew install node 透過 npm 安裝 Hexo 主程式 npm install hexo-cli -g 在指定資料夾內，建立一個 Hexo 網站需要的檔案 hexo init folderName 安裝 minos 主題 進到資料夾 cd folderName 從官方GitHub上clone https://github.com/ppoffice/hexo-theme-minos.git themes/minos 原始資料夾，預設只有_config.yml.example，所以copy或rename為_config.yml，並於檔案中，搜尋theme，並設為minos 開始配置配置 Hexo 配置檔 config(配置檔)又分為 Hexo 本身的，以及主題的，以下先針對 Hexo 配置檔做說明，以下為必要設定的選項，其餘都維持預設即可: language: [&apos;en&apos;, &apos;zh-tw&apos;] //這邊的配置，表示默認以English語系為主，並以Taiwan語系為輔 url: https://tn710617.github.io/ (此為你的網站地址) permalink: :title/ deploy: type: git repo: https://github.com/tn710617/tn710617.github.io.git (此為你在GitHub上的資料夾clone地址) branch: master 主題配置檔內的設定都跟多語系無直接關係，所以這邊不特別做說明，大家依照官方文件以及個人喜好設定完成即可。 配置網頁語系檔 配置完 Hexo 的配置檔後，我們需要先新建一個自己國家的語系檔，如果主題內原本就已經有的話就不必，以本篇例子來說，我需要一個 Taiwan 語系，但是主題內的配置沒有，所以我必須要自己建一個。這個檔案的功用為，當切換到指定語系時， Hexo 會去讀指定語系的配置檔，就是這個檔案，並且依照這個語系檔裡面的內容來顯示 到 minos 的 languages 資料夾內，新建一個檔名為zh-tw.yml的檔案 內容可以比照其他國家的格式，如下：name: &apos;繁體中文&apos;common: archives: &apos;歸檔&apos; category: &apos;分類&apos; tag: &apos;標籤&apos; categories: &apos;分類&apos; tags: &apos;標籤&apos;nav: next: &apos;下一頁&apos; prev: &apos;上一頁&apos; search: &apos;搜尋&apos; toc: &apos;目錄&apos;article: read_more: &apos;點擊閱讀&apos; read: &apos;讀完&apos; about: &apos;大概&apos; words: &apos;字&apos; comments: &apos;留言&apos; contents: &apos;目錄&apos;search: hint: &apos;站內搜尋&apos;insight: hint: &apos;站內搜尋&apos; posts: &apos;文章&apos; pages: &apos;頁面&apos; categories: &apos;分類&apos; tags: &apos;標籤&apos; untitled: &apos;(無標題)&apos; 配置主題下的語系導向檔案 語系檔設定完成後，複製這個主題配置檔，並創立另外兩份配置檔。這幾個檔案的作用為，當我們切換到指定語系，網頁會依照這個檔案內配置的路徑來開啟相對應的檔案，比方說，中文開中文的檔案，英文開英文的檔案。 _config.zh-tw.yml _config.en.yml 先針對’en’配置檔做以下配置： // 這邊的配置可以依照個人需求menu: Archives: /archives Categories: /categories Tags: /tags Schedule: /schedule About: /about Friends: /friends 再來針對’zh-tw’配置檔做以下配置： menu: 歸檔: /zh-tw/archives 分類: /zh-tw/categories 標籤: /zh-tw/tags 行程: /zh-tw/schedule 關於: /zh-tw/about 好友: /zh-tw/friends 大家可能會注意到，這三個檔案內有著重複的配置。規則是這樣的，當我們切換到該語系的網頁時，默認會套用該語系的配置檔裡頭的配置，若該語系配置檔裡頭沒有這個配置，會自動套用主題原本的配置檔裡面的配置，所以這邊可以很靈活的針對不同語系的網頁來做配置調整。 view檔案的配置 現在我們開始針對view的檔案來做配置， minos 的規則是，除了源碼以及主體架構之外，所有的檔案根據語系的數量來配置，簡單來說，有幾種語系，該檔案就要有幾份。這也很合理，不然透過機器翻譯的文章你敢貼出來嗎？ 現在開始針對source底下的檔案來做配置: _posts上圖應該不會很難理解吧？ 簡單來說，_posts資料夾下面放的，是默認語系的檔案，以本篇例子來說，就是英文語系。而在_posts資料夾下面，建立一個名為zh-tw的資料夾，裡頭放著自然是中文語系的檔案 其他的：檔案配置就跟上圖一樣，是不是簡單到言語無法形容了？ 語言切換選單位置調整以我個人來說，當我進到一個網頁，如果密密麻麻的都是我看不懂的語言，我希望我第一個可以找到的就是語言切換的按鈕（如果有的話啦），以目前Ray使用的minos主題版本來說，切換語言的選單默認是在最下面的，所以我希望把它調整到一個顯眼的地方 到footer.ejs中，找到以下的代碼 &lt;%- partial('common/languages') %&gt; 把它剪下之後，貼到navbar.ejs檔案的最下方&lt;/body&gt;上面 如果現在從今整理頁面，應該已經可以看到語言切換選單已經換到上頭去了！可是呢… 怎麼是向上開啟選單的ＸＤ，根本無法選啊！所以我們還要再做一些調整。找到layout裡頭的languages.ejs檔案，並在裡頭找到下面這一行，並加入style=&quot;top:100%&quot;&lt;div class=&quot;dropdown-menu has-text-left&quot; role=&quot;menu&quot; style=&quot;top:100%&quot;&gt; 結語照著上面配置，大概就可以實現雙語系網站了，效果可以看看我的blog 若有說的不對的地方，歡迎指教歡迎轉載，但請註明出處，謝謝！","link":"/zh-tw/buildABilingualBlog/"},{"title":"Cloud Storage:快速開始-CLI/SDK","text":"前言本篇主要是利用 Google 的 Qwiklab 平台學習的同時，做的一份學習筆記 本篇將會做什麼？ 使用 SDK/CLI 建立一個儲存區 設定及要求 Qwiklabs setup在你按下 Start Lab 按鈕之前 詳讀所有的教學。Labs 是有時間限制的，而且你不可以停止時間倒數。倒數計時器在你按下 Start Lab 按鈕後開始倒數，上面顯示的時間為你還能使用 Cloud 資源的時間。 Quiklabs 的手把手環境，讓你可以在真實環境中來操作進行 Quiclabs 上提供的課程，而不是在一個模擬或是展示的環境。我們透過提供你一個全新的、暫時的帳號密碼，在計時器歸零之前，你可以用來登入並存取 Google Cloud Platform。 你需要什麼？ 要完成這個 lab ，你需要: 一個一般的網路瀏覽器（推薦 Chrome） 完成這個 lab 的時間 備註： 如果你已經有你自己的個人 GCP 帳號或專案，請不要使用在這一個 lab 現在你已經開始你的 lab, 你將會登入 Google Cloud Shell 主控台，然後開啟命令列工具 如何開始你的 lab ，然後登入 Console? 按下 Start Lab 按鈕。如果你需要付費，會有一個彈出視窗來讓你選擇付費的方式。在左方你會看到一個面板，上面有暫時的帳號密碼，你必須使用這些帳號密碼在此次 lab 複製 username , 然後點擊 Open Google Console。 Lab 會開啟另外一個視窗，顯示選擇帳號的頁面 tip: 開啟一個全新的視窗，然後跟原本的頁面並排 在選擇帳號頁面, 點擊 Use Another Account 登入頁面開啟，貼上之前複製的 username 以及 password ，然後貼上 重要：必須使用之前於 Connection Details 面板 取得的帳號密碼，不要使用你自己的 Qwiklabs 帳號密碼。 如果你有自己的 GCP 帳號，請不要用在這裡（避免產生費用） 點擊並通過接下來的頁面: 接受terms以及conditions 不要增加recovery optoins 或 two factor authentication (因為這只是一個臨時帳號) 不要註冊免費體驗 稍待一些時候， GCP 控制台將會在這個視窗開啟。 注意：按下左上方位於Google Cloud Platform 隔壁的 Navigation menu ，你可以瀏覽選單，裡面有一系列的 GCP 產品以及服務 啟動 Google Cloud ShellGoogle Cloud Shell 是載有開發工具的虛擬機器。它提供了5GB的 home 資料夾，並且運行在 Google Cloud 上。 Google Cloud Shell 讓你可以利用 command-line 存取 GCP 資源 在 GCP 控制台 ，右上的工具列，點擊 Open Cloud Shell 按鈕 在打開的對話框裡，按下 START CLOUD SHELL: 你可以立即按下 START CLOUD SHELL 當對話視窗打開。 連結並提供環境會需要一點時間。當你連結成功，這代表你已成功獲得授權，且此專案已被設為你的專案ID，例如： gcloud 是 Google Cloud Platform 的 command-line 工具，他已事先被安裝在 Cloud Shell 並且支援自動補齊 使用這個 command ,你可以列出有效帳戶名稱: gcloud auth list 輸出: Credentialed accounts: - &lt;myaccount&gt;@&lt;mydomain&gt;.com (active) 範例輸出: Credentialed accounts: - google1623327_student@qwiklabs.net 你可以使用以下 command 來列出專案 ID gcloud config list project 輸出： [core]project = &lt;project_ID&gt; 範例輸出： [core]project = qwiklabs-gcp-44776a13dea667a6 gcloud 的完整文件可以參閱 Google Cloud gcloud Overview 建立一個儲存區執行 gsutil mb 指令並取代 unique name 來建立一個儲存區gsutil mb gs://YOUR-BUCKET-NAME/ 命名規則： 不要有機敏資訊，因為儲存區的名字是公開可被大家看到的 儲存區的名字一定只可以有 小寫字母 ,數字, -, _, ., 若是名字含有 ., 需要驗證 儲存區的名字必須由數字或字母來開始以及結束 儲存區的名字必須含有 3 到 63 的字元，含有 . 的名字最多 222 個字元，但是每個被 . 分開的字元，最多不可超過 63 字元。 儲存區的名字不可以帶點十進制的方式表示，像是 IP 位址 (例如, 192.168.5.4) 儲存區的名字不可由 goog 開頭 儲存區的名字不可含有 google 或近似字串 還有，為了符合 DNS 命名規則以及之後的相容性，不可使用 _, 或是兩個 . 相連，或與 dash 相連，例如 .., 或 -., 或 .-, 這些都不符合 DNS 命名規則 如果成功執行，回應如下：Creating gs://YOUR-BUCKET-NAME/... 你已經建立一個可以用來儲存你的東西的儲存區備註: 如果名字已經被使用了，可能是你或別人，回應如下Creating gs://YOUR-BUCKET-NAME/... ServiceException: 409 Bucket YOUR-BUCKET-NAME already exists. 用別的名字在試一次 測試是否完成點擊 check my progress 來驗證任務是否完成。如果你已經成功完成 Cloud Storage 儲存區，你將看到一個評定的分數 測試你的理解底下有一些問題用來鞏固你對這個 lab 概念的了解，盡你所能的去回答吧 每個儲存區中，都有一個預設的儲存類別，你可以在建立的時候指定它 true false 上傳一個物件到你的儲存區現在上傳一個物件到你的儲存區 先下載這個圖片到暫時性的 instance (ada.jpg) 到 Cloud Shellwget --output-document ada.jpg https://upload.wikimedia.org/wikipedia/commons/thumb/a/a4/Ada_Lovelace_portrait.jpg/800px-Ada_Lovelace_portrait.jpg 使用 gsutil cp 指令, 從本地儲存的位置上傳圖片到你建立的儲存區中： gsutil cp ada.jpg gs://YOUR-BUCKET-NAME 訣竅: 當你輸入你的儲存區的名字, 可以使用 tab 來自動補齊你可以從 Command Line 看到圖片被上傳了，你已經完成了儲存一個物件在你的儲存區中!現在讓我們刪掉它rm ada.jpg 從儲存區下載物件使用 gsutil cp 指令, 將你存在儲存區的圖片下載到 Cloud Shellgsutil cp -r gs://YOUR-BUCKET-NAME/ada.jpg . 如果成功的話，應會回傳如下：Copying gs://YOUR-BUCKET-NAME/ada.jpg.../ [1 files][299.6 KiB/299.6 KiB]Operation completed over 1 objects/299.6 KiB. 你剛剛已經完成了從儲存區下載圖片！ 複製一個物件到儲存區內的一個資料夾使用 gsutil cp 指令來建立一個名為 image-folder 的資料夾，並且將圖片（ada.jpg) 複製過去gsutil cp gs://YOUR-BUCKET-NAME/ada.jpg gs://YOUR-BUCKET-NAME/image-folder/ 備註: 與本地的文件系統相比，在 Google Cloud Storage 的資料夾有一些限制, 但很多相同的操作是都有支援的。 如果成功的話，應該會回傳如下： Copying gs://YOUR-BUCKET-NAME/ada.jpg [Content-Type=image/png]...- [1 files] [ 299.6 KiB/ 299.6 KiB]Operation completed over 1 objects/299.6 KiB 現在，圖片已經被複製到儲存區內的新的資料夾內 測試是否完成點擊 check my progress 來驗證任務是否完成。如果你已經成功完成 Cloud Storage 儲存區，你將看到一個評定的分數 列出儲存區或資料夾內的內容gsutil ls gs://YOUR-BUCKET-NAME 如果成功，回傳應如下： gs://YOUR-BUCKET-NAME/ada.jpggs://YOUR-BUCKET-NAME/image-folder/ 這些是目前在儲存區內的東西 列出物件的細節使用 gsutil ls 指令, 配合 -l flag 來取得我們上傳圖片的細節資訊： gsutil ls -l gs://YOUR-BUCKET-NAME/ada.jpg 如果成功，應會回傳： 306768 2017-12-26T16:07:570Z gs://YOUR-BUCKET-NAME/ada.jpgTOTAL: 1 objects, 30678 bytes (299.58 KiB) 現在你知道圖片的大小和建立的日期了 讓物件可被公開存取使用 gsutil acl ch 指令來給予全部使用者對儲存區內的物件有讀的權限 gsutil acl ch -u AllUsers:R gs://YOUR-BUCKET-NAME/ada.jpg 如果成功，應該會回傳： Updated ACL on gs://YOUR-BUCKET-NAME/ada.jpg 你的圖片目前已經可被公開存取 測試是否完成點擊 check my progress 來驗證任務是否完成。如果你已經成功完成 Cloud Storage 儲存區，你將看到一個評定的分數 驗證你的圖片是否公開可被存取。 到 Navigation menu > Storage , 然後點擊你的儲存區。 你應會看到你圖片的公開存取格子是有被打勾的，點擊檔案，然後圖片將會在瀏覽器的新視窗被開啟 測試你的理解程度底下有一些問題用來鞏固你對這個 lab 概念的了解，盡你所能的去回答吧 存取控制清單 Access Control List (ACL) 是一種可用來定義誰可以存取你的儲存區的一種機制 true false 移除公開存取權限若要移除被存取的權限，使用以下指令 gsutil acl ch -d AllUsers gs://YOUR-BUCKET-NAME/ada.jpg 如果成功，回傳應像是：Updated ACL on gs://YOUR-BUCKET-NAME/ada.jpg 現在你已經移除對這物件的公開存取權限，你可以驗證看看，點擊控制面板中的 Refresh 按鈕。打勾符號將會被移除，這時如果你重新整理圖片，會出錯 測試你的理解程度底下有一些問題用來鞏固你對這個 lab 概念的了解，盡你所能的去回答吧你可以藉由移除什麼樣的權限屬性來停止公開分享物件： allUsers 移除 project owner role 更新儲存區類別 刪除物件使用 gsutil rm 來移除一個物件 - 在儲存區中的圖片gsutil rm gs://YOUR-BUCKET-NAME/ada.jpg 如果成功，回傳應會如下：Removing gs://YOUR-BUCKET-NAME/ada.jpg... 重新刷新面板。 複製的圖片檔案已經不存在 Cloud Storage 了 （儘管複製在 image-folder 資料夾內還是存在唷）","link":"/zh-tw/cloudStorageQwikStartCLISDK/"},{"title":"Cloud Storage:快速開始-控制面板","text":"前言本篇主要是利用 Google 的 Qwiklab 平台學習的同時，做的一份學習筆記 本篇將會做什麼？ 建立一個儲存區 設定及要求 Qwiklabs setup在你按下 Start Lab 按鈕之前 詳讀所有的教學。Labs 是有時間限制的，而且你不可以停止時間倒數。倒數計時器在你按下 Start Lab 按鈕後開始倒數，上面顯示的時間為你還能使用 Cloud 資源的時間。 Quiklabs 的手把手環境，讓你可以在真實環境中來操作進行 Quiclabs 上提供的課程，而不是在一個模擬或是展示的環境。我們透過提供你一個全新的、暫時的帳號密碼，在計時器歸零之前，你可以用來登入並存取 Google Cloud Platform。 你需要什麼？ 要完成這個 lab ，你需要: 一個一般的網路瀏覽器（推薦 Chrome） 完成這個 lab 的時間 備註： 如果你已經有你自己的個人 GCP 帳號或專案，請不要使用在這一個 lab 現在你已經開始你的 lab, 你將會登入 Google Cloud Shell 主控台，然後開啟命令列工具 如何開始你的 lab ，然後登入 Console? 按下 Start Lab 按鈕。如果你需要付費，會有一個彈出視窗來讓你選擇付費的方式。在左方你會看到一個面板，上面有暫時的帳號密碼，你必須使用這些帳號密碼在此次 lab 複製 username , 然後點擊 Open Google Console。 Lab 會開啟另外一個視窗，顯示選擇帳號的頁面 tip: 開啟一個全新的視窗，然後跟原本的頁面並排 在選擇帳號頁面, 點擊 Use Another Account 登入頁面開啟，貼上之前複製的 username 以及 password ，然後貼上 重要：必須使用之前於 Connection Details 面板 取得的帳號密碼，不要使用你自己的 Qwiklabs 帳號密碼。 如果你有自己的 GCP 帳號，請不要用在這裡（避免產生費用） 點擊並通過接下來的頁面: 接受terms以及conditions 不要增加recovery optoins 或 two factor authentication (因為這只是一個臨時帳號) 不要註冊免費體驗 稍待一些時候， GCP 控制台將會在這個視窗開啟。 注意：按下左上方位於Google Cloud Platform 隔壁的 Navigation menu ，你可以瀏覽選單，裡面有一系列的 GCP 產品以及服務 建立一個儲存區在控制面板，到 Navigation menu &gt; Storage &gt; Browser, 點擊建立儲存區 名字： 為你的儲存區建立一個特別的名字命名規則： 不要有機敏資訊，因為儲存區的名字是公開可被大家看到的 儲存區的名字一定只可以有 小寫字母 ,數字, -, _, ., 若是名字含有 ., 需要驗證 儲存區的名字必須由數字或字母來開始以及結束 儲存區的名字必須含有 3 到 63 的字元，含有 . 的名字最多 222 個字元，但是每個被 . 分開的字元，最多不可超過 63 字元。 儲存區的名字不可以帶點十進制的方式表示，像是 IP 位址 (例如, 192.168.5.4) 儲存區的名字不可由 goog 開頭 儲存區的名字不可含有 google 或近似字串 還有，為了符合 DNS 命名規則以及之後的相容性，不可使用 _, 或是兩個 . 相連，或與 dash 相連，例如 .., 或 -., 或 .-, 這些都不符合 DNS 命名規則 儲存種類： 多區域地區: United States 如果你已經設定好你的儲存區，按下建立 就這麼簡單，你已經建立了一個 Cloud Storage 儲存區 測試是否完成點擊 check my progress 來驗證任務是否完成。如果你已經成功完成 Cloud Storage 儲存區，你將看到一個評定的分數 測試你的理解底下有一些問題用來鞏固你對這個 lab 概念的了解，盡你所能的去回答吧 在整個 Cloud Storage 的命名空間裡，每個儲存區都要有一個獨一無二的名字 true false Cloud Storage 提供以下哪四種儲存區類別？ Nearline Storage Local storage Multi-Regional Storage Cross region storage Regional Storage Coldline Storage 上傳一個物件到儲存區在這個章節中，你將在儲存區中增加一個物件，在這個 lab 中，這個物件是一個圖片 取得圖片。 點擊這個 Ada Lovelace 的連結, 然後儲存圖片到你的本地電腦 儲存區的細節畫面應還會開著，將圖片拖曳到細節畫面處， Drop files here 你應該可以看到圖片被列在儲存區清單中 從儲存區中刪除圖片，勾選檔名旁的空格然後點擊 Delete, 然後再按一次 Delete 確認刪除 在上傳一次檔案，這次點擊 Upload files 從本地電腦中找到圖片，然後點擊 Open 你應該會看到圖片被列在儲存區清單中 重新命名檔案。點擊下拉式清單（三個平行的點） 在圖片列的最右邊，然後點擊 rename 你可能需要變寬你的瀏覽器視窗來顯示下拉式清單 上傳檔案，更名為 ada.jpg, 然後點擊 RENAME 你應會看到 ada.jpg 在你的儲存區中 測試是否完成點擊 check my progress 來驗證任務是否完成。如果你已經成功完成 Cloud Storage 儲存區，你將看到一個評定的分數 測試你的理解底下有一些問題用來鞏固你對這個 lab 概念的了解，盡你所能的去回答吧 物件的名稱只需要在一個儲存區中獨一無二 true false 公開分享物件點擊下拉式清單來取得這個物件的公開存取連結 從下拉式選單中，選擇 Edit permission 在出現的對話格中，點擊 + Add item 按鈕 完成以下的操作來開放權限給所有人 為此實體選擇 User 名字輸入 AllUsers 存取部分選擇 Reader 然後點擊 Save 一旦公開分享，一個連結的圖案會出現在公開存取欄位-點擊連結在新的視窗打開檔案 測試是否完成點擊 check my progress 來驗證任務是否完成。如果你已經成功完成 Cloud Storage 儲存區，你將看到一個評定的分數 建立資料夾在這個章節中，你將建立資料夾 在接近頁面頂端，點擊 Create Folder 連結 取名為 folder1, 然後點擊 Create 你應會看到資料夾出現在儲存區中，而且以不同的圖示來與物件作區分 建立子資料夾現在你將在 folder1 當中建立一個資料夾，並且上傳一個檔案 點擊 folder1, 在頁面頂端處點擊 create Folder 命名為 folder2, 並點擊 Create 點擊剛剛建立的 folder2 將圖片 Ada Lovelace 從本地電腦拖過去 Drop files here 上傳後，你將看到這個圖片列在 subfolder 中 重新命名檔案為 ada.jpg 點擊下拉式清單來取得這個物件的公開存取連結 從下拉式選單中，選擇 Edit permission 在出現的對話格中，點擊 + Add item 按鈕 完成以下的操作來開放權限給所有人 為此實體選擇 User 名字輸入 AllUsers 存取部分選擇 Reader 然後點擊 Save 一旦公開分享，一個連結的圖案會出現在公開存取欄位-點擊連結在新的視窗打開檔案 刪除資料夾在這個章節中，你將從儲存區中移除 folder1 還有他的內容 移動回 Buckets/[你的儲存區]。 你將看到 folder1 列在儲存區內容清單 勾選檔名旁的空格然後點擊 Delete, 然後再按一次 Delete 確認刪除 folder1 還有他的內容將永遠從你的儲存區中刪除 Congratulations!你已經完成本課程。","link":"/zh-tw/cloudStorageQwikStartConsole/"},{"title":"在GCP上開立一台虛擬機","text":"前言本篇主要是利用Google的Qwiklab平台學習的同時，做的一份學習筆記原文可參閱Refer to official link 本篇將會做什麼？ 利用GCP主控台建立一個virtual machine 利用gcloud command line建立一個virtual machine 在virtual machine上部署一個web server 設定及要求 Qwiklabs setup在你按下 Start Lab 按鈕之前 詳讀所有的教學。Labs 是有時間限制的，而且你不可以停止時間倒數。倒數計時器在你按下 Start Lab 按鈕後開始倒數，上面顯示的時間為你還能使用 Cloud 資源的時間。 Quiklabs 的手把手環境，讓你可以在真實環境中來操作進行 Quiclabs 上提供的課程，而不是在一個模擬或是展示的環境。我們透過提供你一個全新的、暫時的帳號密碼，在計時器歸零之前，你可以用來登入並存取 Google Cloud Platform。 你需要什麼？ 要完成這個 lab ，你需要: 一個一般的網路瀏覽器（推薦 Chrome） 完成這個 lab 的時間 備註： 如果你已經有你自己的個人 GCP 帳號或專案，請不要使用在這一個 lab 現在你已經開始你的 lab, 你將會登入 Google Cloud Shell 主控台，然後開啟命令列工具 如何開始你的 lab ，然後登入 Console? 按下 Start Lab 按鈕。如果你需要付費，會有一個彈出視窗來讓你選擇付費的方式。在左方你會看到一個面板，上面有暫時的帳號密碼，你必須使用這些帳號密碼在此次 lab 複製 username , 然後點擊 Open Google Console。 Lab 會開啟另外一個視窗，顯示選擇帳號的頁面 tip: 開啟一個全新的視窗，然後跟原本的頁面並排 在選擇帳號頁面, 點擊 Use Another Account 登入頁面開啟，貼上之前複製的 username 以及 password ，然後貼上 重要：必須使用之前於 Connection Details 面板 取得的帳號密碼，不要使用你自己的 Qwiklabs 帳號密碼。 如果你有自己的 GCP 帳號，請不要用在這裡（避免產生費用） 點擊並通過接下來的頁面: 接受terms以及conditions 不要增加recovery optoins 或 two factor authentication (因為這只是一個臨時帳號) 不要註冊免費體驗 稍待一些時候， GCP 控制台將會在這個視窗開啟。 注意：按下左上方位於Google Cloud Platform 隔壁的 Navigation menu ，你可以瀏覽選單，裡面有一系列的 GCP 產品以及服務 啟動 Google Cloud ShellGoogle Cloud Shell 是載有開發工具的虛擬機器。它提供了5GB的 home 資料夾，並且運行在 Google Cloud 上。 Google Cloud Shell 讓你可以利用 command-line 存取 GCP 資源 在 GCP 控制台 ，右上的工具列，點擊 Open Cloud Shell 按鈕 在打開的對話框裡，按下 START CLOUD SHELL: 你可以立即按下 START CLOUD SHELL 當對話視窗打開。 連結並提供環境會需要一點時間。當你連結成功，這代表你已成功獲得授權，且此專案已被設為你的專案ID，例如： gcloud 是 Google Cloud Platform 的 command-line 工具，他已事先被安裝在 Cloud Shell 並且支援自動補齊 使用這個 command ,你可以列出有效帳戶名稱: gcloud auth list 輸出: Credentialed accounts: - &lt;myaccount&gt;@&lt;mydomain&gt;.com (active) 範例輸出: Credentialed accounts: - google1623327_student@qwiklabs.net 你可以使用以下 command 來列出專案 ID gcloud config list project 輸出： [core]project = &lt;project_ID&gt; 範例輸出： [core]project = qwiklabs-gcp-44776a13dea667a6 gcloud 的完整文件可以參閱 Google Cloud gcloud Overview 理解Regions 和 Zones 特定的Compute Engine 資源位於特定的regions或zones. Region表示一個特定的地理位置，而你的資源就跑在那邊。 每個region都有一個或多個zones，舉例來說，us-central1 region位於Central United States，並且下面有us-central1-a, us-central1-b, us-central1-c, us-central1-f這些zones 位於zone的資源算是zonal資源。 Virtual machine instance還有persistent disk都位於zone, 如果要在一個virtual machine上加一個persistent disk，那兩者必須位於同一個zone 相同的，如果你要分配一個static IP位址到一個instance，這個instance必須要跟這個static IP同一個region 從Cloud Console建立一個新的instance Navigation menu &gt; Compute Engine &gt; VM instance 按create 欄位 值 額外資訊 name gcelab region us-central1(Iowa) or asia-south1(Mumbai) 更多regions的資訊 zone us-central1-c or asia-south1-c 注意：記住你選擇的zone，待會會用到 更多zone的資訊 Machine Type 2 vCPUs 這是一個(n1-standard-1), 1-CPU, 3.75GB RAM instance 有很多種類型可以選擇，從基礎型的到32-core/208GB RAM的都有，更多資訊可以參考機型種類文件 一個新專案有所謂的resource quota, 他會限制可以開立的機型規格。我們可以要求更高規格的機型在此lab之外 Boot Disk New 10 GB standard persistent disk OS Image: Debian GNU/Linux 9 (Stretch) 有很多種類的images可以選擇，包含Debian, Ubuntu, CoreOS，以及一些高級的iamges，像是RedHat Enterprise, Linux，和Windows Server，更多資訊可以參考作業系統文件 Firewall 勾選 Allow HTTP traffic 勾選這個選項，所以我們等等才能存取安裝好的server 注意：這會自動建立防火牆規則，容許HTTP 80 port通道 點擊Create 點擊SSH，經由瀏覽器連到virtual machine 注意：更多資訊可以參考文件 安裝NGINX web server 經由SSH連接virtual machine之後，先取得root權限 sudo su - 更新OS apt-get update 安裝NGINX apt-get install nginx -y 確認NGINX正常運行中 ps auwx | grep nginx 現在我們可以經由點擊Cloud Console上的External IP連結按鈕，或者直接在瀏覽器上輸入http://EXTERNAL_IP/ IP位址來連結到Server的網頁 使用gcloud來建立一個instance除了使用GCP主控台之外，我們也可以使用gcloud的command line 工具來建立一個virtual machine instance，這個工具已經事先被安裝在Google Cloud Shell中了。Cloud Shell 是一台以Debian為基礎的virtual machine，預載有所有你需要的開發工具(gcloud, git, 還有其他的等等), 並且提供5GB persistent disk的home目錄如果你之後想要在自己的機器上嘗試看看，可以參考gcloud command line tool guide 在Cloud Shell，利用command line gloud工具建立一台新的virtual machine instance gcloud compute instances create gcelab2 --zone us-central1-c 建立的instance將會有以下的預設值 最新的Debian 9 image n1-standard-1 machine type, 在這個lab中，你可以選擇其他的machine type，像是n1-highmen-4或n1-highcpu-4，如果你在做這個lab之外的專案，你可以選擇客製化的machinee type 預設的persistent disk名稱將與此instance一樣，並自動加到此instance 使用 gcloud compute instances create --help 檢視所有預設 如果你總是使用同一個區域，你可以將指定的地區設為預設，這樣就不需要每次都要使用--zone參數gcloud config set compute/zone gcloud config set compute/region 檢視你的instance, Navigation menu &gt; Compute Engine &gt; VM instances 最後，你可以使用gcloud經由SSH連線到你的instance，當你在連接時，確定一下後面的zone是跟你當初建的時候指定的一樣，或者如果你已經使用的上述的指定默認指令，那就不需要在指定一次。 gcloud compute ssh gcelab2 --zone us-central1-c 選y繼續 考考你！ Through which of the following ways you can create a VM instance in Google Compute Engine(GCE)? Through web console The gcloud command line tool.","link":"/zh-tw/createAVirtualMachineInGCP/"},{"title":"在 GCP 上建立一個 persistent disk","text":"前言本篇主要是利用 Google的Qwiklab 平台學習的同時，做的一份學習筆記原文請參閱 Refer to official link 概述Google Compute Engine 讓你在 Google 的基礎設施上建立以及運行虛擬機。 你可以在建立運行著不同作業系統的虛擬機，包含不同偏好的 Linux (Debian, Ubuntu, Suse, Red Hat, CoreOS) 以及 Windows Server Google Compute Engine 提供 persistent disks, 這是虛擬機上的主要儲存空間。 就像是實體的硬碟一樣， persistent disks 可獨立存在於你的虛擬機 - 如果一台虛擬機被刪除了，附加的 persistent disk 將可以持續將資料留住，並且可以附加到其他的虛擬機上。 Persistent disks 有兩種： 一般persistent diskSSD persistent disk 更多兩者差異的資訊，可以參考 Storage Options 。 兩種類型的 persistent type 有其不同的容量限制，更多資訊請參考 Persistent Disk 官方文件 本篇將會做什麼？ 建立一個新的 VM instance ，然後在其新增 persistent disk 掛載並格式化 persistent disk 設定及要求 Qwiklabs setup在你按下 Start Lab 按鈕之前 詳讀所有的教學。Labs 是有時間限制的，而且你不可以停止時間倒數。倒數計時器在你按下 Start Lab 按鈕後開始倒數，上面顯示的時間為你還能使用 Cloud 資源的時間。 Quiklabs 的手把手環境，讓你可以在真實環境中來操作進行 Quiclabs 上提供的課程，而不是在一個模擬或是展示的環境。我們透過提供你一個全新的、暫時的帳號密碼，在計時器歸零之前，你可以用來登入並存取 Google Cloud Platform。 你需要什麼？ 要完成這個 lab ，你需要: 一個一般的網路瀏覽器（推薦 Chrome） 完成這個 lab 的時間 備註： 如果你已經有你自己的個人 GCP 帳號或專案，請不要使用在這一個 lab 現在你已經開始你的 lab, 你將會登入 Google Cloud Shell 主控台，然後開啟命令列工具 如何開始你的 lab ，然後登入 Console? 按下 Start Lab 按鈕。如果你需要付費，會有一個彈出視窗來讓你選擇付費的方式。在左方你會看到一個面板，上面有暫時的帳號密碼，你必須使用這些帳號密碼在此次 lab 複製 username , 然後點擊 Open Google Console。 Lab 會開啟另外一個視窗，顯示選擇帳號的頁面 tip: 開啟一個全新的視窗，然後跟原本的頁面並排 在選擇帳號頁面, 點擊 Use Another Account 登入頁面開啟，貼上之前複製的 username 以及 password ，然後貼上 重要：必須使用之前於 Connection Details 面板 取得的帳號密碼，不要使用你自己的 Qwiklabs 帳號密碼。 如果你有自己的 GCP 帳號，請不要用在這裡（避免產生費用） 點擊並通過接下來的頁面: 接受terms以及conditions 不要增加recovery optoins 或 two factor authentication (因為這只是一個臨時帳號) 不要註冊免費體驗 稍待一些時候， GCP 控制台將會在這個視窗開啟。 注意：按下左上方位於Google Cloud Platform 隔壁的 Navigation menu ，你可以瀏覽選單，裡面有一系列的 GCP 產品以及服務 啟動 Google Cloud ShellGoogle Cloud Shell 是載有開發工具的虛擬機器。它提供了5GB的 home 資料夾，並且運行在 Google Cloud 上。 Google Cloud Shell 讓你可以利用 command-line 存取 GCP 資源 在 GCP 控制台 ，右上的工具列，點擊 Open Cloud Shell 按鈕 在打開的對話框裡，按下 START CLOUD SHELL: 你可以立即按下 START CLOUD SHELL 當對話視窗打開。 連結並提供環境會需要一點時間。當你連結成功，這代表你已成功獲得授權，且此專案已被設為你的專案ID，例如： gcloud 是 Google Cloud Platform 的 command-line 工具，他已事先被安裝在 Cloud Shell 並且支援自動補齊 使用這個 command ,你可以列出有效帳戶名稱: gcloud auth list 輸出: Credentialed accounts: - &lt;myaccount&gt;@&lt;mydomain&gt;.com (active) 範例輸出: Credentialed accounts: - google1623327_student@qwiklabs.net 你可以使用以下 command 來列出專案 ID gcloud config list project 輸出： [core]project = &lt;project_ID&gt; 範例輸出： [core]project = qwiklabs-gcp-44776a13dea667a6 gcloud 的完整文件可以參閱 Google Cloud gcloud Overview 建立 VM instance 建立一個名為 ‘gcelab’ 的新虛擬機 instance gcloud compute instances create gcelab --zone us-central1-c 新建的VM instance將有內建10GB的初始化disk 建立新的 persistent disk 在 Cloud Shell 中輸入以下指令，注意 zone 參數需與 VM instance 一致gcloud compute disks create mydisk --size=200GB --zone us-centrall-c 在運轉中的 VM instance 上新增剛建立的 persistent diskgcloud compute instances attach-disk gcelab --disk mydisk --zone us-central1-c 在 VM instance 上找到剛剛新增的 persistent disk SSH 到 virtual machinegcloud compute ssh gcelab --zone us-central1-c 輸入y繼續 如果需要設定密碼，可以輸入密碼 在 /dev/disk/by-id/ 下找到 disk 裝置 ls -l /dev/disk/by-id/ 找到預設裝置名稱如下: scsi-0Google_PersistentDisk_persistent-disk-1. 如果你想要一個不一樣的裝置名稱，當你在新增 disk 時，你可以加入裝置名稱參數 gcloud compute instances attach-disk gcelab --disk mydisk --device-name yourDeviceName --zone us-central1-c 格式化，並且掛載 persistent disk 在找到裝置後，我們可以將 disk 分區，格式化，並且掛載 建立一個掛載點sudo mkdir /mnt/mydisk 使用 mkfs 工具，格式化 disk 為 ext4 格式，這個指令將會刪除指定 disk 下的所有資料 sudo mkfs.ext4 -F -E lazy_itable_init=0,lazy_journal_init=0,discard /dev/disk/by-id/scsi-0Google_PersistentDisk_persistent-disk-1 利用 mount 工具，掛載 disk sudo mount -o discard,defaults /dev/disk/by-id/scsi-0Google_PersistentDisk_persistent-disk-1 /mnt/mydisk 設定自動掛載 預設值中，在 VM instance 重新啟動之後， persistent disk 並不會自動掛載，我們需要在/etc/fstab檔案中增加一些輸入 sudo vim /etc/fstab 在開頭是 UUID 那段程式碼之後，加入： /dev/disk/by-id/scsi-0Google_PersistentDisk_persistent-disk-1 /mnt/mydisk ext4 defaults 1 1 此時，你的 /etc/fstab 應該看起來要像這樣:UUID=e084c728-36b5-4806-bb9f-1dfb6a34b396 / ext4 defaults 1 1/dev/disk/by-id/scsi-0Google_PersistentDisk_persistent-disk-1 /mnt/mydisk ext4 defaults 1 1 按:wq 小習題： Can you prevent the destruction of an attached persistent disk when the instance is deleted? No, attached persistent disks are always associated with the lifetime of the instance. Yes, deselect the option Delete boot disk when instance is deleted when creating an instance Yes, use the -keep-disks option with the gcloud compute instances delete command For migrating data from a persistent disk to another region, reorder the following steps in which they should be performed: Attach disk Create disk Create snapshot Create instance Unmount file system(s) (4, 1, 2, 3, 5) (2, 3, 1, 4, 5) (1, 3, 2, 4, 5) (5, 3, 2, 4, 1) 非必要指令 顯示活躍中帳戶gcloud auth list 顯示project idgcloud config list project","link":"/zh-tw/createAPersistentDisk/"},{"title":"My learning journey in Docker","text":"前言這是一份未整理過的 Docker 學習筆記 環境GCP - ubuntu 18.04 安裝 移除舊版本sudo apt-get remove docker docker-engine docker.io containerd runc 從 Docker 倉庫安裝 更新 apt sudo apt-get update 安裝以下套件，使 apt 可以經由 HTTPS 使用倉庫 sudo apt-get install -y \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-common 增加 Docker 的正式 GPG 密鑰 curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - 核對一下我們現在擁有含有 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88 指印的密鑰，我們可以搜尋最後八碼 sudo apt-key fingerprint 0EBFCD88 理應得到輸出如下： pub rsa4096 2017-02-22 [SCEA] 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88uid [ unknown] Docker Release (CE deb) &lt;docker@docker.com&gt;sub rsa4096 2017-02-22 [S] 將 Docker 倉庫 設定為 stable 版，若要設定為 nightly 或 test 版，可在以下的指令中自由取代 stable sudo add-apt-repository \\ \"deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable\" 安裝最新的 Docker CE 版本 sudo apt-get install docker-ce docker-ce-cli containerd.io -y 你也可以安裝特定版本的 Docker: 列出版本 apt-cache madison docker-ce 應該會得到輸出如下： docker-ce | 5:18.09.1~3-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 5:18.09.0~3-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 18.06.1~ce~3-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 18.06.0~ce~3-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages ... 使用上面輸出的第二欄位版本號，結合下面的指令來安裝特定版本 sudo apt-get install docker-ce=&lt;VERSION_STRING&gt; docker-ce-cli=&lt;VERSION_STRING&gt; containerd.io 運行鏡像 hello-world 來驗證 Docker CE 是否已經正確安裝 sudo docker run hello-world 如果要使用非 root 身份運行 Docker 的話，可以把你的使用者加到 Docker 群組 sudo usermod -aG docker your-user 解除安裝 解除安裝 Docker CE sudo apt-get purge docker-ce 刪除所有的 image, containers, volumes, 可以使用以下指令。慎用！此指令適合解除安裝後使用。 sudo rm -rf /var/lib/docker/ 基本指令Docker 列出 Docker 的指令 docker 查看 Docker 版本 docker version 查看 Docker 完美安裝資訊 docker info 以 root 身份登入 docker exec -it --user root &lt;container id&gt; /bin/bash 開啟防火牆 登入 gcloud auth 帳號 gcloud auth login 輸入網頁上得到的驗證碼 登入成功後，利用 gcloud 身份，開啟防火牆gcloud compute firewall-rules create ruleName --allow tcp:thePortYouWantToExpose 傳檔案進 containerdocker cp file containerName:/location Docker container 運行 containerdocker container run -it ubuntu:latest /bin/bash Docker container run 告訴 Docker daemon 開始一個新的 container -i 告訴 Docker daeman 讓 container 可以互動 -t 使目前的 terminal 視窗連接 container 的 shell ubuntu:latest 為開始這個 container 的 image /bin/bash 指定了我們想要運行 container 裡頭的哪一個程序 確認 Docker daemon 運行狀況service docker status systemctl is-active docker 離開 container 但不關掉它 CTRL + PQ 連接還在運行中的 container docker container exec -it yourContainerIDOrContainerName bash exec 在運行中的 container 中運行一個新的程序 列出運行中的 container docker container ls 列出所有的 container ， 包含已停止的 docker container ls -a 列出 hello-world container（由 image 產生），他們在顯示訊息之後就退出了，如果他們還在運行中的話，以下指令中的 --all 可以不用加 docker container ls --all ordocker ps -a 理應得到輸出如下： CONTAINER ID IMAGE COMMAND CREATED STATUS54f4984ed6a8 hello-world \"/hello\" 20 seconds ago Exited (0) 19 seconds ago 停止 container docker container stop containerIdOrContainerName 重新開始停止中的 container docker container start containerName 刪除 container docker rm containerID 刪除所有的 container docker rm $(docker container ls -aq) -f 根據指定的 image 運行 container 並指定 port, 賦予 container name。若想自定義 port 的話， Dockerfile 跟 server 的 port 需一致，且防火牆要開啟該 port docker container run -d \\--name web1 \\ -p 8080:8080 \\test:latest -d 表示讓 container 運行在背景 ， 與 -it 相反，無法共存--name 指定 container 的名稱-p 指定 port ， 左邊的是外部可以從瀏覽器存取的 port ，右邊的是 container 向外暴露的 port 將現有的 container 存成一個新的 imagedocker commit -m 'imageMessage' -a 'AuthorName' containerSHA imageName:imageTag Multi Stage Multi Stage Build 範本FROM node:latest AS storefrontWORKDIR /usr/src/atsea/app/react-appCOPY react-app .RUN npm installRUN npm run buildFROM maven:latest AS appserverWORKDIR /usr/src/atseaCOPY pom.xml .RUN mvn -B -f pom.xml -s /usr/share/maven/ref/settings-docker.xml dependency:resolveCOPY . .RUN mvn -B -s /usr/share/maven/ref/settings-docker.xml package -DskipTestsFROM java:8-jdk-alpineRUN adduser -Dh /home/gordon gordonWORKDIR /staticCOPY --from=storefront /usr/src/atsea/app/react-app/build/ .WORKDIR /appCOPY --from=appserver /usr/src/atsea/target/AtSea-0.0.1-SNAPSHOT.jar .ENTRYPOINT [\"java\", \"-jar\", \"/app/AtSea-0.0.1-SNAPSHOT.jar\"]CMD [\"--spring.profiles.active=postgres\"] -t 用來指定 image 的名字-f 可以用來指定名稱不是 Dockfile 的 DockerfileFrom 指定基礎 image 來源RUN 可以在 image 內執行 command 並建立新的 layer ，每一個 RUN 都會建立一層 layerCOPY 可以增加複製檔案到你的 image 內EXPOSE 暴露 APP 用的 portENTRYPOINT 設定當 image 被啟動為一個 container 時，預設執行的指令 Docker image 拉下 image docker image pull ubuntu:latest 根據 digests 拉下 image docker image pull imageNane@sha256:specificDigests 列出下載過的 image docker image ls 刪除 image docker rmi imageID 刪除所有的 image docker image rm $(docker image ls -q) -f 建立 image docker image build -t imageName:tagName . 列出下載過的 image 以及 digest docker image ls --digests 列出一個 image 的結構 docker image inspect inamgeID 將 image 存成映像檔 docker save -o outputFileName imageName:imageTag -o 代表 output 架設一個私有倉庫docker run -d -p 5000:5000 registry 我們也可以將上傳的映像檔備份一份到容器外docker run -d -p 5000:5000 -v outsideAddress:insideAddress registry Docker push 首先， tag 本地的 image 一個可以用來推上 DockerHub 的名字 docker tag localImageName:localTagName userAccount/toBeTaggedImageName:toBeTaggedImageTagName 推上 DockerHub docker push userAccount/taggedImageName:taggedImageTag Docker-Compose 安裝 Docker Compose, 儘管我們可以從官方的 ubuntu 倉庫 安裝 Docker Compose ，但因為最新的版本中有很多細小的版本差異，所以我們從 Docker GitHub 來安裝。 先到官方頁面確認版本，並且視需求更新下面指令的版本號。 sudo curl -L https://github.com/docker/compose/releases/download/1.21.2/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose 設定權限 sudo chmod +x /usr/local/bin/docker-compose 確認 Docker-compose 版本 docker-compose --version 建立 yaml 檔案 vim docker-compose.yml 輸入內容如下： my-test:image: hello-world 建立一個 container docker-compose up 輸出理應如下： 建立一個 Swarm 開啟 docker swarm 模式docker swarm init \\--advertise-addr 0.0.0.1:8080 \\--listen-addr 0.0.0.1:8080 上面的 IP 跟 PORT 自己訂的--advertise-addr: 指定別的節點要連接這個 manager 時該使用的 IP 以及 port。這不是個必要的選項，但是你可以對哪個 IP 被使用有完全的控制權，並且你也可以訂一個不存在於節點上的 IP ，像是負載平衡的 IP --listen-addr: 讓你可以指定用來聽 swarm traffic 的 IP 以及 port ，通常他會跟 --advertise-addr 相同，但如果你想要限制 swarm 在特定的 IP，就特別有用。 還有一種情況，當 advertise-addr 是一個遠端的 IP ，像是平衡負載器，那這個也是必要的。 建議總是使用兩個附加選項。 從一個 node 開始 swarm mode ，並且設為 leader docker swarm init \\--advertise-addr yourInternalIP:yourPort \\--listen-addr yourInternalIP:yourPort 取得新增 manager 的 token docker swarm join-token manager 輸出大概如下： docker swarm join \\token SWMTKN-1-0uahebax...c87tu8dx2c \\10.0.0.1:2377 取得新增 worker 的 tokendocker swarm join-token token 輸出大概如下： docker swarm join \\token SWMTKN-1-0uahebax...c87tu8dx2c \\10.0.0.1:2377 重新產生 token docker swarm join-token --rotate managerOrWorker 開啟並且登入一台新的 instance ， 輸入上面的 token 還有自己的 IP 位址 docker swarm join \\token SWMTKN-1-0uahebax...c87tu8dx2c \\10.0.0.1:2377 \\advertise-addr yourInternalIP:yourPort \\listen-addr yourInternalIP:yourPort 不管你是想加入成為 manager 或是 workder ，只要輸入相對應的 token 就可以加入。 在 Leader 的 node 上可以查看 swarm 的詳細資料 docker swarm node ls 離開當前的 swarm docker swarm leave --force 開啟一個 SERVICE 要開立 service 首先必須確定， swarm 已建立。docker service create --name web-fe \\-p 8080:8080 \\--replicas 5 \\nigelpoulton/pluralsight-docker-ci docker service create: 建立一個 service--name: 指定 service 的名稱-p: 指定 container 內以及連接外部的 port--replicas: 在這個服務內，至少要有 5 個 containernigelpoulton/pluralsight-docker-ci: image 以及 tag 開立 service 之後， swarm 會一直的監看真實的狀態是否跟我的理想的狀態一致，如果一致的話那很好，如果不， swarm 會採取相對應的動作。舉例來說，如果五個 container 裡面有一個關閉了， swarm 會自動在啟動一個 查看 service 清單 docker service ls 查看 service 內的任務狀態 docker service ps serviceName 更詳盡的資訊 docker service inspect --pretty serviceName 擴展規模 docker service scale web-fe=10 刪除 service docker service rm web-fe 建立一個 overlay network docker network create -d overlay uber-net 連接到相同 overlay network 的 container ， 儘管他們的 docker host 連接的網路不同，彼此也可以互相溝通連接。 列出 network 資料 docker network ls 刪除一個 network docker network rm networkName 依據指定的 network 建立一個新的服務 docker service create --name uber-svc \\--network uber-net \\-p 80:80 --replicas 12 \\nigelpoulton/tu-demo:v1 --network: 指定 network 滾動升級 rolling update 滾動升級運行中的服務docker service update \\--image nigelpoulton/tu-demo:v2 \\--update-parallelism 2 \\--update-delay 20s uber-svc docker service update: 升級 service--image: 升級的 image 來源--update-parallelism 2: 一次升級兩個 container--update-delay 20s uber-svc: 每批次的等待時間為 20 秒 ， 需等當前批次的升級完成，時間才會開始計算。 最後指定要升級的 service 名稱 查看上次升級的參數docker service inspect --pretty serviceName 如上圖，前一次升級的參數都會被保留下來，除非你再次升級去覆蓋它 Composer 利用 container 安裝 Composer docker run --rm -v $(pwd):/app composer install --rm: 當 container 關閉後，自動刪除-v: 使用 volumes$(pwd):/app: $(pwd) 表示當前資料夾, /app 表示 container 裡頭一個叫做 app 的資料夾, 所以這個指令代表 : 前後的兩個資料夾會在 container 關閉之前，同步所有資料composer install: 安裝 composer 所以這個指令實際上做的事情，就是從 Docker Hub 拉下官方的 composer image ，然後開啟一個 container 並執行安裝， composer 會依照資料夾內 composer.json 或 composer.lock 來安裝相對應的 package 。 package 會被安裝在 app 這個資料夾內，但因為 volumes 的關係，所以兩個資料夾會同步， $(pwd) 內也會有安裝的 package 。 當安裝結束後， container 關閉，因為 --rm 的作用， container 會自動刪除。 利用 Docker-compose 部署 Laravel環境環境為 Ubuntu 18.04 安裝 docker-compose 安裝 Docker Compose, 儘管我們可以從官方的 ubuntu 倉庫 安裝 Docker Compose ，但因為最新的版本中有很多細小的版本差異，所以我們從 Docker GitHub 來安裝。 先到官方頁面確認版本，並且視需求更新下面指令的版本號。 sudo curl -L https://github.com/docker/compose/releases/download/1.21.2/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose 設定權限sudo chmod +x /usr/local/bin/docker-compose 利用 Docker 來安裝環境MySQL 安裝 MySQL ， 並指定連接一個外部不同的 port 號 ， 像是 52000docker run --name serviceName -e MYSQL_ROOT_PASSWORD=yourPassword -d -p 52000:3306 mysql:5.7 docker run: 啟動一個 container--name: 指定這個服務的名稱-e MYSQL_ROOT_PASSWORD: 指定環境參數-d: 使這個服務跑在 container 當中-p: 指定外跟內的 port 號， container 內部的 3306 連接外部的 52000mysql:5.7: 指定 image 以及 tag 連接本地安裝的 MySQL 以及 Docker container 內的 MySQL 本地安裝的 sudo mysql -uroot Docker Container mysql -h 127.0.0.1 -uroot -p2434 -P52000 製作 Docker image 時區問題我的第一個目標，是利用 Docker commit 來做一個專屬的 image。簡單來說，就是起一個純淨的 container ，然後在這個 container 裡頭部署完之後，再使用 docker commit 將這個 container 變成一個 image ， 結果發現在安裝 php7.2-imagick 中會出現 Configuring tzdata ，會彈出一個視窗並要求選擇時區，如下圖 後來找到解決方法，是在安裝 php7.2-imagick 之前就把時區設定好，所以在一開始就加入export DEBIAN_FRONTEND=noninteractive &amp;&amp; apt-get install -y tzdata &amp;&amp; ln -fs /usr/share/zoneinfo/Asia/Taipei /etc/localtime &amp;&amp; dpkg-reconfigure --frontend noninteractive tzdata MySQL 問題接下來，又遇到一個問題，在我利用我製作好的 image 開一個 container 時， MySQL 無法成功啟動，會一直出現 Failed後來的解決方法非常的奇怪，我是到 /var/www/mysql/mysql 中，下 chown -R mysql:mysql . 的指令，然後它就好了…可問題是，我仔細地確認過，在我下這指令之前，這個資料夾下的所有 user 以及 group 早就已經是 mysql:mysql 了 Apache 以及 MySQL 無法設定自動重啟的問題所以我們必須要在 container 裏頭啟動這些服務，需要啟動的服務如下： Apache MySQL 所以從目前的進度看來， container 啟動之後，我們必須要執行三個指令，如下：chown -R mysql:mysql /var/www/mysql/mysqlservice apache restartservice mysql restart 沒想到實際執行之後，我們遇到了一個新的問題… Container 自動退出的問題Container 的特性，是只要 command 執行完畢後，就會自動退出。 container 一旦退出了，我們原本建構的環境當然也就不在了。我們怎麼可以容許這種事情發生呢？因此，我們需要給 container 一個會一直持續存在的指令，好比是 /bin/bash 該怎麼樣讓 container 在啟動的時候又執行多個指令呢？在 container 啟動時， 我們需要執行多個指令來啟動 container 裡面的服務，但是 entrypoint 只能帶一個指令進去，所以我們要寫一個 shell script ，然後當 container 開啟之後去執行這個 shell script ，當然，這個 shell script 裡頭的指令就是上述提到的指令，如下： chown -R mysql:mysql /var/www/mysql/mysqlservice apache2 restartservice mysql restart/bin/bash 假設這個 shell script 叫做 test.sh ，然後放在 /usr/sbin/ 之下，那我們的 docker 指令如下：docker run -dt --entrypoint \"/usr/sbin/test.sh\" -p 8880:80 --name containerName yourAccount/imageName:tagName Debug 查 logdocker logs -f containerID man 指令Docker 為了縮小 image 大小，預設不產生 man 說明文件。 在安裝 man 以及 man-pages 之前，需要先將此設定改掉 修改設定Docker 為了縮小 image 大小，預設不產生 man 說明文件。 在安裝 man 以及 man-pages 之前，需要先將此設定改掉vi /etc/yum.conf 將以下這行 comment 掉tsflags=nodocs 安裝 yum install man-pages -y; yum install man -y 更新 mandb mandb 安裝 vim 套件測試 yum install vim 測試 man vim 可以用了","link":"/zh-tw/docker/"},{"title":"使用 vsftpd 在 GCP VM 上部署 FTP Server","text":"前言本篇將分享： vsftpd 的設定細節 建立一個特定的 FTP user 使用 gcloud command line 開啟相對應的防火牆 環境 GCP VM ubuntu 18.04 安裝 vsftpdsudo apt install vsftpd 設定檔 打開設定檔 sudo vim /etc/vsftpd.conf 設定參數如下： # 如果不想跑在預設的 21 port, 這個必須要打開listen=YES# 承上，如果 listen 為 yes, 這個必須是 NOlisten_ipv6=NO# 是否允許匿名者登入，預設是 NO。此例子中，我們只允許我們設定的 user 存取 server, 所以設定為 NOanonymous_enable=NO# 本篇目的是要建立一個特定使用者，並且只允許這位使用者登入，所以須為 YESlocal_enable=YES## 允許寫入的權限write_enable=YES# 該使用者的預設 umasklocal_umask=002# 在每個資料夾內，我們可以建一個檔名為 `.mssage` 的檔案，裡頭輸入訊息，當登入者進到這個資料夾實，就會顯示這則訊息dirmessage_enable=YES# 使用當地時間use_localtime=YES# 當登入者上傳或下載檔案時，都將之記錄下來xferlog_enable=YES# 檔案傳輸的 port 為 20, 我們用被動模式, 所以選 NOconnect_from_port_20=NO# 啟用被動模式pasv_enable=YES# xferlog 的位置，可以更改xferlog_file=/var/log/vsftpd.log# 是否使用正式格式。 選擇 NO 的話會比較易讀，但若有使用 log 分析軟體，建議選 YESxferlog_std_format=YES# 當使用者登入時，會顯示的歡迎訊息ftpd_banner=\"Welcome to QCDN's FTP server, feel free to upload whatever you would like to deploy on Website.\"# chroot 意思就是 change root，是否要將使用者預設就限制在自己的根目錄內，為了安全性考量，此選項建議打開, 否則登入者就被允許在你的 server 裡面閒晃chroot_local_user=YES# 允許這項功能的話，我們可以建立一個列表，列表裡頭的使用者將被允許可以離開自己的根目錄chroot_list_enable=YES# 乘上，該列表位置chroot_list_file=/etc/vsftpd.chroot_list# 須為一個名稱為 empty 的資料夾，且使用者不可對該資料夾有寫入的權限。當使用者未獲得檔案存取權限之前，會被限制在這個資料夾內secure_chroot_dir=/var/run/vsftpd/empty# 這是用來管理使用者權限的一個檔案，檔案位於 /etc/pam.d/vsftpd, 裡頭可以找到一個被限制存取的列表, /etc/ftpusers, 如果你不想讓哪一位使用者存取，你只要把他的帳號加到這個檔案裡頭就行了pam_service_name=vsftpd## 利用 TLS 加密傳輸的資料，本篇不使用rsa_cert_file=/etc/ssl/certs/ssl-cert-snakeoil.pemrsa_private_key_file=/etc/ssl/private/ssl-cert-snakeoil.keyssl_enable=NO# 為了要指定每個不同登入者的家目錄，這邊取得登入者的變數user_sub_token=$USER# 指定本地登入者的 root 位置, 若指定在別的位置，會跟 chroot 相衝突，如果要將使用者限制在自己的根目錄，需指定此路徑local_root=/home/$USER/ftp# 如果不想使用預設的 21 port, 可以自己指定 port 號listen_port=21212# 預設0, 使用任何 port 號。 這邊是一個被動模式的 port 使用範圍。 當伺服器端收到使用者端的被動模式要求，伺服器端會從這個區間內回覆使用者端一個用來傳輸資料的 port 供資料傳輸使用pasv_min_port=40000# 預設0, 使用任何 port 號。 這邊是一個被動模式的 port 使用範圍。 當伺服器端收到使用者端的被動模式要求，伺服器端會從這個區間內回覆使用者端一個用來傳輸資料的 port 供資料傳輸使用pasv_max_port=50000# 啟用 userlist 功能來限制可以存取的使用者，其功能基本上跟 pam 是類似的，是另外一種方式, 若要啟用，為 YESuserlist_enable=YES# 當此值為 YES, 則填入下一個設定檔中的帳號為禁止存取。 當此值為 NO, 為嚴格模式，只有被加入檔案的使用者可以存取userlist_deny=NO# 呈上，為使用者限制的列表檔案userlist_file=/etc/vsftpd.userlist# 每秒存取的最大流量 bytslocal_max_rate=10000000# 是否允許被限制在 chroot 的使用者有寫入的權限，因為我們要允許使用者上傳檔案，所以為 YESallow_writeable_chroot=YES# 預設為0, 表示無限制。 最大允許連線 server 的用戶端數量max_clients=50# 預設為0, 表示無限制。 來自同 ip 的最大允許連線數量max_per_ip=5# 是否使用 TCP Wrappers。TCP wrappers 是透過用戶端想要連結的程式檔名，然後分析用戶端的 IP ，看看是否需要放行tcp_wrappers=YES# 是否允許紀錄兩種不同格式的 logdual_log_enable=YES# log 的位置vsftpd_log_file=/var/log/vsftpd.log 建立 usersudo adduser test 之後再輸入密碼，假設為 1234 建立相關設定檔sudo touch /etc/vsftpd.chroot_list &amp;&amp; sudo mkdir /home/test/ftp &amp;&amp; sudo touch /etc/vsftpd.userlist &amp;&amp; sudo touch /var/log/vsftpd.log 權限設定 我架設這個 FTP Server 主要是要讓前端可以簡單地利用上傳來做簡單的部署，所以下面才會有 www-data 的相關權限設定。 有興趣可以看看，不然跳過也沒關係，因為這跟 FTP Server 沒有很直接的關係 建立共同群組此資料夾，預設只有該使用者以及 nginx 的 www-data 可以存取，所以先建立共同群組 sudo groupadd ftp_access 將 ftp 使用者以及 www-data 加入此群組 sudo usermod -a -G ftp_access test &amp;&amp; sudo usermod -a -G ftp_access www-data 設定權限 sudo find /home/test/ftp -type d -exec chmod 2770 &#123;&#125; \\; &amp;&amp; sudo find /home/test/ftp -type f -exec chmod 0664 &#123;&#125; \\; &amp;&amp; sudo chmod /home/test/ftp test:ftp_access 設定允許存取者echo 'test' &gt; /etc/vsftpd.userlist GCP 防火牆設定給機器加 tag 我個人習慣用 gcloud shell, 可以選擇以下兩種方式 從官網安裝SDK 可參考 GCP 提供的 gcloud shell 網頁版, 快速教學 在此 若你對 gcloud 不熟，也可以選擇使用網頁 UI 操作 登入跟開機器的部分就略過，因為不在本篇主題範圍內 給機器加 taggcloud compute instances add-tags instanceName \\--tags test 開啟防火牆 依據指定的 tag 來開啟防火牆，這樣才不會開到所有的機器上 開啟連線 port gcloud compute firewall-rules create ftp-communication --allow tcp:21212 --target-tags test 開啟 passive port 的範圍 gcloud compute firewall-rules create ftp-dataportrange --allow tcp:40000-50000 --target-tags test FTP 連線安裝 mac brew install inetutils ubuntu應該已經有了 重啟sudo service vsftpd restart;sudo service vsftpd status 應該要是 running 連線ftp -p yourIP 21212 輸入我們設定 user: test 輸入密碼: 1234 試試上傳一個檔案put whateverFile 結論沈浸在技術研究的感覺總是令人沈醉，雖然當遇到難題時，還真的想大醉一場有設定到 www-data 的部分，那是因為其實這個 FTP server 是架設來讓前端可以做簡單的部署，只要把 code 上傳，我的 NginX 會有一個 config 是反向代理這個資料夾, 不過因為跟本篇較無關係，看看就好！ 參考資料 我心目中的 Linux 之神，鳥哥大http://linux.vbird.org/linux_server/0410vsftpd.php Digital Ocean 的大神https://www.digitalocean.com/community/questions/proper-permissions-for-web-server-s-directory","link":"/zh-tw/ftpServer/"},{"title":"伸縮自如的 git flow","text":"前言今天將分享一個具有以下特性的 git flow: 在開發過程中，可以隨意 commit 測試完成後，即可將相對較友善於開發的 commit 轉換成正式上線標準的 commit 兩個分支檔案內容完全相同，但卻擁有完全不相干的 commit 歷史 以 Ray 來說，我在開發時，習慣畫流程圖，並且將我腦中覺得可行的邏輯一條條寫下來，然後實踐。 通常一個大功能可能會由好幾個邏輯組成，而這個 git flow 讓我可以在一個 feature 分支上，將我的每一個小邏輯都記錄下來，分成一個個 commit 。 最後確定沒有問題了，在轉換成正式上線時需要的大功能 commit 。在實踐這個 git flow 的過程中，我對 git rebase 的熟悉與日俱增，並且訓練自己以更嚴謹的方式來做每一個 commit。以下 Ray 個人覺得這個 git flow 可以帶來的好處： 因為 commit 很小，邏輯單一，不管是在實驗或是除錯方面，都有不可言諭的便利性。 利用小 commit 的方式將邏輯都記錄下來，一方面讓自己的思緒清晰，一方面讓每一個功能的邏輯清清楚楚。 看似複雜的流程，但其實熟悉之後，分支的整理只是一瞬間，可以在開發過程中更加的熟悉 Git 的進階操作。 因為 commit 很小，可以訓練較嚴謹的 commit 風格。 理想的 commit今天提出的 git flow 只是一個舉例，不一定適用於每一個人，但重點是在實現這個 git flow 所需要的概念！ 當我們在本地 commit 時，我們傾向這個 commit 可以越小越好，因為越小越純粹功能越單一的 commit ，不管是在 Debug ，或是邏輯實驗與印證都有不可言傳，只可意會的妙用！ 例如呢？讓我們具體一點! 當今天你在 Debug ，發現印出來的東西不如你的預期。你嘗試不同的方式來測試，直到印出的數據是你想要的！ 如果你的 commit 有符合上面的原則，在這個時候呢，在每一次失敗的嘗試之後，你不需要繁複的修修改改。你只需要簡單的git reset --hard 就算你一個 commit 邏輯整個錯了，如果你的 commit 功能夠單一，要拿掉這個 commit ，你只需要git reset @^ --hard 我們想要的是什麼？然而，正式上線的 git flow 不容許我們這樣做。正式上線的 git flow 通常會要求推上去的每一個 commit 都要’指定的功能正常’。意思可以理解說，如果要將 commit 最小化，那很有可能我們會需要多個最小化的 commit 來組成一個正式上線公司所需要的大功能。 需求整理 開發時： 我們需要隨時可以 commit 的靈活度，功能越單一越好 正式上線後： 我們需要每一個 commit 都符合公司指定的要求，功能正常 該選哪一種？人家說，魚與熊掌，不可兼得，真的是這樣嗎？可以兩種都要嗎？ 歸納具體需求那先來歸納一下，我們具體上，需要的東西 我們需要一支本地開發的 develop 分支，在這分支上，只要你爽，你想怎麼 commit 就怎麼 commit 我們需要一支正式要推上線的 master 分支，在這分支上，每個 commit 都代表著公司指定的功能 上面兩個分支，被 commit 的檔案內容是完全一樣 (選擇性)以上兩個分支我都要保留其各自獨特的歷史 具體看起來是？如下圖可以看到，左邊是檔案內容，右邊是 commit ，大家可以看到，在 develop branch 上，每個 small function 都對應到相應的檔案，這只是範例，表達我們所要的最小 commit 的概念。 master 分支:接下來，如下圖我們來看看實際上線時， commit 應該是什麼樣子。我們可以看到，在 master branch 上，我們只有4個 commit ，而每個 commit 都包含了4個檔案(除了 .gitignore 的 commit 之外)。這只是範例，表達正式上線時所需求的 commit 標準往往比我們理想的最小 commit 還要大。 範例連結 實作一切的起點通常 .gitignore 會是一切的起點！ 使用 vim 建立 .gitignore 檔案，然後輸入想要 ignore 的檔案，再按 :wq 離開。 vim .gitignore 完成第一個 commit git add .ignore; git commit -m 'Added .gitignore'; develop 分支接下來，我們將以 master branch 為基礎，建立 develop branch ，如同前面敘述的， develop branch 上面的 commit 會是最細最小的，而 master branch 上的 commit 會是符合正式上線標準的。 首先，從已經設定好 .gitignore 的 master 分支為基礎，建立 develop 分支 git checkout -b develop feature 分支然後呢，我們要開始開發了！ 建立一個 feature 分支 這個 feature 分支代表當前正在開發的功能 這邊所說的功能，是依照正式上線的標準 所以，一個功能等於一個 feature 分支git checkout -b feature; 自由的 commit 在 feature branch 上，我們可以隨便 commit ，可以完全依照我們本身的 commit 習慣，把 commit 做到最細小，以享受在開發以及測試過程中帶來的方便 建立檔案1~4，然後每個檔案分別代表一個最細小的 committouch &#123;1..4&#125;;git add 1;git commit 1 -m 'small function 1';git add 2;git commit 2 -m 'small function 2';git add 3;git commit 3 -m 'small function 3';git add 4;git commit 4 -m 'small function 4'; 功能完成了 在測試完成之後，確定沒有問題了！現在我們要把我們 commit 的標準轉換成正式上線的標準 如同前面提過的， feature branch 的開發範圍，是以正式上線的一個功能為單位 所以呢？我們要將一整個 feature branch ，濃縮成一個 commit 因為我們要保有兩個分支，所以我們不可以直接在 feature branch 幹這件事，因為 develop branch 會需要它！ 這邊特別說明一下，其實以這個 git flow 來說，開發過程中的 develop 分支不見得需要保留，但本篇範例會以如果你需要保留的狀況下來實作。如果開發用的 develop 不須保留的話，程序上會簡化很多。 用來 merged 的分支 為正式上線的 master branch 來建一個一次性的 toBeMerged branch git checkout -b toBeMerged 接下來，要把 toBeMerged branch 變成符合被 master branch merge 的狀態 git rebase -i master 壓縮、重新命名 commit 然後，我們剛剛有說過，我們要將多個開發流程中的最小 commit 壓縮成一個正式上線的 commit ，對吧？所以我們要將所有的 commit 往前壓縮，可以利用 fixup 這個選項，再來，正式上線的 commit 名稱肯定會跟我們開發時的 commit 名稱不同，所以這邊我們要重新命名這個壓縮後的 commit ，如下： reword 96c6c18 small function 1fixup 1dd84d2 small function 2fixup 1a71401 small function 3fixup f9c90c6 small function 4 接下來，我們將這個壓縮過後的 commit 命名為 big function 1 然後:wq存檔離開 此時使用git log來看看，看起來會像是下圖那樣git log merge 讓我們回到 master 來把它 merge 掉吧！ git checkout master;git merge toBeMerged; 接下來，切到 develop ，並且 merge feature branch git checkout develop;git merge feature; 最後，把已經被 merge 完成的 feature branch 以及 toBeMerge branch 刪掉吧！ git branch -D feature toBeMerged 複習一下，還記得我們要的是什麼嗎？ 在 develop 分支上，是最小的 commit 在 master 分支上，是正式上線標準的 commit 兩個分支的檔案內容必須要一模一樣 (選擇性的)同時保有兩個分支 看看我們的現在的 master 分支是否跟我們要的一樣？ git checkout master;git log 看看檔案內容ls 看看 develop 分支的 commit git checkout develop;git tag 'bigFunction1'git log 看看檔案內容 ls 第二階段 一樣的流程，建立 feature branch ，然後是 toBeMerge branch git checkout develop;git checkout -b feature;touch &#123;5..8&#125;;git add 5;git commit -m 'small function 5';git add 6;git commit -m 'small function 6';git add 7;git commit -m 'small function 7';git add 8;git commit -m 'small function 8';git checkout -b toBeMerged; 重點來了，這時我們不能使用傳統的 rebase 來改造 toBeMerged branch ，因為 toBeMerged branch 的歷史不曾存在於 master branch 。 讓我們想想，toBeMerged branch 應該要是什麼樣子才符合我們要的，適合被 master branch merge ？ 兩者要有共同的歷史(同sha1值) 先前已經被 merge 過的，未壓縮過的 commit 不可以重複出現。簡單來說， samll function 1~4 早就被壓縮成 big function 1 了，所以 small funciton 1~4 不可以再出現 master branch 上面沒有的內容，要壓縮成一個 commit 完成以上條件之後， toBeMerged branch 就可以被 master merge 了 第二次 rebase 與壓縮 所以具體該怎麼操作？ 我們將會使用到 git rebase 的進階應用 git rebase --onto 。我們 rebase toBeMerged branch 到 master branch 上，然後只要是 develop branch 上已經存在的 commit ，我們都不要，最後，將被 rebase 的 branch 叫做 toBeMerged，照這個順序往下排列，就成了以下的指令。 git rebase --onto 的用法，可以參考官方的文件 git rebase -i --onto master develop toBeMerged 然後同上，將最小的 commit 壓縮成一個正式上線的 commit reword 3668e72 small function 5fixup fd05fa1 small function 6fixup 3a87c08 small function 7fixup c38957e small function 8 壓縮後的 commit ，名稱為big function 2 重複之前步驟，該 merge 的 merge ，該刪的刪 來看看當前 develop 分支上的 commit 狀態，以及檔案內容 git checkout develop;git tag bigFunction2;git log --oneline develop 分支上的 commit ls develop 分支上的檔案內容 來看看當前 master 分支上的 commit 狀態，以及檔案內容 git checkout master;git log develop 分支上的 commit ls develop 分支上的檔案內容 總結此範例中的git flow，可以讓我們在開發過程中以最小的 commit 來進行，甚至是以任何我們喜歡的方式來進行，而不需因為正式上線的 commit 標準有所犧牲。過程看似複雜，看就 Ray 的使用經驗，如果相關原理都已經非常熟悉，其實指令輸入很快就完成了。範例中的 develop 分支不一定需要保留，因為日後若正式上線的 commit 有錯誤的話還是得從正式上線的 commit 來做修正，當然如果保留的話，應該還可以衍生一些其他的變化以及應用，這些就留待各位自己去發掘啦！若大家有任何想法歡迎在下面留言，我相信意見想法的交流是進步的捷徑。","link":"/zh-tw/flexibleGitFlow/"},{"title":"串接Facebook graph API","text":"前言本篇將分享如何使用JavaScript SDK讓用戶登入並取得token，然後利用PHP SDK向Facebook發請求，進而取得使用者的資訊。 到FB的開發者頁面，申請一個帳號，並且在主控台的地方，新增一個應用程式 到應用程式內的基本資料裡頭，複製應用程式編號以及應用程式密鑰創建Laravel專案laravel new Facebook 初始化Gitgit init 安裝Facebook PHP SDK 於專案目錄下composer require facebook/graph-sdk 建立一個稍後用來向FB拿資料的Controllerphp artisan make:controller FBController 建立一個getFacebookResources function 複製Facebook SDK 首頁的範例程式碼，並貼在這個function裏頭 require_once __DIR__ . &apos;/vendor/autoload.php&apos;; // change path as needed$fb = new \\Facebook\\Facebook([ &apos;app_id&apos; =&gt; &apos;&#123;app-id&#125;&apos;, &apos;app_secret&apos; =&gt; &apos;&#123;app-secret&#125;&apos;, &apos;default_graph_version&apos; =&gt; &apos;v2.10&apos;, //&apos;default_access_token&apos; =&gt; &apos;&#123;access-token&#125;&apos;, // optional]);// Use one of the helper classes to get a Facebook\\Authentication\\AccessToken entity.// $helper = $fb-&gt;getRedirectLoginHelper();// $helper = $fb-&gt;getJavaScriptHelper();// $helper = $fb-&gt;getCanvasHelper();// $helper = $fb-&gt;getPageTabHelper();try &#123; // Get the \\Facebook\\GraphNodes\\GraphUser object for the current user. // If you provided a &apos;default_access_token&apos;, the &apos;&#123;access-token&#125;&apos; is optional. $response = $fb-&gt;get(&apos;/me&apos;, &apos;&#123;access-token&#125;&apos;);&#125; catch(\\Facebook\\Exceptions\\FacebookResponseException $e) &#123; // When Graph returns an error echo &apos;Graph returned an error: &apos; . $e-&gt;getMessage(); exit;&#125; catch(\\Facebook\\Exceptions\\FacebookSDKException $e) &#123; // When validation fails or other local issues echo &apos;Facebook SDK returned an error: &apos; . $e-&gt;getMessage(); exit;&#125;$me = $response-&gt;getGraphUser();echo &apos;Logged in as &apos; . $me-&gt;getName(); 填入應用程式編號以及應用程式密鑰 上頭的範例中，在以下地方填入我們從FB開發者帳號中得到的資訊$fb = new \\Facebook\\Facebook([ &apos;app_id&apos; =&gt; &apos;應用程式編號&apos;, &apos;app_secret&apos; =&gt; &apos;應用程式密鑰&apos;, &apos;default_graph_version&apos; =&gt; &apos;目前版本&apos;, //&apos;default_access_token&apos; =&gt; &apos;&#123;access-token&#125;&apos;, // optional]); 建立使用者登入按鈕 使用者要先登入進而拿到token，我們才可以使用token來做事 於routes/web.php檔案中，新建一個給登入頁面使用的route Route::get(&apos;/FBToken&apos;, function()&#123;return view(&apos;FBToken&apos;);&#125;); 於resources/views/資料夾底下，新增FBToken.blade PHP檔, 然後在裡頭貼上以下的JS code &lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Facebook Login JavaScript Example&lt;/title&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;/head&gt;&lt;body&gt;&lt;script&gt; // This is called with the results from from FB.getLoginStatus(). function statusChangeCallback(response) &#123; console.log(&apos;statusChangeCallback&apos;); console.log(response); // The response object is returned with a status field that lets the // app know the current login status of the person. // Full docs on the response object can be found in the documentation // for FB.getLoginStatus(). if (response.status === &apos;connected&apos;) &#123; // Logged into your app and Facebook. testAPI(); &#125; else &#123; // The person is not logged into your app or we are unable to tell. document.getElementById(&apos;status&apos;).innerHTML = &apos;Please log &apos; + &apos;into this app.&apos;; &#125; &#125; // This function is called when someone finishes with the Login // Button. See the onlogin handler attached to it in the sample // code below. function checkLoginState() &#123; FB.getLoginStatus(function(response) &#123; statusChangeCallback(response); &#125;); &#125; window.fbAsyncInit = function() &#123; FB.init(&#123; appId : &apos;&#123;your-app-id&#125;&apos;, cookie : true, // enable cookies to allow the server to access // the session xfbml : true, // parse social plugins on this page version : &apos;&#123;api-version&#125;&apos; // The Graph API version to use for the call &#125;); // Now that we&apos;ve initialized the JavaScript SDK, we call // FB.getLoginStatus(). This function gets the state of the // person visiting this page and can return one of three states to // the callback you provide. They can be: // // 1. Logged into your app (&apos;connected&apos;) // 2. Logged into Facebook, but not your app (&apos;not_authorized&apos;) // 3. Not logged into Facebook and can&apos;t tell if they are logged into // your app or not. // // These three cases are handled in the callback function. FB.getLoginStatus(function(response) &#123; statusChangeCallback(response); &#125;); &#125;; // Load the SDK asynchronously (function(d, s, id) &#123; var js, fjs = d.getElementsByTagName(s)[0]; if (d.getElementById(id)) return; js = d.createElement(s); js.id = id; js.src = &quot;https://connect.facebook.net/en_US/sdk.js&quot;; fjs.parentNode.insertBefore(js, fjs); &#125;(document, &apos;script&apos;, &apos;facebook-jssdk&apos;)); // Here we run a very simple test of the Graph API after login is // successful. See statusChangeCallback() for when this call is made. function testAPI() &#123; console.log(&apos;Welcome! Fetching your information.... &apos;); FB.api(&apos;/me&apos;, function(response) &#123; console.log(&apos;Successful login for: &apos; + response.name); document.getElementById(&apos;status&apos;).innerHTML = &apos;Thanks for logging in, &apos; + response.name + &apos;!&apos;; &#125;); &#125;&lt;/script&gt;&lt;!-- Below we include the Login Button social plugin. This button uses the JavaScript SDK to present a graphical Login button that triggers the FB.login() function when clicked.--&gt;&lt;fb:login-button scope=&quot;public_profile,email&quot; onlogin=&quot;checkLoginState();&quot;&gt;&lt;/fb:login-button&gt;&lt;div id=&quot;status&quot;&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 同樣，在上面的程式碼中需填入編號及版本號，如下 FB.init(&#123; appId : &apos;編號&apos;, cookie : true, // enable cookies to allow the server to access // the session xfbml : true, // parse social plugins on this page version : &apos;版本&apos; // The Graph API version to use for the call&#125;); 熟悉FB graph API 工具 利用FB graph API測試工具，我們可以找到我們需要的API 客製endpoint 因為之後我們可能會直接複製經由graph API 工具 取得的endpoint，如下： 所以我們可以把endpoint這段移到.env中，如下： $endpoint = env(&apos;FBEndpoint&apos;);try&#123; // Get the \\Facebook\\GraphNodes\\GraphUser object for the current user. // If you provided a &apos;default_access_token&apos;, the &apos;&#123;access-token&#125;&apos; is optional. $response = $fb-&gt;get($endpoint, $token); 然後.env裡頭 FBEndpoint=me?fields=id,name,email 如此一來，之後我們只要直接複製graph API取得的值，貼到.env，打完收工！ 修改錯誤回傳值 PHP SDK預設錯誤時，會依照錯誤狀況回傳錯誤訊息，可我只需知道true or false，就行了，token無效有可能是因為以下幾種狀況 根本沒帶 帶的是錯的 過期了 不管是哪一種，我都需要回傳錯誤訊息給前端，並要求前端再去跟FB要一次，拿對的來，所以說，我必須要判斷PHP SDK的輸出，有沒有錯誤，若錯做一件事，對也做一件事，因此我們需要修改原本錯誤訊息輸出的地方，改成簡單的true or false，如下：catch (\\Facebook\\Exceptions\\FacebookResponseException $e) { return false; // echo &apos;Graph returned an error: &apos; . $e-&gt;getMessage(); // exit; } 取得public url 使用ngrok取得用來拿token，HTML頁面的public url 登入開發者應用程式 =&gt; 找到產品Facebook登入 =&gt; 快速入門 =&gt; 網站 =&gt; 貼上public url 登入取得token將token打到Laravel裡的FBController裡頭的getFacebookResources將取得的資料，存入資料庫，完成會員建檔打完收工","link":"/zh-tw/getINFOViaFBToken/"},{"title":"Stackdriver Logging 的基礎知識","text":"前言本篇主要是利用 Google 的 Qwiklab 平台學習的同時，做的一份學習筆記為避免翻譯誤解，專業術語在本篇將不會被翻譯，保留原文 概述Stackdriver Logging 是 Google Cloud Platform (GCP) Stackdriver 套裝產品的一部分。 它包含紀錄的儲存，一個使用者介面名為 Logs Viewer, 還提供 API 讓你可程式化的去管理紀錄. 使用 Stackdriver logging 來讀寫紀錄, 搜尋以及篩選紀錄, 匯出紀錄, 以及建立記錄指標 在這個練習中, 你將學習如何使用 Stackdriver Logging, 在同一個地方累積應用的 logs, 通過篩選來取得實際上需求的 紀錄, 理解如何建立紀錄指標來進行更進階的分析, 稽核紀錄 的使用案例, 以及匯出紀錄如果有更進階分析的需要 你需要做什麼？ 部署一個 Google App Engine 應用的範例來產生紀錄 使用 Stackdriver Logging 主控台來對應用產生的紀錄做相關操作 建立 Stackdriver monitoring 記錄指標 建立 Stackdriver logs 的 Export 至 Google BigQuery 設定及要求 Qwiklabs setup在你按下 Start Lab 按鈕之前 詳讀所有的教學。Labs 是有時間限制的，而且你不可以停止時間倒數。倒數計時器在你按下 Start Lab 按鈕後開始倒數，上面顯示的時間為你還能使用 Cloud 資源的時間。 Quiklabs 的手把手環境，讓你可以在真實環境中來操作進行 Quiclabs 上提供的課程，而不是在一個模擬或是展示的環境。我們透過提供你一個全新的、暫時的帳號密碼，在計時器歸零之前，你可以用來登入並存取 Google Cloud Platform。 你需要什麼？ 要完成這個 lab ，你需要: 一個一般的網路瀏覽器（推薦 Chrome） 完成這個 lab 的時間 備註： 如果你已經有你自己的個人 GCP 帳號或專案，請不要使用在這一個 lab 現在你已經開始你的 lab, 你將會登入 Google Cloud Shell 主控台，然後開啟命令列工具 如何開始你的 lab ，然後登入 Console? 按下 Start Lab 按鈕。如果你需要付費，會有一個彈出視窗來讓你選擇付費的方式。在左方你會看到一個面板，上面有暫時的帳號密碼，你必須使用這些帳號密碼在此次 lab 複製 username , 然後點擊 Open Google Console。 Lab 會開啟另外一個視窗，顯示選擇帳號的頁面 tip: 開啟一個全新的視窗，然後跟原本的頁面並排 在選擇帳號頁面, 點擊 Use Another Account 登入頁面開啟，貼上之前複製的 username 以及 password ，然後貼上 重要：必須使用之前於 Connection Details 面板 取得的帳號密碼，不要使用你自己的 Qwiklabs 帳號密碼。 如果你有自己的 GCP 帳號，請不要用在這裡（避免產生費用） 點擊並通過接下來的頁面: 接受terms以及conditions 不要增加recovery optoins 或 two factor authentication (因為這只是一個臨時帳號) 不要註冊免費體驗 稍待一些時候， GCP 控制台將會在這個視窗開啟。 注意：按下左上方位於Google Cloud Platform 隔壁的 Navigation menu ，你可以瀏覽選單，裡面有一系列的 GCP 產品以及服務 啟動 Google Cloud ShellGoogle Cloud Shell 是載有開發工具的虛擬機器。它提供了5GB的 home 資料夾，並且運行在 Google Cloud 上。 Google Cloud Shell 讓你可以利用 command-line 存取 GCP 資源 在 GCP 控制台 ，右上的工具列，點擊 Open Cloud Shell 按鈕 在打開的對話框裡，按下 START CLOUD SHELL: 你可以立即按下 START CLOUD SHELL 當對話視窗打開。 連結並提供環境會需要一點時間。當你連結成功，這代表你已成功獲得授權，且此專案已被設為你的專案ID，例如： gcloud 是 Google Cloud Platform 的 command-line 工具，他已事先被安裝在 Cloud Shell 並且支援自動補齊 使用這個 command ,你可以列出有效帳戶名稱: gcloud auth list 輸出: Credentialed accounts: - &lt;myaccount&gt;@&lt;mydomain&gt;.com (active) 範例輸出: Credentialed accounts: - google1623327_student@qwiklabs.net 你可以使用以下 command 來列出專案 ID gcloud config list project 輸出： [core]project = &lt;project_ID&gt; 範例輸出： [core]project = qwiklabs-gcp-44776a13dea667a6 gcloud 的完整文件可以參閱 Google Cloud gcloud Overview 部署應用使用 Cloud Shell 命令行工具來部署 guestbook, 一個 Google App Engine 的範例應用。 這個網頁應用將會產生我們需要的紀錄 從遠端 Clone guestbook 應用 git clone https://github.com/GoogleCloudPlatform/appengine-guestbook-python.git 移動到 clone 下來的資料夾內 cd appengine-guestbook-python/ 部署 guestbook 應用 gcloud app deploy app.yaml index.yaml 選擇離你較近的地區 Please choose the region where you want your App Engine application located: [1] europe-west2 (supports standard and flexible) [2] us-east1 (supports standard and flexible) [3] us-east4 (supports standard and flexible) [4] asia-northeast1 (supports standard and flexible) [5] asia-south1 (supports standard and flexible) [6] australia-southeast1 (supports standard and flexible) [7] southamerica-east1 (supports standard and flexible) [8] us-central (supports standard and flexible) [9] europe-west3 (supports standard and flexible) [10] europe-west (supports standard and flexible) [11] cancelWhen prompted to continue type \"Y\":Do you want to continue (Y/n)? Y 輸入 “Y” 繼續。幾分鐘後，應用將會被完全部署完畢 檢視以及搜尋紀錄移動到 Stackdriver Logs Viewer 設置要檢視的紀錄 選擇Navigation menu &gt; Logging &gt; Logs Viewer Stackdriver Logging 主控台有以下功能： (1) 服務篩選器： 根據資源種類篩選 (2) 紀錄篩選器： 根據選擇的資源的特定類型來篩選 (3) 紀錄等級篩選器： 篩選特定紀錄等級 (4) 日期篩選器： 根據特定日期篩選來檢視之前發生的問題 (5) 切換持續串流 (6) 一個搜索框，可以根據文字，標籤，正則，進階篩選器來搜尋 產生紀錄 造訪早前建立的 Google App Engine 應用 (guestbook) 來產生用來檢視的紀錄 在一個新的網頁視窗，打開 guestbook 應用，應用的 URL 如下： https://&lt;PROJECT_ID&gt;.appspot.com 用位於 lab 左方面板上的GCP Project ID來替換&lt;PROJECT_ID&gt; 或者，你也可以從 Cloud Shell (當你部署 App Engine app 時的輸出) 複製完整的 URL，然後在新的網頁視窗貼上 如果你看到Internal Server Error, 那是因為 Datastore Index 還沒準備好，等個一分鐘再重新整理瀏覽器 預測該有的結果： 當你在你的瀏覽器視窗看到 App Engine Guestbook, 這代表你的 App Engine 應用已經部署且驗證完畢，讓我們來產生一些紀錄吧 重整瀏覽器幾次，並且輸入一些名字到 Guestbook 應用來產生一些紀錄 回到 Stackdriver Logs Viewer 篩選器Logs Viewer 提供多樣化的基本篩選以及進階篩選的搜尋功能 基礎篩選 一樣在 Logs Viewer，在第一個下拉式窗 (服務選擇器)，選擇GAE Application &gt; Default Service &gt; All version_id, 表示我們想要檢視該服務的紀錄。這會顯示 guestbook 的所有紀錄 在下一個下拉選單 (紀錄選擇器), 選擇All logs 在下一個下拉選單 (紀錄等級選擇器), 選擇Any log level 其他下拉選單為默認值, 你的 Basic Filter 應該看起來是像這樣 注意，當你更換選擇時紀錄清單會自動重整 進階篩選器使用進階篩選器來進一步訂做你的搜尋 在Filter by label or text search下拉選單，選擇Covert to advanced filter 注意，你選擇的基礎篩選器已經在進階篩選器被轉譯成查詢表達式 在進階篩選器的輸入文字區塊，加上下面新的一行。 輸入新的一行來看自動完成功能 protoPayload.latency&gt;=0.01s 這行顯示所有延遲大於或等於 0.01 秒的 GAE app 紀錄 點擊Submit Filter然後檢視更新過的紀錄資料，可看到所有延遲超過 0.01 秒的紀錄 回到基礎篩選模式。點擊右上方，位於進階篩選器文字區塊區中的箭頭，在下拉選單選擇Clear filters and return to basic mode 紀錄指標紀錄指標是根據於紀錄的內容的 Stackdriver Monitoring 指標。 因此，你的紀錄不會只坐在那什麼事情也不做就等著別人來發現錯誤; Stackdriver Monitoring 會自動地監控你的紀錄，監控那些你定義的事件以及指標。由此可見，紀錄指標真是一個監控你客製化應用的一個絕佳的好方式。如果你的應用可以寫紀錄到 VM 的文件系統，你可以在那之上建立監控系統。 Stackdriver Monitoring 提供兩種使用者定義的紀錄指標 - Counter 以及 Distribution 計數器指標 (Counter Metrics)計數器指標計數那些符合進階紀錄篩選器的紀錄內容。舉例來說，一種指標，計數著那些，在特定資源中，代表某些類型的錯誤的紀錄內容。當很多拜訪你網頁的使用者收到了 HTTP 500 錯誤，想要收到警告嗎？ 計數器指標可以幫到你 分佈指標分布指標從紀錄中，累積那些符合篩選器的數據資料並且做數學運算。來說說一個分佈指標的普遍運用，像是追蹤一段時間的延遲模式/趨勢。當收到每一筆紀錄，延遲的數據會從紀錄中被取出並且加到分佈。累積的分佈將會有規律間隔的被寫到 Stackdriver Monitoring 建立計數器指標在此節中，你將建立一個計數器指標來計數成功拜訪網站的次數 - 在這個例子中，所有帶的 HTTP 200 的紀錄都算 依然在 Logs Viewer, 在select service的下拉選單中，選擇GAE Application &gt; Default Service 在log level selector下拉選單中，選擇All logs, 你的篩選器應該看起來如下： 在紀錄清單中，點擊狀態 “200” (任何列有 200 就行) 然後選擇Show matching entries 你將會看到 清單只會列出狀態 200 的紀錄 在進階的篩選編輯器中，一條進階的篩選條件已經自動地被建立了 protoPayload.status=200 根據你的篩選器建立一個監控指標 點擊Create Metric 來建立監控指標，根據你的進階篩選器 在指標編輯器中，根據下圖賦值，其他的欄位留為預設值就可 點擊Create Metric 下滑紀錄指標清單來檢視剛剛建立的回應 200 的指標, 你的新指標被列在最尾端， User-defined Metrics 的區塊中 在下圖三點圖案處點擊，選擇 View in Metrics Explorer 來檢視回應 200 的指標 在 Metrics Explorer 視窗打開 Stackdriver 主控台大概會需要一分鐘的時間 在 Metric Explorer, 點擊 GAE Application 資源類型，應該在數秒後會被自動增添進去 如果在資源類型選項中你沒有看到 GAE Application 關閉 Metrics Explorer 視窗 重整你的 guestbook app 幾次，來產生紀錄數據 等待一分鐘，等你的記錄數據被添載進去 (在你重整 App Engine app 之後), 很有可能會花 2 到 3 分鐘 點擊三個點圖案，選擇View in Metrics Explorer 一旦紀錄有被吃到，你將會看到 GAE Application 出現在Resource types 選擇器當中 這個指標已經準備好可以監控並且分析你應用的行為 建立一個分佈指標在此節中，你將會建立一個分佈計數器來監控 guestbook 應用的延遲 回到 Stackdriver Logging Console &gt; Logs Viewer, 建立一個篩選器來選擇GAE Application &gt; Default Service, All Logs, 以及 Any Log Level, 如下圖: 在頁面上方點擊Create Metrics 在指標編輯器的面板中，設定如下圖中的值 點擊Create Metric 核對延遲指標已經被建立在使用者定義的指標中 產生更多紀錄。重整 guestbook 應用多次，給指標 1 到 2 分鐘去取得以及累積新的紀錄資料 點擊三個點的圖案，然後點擊View In Metrics Explorer, 如下圖: 跟之前一樣，從resource type點擊GAE Application, 然後確認一下指標是你剛剛建立的那一個 如果GAE Application沒有自動載入 關閉 Metrics Explorer 視窗 重整你的 guestbook app 幾次，來產生紀錄數據 等待一分鐘，等你的記錄數據被添載進去 (在你重整 App Engine app 之後), 很有可能會花 2 到 3 分鐘 點擊三個點圖案，選擇View in Metrics Explorer 一旦紀錄有被吃到，你將會看到 GAE Application 出現在Resource types 選擇器當中 在 Stackdriver 監控主控台中檢視紀錄指標Stackdriver Monitoring Overview 視窗提供監控資源縱覽，紀錄指標就被列在圖表中 Stackdriver 會用這四種格式的其中一種來顯示圖表資料: Line, Stacked Bar, Stacked Area, 或是 HeatMap, 如果你想要指定格式： 在其中一個圖表點擊三個點的圖案，然後點擊Edit 在格式的下拉選單中，選擇一種格式 點擊Save把四種格式都試試看，看哪一種可以最好的呈現延遲指標 也試試其他圖表 稽核紀錄GCP 默認為所有的 GCP 資源提供稽核。稽核紀錄提供了 “誰做的？什麼時候做的？”, 讓我們來看看稽核紀錄吧，讓我們從建立一台 VM 開始。 開啟一台 VM 算是稽核權限活動的一種，所以會產生紀錄 開啟一台 VM 來產生稽核紀錄事件 在 GCP 主控台，選擇Navigation menu &gt; Compute Engine &gt; VM Instances 等待 Compute Engine 服務初始化 點擊Create 依下圖設定相關欄位中的值，其餘的保留預設 點擊Create 在活動檢視器中檢視稽核紀錄GCP Dashboard 的活動檢視器提供快速檢視稽核紀錄的功能 點擊主控台視窗上方的Google Cloud Platform來回到 GCP Dashboard 切到 ACTIVITY 視窗，你可能要點擊Navigation menu來關閉選單，所以才能看到ACTIVITY視窗 檢視最近的稽核紀錄數據，可以看到在最上面，有很多跟建立 VM 相關的數據 在上面的截圖，注意到四筆紀錄數據記錄著 VM 的建立以及與之相關的 HTTP 防火牆規則 點擊其他行來看看他們說明些什麼。是否有認出這好像是在本教程中我們先前做過的動作 從 Stackdriver 記錄檢視器來檢視稽核紀錄在 Stackdriver 記錄檢視器中，就像在活動檢視器一樣，你可以看到稽核紀錄數據。不同的是，記錄檢視器提供了更多功能，像是進階的篩選器以及其他的記錄管理功能 從 GCP 主控台回到 Stackdriver 記錄檢視器 (Navigation menu &gt; Logging &gt; Logs Viewer) 在service selector, 選擇 GCE VM Instance &gt; All instance_id 在 logs selector 下拉選單，選擇cloudaudit.googleapis.com/activity, 然後點擊OK 檢視與Create VM 以及 Completed對應的兩筆稽核紀錄, 以及在活動檢視器看到的Create VM紀錄 看看基本篩選器是怎麼呈現的，對比進階篩選器。從標籤或文字搜尋下拉視窗，點擊篩選器，並且轉換成進階篩選器，看看進階篩選器的代碼如下： 進階篩選器只顯示 GCE instance 的被稽核的活動 放寬範圍來看看 GCP 服務的所有稽核紀錄。 移除第一行，第一行限制了稽核紀錄的範圍，然後點擊Submit Filter 檢視所有在 Google Cloud Platform 上被使用者所執行的活動 在任何一行，點擊你的 Qwiklabs 使用者名稱（信箱）, 然後點擊Show matching entries 這增加了一行新的規則到進階篩選器中，限制只顯示被你所執行的活動 匯出紀錄Stackdriver Logging 保留 30 天的記錄，超過就刪除。如果你要保留紀錄久一點，你可以將他們會出到其他的儲存系統，或者 sink, 像是 BigQuery 。 Stackdriver Logging 可以讓你設定自動化的匯出腳本，所以所有的紀錄都會自動地被匯出。 紀錄也可以在你選擇的接收器被進一步的分析 建立一個匯出工作設定一個匯出工作來發送所有的稽核紀錄到 BigQuery 來長期儲存與分析。 在 Stackdriver 記錄檢視器的視窗，從進階篩選器移除第二行，然後點擊Submit Filter, 然後你可以檢視 GCP Project 所有的稽核紀錄 在頁面的上方，點擊Create Export，然後依照下圖輸入值 點擊Create Sink。 點擊Close離開接收器建立確認視窗 在 BigQuery 檢視稽核紀錄 開啟 BigQuery, 選擇Navigation menu &gt; BigQuery 關閉歡迎標語 在左邊面板處，點擊 Project ID 旁邊的箭頭來展開 GCP 專案名稱，來看新的 AuditLogs 資料 注意到 AuditLogs 之下還沒有任何的表格。 Log Exporting 會再匯出作業建立之後，開始發送資料到接受器。 Log Exporting 會產生一些稽核記錄數據，然後會再接受器建立表格，並且開始存入資料 回到 VM instance 視窗 (Navigation menu &gt; Compute Engine &gt; VM instances) 點擊 GCE VM instance 來檢視細節 點擊上方的Edit, 對 VM 做兩個小變更 (1) 勾選Enable connection to serial ports 的小格子，來允許連續 port 的連線 (2) 往下滑，勾選Allow HTTPS Traffic來允許 HTTPS 連線 點擊Save 到主要 GCP Dashboard 的 Activity 視窗，你應會看到一些 Audit Log 數據，包含一個叫做 “Set metadata on VM (設定 VM 的中繼資料)”, 另一個叫做 “Create firewall rule (建立防火牆規則)”, 還有一些其他跟 VM 變更有關的。 你將會看到一個叫做 “Create Table (建立表格)” 的事件，顯示 BigQuery 接收器已經被建立 約一分鐘後(你可能需要重整頁面), 你將會看到 Audit Log 數據，顯示 BigQuery 的表格已經被更新了，更新資料為我們剛剛變更 VM 之後而產生的新的 Audit Log 數據。 看一下時間戳記來辨認所有 BigQuery 有接收到，那些與這次 VM 變更有關的數據資料 回到 BigQuery 主控台，展開 AuditLog 資料組。你可能需要重整頁面。 你應會看到新的 cloudaudit 表格已經被建立了，點擊它 使用 BigQuery 來探查稽核紀錄 點擊新的 cloudaudit 表格, 然後點擊 Query Table 按鈕 Query Editor 的輸入文字處已經事先仔入一部分的 SQL query, 且游標置於 “SELECT”, 以及 “FROM” 在 “SELECT” 以及 “FROM” 之間輸入 *, 然後點擊 Run 幾分鐘後，查詢完成了，你會在下方的結果處看到 Audit Log 數據, 有很多欄位, 裡頭有些是巢狀的 點擊結果視窗的任何地方，然後使用方向鍵來左右移動，可以看到稽核紀錄非常的詳細 現在定義一個範圍小一點的查詢來檢視每個稽核數據的大概 (1) 在右上方點擊 Compose New Query (2) 複製下面的 code, 貼到查詢編輯器 SELECTtimestamp,resource.type,protopayload_auditlog.authenticationInfo.principalEmail,protopayload_auditlog.methodNameFROM `&lt;your-project-ID&gt;.AuditLogs.&lt;your_audit_log_table_name&gt;`WHERE protopayload_auditlog.authenticationInfo.principalEmail = \"&lt;your_qwiklabs_username_email&gt;\"LIMIT 1000 (3) 上面有些參數，參照下圖的表格內資訊替換 (4) 點擊 Run 來開始查詢。 你應會看到小一點的欄位，根據我們做的操作做限制，結果應會跟下圖相似: 這個簡單的查詢只是使用 BigQuery 來產生客制紀錄的一個範例，你可以建構任何數量的 SQL queries 來分析你的稽核紀錄來符合你的需求 恭喜，你已經完成本教程","link":"/zh-tw/fundamentalsOfStackdriverLogging/"},{"title":"Git-從哪裡開始？","text":"嗨大家好，我是Ray! 如上一篇提到，Git對於一個coder來說可以說是不可或缺的，今天我就來分享一下Git的基本操作 首先呢，讓我們先來創一個範例資料夾，名稱就叫做my-git-repository吧！ 到Command Line cd 你想要這個資料夾在哪的路徑/ 輸入mkdir my-git-repository 然後cd code/my-git-repository 進到資料夾內，code是我自己的母資料夾，各位請輸入你們自己的路徑 進到資料夾的位置，如下圖：￼ 讓我們在裡面建立一個檔案touch example1.html 然後在該檔案裡面添加以下內容：&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;First example&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;This is the first example&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 輸入git init ￼ 然後輸入 git status ￼ 如上圖所示，我們已經可以開始使用git的相關功能，目前example1的檔案還處於untracked狀態，在建立任何存擋點之前，我們必須要先將檔案加入追蹤，就好像我們在FB上追蹤那些名人一樣！ 輸入git add example1.html 如下圖：￼ 再來輸入git commit 看起來如下：￼ 應該會出現以下的畫面￼ 接著我們隨便輸入first example當作這個存擋點的訊息記錄 接著我們按:wq 儲存並離開視窗 輸入git status 看起來如上圖： 輸入git log 然後你應該可以看到一串代表著此次commit，獨一無二的號碼。￼ 你應該會看到以下的commit，commit 的號碼每個人都不同，所以如果你的號碼跟我的不同是正常的，不用覺得奇怪！ 這樣一來就算是完成了一次的存擋啦！之後我們可以隨時回到這個狀況只要我們想要的話！ 今天的分享就先到這啦，之後若有機會會再做進一步的介紹！","link":"/zh-tw/gitInit/"},{"title":"My learning note on Gitlab","text":"前言個人 Gitlab 學習筆記，內容未整理過。 Event 通知Project =&gt; Settings =&gt; Integrations =&gt; Slack notifications","link":"/zh-tw/gitlab/"},{"title":"利用 Gitlab CI/CD 部署專案到 GCP virtual machine","text":"前言本篇將分享如下： 利用 gcloud 開立一台 GCP instance 如何利用 gcloud 在 instance 上匯入 ssh key 利用 Daemon 使服務常駐 利用 gitlab pusher 部署專案到 GCP virtual machine 上 環境建立開啟一台 GCP 虛擬機以下是個人做法，不需要照做 Ray 使用 Mac 所以我在本地端安裝了 Google Cloud SDK, 安裝方式可以參考官方文件 建立一台 VM 建立一台機器, 叫做 example-instance-1 開機碟的空間為 10GB 從 ubuntu-os-cloud, 來 pull 我們需要的 image 我們使用 ubuntu-1804-lts 的 image 版本, 這會自動使用這個版本的最新版 硬碟類型為 pd-stand, 不知道類型可以跑 gcloud compute disk-types list 來看看 機器型號為 f1-micro, 不知道類型可以跑 gcloud compute machine-types list 來看看 tags 用來當作該 instance 的一個識別，等等開防火牆的時候會用到 zone 指定該 instance 的地區, 有些資源只有相同 zone 或者 region 可以取用，要注意 如下:gcloud compute instances create example-instance-1 \\--image-project=ubuntu-os-cloud \\--image-family=ubuntu-1804-lts \\--boot-disk-size=10GB \\--boot-disk-type=pd-standard \\--machine-type=f1-micro \\--tags=example-instance-1,http-server,https-server \\--zone=asia-east1-a 開啟後，我們先來產 keyssh-keygen -t rsa -b 4096 -C \"root@example\" 假設 key 的名稱為 examplecat example.pub &gt; instanceSSHConfig &amp;&amp; vim instanceSSHList 在最前面加上 root, 格式如下：[USERNAME]:ssh-rsa [KEY] [USERNAME] 我們只有一把 key 獲得 instance 名稱gcloud compute instances list 新增 public key 到 instance(這邊請注意，這個指令會替換掉這個 instance 在 GCP 的 SSH key, 換言之，這個檔案裡面沒有的 key 都會消失)gcloud compute instances add-metadata instanceName --metadata-from-file ssh-keys=instanceSSHList 安裝以下主要是安裝 nvm, node 版本v12.1.0, 以及 npm, 細節可以參考官方文件apt-get update -y &amp;&amp; apt-get install curl -y &amp;&amp; curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.34.0/install.sh | bash &amp;&amp; export NVM_DIR=\"$HOME/.nvm\" &amp;&amp; [ -s \"$NVM_DIR/nvm.sh\" ] &amp;&amp; \\. \"$NVM_DIR/nvm.sh\" &amp;&amp; [ -s \"$NVM_DIR/bash_completion\" ] &amp;&amp; \\. \"$NVM_DIR/bash_completion\" &amp;&amp; nvm install v12.1.0 &amp;&amp; apt-get install npm -y Daemon接下來，以下為 Daemon 設定, 我們將使用 Daemon 來幫我們跑我們的服務，並且讓我們的服務在斷開的時候可以自動重啟sudo vim /etc/init.d/serviceName #!/bin/sh### BEGIN INIT INFO# Provides: yourServiceName (optional)# Required-Start: $remote_fs $syslog# Required-Stop: $remote_fs $syslog# Default-Start: 2 3 4 5# Default-Stop: 0 1 6# Short-Description: Start daemon at boot time# Description: Enable service provided by daemon.### END INIT INFOdir=\"yourProjectLocation\"cmd=\"theCommandItRequiresToStartYourService\"user=\"root\"name=`basename $0`pid_file=\"/var/run/$name.pid\"stdout_log=\"/var/log/$name.log\"stderr_log=\"/var/log/$name.log\"get_pid() &#123; cat \"$pid_file\"&#125;is_running() &#123; [ -f \"$pid_file\" ] &amp;&amp; ps -p `get_pid` &gt; /dev/null 2&gt;&amp;1&#125;case \"$1\" in start) if is_running; then echo \"Already started\" else echo \"Starting $name\" cd \"$dir\" export NODE_ENV=test if [ -z \"$user\" ]; then sudo $cmd &gt;&gt; \"$stdout_log\" 2&gt;&gt; \"$stderr_log\" &amp; else sudo -u \"$user\" $cmd &gt;&gt; \"$stdout_log\" 2&gt;&gt; \"$stderr_log\" &amp; fi echo $! &gt; \"$pid_file\" if ! is_running; then echo \"Unable to start, see $stdout_log and $stderr_log\" exit 1 fi fi ;; stop) if is_running; then echo -n \"Stopping $name..\" kill `get_pid` for i in 1 2 3 4 5 6 7 8 9 10 # for i in `seq 10` do if ! is_running; then break fi echo -n \".\" sleep 1 done echo if is_running; then echo \"Not stopped; may still be shutting down or shutdown may have failed\" exit 1 else echo \"Stopped\" if [ -f \"$pid_file\" ]; then rm \"$pid_file\" fi fi else echo \"Not running\" fi ;; restart) $0 stop if is_running; then echo \"Unable to stop, will not attempt to start\" exit 1 fi $0 start ;; status) if is_running; then echo \"Running\" else echo \"Stopped\" exit 1 fi ;; *) echo \"Usage: $0 &#123;start|stop|restart|status&#125;\" exit 1 ;;esacexit 0 若發現找不到 service 的話，那需要重新載入 daemon sudo systemctl daemon-reload 記得更改權限，讓 deamon 可以執行 sudo chmod 755 serviceName 開啟自動重啟，當 VM 重啟時，服務會跟著重啟 sudo systemctl enable serviceName Daemon 的名稱在此範例中，會設置的跟專案名稱一樣 CI/CDGitlab variables setting 我們將使用 Gitlab 的 pusher 來做 CI/CD 的部分，所以這邊先建立一組 ssh key, 並且在 gitlab 中設定為 $SSH_PRIVATE_KEY ssh-keygen -t rsa -b 4096 -C \"root@deploy\" Gitlab yaml config file下面我們會開始設定 Gitlab 的 pusher config yaml 檔案在我們的專案中：vim .gitlab-ci.yml # This file is a template, and might need editing before it works on your project.# Official framework image. Look for the different tagged releases at:# https://hub.docker.com/r/library/node/tags/# 在 Docker 內部，我們要使用的環境 imageimage: node:8# This folder is cached between builds# http://docs.gitlab.com/ce/ci/yaml/README.html#cache# cache 可以讓我們使用在所有的 buildcache: paths: - node_modules/stages:- build- deploy# 只是個名字npm-build: stage: build script: # 刪掉 node_modules, 安裝最新版的 npm, 並更新 project 裡頭的 npm 套件 - rm -rf node_modules/ &amp;&amp; npm i npm@latest -g &amp;&amp; npm install # 只是個名字depoly-test:# 將在 `deploy` stage 做以下的事 stage: deploy script: # cfr. https://docs.gitlab.com/ee/ci/ssh_keys/README.html # Install ssh-agent if not already installed, it is required by Docker. # (change apt-get to yum if you use a CentOS-based image) # 如果 ssh-agent 不存在，更新 apt-get 並且安裝 openssh-client - 'which ssh-agent || ( apt-get update -y &amp;&amp; apt-get install openssh-client -y )' # Run ssh-agent (inside the build environment) # 當運行 ssh-agent -s 時，會輸出一些 command, 但是他們並還沒有被執行，所以必須使用 eval ，他可以用來執行迭代運算 - eval $(ssh-agent -s) # Add the SSH key stored in SSH_PRIVATE_KEY variable to the agent store # 將 $SSH_PRIVATE_KEY 加到 ssh agent - ssh-add &lt;(echo \"$SSH_PRIVATE_KEY\") # For Docker builds disable host key checking. Be aware that by adding that # you are suspectible to man-in-the-middle attacks. # WARNING: Use this only with the Docker executor, if you use it with shell # you will overwrite your user's SSH config. #- mkdir -p ~/.ssh #- '[[ -f /.dockerenv ]] &amp;&amp; echo -e \"Host *\\n\\tStrictHostKeyChecking no\\n\\n\" &gt; ~/.ssh/config' # In order to properly check the server's host key, assuming you created the # SSH_SERVER_HOSTKEYS variable previously, uncomment the following two lines # instead. # 在 docker container 中，建立 .ssh 資料夾, 並設立權限 - mkdir -m 700 -p /root/.ssh # 使用 gz 格式來將位於當層的專案資料夾整個壓縮，並將壓縮檔丟到上一層目錄去 - tar zcf ../$CI_PROJECT_NAME.tar.gz ./ # 將壓縮檔丟到指定機器上的指定目錄 - scp -o StrictHostKeyChecking=no ../$CI_PROJECT_NAME.tar.gz root@35.201.171.244:/locationYouPrefer # 接下來，我們利用 ssh 到指定的機器，然後開始做以下的事 # 建立一個跟專案同名的資料夾 # 將剛剛打包好的檔案，解壓縮到這個資料夾內，並不顯示解壓縮訊息 # 更改專案資料夾的權限 # 進到資料夾中, npm rebuild, 並且打開事先設定好的 daemon service - ssh root@yourIP \"rm -rf /locationYouPrefer/$CI_PROJECT_NAME &amp;&amp; mkdir -p locationYouPrefer/$CI_PROJECT_NAME &amp;&amp; tar zxf locationYouPrefer/$CI_PROJECT_NAME.tar.gz -C locationYouPrefer/$CI_PROJECT_NAME &amp;&amp; chmod -R 655 locationYouPrefer/$CI_PROJECT_NAME &amp;&amp; cd locationYouPrefer/$CI_PROJECT_NAME &amp;&amp; npm rebuild &amp;&amp; /etc/init.d/$CI_PROJECT_NAME restart\" # 以上的 deploy stage 唯有在你指定的 branch 觸發 only: - branchYouPrefer 結論到這邊，當我們 git push 到指定的 branch 時，就會觸發 gitlab 的 pusher 來達成自動部署。","link":"/zh-tw/gitlabCICDOnGCP/"},{"title":"推錯了Commit該怎麼辦？","text":"有時我們把功能做好並且推上公共資料夾之後才發現，靠…我commit好像推錯了…別緊張，這時候我們可以使用git revert 來取消我們的commit。現在讓我來為各位做個示範： 建立一個本地遠端資料夾 因為有些朋友可能沒有網路，所以本篇範例將創立一個在本地的遠端資料夾 到你一般存放專案的資料夾底下 mkdir git_demonstration git_demonstration_central cd git_demonstration_central git init --bare git_demonstration_central將會是本篇範例中的遠端資料夾 建造本地測試環境 進到本範例本地資料夾 cd ../git_demonstration 初始化git git init 建立名為test的檔案 touch test 在檔案內增加內容1 cat 1 &gt; test 將test檔案加到git追蹤清單 git add test 針對目前檔案以及內容做一個commit名為1 git commit -m&#39;1&#39; 在檔案test中增加數字2，並做一個新的commit名為2 cat 2 &gt;&gt; test;git commit -am&#39;2&#39; 在檔案test中增加數字3，並做一個新的commit名為3 cat 3 &gt;&gt; test;git commit -am&#39;3&#39; 建立遠端branchBuild remote branch 將我們一開始建立的位於本地的模擬遠端資料夾加到當前測試環境的遠端 git remote add origin /user/yourUserName/yourDirectory/git_demonstration_central 將目前master branch 推到此遠端，並將遠端新增的分支設為本地的上游分支 git push -u origin master 到遠端資料夾看一下，目前狀況 cd ../git_demonstration_central;git log Revert已存在的commit 假設今天我們要將commit 3的內容移除 git revert f06550f7 更新到遠端 git push 看一下檔案test的內容是否已變更 cat test 得值1 2，原本數字3已經在revert之後被移除了 確認遠端歷史狀況 cd ../git_demonstration_central;git log 總結有些剛接觸git的人可能會跟我當初有同樣的疑問，那為啥不要整個git的log紀錄都抹掉就好，為啥要多一個commit？這邊跟大家解釋一下，如果今天我們已經把我們完成的進度推到共同資料夾了，我們就不建議去修改歷史了，因為你一但修改了歷史再往上推，整個共同資料夾的歷史就會改變，共同資料夾的紀錄相當於所有協作者的紀錄，所以如果你單方面變動了歷史，很可能會造成所有協作者的歷史都跟你的不一致，甚至在commit的過程中會有衝突，這在多人協作是相當不建議的。我們要拿掉的，是我們檔案內的一段有commit紀錄的code，所以實際上我們要取消的是code，不是歷史，而在多人協作中，歷史是可以增加，不建議修改的。你可以新增一個commit明確說明我這段commit是新增或者拿掉了什麼東西，但是不建議單方面地把東西拿掉並且去修改你的歷史紀錄，因為你改的東西只有你自己知道，對於其他的協作者來說他們並不知道在你的電腦上發生了什麼事。簡單來說，在你上傳到共同資料夾之前，你可以對你的歷史做任何事（這邊僅限於還未上傳的部分，已經上傳的不建議去修改），但是一但上傳之後，就不建議去修改歷史。如果你要對檔案內容做任何修改，請新增一個commit說明修改的內容，這樣才不會造成其他協作者的疑惑以及大家的git歷史有衝突。以上就是今天的分享，我們明天見！","link":"/zh-tw/gitRevert/"},{"title":"Git-標注一個版本號碼","text":"哈囉大家好，我是Ray！ 今天我將跟大家分享git tag，如何建立一個版本號。 當我們接二連三地完成了專案裡的一些功能，一系列的功能可能代表著一個版本的產生，比方來說，大家都玩過線上遊戲吧？ 每次改版時，常常都是釋出一些新的功能，這個版本號常常意味著，除了這些功能開發完成之外，並且都正常的運作著。 這個版本號對於開發者來說非常方便與重要，這樣來解釋，一系列的小功能構成一個大功能，而這個大功能的完成也代表著新版本的推出。 當每一次我們完成了一個小功能，我們使用git commit把它記錄下來，而當我們陸陸續續完成一系列的小功能而構成一個大功能時，我們使用git tag來標注，代表著一個版本的釋出。若日後我們需要回到這一版來做相關的一些測試的話，非常的方便！ 輸入 git log --oneline 以上是我們還沒有tag之前的樣子。 輸入git tag -a v1.0 -m “The stable version of example” 如上圖你可以看到我們剛剛加入的版本號 v1.0 輸入 git tag 可以看到我們至今tag的任何版本號 現在讓我們新增一個檔案，example2.html，並且新增以下的code: &lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;This is the experimental file created after reversion v1.0&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 然後輸入Git add example2.htmlgit commit -am “An example2 file after v1.0”Git log --oneline 如上圖，我們目前在第六個commit，而我們的版本是在第五個commit 當我們想要回到v1.0的版本時，我們不需要checkout第五個commit的名稱，我們只需要輸入版本編號即可，如下輸入： Git checkout v1.0Git log --oneline 如上圖，我們已經回到版本v1.0的紀錄了 希望我今天的文章對你有所幫助！","link":"/zh-tw/gitTag/"},{"title":"Hello World","text":"FeaturesEnglish version中文版日本語版 Do not modify this note. Thank you very much :smile:If you want to say hello or play with something, please go to Playground Introduction HackMD is a realtime, multi-platform collaborative markdown note editor.This means that you can write notes with other people on your desktop, tablet or even on the phone.You can sign-in via multiple auth providers like Facebook, Twitter, GitHub and many more on the homepage. Please report new issues in GitHub.If you need instant help, please send us a Facebook message.Thank you very much! WorkspaceModesDesktop &amp; Tablet Edit: See only the editor. View: See only the result. Both: See both in split view. Mobile View: See only the result. Edit: See only the editor. Image Upload:You can upload an image simply by clicking on the camera button .Alternatively, you can drag-n-drop an image into the editor. Even pasting images is possible!This will automatically upload the image to imgur, nothing to worry. :tada: Share Notes:If you want to share an editable note, just copy the URL.If you want to share a read-only note, simply press publish button and copy the URL. Save a Note:Currently, you can save to Dropbox or save an .md file locally. Import Notes:Similarly to the save feature, you can also import an .md file from Dropbox ,or import content from your clipboard , and that can parse some html which might be useful :smiley: Permissions:It is possible to change the access permission to a note through the little button on the top right of the view.There are six possible options: Owner read/write Signed-in read Signed-in write Guest read Guest write Freely ✔ ✔ ✔ ✔ ✔ Editable ✔ ✔ ✔ ✔ ✖ Limited ✔ ✔ ✔ ✖ ✖ Locked ✔ ✔ ✖ ✔ ✖ Protected ✔ ✔ ✖ ✖ ✖ Private ✔ ✖ ✖ ✖ ✖ Only the owner of the note can change the note’s permissions. Embed a Note:Notes can be embedded as follows: &lt;iframe width=\"100%\" height=\"500\" src=\"https://hackmd.io/features\" frameborder=\"0\"&gt;&lt;/iframe&gt; Slide Mode:You can use a special syntax to organize your note into slides.After that, you can use the Slide Mode to make a presentation.Visit the above link for details. Book Mode:You can make your notes into a book.List your links in order or nest them.Then use the Book Mode to make a collection.Visit the above link for details. ViewTable of Contents:You can look at the bottom right section of the view area, there is a ToC button .Pressing that button will show you a current Table of Contents, and will highlight which section you’re at.ToCs support up to three header levels. PermalinkEvery header will automatically add a permalink on the right side.You can hover and click to anchor on it. Edit:Shortcut Keys:Just like Sublime text, which is pretty quick and convenient. For more infomation, see here. Auto-Complete:This editor provides full auto-complete hints in markdown. Emojis: type : to show hints. Code blocks: type ` and plus a character to show hint. ```- Headers: type `#` to show hint.- Referrals: type `[]` to show hint.- Externals: type `&#123;&#125;` to show hint.- Images: type `!` to show hint.## Title:This will take the first **level 1 header** as the note title.## Tags:Using tags as follows, the specified tags will show in your **history**.###### tags: `features` `cool` `updated`## [YAML Metadata](/yaml-metadata)You can provide advanced note information to set the browser behavior (visit above link for details):- title: set note title- description: set note description- image: set note default image (for link preview)- tags: set note tags- robots: set web robots meta- lang: set browser language- dir: set text direction- breaks: set to use line breaks- GA: set to use Google Analytics- disqus: set to use Disqus- slideOptions: setup slide mode options## ToC:Use the syntax `[TOC]` to embed table of content into your note.[TOC]## EmojiYou can type any emoji like this :smile: :smiley: :cry: :wink:&gt; See full emoji list [here](http://www.emoji-cheat-sheet.com/).## ToDo List:- [ ] ToDos - [x] Buy some salad - [ ] Brush teeth - [x] Drink some water## Code Block:We support many programming languages, use the auto complete function to see the entire list.```javascript=var s = &quot;JavaScript syntax highlighting&quot;;alert(s);function $initHighlight(block, cls) &#123; try &#123; if (cls.search(/\\bno\\-highlight\\b/) != -1) return process(block, true, 0x0F) + &apos; class=&quot;&quot;&apos;; &#125; catch (e) &#123; /* handle exception */ &#125; for (var i = 0 / 2; i &lt; classes.length; i++) &#123; if (checkCondition(classes[i]) === undefined) return /\\d+[\\s/]/g; &#125;&#125; If you want line numbers, type = after specifying the code block languagues.Also, you can specify the start line number.Like below, the line number starts from 101:var s = \"JavaScript syntax highlighting\";alert(s);function $initHighlight(block, cls) &#123; try &#123; if (cls.search(/\\bno\\-highlight\\b/) != -1) return process(block, true, 0x0F) + ' class=\"\"'; &#125; catch (e) &#123; /* handle exception */ &#125; for (var i = 0 / 2; i &lt; classes.length; i++) &#123; if (checkCondition(classes[i]) === undefined) return /\\d+[\\s/]/g; &#125;&#125; Or you might want to continue the previous code block’s line number, use =+ var s = \"JavaScript syntax highlighting\";alert(s); Somtimes you have a super long text without breaks. It’s time to use ! to wrap your code. When you’re a carpenter making a beautiful chest of drawers, you’re not going to use a piece of plywood on the back. Blockquote Tags: Using the syntax below to specifiy your name, time and color to vary the blockquotes.[name=ChengHan Wu] [time=Sun, Jun 28, 2015 9:59 PM] [color=#907bf7] Even support the nest blockquotes![name=ChengHan Wu] [time=Sun, Jun 28, 2015 10:00 PM] [color=red] ExternalsYouTube Vimeo Gist SlideShareMathJaxYou can render LaTeX mathematical expressions using MathJax, as on math.stackexchange.com, except the space after the start $ and the space before the end $ are not allowed in the inline math: The Gamma function satisfying $\\Gamma(n) = (n-1)!\\quad\\forall n\\in\\mathbb N$ is via the Euler integral $$x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}.$$ $$\\Gamma(z) = \\int_0^\\infty t^{z-1}e^{-t}dt\\,.$$ More information about LaTeX mathematical expressions here. UML DiagramsSequence DiagramsYou can render sequence diagrams like this: Alice-&gt;Bob: Hello Bob, how are you?Note right of Bob: Bob thinksBob--&gt;Alice: I am good thanks!Note left of Alice: Alice respondsAlice-&gt;Bob: Where have you been? Flow ChartsFlow charts can be specified like this:st=&gt;start: Starte=&gt;end: Endop=&gt;operation: My Operationop2=&gt;operation: lalalacond=&gt;condition: Yes or No?st-&gt;op-&gt;op2-&gt;condcond(yes)-&gt;econd(no)-&gt;op2 Graphvizdigraph hierarchy &#123; nodesep=1.0 // increases the separation between nodes node [color=Red,fontname=Courier,shape=box] //All nodes will this shape and colour edge [color=Blue, style=dashed] //All the lines look like this Headteacher-&gt;&#123;Deputy1 Deputy2 BusinessManager&#125; Deputy1-&gt;&#123;Teacher1 Teacher2&#125; BusinessManager-&gt;ITManager &#123;rank=same;ITManager Teacher1 Teacher2&#125; // Put them on the same level&#125; Mermaidgantt title A Gantt Diagram section Section A task :a1, 2014-01-01, 30d Another task :after a1 , 20d section Another Task in sec :2014-01-12 , 12d anther task : 24d AbcX:1T:Speed the PloughM:4/4C:Trad.K:G|:GABc dedB|dedB dedB|c2ec B2dB|c2A2 A2BA|GABc dedB|dedB dedB|c2ec B2dB|A2F2 G4:||:g2gf gdBd|g2f2 e2d2|c2ec B2dB|c2A2 A2df|g2gf g2Bd|g2f2 e2d2|c2ec B2dB|A2F2 G4:| More information about sequence diagrams syntax here.More information about flow charts syntax here.More information about graphviz syntax hereMore information about mermaid syntax hereMore information about abc syntax here Alert Area:::successYes :tada:::: :::infoThis is a message :mega:::: :::warningWatch out :zap:::: :::dangerOh No! :fire:::: TypographyHeaders# h1 Heading## h2 Heading### h3 Heading#### h4 Heading##### h5 Heading###### h6 Heading Horizontal Rules Typographic ReplacementsEnable typographer option to see result. (c) (C) (r) (R) (tm) (TM) (p) (P) +- test.. test… test….. test?….. test!…. !!!!!! ???? ,, Remarkable – awesome “Smartypants, double quotes” ‘Smartypants, single quotes’ EmphasisThis is bold text This is bold text This is italic text This is italic text Deleted text lu~lala~ Superscript: 19^th^ Subscript: H~2~O ++Inserted text++ ==Marked text== Blockquotes Blockquotes can also be nested… …by using additional greater-than signs right next to each other… …or with spaces between arrows. ListsUnordered Create a list by starting a line with +, -, or * Sub-lists are made by indenting 2 spaces: Marker character change forces new list start: Ac tristique libero volutpat at Facilisis in pretium nisl aliquet Nulla volutpat aliquam velit Very easy! Ordered Lorem ipsum dolor sit amet Consectetur adipiscing elit Integer molestie lorem at massa You can use sequential numbers… …or keep all the numbers as 1. feafw 332 242 2552 e2 Start numbering with offset: foo bar CodeInline code Indented code // Some comments line 1 of code line 2 of code line 3 of code Block code “fences” Sample text here... Syntax highlighting var foo = function (bar) &#123; return bar++;&#125;;console.log(foo(5)); Tables Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. Right aligned columns Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. Left aligned columns Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. Center aligned columns Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. Linkslink textlink with titleAutoconverted link https://github.com/nodeca/pica ImagesLike links, Images also have a footnote style syntaxWith a reference later in the document defining the URL location: Show the image with given size FootnotesFootnote 1 link[^first].Footnote 2 link[^second].Inline footnote^[Text of inline footnote] definition.Duplicated footnote reference[^second]. [^first]: Footnote can have markup and multiple paragraphs.[^second]: Footnote text. Definition ListsTerm 1 : Definition 1with lazy continuation. Term 2 with inline markup : Definition 2 { some code, part of Definition 2 } Third paragraph of definition 2. Compact style: Term 1 ~ Definition 1 Term 2 ~ Definition 2a ~ Definition 2b AbbreviationsThis is an HTML abbreviation example.It converts “HTML”, but keeps intact partial entries like “xxxHTMLyyy” and so on. *[HTML]: Hyper Text Markup Language","link":"/zh-tw/hello-world/"},{"title":"如何設置Git的個人資訊？","text":"大家好，我是Ray! 今天要來跟大家分享，如何配置Git的基本資訊。 讓我們新增一行敘述在現有的example1.html 的檔案裡，如下： &lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;First example&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;This is the first example&lt;/p&gt;&lt;p&gt;We add a new paragraph on the first example&lt;/p&gt;&lt;p&gt;This is the example commit for git commit -am&lt;/p&gt;&lt;p&gt;This is the example1 for git configuration&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; Git commit -am “Before configuration” Git log 各位可以看一下上面我們我們剛剛所commit的Author 資料。 現在加入另一段敘述在example1.html檔案內，如下： &lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;First example&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;This is the first example&lt;/p&gt;&lt;p&gt;We add a new paragraph on the first example&lt;/p&gt;&lt;p&gt;This is the example commit for git commit -am&lt;/p&gt;&lt;p&gt;This is the example1 for git configuration&lt;/p&gt;&lt;p&gt;This is the example after git configuration&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 現在讓我們來定義git 配置的使用者資訊： 輸入 Git config --global user.name RayGit config --global user.email example@email.com 上面的Ray以及example@email欄位請填你們自己的！ 接下來輸入 Git commit -am “after configuration” Git log 由上面的截圖可以看到，我們已經成功的配置的使用者的名稱還有信箱改掉了！ 這邊補充說明，這裡使用–global進行配置，所以這裡的設定是全域通用的，簡單來說，你電腦內的所有資料夾都套用這個資料，之後有機會我們再介紹如何針對單一資料夾進行更改。 今天的分享就到這裡了，我們明天見！","link":"/zh-tw/howToConfigureGit/"},{"title":"Google Cloud Pub/Sub:Qwik Start - 控制面板","text":"前言本篇主要是利用 Google 的 Qwiklab 平台學習的同時，做的一份學習筆記為避免翻譯誤解，專業術語在本篇將不會被翻譯，保留原文 概述Google Cloud Pub/Sub 是一個訊息服務，提供在不同的應用或服務之間，傳遞事件資料，資料的產生者發佈訊息到 Cloud Pub/Sub topic, 訂閱者可以經由訂閱拉回訊息，或是設定好，當某事件被觸發時，就觸發訂閱。 每個訂閱者必須在可設定的一段時間內確認收到訊息 你將會做什麼？ 設定一個 topic 來存放資料 訂閱一個 topic 來存取資料 發佈，然後經由訂閱者來消耗訊息 設定及要求 Qwiklabs setup在你按下 Start Lab 按鈕之前 詳讀所有的教學。Labs 是有時間限制的，而且你不可以停止時間倒數。倒數計時器在你按下 Start Lab 按鈕後開始倒數，上面顯示的時間為你還能使用 Cloud 資源的時間。 Quiklabs 的手把手環境，讓你可以在真實環境中來操作進行 Quiclabs 上提供的課程，而不是在一個模擬或是展示的環境。我們透過提供你一個全新的、暫時的帳號密碼，在計時器歸零之前，你可以用來登入並存取 Google Cloud Platform。 你需要什麼？ 要完成這個 lab ，你需要: 一個一般的網路瀏覽器（推薦 Chrome） 完成這個 lab 的時間 備註： 如果你已經有你自己的個人 GCP 帳號或專案，請不要使用在這一個 lab 現在你已經開始你的 lab, 你將會登入 Google Cloud Shell 主控台，然後開啟命令列工具 如何開始你的 lab ，然後登入 Console? 按下 Start Lab 按鈕。如果你需要付費，會有一個彈出視窗來讓你選擇付費的方式。在左方你會看到一個面板，上面有暫時的帳號密碼，你必須使用這些帳號密碼在此次 lab 複製 username , 然後點擊 Open Google Console。 Lab 會開啟另外一個視窗，顯示選擇帳號的頁面 tip: 開啟一個全新的視窗，然後跟原本的頁面並排 在選擇帳號頁面, 點擊 Use Another Account 登入頁面開啟，貼上之前複製的 username 以及 password ，然後貼上 重要：必須使用之前於 Connection Details 面板 取得的帳號密碼，不要使用你自己的 Qwiklabs 帳號密碼。 如果你有自己的 GCP 帳號，請不要用在這裡（避免產生費用） 點擊並通過接下來的頁面: 接受terms以及conditions 不要增加recovery optoins 或 two factor authentication (因為這只是一個臨時帳號) 不要註冊免費體驗 稍待一些時候， GCP 控制台將會在這個視窗開啟。 注意：按下左上方位於Google Cloud Platform 隔壁的 Navigation menu ，你可以瀏覽選單，裡面有一系列的 GCP 產品以及服務 啟動 Google Cloud ShellGoogle Cloud Shell 是載有開發工具的虛擬機器。它提供了5GB的 home 資料夾，並且運行在 Google Cloud 上。 Google Cloud Shell 讓你可以利用 command-line 存取 GCP 資源 在 GCP 控制台 ，右上的工具列，點擊 Open Cloud Shell 按鈕 在打開的對話框裡，按下 START CLOUD SHELL: 你可以立即按下 START CLOUD SHELL 當對話視窗打開。 連結並提供環境會需要一點時間。當你連結成功，這代表你已成功獲得授權，且此專案已被設為你的專案ID，例如： gcloud 是 Google Cloud Platform 的 command-line 工具，他已事先被安裝在 Cloud Shell 並且支援自動補齊 使用這個 command ,你可以列出有效帳戶名稱: gcloud auth list 輸出: Credentialed accounts: - &lt;myaccount&gt;@&lt;mydomain&gt;.com (active) 範例輸出: Credentialed accounts: - google1623327_student@qwiklabs.net 你可以使用以下 command 來列出專案 ID gcloud config list project 輸出： [core]project = &lt;project_ID&gt; 範例輸出： [core]project = qwiklabs-gcp-44776a13dea667a6 gcloud 的完整文件可以參閱 Google Cloud gcloud Overview 設定 Pub/Sub你可以使用 Google Cloud Shell 主控台來操作 Google Cloud Pub/Sub 要使用 Pub/Sub, 你建立一個 topic 來存放資料，以及一個訂閱來存取被發佈到 topic 的資料 點擊 Navigation menu &gt; Pub/Sub &gt; Topics 點擊Create a topic topic 必須是一個獨一無二的名字，在這個 lab 中，將你的 topic 取名為 MyTopic. 在 Create a topic 視窗中： 將你的 topic 取名為 MyTopic 將 Encryption 留為默認值 點擊 CREATE TOPIC 你已經建立了 topic 測試任務是否完成點擊Check my progress 來和對目前任務進度。如果你已經成功建立 Cloud Pub/Sub topic, 你會得到評價的分數 增加一個訂閱現在你將建立一個訂閱來存取 topic 在左邊的控制列點擊 Topics 回到 Topics 對話框, 在我們剛剛建立的 topic，在三個點的圖案處按一下，然後點擊 Create subscription 在 Add subscription to topic 對話框： 輸入 subscription 的名字，例如 MySub 將 Delivery type 設為 Pull 將其他選項都留為預設值 點擊 Create 你的訂閱被列在訂閱清單中 測試任務是否完成點擊Check my progress 來和對目前任務進度。如果你已經成功建立 Cloud Pub/Sub topic, 你會得到評價的分數 測試你的理解底下有一些問題用來鞏固你對這個 lab 概念的了解，盡你所能的去回答吧 一個發佈者的的應用，建立並且傳送訊息到 ___. 訂閱者的應用建立一個 ___ 到 topic 來取得訊息 topic, subscription topic, topic subscription, subscription subscription, topic Cloud Pub/Sub 是一個被設計為高度可靠以及可規模化的異步訊息服務 發佈訊息到 topic 在 Topics details 對話框的上方，點擊 PUBLISH MESSAGE。 你可能需要調寬瀏覽器的視窗來檢視 PUBLISH MESSAGE 選項 在 Message 欄位中輸入 Hello World, 然後點擊 Publish 檢視訊息要檢視訊息，你將需要使用 subscription (MySub) 來從 topic (MyTopic) 取得訊息 (Hello World) 在命令行輸入以下指令 gcloud pubsub subscriptions pull --auto-ack MySub 訊息將會出現在輸出的 DATA 欄位 你建立了 Pub/Sub topic，並且發佈到這個 topic, 建立了 subscription, 然後使用 subscription 來取得在 topic 的資料 恭喜完成本教程！","link":"/zh-tw/googleCloudPubSubQwikStartConsole/"},{"title":"如何經由PHP導入中文到MySQL而不會出現亂碼？","text":"如何正確的導入中文而不會出現亂碼？ 大家好，我是Ray!今天我想跟大家分享CSV檔案匯入MySQL的更多細節部分，像是如何正確的導入中文字而不會出現亂碼。 首先，先講PHP的部分： &lt;?phpmysqli_set_charset($dbc,&quot;utf8&quot;); 在連接資料庫之後，請記得一定要加入上面的code，目的是明確來往資料庫的資料編碼格式。 檔案部分： 首先，打開Excel，然後開啓新檔案 接下來，點選Data，並且選取From text 這邊請選擇使用分界符號 這裏選擇使用逗號來做分隔 最後選擇一般即可 接下來爲，資料庫部分： 如果你是使用Sequel Pro,那請務必在創建表格時點選UTF-8，如下圖 如果你是使用終端機部分，如下圖，請記得要在創立表格的同時賦予utf8的編碼。 如果依然在匯入之後顯示亂碼，請確認column的編碼是否爲utf-8 基本上如果以上的細節都有注意到，應該就可以順利的導入中文，並且成功的在資料庫內顯示中文，如下圖： 大家寫code愉快！","link":"/zh-tw/howToImportChineseIntoDatabaseWithoutGarble/"},{"title":"如何在AWS上部署多個專案？","text":"建立一個AWS EC2 instance, 本文章使用的instance型號為 Amazon Linux 2 AMI (HVM), SSD Volume Type - ami-0d7ed3ddb85b521a6 連結到你的EC2 instance, 輸入：sudo vim /etc/httpd/conf.d/yourProjectName.conf 貼上下面的code &lt;VirtualHost *:443&gt; # port 443，給https用的 ServerName letussleep.space # 你的Domain名稱 DocumentRoot &quot;/var/www/html/yourLaravelProjectName/public&quot; # 你在EC2上的專案絕對路徑 SSLEngine on SSLCertificateFile /whateverLocationYouWant/certificate.crt SSLCertificateKeyFile /whateverLocationYouWant/private.key SSLCertificateChainFile /whateverLocationYouWant/ca_bundle.crt # 簽署SSL簽證，分別對應你從從簽證網站上面取得的簽證檔案&lt;/VirtualHost&gt;&lt;VirtualHost *:80&gt; # port 80 給 http用的 ServerName letussleep.space DocumentRoot &quot;/var/www/html/yourLaravelProjectName/public&quot; redirect / Https://letussleep.space # 當使用者使用http連接，重新導向到https&lt;/VirtualHost&gt;&lt;VirtualHost *:80&gt;ServerName oldletussleep.space # 在同一個conf檔案裡頭，其實就可以部署不同的專案，只要把Domain name區分好DocumentRoot &quot;/var/www/html/yourProjectName/public&quot;&lt;/VirtualHost&gt; 雖然在同一個config檔案裡頭，只要設好domain name 以及不同的專案路徑就可以完成多專案部署，但是這樣難免混亂，所以個人偏好一個專案一個conf檔案。 所以只要重複上面的步驟，創一個新的config檔，並且輸入相對應的資訊，最後輸入sudo service httpd restart 連到你的Domain, 應該已經沒問題了！","link":"/zh-tw/howToDeployMultipleProjectOnAWS/"},{"title":"怎麼在Laravel中，利用AWS SES發郵件?","text":"申請AWS SES(simple Email Service)服務 建立一個使用者，並建立政策(SES full access)，取得Access key 跟Secret key 到AWS SES 主控台，左方Email Addresses，然後進去點選verify a new email address 進行驗證 Google AWS support center，提交‘移出沙盒’申請，約24小時內會解封。否則寄信數量跟頻率都會被很大程度上限制住，且任何收件人都必須要經過AWS驗證。 開立一個Laravel專案 輸入composer require guzzlehttp/guzzle，安裝套件 安裝AWS SDK composer require aws/aws-sdk-php 到config/mail.php中，將driver選項相對的env參數改成ses 到config/services.php中，進行以下配置 &apos;ses&apos; =&gt; [ &apos;key&apos; =&gt; &apos;your-ses-key&apos;, &apos;secret&apos; =&gt; &apos;your-ses-secret&apos;, &apos;region&apos; =&gt; &apos;ses-region&apos;, // e.g. us-east-1], 以上參數在env的配置，大概如下： MAIL_DRIVER=sesMAIL_FROM_ADDRESS=your-mail-addressMAIL_FROM_NAME=BuyBuyGoSES_KEY=your-ses-keySES_SECRET=your-ses-secretSES_REGION=us-west-2 建立Maiiables class，php artisan make:mail OrderCreated --markdown=emails.orders.created 到OrderCreated中，建立build檔案，大略如下: &lt;?phpnamespace App\\Mail;use Illuminate\\Bus\\Queueable;use Illuminate\\Mail\\Mailable;use Illuminate\\Queue\\SerializesModels;use Illuminate\\Contracts\\Queue\\ShouldQueue;class OrderShipped extends Mailable&#123; use Queueable, SerializesModels; protected $order; /** * Create a new message instance. * * @return void */ public function __construct($order) &#123; $this-&gt;order = $order; // &#125; /** * Build the message. * * @return $this */ public function build() &#123; return $this-&gt;markdown(&apos;emails.orders.created&apos;) -&gt;with([ &apos;buyer&apos; =&gt; $this-&gt;order-&gt;user-&gt;name, &apos;order&apos; =&gt; $this-&gt;order-&gt;name, &apos;item_name&apos; =&gt; $this-&gt;order-&gt;item_name, &apos;item_description&apos; =&gt; $this-&gt;order-&gt;item_description, &apos;quantity&apos; =&gt; $this-&gt;order-&gt;quantity, &apos;total_amount&apos; =&gt; $this-&gt;order-&gt;total_amount, &apos;unit_price&apos; =&gt; $this-&gt;order-&gt;unit_price, &apos;expiry_time&apos; =&gt; $this-&gt;order-&gt;expiry_time, ]); &#125;&#125; 到created.blade當中做版面客制，大略如下： @component(&apos;mail::message&apos;)# Dear &#123;&#123; $buyer &#125;&#125;Thanks for your patronage!- Order: &#123;&#123;$order&#125;&#125;- Item: &#123;&#123;$item_name&#125;&#125;- Item description: &#123;&#123;$item_description&#125;&#125;- Quantity: &#123;&#123;$quantity&#125;&#125;- Unit price: &#123;&#123;$unit_price&#125;&#125;- Amount: &#123;&#123;$total_amount&#125;&#125;## Kindly make this payment before &lt;span style=&quot;color: red&quot;&gt;&#123;&#123;$expiry_time&#125;&#125;&lt;/span&gt;&lt;hr&gt;&lt;br&gt;## If you have any question, feel free to contact us@component(&apos;mail::button&apos;, [&apos;url&apos; =&gt; &apos;https://tn710617.github.io/&apos;])Contact Us@endcomponentThanks,&lt;br&gt;&#123;&#123; config(&apos;app.name&apos;) &#125;&#125;@endcomponent 在任何你想要發這封mail的地方，使用mail來寄信，大略如下： Mail::to($buyer-&gt;email)-&gt;send(new OrderCreated($order)); 至此，應該可以成功寄信了！ 你以為結束了嗎？ 呵呵，是快結束了啦！ 不過呢，還有一件事情非常重要！上面的部分大概花了我一天，然後我遇到一個未解的謎題，又被搞了一天。身為一個backend programmer，如果遇到需要接金流的話，我都是用ngrok來測試。這次遇到的問題很奇怪，當我收到金流服務商的回饋時，我必須要去做一些事，自controller收到request之後所做的任何function都沒有問題，資料庫的CRUD也都正常，可偏偏只要執行到這一行寄mail的，就給我報錯！！ 錯誤訊息如下： &quot;message&quot;: &quot;Expected response code 250 but got code \\&quot;530\\&quot;, with message \\&quot;530 5.7.1 Authentication required\\r\\n\\&quot;&quot;,&quot;exception&quot;: &quot;Swift_TransportException&quot;,&quot;file&quot;: &quot;/Users/ray/code/FacebookOptimizedSellingSystem/vendor/swiftmailer/swiftmailer/lib/classes/Swift/Transport/AbstractSmtpTransport.php&quot;,&quot;line&quot;: 457,&quot;trace&quot;: [ 以下省略一千行… 在經過超級無敵疲勞的Debug之後，終於發現問題… 只要使用valet share，就不會有這個問題只要是用php artisan serve --port=yourPort，然後ngrok http yourPort，這樣就會遇到我說的這個問題。 雖然最後問題解決了，但說實在的我還是不知道為什麼… 如果有大大知道這是什麼原因，還請麻煩來信幫我解惑一下！感激不盡！","link":"/zh-tw/howToSendMailViaAWSSES/"},{"title":"如何使用 git checkout","text":"大家好，我是Ray! 還記得我們上次到了哪裡了嗎？看完上面的圖片有沒有讓你回想些什麼呢？ 沒錯，上次的git介紹我們從初始化開始，並且建立一個名為example1.html的檔案，然後完成了我們第一個存擋！ 如同之前提到的，我說git讓我們再存擋後，如果我們有需要的話，我們可以隨時地回到任何一個我們用git做的存擋點，今天我將跟大家分享如何回到存擋點，並且在存擋點之間自由的切換。 現在，讓我們在檔案內加入下面highlight的一段 &lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;First example&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;This is the first example&lt;/p&gt;&lt;p&gt;We add a new paragraph on the first example&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 然後我們到command line，輸入git status 你應該會看到如下圖，如下圖所示，git 顯示example1.html已經被修改過了。 如上一篇提到的，再做存擋之前，我們必須要先使用git add 來指定我們想要存擋的進度，所以 輸入git add example1.html 輸入git status 如上圖，我們已經指定了要存擋的進度 現在輸入git commit 並記錄訊息”New paragraph added in example1.html file” 完成後輸入git status確認一下狀態 然後git log 現在我們可以看到我們的第二個commit如下圖： 好啦，接下來我們來切換回第一個記錄點 git log 的功能是顯示我們所有記錄點的歷史，我們可以經由log裡面提供的資料自由的切換於不同的紀錄點。 輸入 git checkout b45934852da471efbbbc52b5a119e8723fb01866 這是我的版本，你們的版本會是一串不同的數字 如下圖所示，我們現在已經在一個第一個記錄點。 現在可以打開我editor查看，我們新增加的We add a new paragraph on the first example 已經不見了，此時版本恢復到我們第一個記錄點的狀態，不管我們是否有另外在editor做任何的紀錄。 那要如何回到我們的最新的紀錄點呢？ 輸入git checkout master 如上圖，我們現在已經回復到我們最新的紀錄點啦！ 現在打開我們的editor做確認，登登！ 原本消失的new paragraph 又出現啦！ 是不是很神奇呢？ 以上是今天的分享，希望可以讓大家對Git有更深的了解，我們明天見！","link":"/zh-tw/howToUseCheckout/"},{"title":"Japanese Practice Note","text":"前言這是我的日語練習筆記，未整理 練習2019-9-24遅い こう 次 安い 知る 部屋 一番 彼は意外に気が小さい 見つかる レストランは空いていました 十日後に帰ります 細い 汚い お母さんによろしくを伝えください 彼は昼過ぎに来ます 治る この道を真っ直ぐ行くと駅です 悪い 一杯 ご主人 お腹が空きますた 私の祖母は100歳です 彼はこの辺に住んでいる 五月五日は祝日です 構成 生活 交渉 彼がクラスの代表だ より 開発 可能 彼は非常に高い技術を持っている 初めて 試合 文章 私たちがその問題を調査しています 良い方法思いつきました 利用 方針 段階 トラブルがやっと解決しだ 遅れた理由を教えてください なお 対する 今日中にこの問題を検討してください 帰ったらまず手を洗いましょう 影響 決定 話 管理 引越しを業者に頼んだ 意見 母は日本料理を作ることができます 期末レポートは大変です 浅い川 日本語が上手になる 貯金箱に40個のコインがあります 傘は長いです 私は日本料理を作ることがよくできます 試合の相手は誰ですか 両親は日本に行きます、私も行きます あの人は木を登ることができます さあ、私もわかりませんね ピザを買いました、パスタも買いました 小林さんは中国を話すことができます お母さんは実家に帰ります レシートをください うそ 美味しいデザート ボタンを押す 教室が静かではありません 彼女は飛行機を運転することができます キャベツ 蚊 辞書 餌 サツマイモは、焼いても揚げても美味しい もも センチメートル 茶髪 2019-9-24取る 彼の日本語のレベルは私と同じ位だ 短い 食べる 今朝は早く家を出ました もっと近くに来てください 病気 立つ 彼は意外に気が小さいい 飛行機 私は二日待った 米 妹 十日後に帰ります 閉まる これは医者のためのサイトです 教科書閉じてください 答えが違います 閉める 店員は若い女の人でした 悲しい 後で電話します 増える 彼がクラスの代表だ 段階 彼は意外に気が小さいい 写真はいい思い出になります 問題 加える 政権が交代した 変わる 資金 集める 前売券は窓口で販売しています 可能 国会 変化 病院 土地 方針 のち 彼がクラスの代表だ 段階 これら 明らかに彼が悪い 調べる ここは静かな住宅地だ 私は世界一周をしたかったです 冬は暖かくありません 彼女はボーリングができます 彼は実家に帰りたがります 彼女を幸せにする あなたの会社は私の会社に統計ソフトウエアをくれました 私は日本語ができます 先生は私に100点くれました 石原さんは彼に防虫スプレーをもらいました 可能 先生は学生の気持ちがわかります 文房具 液晶テレビ 翻訳する たつ 一眼レフカメラ 皿 蚊 雄鶏 私は物理の基礎はしています 教授ガズを説明する フロント 2019-9-23古い 引く 肩 全部 軽い 起こす 勝つ 少し疲れました 一番 使う 持つ 始める 質問 図書館 太い 冷たい ６ 三つ 茶色 野球は九人で人チームです 開く 口 彼に会えて嬉しかった 姉は大学生です 泊まる 彼はシートベルト締めた 宿題は自分でやりなさい 導入 対策 十分 種類 内容 私たちは二階に上がった まま 会談の内容が発表されました 彼はその詩を用いて、自分の気持ちを伝えた 今日の予定教えてください 首相 あまり 完成 我が社の経営はうまくいっています 部分 行う 工場 一部 政権が交代した 経営 仕事がほぼ終わりました 対する 彼は新製品に興味を示している 関係 ここは静かな住宅地だ 今夜は大いに語りましょう 調べる 私は先生と事務室に行きます プールで泳ぎます 私は歌を歌うことができます 私は日本料理を作ることができます 石原さんは彼に防虫スプレーをもらいました 私は日本語がよくできます 元気な子供う 向日葵は草より綺麗です あなたの会社わ私の会社に統計ソフトウエアをくれました ドアを開ける 運動場で走ります 政権が交代した あの人は木に登ることができます ベッドの下にゴキブリがいます 私は日本料理を作ることが大体できます ジーンズを買いましょう 川の岸に桜の木があります 新設の先生 下手 布 期末レポート 大きな竜巻 明後日 暑い 教授が、図を説明する スーツケースに詰める 腹部は肋とお尻の間の部分です フルード 黒犀が草原を歩いている フットボール あなたの会社わ私の会社に統計ソフトウエアをくれました 2019-9-22学校 一番 私は朝シャワーを浴びます 約束を忘れないてください ウエイターを呼びましょう こう小さい字は読めない 学校は8時半に始まります 彼の日本語のレベルは私の同じくらいだ 弱い 私は二日待った 私は絵手伝いましょう お腹 泊まる 宿題が自分でやりなさい 一番 喋る 閉める 晴れる 腰 彼女は眠いようです 神 増える 方針 生まれる 代表 宿題は自分でやりなさい 生活 外国 増加 計算 解決 新聞 首相 開発 私たちは今結婚資金を貯めています 実現 試合の相手は誰ですか 実施 一般 強化 より 特徴 ほとんど 調べる 彼は食品工場で働いています 今後の方針が決まった 建設 開く 変化 私にはたくさんのお金が必要だ 販売 住宅 立場 計画 存在 今回 彼女は同じ間違いを繰り返した なお、雨の場合は中止です いずれ システムの構成を変えてみました 予定 決定 ニュースで道の状況がわかります 私は日本料理を大体できます 私は日本料理作ることがまあまあできます 長い傘 あの屋敷に幽霊がいますよ 彼は学校に来ませんでした 引き出しにハムスターが一匹います 佐々木さんはサラリーマンです 私のノートはどれですか 白い紙を黒くする 川の岸に桜の木があります ご飯を食べましょう 私は会社に行きます 台湾は暑いです 私は日本語が全然できません 私はもっと頑張りたかったです 私は日本料理を作ることがあまりできません 私は日本料理を作ることが全然できません 田舎は都市ほど便利ではありません チケットをください ハンバーガーとコーラ はい、そうです 私は実家に帰りたがります 林さんは私にコンサートのチッケトをくれました 彼は明日の天気がわかります 小林さんの妻は小林さんに愛妻弁当あげました 乗客 鶏 ゲーム機 翻訳する 社員食堂 ゴミ箱 腹部は、肋とお尻の間の部分です サツマイモは、焼いてもあげても美味しい 女性はももの太さを計っている 栓抜きありますか む 2019-9-21生活 なお、雨の場合は中止です 実現 決定 試合の相手は誰ですか 会談 試合の結果早く知りたい 政府 私は日本語がまあまあできます 私は料理を作ることができます 国仲さんは貴方にギターをもらいました それは正方形です 私は世界一周をしたいです 車の後ろに子猫と子犬がいます お元気な子供 貴方は貴方の弟にケーキをあげましたか なお、雨の場合は中止です 日本語を上手にする 私は日本料理を作ることがあまりできません 私は日本料理を作ることができます 先生は私に100点をくれました 私は日本料理を作ることが少しできます 正方形はどれですか 私は日本料理を作ることがまあまあできます 犬と猫と兎、どれが好きですか 役所の人はお婆ちゃんに綺麗なカレンダーをくれました 試合の相手は誰ですか 床に蟻がいます 私は弟と妹と実家に帰りました 調べる ポルトガル 烏龍茶 簡単 翻訳する 隣人 年齢 海外旅行 腹部は肋とお尻の間の部分です 雄鶏 ロブスター センチメートル む う 翻訳する 腹部は、肋とお尻の間の部分です 2019-9-20九份わ賑やかです 肉と魚とどちらが好きですか 知る 国 体 この靴はとても軽い 帰国することに決めました 家に帰ろ 軽い 酒 質問の意味はわかりましたか 今日は日本語の授業があります 見つける 私は友達が沢山います 笑う 飛行機 私は平仮名を全部読めます 時 六つ 私は腕時計を四つ持っています この道を真っ直ぐ行くと駅です 柿の木に実が沢山なっています 時の経つのは早い 書ける 辛い 細い 彼はこの辺に住んでいます 冷たい 他に方法がありません 九日に荷物が届きます 飛行機 彼はこの辺に住んでいます 野球 先 一部 昨年 資金 示す その問題に関する記事を読みます ここは一方通行です 会社 従来 生産 彼は行政を改革したいと思っていあ 資金 帰ったら、まず手を洗いましょう 増える 方針 工場 やる 兄は船の設計をしています彼は就職試験を受けた 問題 株 交渉 一緒に対策を考えもしょ 政権が交代した 強調 商品 評価 変わる 開発 島の人口は年々増加しています 情報 私たちがその問題を調査しています 増える 工場 事務的な処理に1週間かかります 解決した 機能 彼は歌で自分の気持ちを表現した 20キロのダイエットは可能だと 良い方法を思いつきました 今日の予定教えてください 彼はその詩を用いて自分の気持ちを伝えた 私は日本語があまりできません 料理を美味しくする この犬 浅い川 皆に運動会の予定わかります 私は日本料理を作ることが少しできます 私は日本語が全然できません ハンバーガーとコーラ 夏はシズしかったです 先生は学生の気持ちがよくできます 私は日本語が少しできます 深い湖 運動場で走ります 鉛筆で字を書く 私は日本語がよくできます 国内旅行 キャベツ 一眼レフカメラ 皿 子猫眠った センチメートル 雄鶏 私が物理の基礎はしています 良い方法思いつきました フットボール 夜市は賑やかです サツマイモは焼いても揚げても美味しい 教授が図を説明する フロント 栓抜きありますか クロサイが草原を歩いている スーツケースに詰める ぬ い ゆ ぎ ざ ね 2019-9-19サツマイモは焼いても揚げても美味しい 歩く 首 働く 肩 質問のある方はどうぞ 払う 彼に手紙を書きました まだ わかる 直る 八 五日 大好き 今週 お先にどうぞ 私は平仮名を全部読めます 鼻がかゆいです 冷たい 答える これはかなり金がかかった これは医者のためのサイトです 彼には子供が六人います 後ろを向いて 場合 愛する 他に方法がありません 経済 導入 関係 前売券は窓口で販売しています 国は国語教育を強化しています 冷たい はげしい雨が降っています 彼は新製品に興味を示している その問題に関する記事を読みました 消える 一部 政権が交代した 動き ガソリンの価格がどんどん上がっている 変わる 計画 増える 普及 対処 今の首相はあまり力がない 力 トラブルがやっと解決した 信号が青に変わりました 一部 政権が交代した 変わる 問題 増える 政権 報告 結果 ドル 今後ともよろしくお願いします 母はペットと海外旅行しました うそ 私は使い捨ての箸をあげました ハンバーガーとコーラ 方針 私は日本語があまりできません 彼のお父さんは彼に新し腕時計をもらいました 楽し一日 彼女を幸せにする 私は学生でした いつが暇ですか 私は泳ぐことができます 隣の人は私の猫に餌をくれました コーヒーを飲みましょうか 私は貴方にデジタルカメラをくれました 大学の先輩は商売ができます 小西さんは貴方に映画のチケットをあげましたよね 私は討論を始めたいです ハンバーガーとコーラ 大きくなかった お爺さんは昔の記憶を忘れたがります 西洋料理 鶏 一眼レフィカメラ 布 金曜日 文房具 液晶テレビ 映画 タンス フクロウ フットボール フロント 栓抜きありますか 栓抜き 買い物カート 教授が、図を説明する 妹はコップを割った 蝉 十八 葉が落ちます フルート 雄鶏 虹 センチメートル 物理学 説明する 買い物カートはからです フットボール フロント 栓抜きありますか スーツケースに詰める 女性がももの太さを計っている 教授が、図を説明する 私は物理の基礎はしてリマス 鳴いている雄鶏 雄鶏 炒める アリクイ センチメートル コロサイが草原を歩いている 彼女は茶髪でえくぼがあります スーツケースに詰める 私は物理の基礎は知っています 緑色の蝉 ７.９センチメートル センチメートル コロサイが草原を歩いている 2019-9-18親の愛は有難い 出来る 美しい 肩 私は電車で通学しています 質問 彼女は秋に結婚します 入れる 質問のある方はどうぞ 広い 言う 知る 今年 喉が渇きました 四月に大学に入学しました 二つ 何か飲み物が欲しいな 私は昼のドラマを毎日見ます 彼女はとても綺麗だ クーラーはまだ直りません 要る これは医者のためのサイトです 入る お父さんは会社員です 決まる 赤い線を2本引いてください 帰ったら先ず手を洗いましょう 報告 自由 よく答えが分かりましたね 質問のある方はどうぞ 新製品に興味を示している 以上 より システム 銀行は3時まで開いています 住宅 導入 まあ今回は許してあげよう 目たつ 文章 強化 彼はその詩を用いて自分の気持ちを伝えた 企業 これからより一層努力します これは医者のためのサイトです 首相 解決 実現 関係 運動場で走ります 弟は父の性格が分かります 私は石原さんに防虫スプレーをあげました 先生はテストの解答が分かります 教室は静かではありません 遊びましょう 私は日本語が少しできます 短い鉛筆 導入 日本語が上手になる 私は王建民ほど有名ではありません 私は親友と遊びたいです ご飯を食べましょう 烏龍茶 ドラゴン 一眼レフカメラ 土曜日 車の乗客 期末レポート 下手 あっさて 明後日 日本 女性がももの太さを 女性がももの太さを測っている 関係 調味料 料理を炒める 説明する 茶髪 質問する フルート チームでフットボールをしています サツマイモは、焼いても揚げても美味しい サツマイモは、焼いても揚げても美味しい 女性がももの太さを計っている フルート 妹はコップを割った 2019-9-17運動場で走ります あの歌手は有名です 次 聞く 近い 彼は荷物を網棚に上げだ 大学に行ってもっと勉強したいです 立つ 会議は四時に終わります 肩 彼はまだ若いです 作る 私達のチームはその試合で負けた 楽しむ 私は毎朝6時に起きます 決まる 使う 立てる 父 彼女は茶色の靴を履いています 先 柿の木に実がたくさんなっています 金 駅 来る 今夜は月がとても綺麗です 悪い 土曜日 肩 有る この道を真っ直ぐ行くと駅です 知る 喉が渇きました そばにいてください 悲し お金はまだ十分あります 多く 語る 私たちは今、結婚資金を貯めています 交渉 資金 まま 私たちがその問題を調査しています 銀行は3時まで開いています それはどういう意味ですか 計画 女性 採用 このアンケート大学生が対象です 一緒に対策を考えましょう 実現 けれは新製品に興味を示している 銀行は3時まで開いています ここは父の土地です 土地 社会 私たちは二階に上がった 文章 首相 帰ったら先ず手を洗いましょう 強化 今日の新聞どこに置いた 彼はその詩を用いて自分の気持ちを伝えだ お金がほとんどありません 実現 開発 引き出しにハムスターが一匹います 歩きます 首相 私は日本語が大体できます 私は世界一周をしたかったです 彼は学校に来ませんでした 簡単な質問 佐々木さんはサラリーマンです 私は日本料理を作ることがよくできます 机の上に雑誌があります 帰ったら、先ず手を洗いましょう 強化 ご飯を食べましょう 私は頑張りたくありませんでした 石原さんは彼に防虫スプレーをもらいました 彼はその詩を用いて自分の気持ちを伝えた あの屋敷に幽霊がいましよ 浅い川 私は日本語がまあまあできます お爺さんは昔の記憶を忘れたがります 私のノートはどれですか 庭に松があります 小林さんは中国語を話すことができます 愛妻弁当 烏龍茶 乗客 ご飯を食べましょう 皿 烏龍茶 ポルトガル 布団 液晶テレビ 和食 引き出し 隣人 暇 腕時計 一眼レフカメラ 社員食堂 親戚 フライト 解答 スマホ 果物 羊 鶏 涼しい 社長 オフィス 学長 年齢 紙箱 親切 文房具 布 折りたたみ傘 トンネル 竹 カレンダー 上手 一眼レフカメラ 調味料 アリクイ 2019-9-16予約は要りません 八つ 娘は明日九つになります 今日の予定を教えてください 構成 この商品はよく売れている 彼はロボットの研究をしています 計画 命令 中心 重要 話 彼は新製品に興味を示している 一緒に対策を考えましょう 私たちがその問題を調査しています 十分 変化 対する なお 開発 動き 島の人口が年々増加しています この曲線がこの車の特徴です 交渉 その事件の犯人はまだ捕まっていない 彼は社員ですか 九份は賑やかです 私は日本語があまりできません うそ 川の岸に桜の木があります 先生は私に100点をくれました 私は妹と弟と実家に帰りました 計画 ドアをあげました 書店で小説を買う 狭い部屋 私は鉛筆で字を書く 彼は新製品に興味を示している あの服のほうが可愛いです 向日葵は草より綺麗です 台湾は日本より暑いです 一緒に対策を考えましょう ニュースて道の状況がわかります 私たちかその問題を調査しています 開発 交渉 国仲さんは彼にギターをもらいましたよう あの人は字を登ることができます 日本語を上手にする 夏は涼しくありません 猫の方が好きですジュースはコーヒーほど高くありません 深い湖 運動場で走ります 貴方は彼女に期末テストの解答をもらいましたようね インターネットで新幹線の時刻表が分かります 車の後ろに子猫と子犬がいます キマレポート 鶴 中学生 大きな竜巻 うし 乗客 布団 キャベツ 文房具 動物園 布 フライト 下手 虎 手 2019-9-15下手 液晶テレビ 今朝は早く家を出ました 起きる 切る 言う もつ この本はとても面白い 私たちは大きな声で歌いました 鳥が飛んでいます 工事は3月まで続きます 日記 まだ会いましょう 負けた いろ 入れた 送る 言う 入れる 兄 肉と魚とどちらが好きですか 漢字は中国から来ました 私は朝シャワーを浴びます 帰国することに決めました 今年はイタリヤに旅行したい 死ぬ 私が手伝いましょう 強い 万 彼はシートベルト締めた その子は指で十数えました 母 一杯 神 大人 時計を見たらちょうどさん時だった この部屋は寒いです 宿題は自分でやりなさい 彼は時々遅刻します 妻 店員は若い女の人でした この道を真っ直ぐ行くと駅です帰国することに決めました 他に方法がありません 十日後に帰ります ご主人 彼は昼過ぎに来ます 前売券は窓口で販売しています 彼は食品工場で働いています 加える トラブルがやっと解決した 対する 彼かクラスの代表だ 相手 一般 この段階では決断すろのはまだ早いです ポルトガル コンピューター 私はテレビをあまり見ません ほぼ 集める その計算は間違っている 島の人口は年々増加しています 写真はいい思い手になります 関する 引越しを業者に頼んだ 生まれる 国会が再開した 種類 動き 彼は就職試験を受けだ 消える 我が社の経営はうまく行っています これは重要な書類です 病院 彼は非常に高い技術を持っている 音楽は彼の得意な分野です 内容 ポルトガル 状態 システムの構成を変えてみました ここは静かな住宅地だ 住宅 提供 彼は選挙に出るつもりだ 島の人口は年々増加しています 株 それはどういう意味でスカ いずれ この段階です決断するのはまだ早いです 今回 彼女は幸せにするベッドの下にゴキブリがいます 静かな教室 動き 床に蟻がいます 浅い川 2019-9-14社員食堂 見せる 帰る 私の部屋は狭いです こう 見つける 負ける 今朝は早く家を出ました 待つ 疲れました 起こす 生きる 来月の一日は空いていました 社員食堂 わかった人は手を上げてください 来る 不味い 彼女は足が太い 他に方法がありません 九日に荷物が届きます 私の祖母は100歳です 悲し 五日 答が違います 教科書閉じてください 千円貸してください いる 風邪 腰 細い 彼は私の方見ました 方針 完成 この道をまっすぐ行くと駅です 他に方法がありません 国内 会長 制度 強化 この温泉はただです 今後ともよろしくお願いします 仕事がほぼ終わりました 生産 研究 受ける 部分 構成 外国 事務的な処理に1週間かかります 多く 叔母は小さな会社の社長です ガソリンの価格がどんどん上がっている 影響 消える ここは一方通行です 貴方の意見が聞きたいです 前売券は窓口で販売しています フランスの大統領は誰ですか 料理が沢山残りました 存在 評価 全体の80%が完成しました 管理 輸入 トラブルがやっと解決した 強調 彼は私にノートパソコンをくれました ビザを買いました、パスタも買いました 彼女はボーリングができます 佐々木さんはサラリーマンです 役所の人はお婆ちゃんに綺麗なカレンダーをくれました 石原さんは彼に防虫スプレーをもらいました 前売券は窓口で販売しています 教室は静かではありません 私は日本語があまりできません 日本語が上手になる 彼は学校に来ませんでした母はペットと海外旅行しました あの屋敷幽霊がいますよ トラブルがやっと解決した 私のノートはどれですか 夏は涼しかったです 私はもっと頑張りたいです 私は世界一周をしたかったです 犬と猫と兎、どれが好きですか うそ 長い傘 引き出しにハムスターが一匹います 先生は私に１００点をくれました ストップウォッチ 期末レポート 猿 緑茶 文房具 布 キャベツ 隣人 書店 皿 乗客 そば 餌 レンタサイクル 蜘蛛 車の乗客 うそ 解答 年齢 ペットボトル 原稿を改訂する 嫌い ソファ 自転車 一眼レフカメラ 期末レポート 雑誌 文房具 布 キャベツ 大人 彼は行ったり来たりして、とても焦っています 隣人 皿 乗客 年齢 うそ 暇 下手 博物館 カレーライス 海 故郷 一眼レフカメラ マイカー 消しゴム 香水 レタス 牛 液晶テレビ 2019-9-13引き出しにハムスターが一匹います 今年は雨が少ないです 学校は8時半に始まります 彼女からプレゼントをもらいました もう寝よう 祖父が病気になった 弱い 約束を忘れないでください 数 続きます 使う あげる 仕事のあと映画を見た 彼は毎晩3キロ走っています 授業 去年 悲し お店はもう閉まっていました 10日後に帰ります 彼女は眠いようです 男の人が私達に話しかけだ 私は好み性に良く来ます 三つ 夫の服をハンガーにかれた 後ろ向いて 米 来る 私は腕時計を四つ持っています 日本人はお米が大好きです 彼に会えて嬉しかった 悲し 休む いる 3日 時の経つのは早い 酸っぱい 一方 私の両親は昭和生まれです 選挙 部長除く全員がと土曜日も働いた 会談の内容は発表されました 対立 発生 輸入 遠くに彼女の姿が見えた 事件 うんどうかいはくじに開始です 来る これからより一層努力します 建設 強化 病院はどこですか 競争 規模 いる 開発 予定 原因 工場 トラブルがやっと解決した 電話 住宅 彼女は同じ間違いを繰り返した 経済 私は討論を始めたいです 鉛筆は短くありません 強化 カレーライスとオムライス、どちらが美味しですか 石原さんは彼に防虫スプレーをもらいました 私は父と食事をしました 彼は学校に来ませんでした ドアを開ける 皆は運動会の予定が分かります 楽しい一日 彼女は幸せにする 貴方は小西さんに映画のチケットをもらいましたよね トラブルがやっと解決した 料理を美味しいくする 私は学生です その子は親友と遊びただります 私は貴方にデジタルカメラをもらいました 石原さんは彼に防虫スプレーをもらいました 私は彼に使い捨ての箸をあげました 彼は学校に来ませんでした 私は日本語があまりできません 川の岸に桜の木があります 傘を長くありません 彼女は私に新し手帳をくれました 部屋で食べます 私は王建民ほど有名ではありません 私は学業を続きたいです 先生は私に100点をくれました 弟は父の性格がわかります 私は鉛筆で字を書く 彼の父は彼に新し腕時計をもらいました 私にデジタルカメラを 私は日本語があまりできません 先生は私に１００点をくれました 私は親友と遊びたいです このリングをください お爺さんは昔の記憶を忘れただります 楓 机 ロッキングチェア 社員食堂 森 夜市 予備校生 生まれる 中学生 レストラン 着物 紅茶 部長 ペット 課長 校長 宝石 2019-9-12おじいさんは昔の記憶を忘れたがります 九份は賑やかです 約束を忘れないでください 仕事 見る 胸 肉と魚とどちらが好きですか 忘れす 冬 私はワインが好きです 誰 私は去年フランスへ行った 座る 乗る 帰る 授業 20日 鼻 時の経つのははやい 喉が渇きました 強い 今週 お願い 閉める 柿木に実が沢山なっています 先月の7日に孫が生まれました 多分 太い お先にどうぞ 約束を忘れないでください 国は国語教育を強化しています 彼は何年も地震の研究をしている 授業 国内 あの人たちは皆同じ方向見ている お金はまだ十分あります 体重がかなり減りました 経済 私たちは二階に上がった 変わる 以上 のちに 構造 建設 備える 交渉 より 今後ともよろしくお願いします 良く答えが分かりましたね 私は四つの会社に投資しています 目たつ 文章 方法 昭和 普及 それは最近話題の本ですね 問題が一つあります 怪我はもう治るましたか 住宅 用いる 販売 与える 声 皆私たちに期待しています 検討 生活 商品 ただです 庭の中に松があります 簡単な質問 ドアを開ける 佐々木さんはサラリーマンです 深い湖 川の岸に桜の木があります 私は世界一周をしたかったです 学生ではない 日本語が上手になる ニュースで道の状況がわかります 夏は涼しいです 国仲さんは貴方にギターをもらいましたよね 住宅 床に蟻がいます 私は学業続けたいです 私のノートはどれですか この服とあの服、どちらが可愛いですか 運動場で走ります 貴方にプレゼントをあげました 貴方は教師ではありません ドアを開ける 回 期末テストは大変でした 日本語を上手にすろ 私は弟と妹と実家に帰りました ペットを飼いましょうか キマワリは草より綺麗です カバンに香水があります あの屋敷に幽霊がいますよ 九份は賑やかではありません 引き出しにハムスターが一匹います 飲み物を買いません 学食の料理は不味いです、このレストランの料理も不味いでしょ 教室は静かではありません これはなんですか あの人は木を登ることがでします 大学の先輩は商売ができます 本棚に小説と雑誌があります 2019-9-11私は朝シャワーを浴びます 飛行機 春 引く 見つける 彼は数学を教えています 言葉 宿題はまだ終わっていません いつ かく 一緒に たつ 見つかる 口 私はパンよりご飯が好きだ 宿題は自分でやりなさい 私は夏が大好き 野球は九人で人チームです 喋る 先月の7日に孫が生まれました 側 強い 6日前日本に帰ってきました 階段 変化 国会 今後ともよろしくお願いします 報告 競争 生まれる 販売 関する 国内 行う 命令 ここは静かな住宅地だ 語る 一般 導入 パソコン システムの構成を変えてみました 先月の7日に孫が生まれました 強い 東京は日本一大きな都市です 今後ともよろしくお願いします 資金 ガソリンの価格がどんどん上がっている 計算 消える 理由 いるに餌をやった 土地 株 彼はパーティー会場を提供してくれました 決定 傘は長くありません 深い湖 私は頑張りたくありません あのバカは2本の鉛筆を箸にして、ご飯を食べる 母はペットと海外旅行しました お爺さんは昔の記憶を忘れたがります テレビをつけました 国仲さんは貴方にギターをもらいましたよ これは私のコンピューターです 父は台湾料理を作ることができます 私は鉛筆で字を書く 役所の人はお婆ちゃんに綺麗なカレンダーをくれました 先生はテストの解答がわかります 刺身をください プールで泳ぎます 深い湖 私は日本語が大体できます 庭の松は高くありません 九份は賑やかでわありません 2019-9-10あの人は木の登ることができます 日本語が上手になる 教室は静かではありません 彼女を幸せにする 川の岸に桜の木があります あの屋敷に幽霊がいますよう 置く 彼は荷物を網棚に上げた 使う 私たちのチームはその試合で負けた 肉と魚とどちらが好きですか 親の愛入り難い 午前 どれ 大学に行って、もっと勉強したいです 次 彼は郵便局を探していました 取る 消す 軽い 飛ぶ 掛ける 分からない場合は私に聞いてください 私が手伝いましょう 宿題は自分でやりなさい 九日に荷物が届きます クーラーはまだ直りません あの屋敷に幽霊がいますよう 載せる 娘は明日九つになります 晴れる 曇る 悪い 終わり 九日 四月に大学に入学したした 五日 音楽は彼の得意な分野です 都市 昨年 事務的な処理に1週間かかります システムの構成を変えてみました まま 彼は選挙に出るつもりだ それはどういう意味ですか 消える 宿題は自分でやりなさい 彼は食品工場で働いています 参加 女性 部分 彼は就職試験を受けた 彼がクラスの代表だ 加える 結果 彼は行政を改革したいと思っている ガソリンの価格がどんどん上がっている 一般 内容 力 可能 対する 十分 文章 ここは一方通行です システムの構成を変えてみました 佐々木さんは大学生です、私も大学生です 彼女はボーリングができます 消える 床に蟻がいます 私は学生です 楽しい一日 私は鉛筆で字を書く（書きます） 役所の人はお婆ちゃんに綺麗なカレンダーをくれました 私のノートはどれですか ガソリンの価格がどんどん上がっている ペットを飼いましょうう 一般 佐々木さんはサラリーマンです あの服のほうが可愛です 私は世界一周をしたかったです 庭の松は高いです 先生は討論を始めたがります 床に蟻がいます 私にデジタルカメラをくれました アフリカにきりんがいます 私は鉛筆で字を書く 弟は家に帰りました お釣りをください 私は書いた原稿本にする 小林さんは中国語を話すことができます 弟は父の性格がわかります 私のノートはどれですか 母は日本料理ができます 私は彼に使い捨ての箸をあげました","link":"/zh-tw/japanesePractice/"},{"title":"利用 PayPal 付款標準版 (PayPal Payment Standard) 以及 PayPal 即時付款通知 (PayPal IPN) 方式結帳付款","text":"前言有嘗試串接過 PayPal 的人都知道， PayPal 提供了好幾種方式供使用者串接使用。本篇記錄了： 如何使用 PayPal 付款標準版 (PayPal Payment Standard) 來付款結帳。 如用使用 PayPal 即時付款通知 (PayPal IPN) 來驗證付款結果。 如何在 PayPal 付款標準版 (PayPal Payment Standard) 中，自定義多個商品以及每個商品的明細，包含名稱、單價、數量。 在本文章中，我使用的是PHP的框架，Laravel因為此篇文章主要紀錄我這個專案大概的一個流程，雖說主題是金流部分，但難免會記錄到一些跟金流無關的部分。可以直接從’建金流訂單’的部分開始看即可。 驗證此節是整個流程的一個程序，跟金流較無關係，可以跳過。$toBeValidatedCondition = [ 'order_id' =&gt; 'required|array',];$failMessage = Helpers::validation($toBeValidatedCondition, $request);if ($failMessage) return Helpers::result(false, $failMessage, 400);if (!Helpers::checkIfIDExists($request, new Order(), 'order_id')) return Helpers::result(false, 'The orders doesn\\'t exist', 400);if (!Helpers::checkIfBelongToTheUser($request, new Order(), 'order_id')) return Helpers::result(false, 'The order doesn\\'t belong to this user', 400);$orders = Order::whereIn('id', $request-&gt;order_id)-&gt;get();if (Order::checkIfOrderPaid($orders)) return Helpers::result(false, 'The order has already been paid', 400);if (Order::checkIfOrderExpired($orders)) return Helpers::result(false, 'The order has expired', 400);if ($recipient-&gt;user_id !== User::getUserID($request)) return Helpers::result(false, 'The recipient doesn\\'t belong to the user', 400); 收集必要資訊因為我在做這個專案時，前端的時間比較吃緊一點，所以後端這邊決定除必要資訊之外，後端這邊將所有資訊搞定，盡量讓前端帶最少的資料，做最多的事。$toBeSavedInfo = [ 'total_amount' =&gt; Order::getTotalAmountForPayments($orders), 'orders_name' =&gt; Order::getOrdersNameForPayments($orders), 'merchant_trade_no' =&gt; time() . Helpers::createAUniqueNumber(), 'merchant_trade_date' =&gt; date('Y/m/d H:i:s'), 'trade_desc' =&gt; 'BuyBuyGo', 'quantity' =&gt; 1, 'user_id' =&gt; User::getUserID($request), 'payment_service' =&gt; $thirdPartyPaymentService, 'expiry_time' =&gt; (new Carbon())-&gt;now()-&gt;addDay(1)-&gt;toDateTimeString(), 'orders' =&gt; $orders, 'mc_currency' =&gt; 'TWD', 'ClintBackURL' =&gt; $request-&gt;ClintBackURL]; 分流點因為這個專案接了兩家金流，所以會需要一個地方來判定金流服務商switch ($thirdPartyPaymentService-&gt;id)&#123; case 1: $error = (new AllPay)-&gt;make($toBeSavedInfo, $request, $recipient); if($error) return Helpers::result(false, $error,400); return (new AllPay())-&gt;send($toBeSavedInfo, $request); break; case 2: $error = (new PayPal)-&gt;make($toBeSavedInfo, $request, $recipient); if($error) return Helpers::result(false, $error, 400); $url = (new PayPal)-&gt;send($toBeSavedInfo, $request, $recipient); return Helpers::result(true, $url, 200); break;&#125; 建金流訂單在使用者按下付款之後，一張臨時的金流訂單會被建立。此訂單只介於你與你與 PayPal 之間，使用者不會接觸到這張訂單。因為會一次性的寫入兩張 table ，所以這邊會特別使用 Laravel 的 Transaction 來將資料處理，如果對 Laravel Transaction 有興趣的，可以參考我在另外一篇文章中，有一小段針對 Laravel Transaction 的解說public function make(Array $toBeSavedInfo, Request $request, Recipient $recipient)&#123; DB::beginTransaction(); try &#123; $PayPal = new self(); $PayPal-&gt;user_id = $toBeSavedInfo['user_id']; $PayPal-&gt;payment_service_id = $toBeSavedInfo['payment_service']-&gt;id; $PayPal-&gt;expiry_time = $toBeSavedInfo['expiry_time']; $PayPal-&gt;merchant_trade_no = $toBeSavedInfo['merchant_trade_no']; $PayPal-&gt;total_amount = $toBeSavedInfo['total_amount']; $PayPal-&gt;trade_desc = $toBeSavedInfo['trade_desc']; $PayPal-&gt;item_name = $toBeSavedInfo['orders_name']; $PayPal-&gt;mc_currency = $toBeSavedInfo['mc_currency']; $PayPal-&gt;recipient_id = $recipient-&gt;id; $PayPal-&gt;save(); foreach ($toBeSavedInfo['orders'] as $order) &#123; $order_relations = new OrderRelations(); $order_relations-&gt;payment_service_id = $toBeSavedInfo['payment_service']-&gt;id; $order_relations-&gt;payment_service_order_id = $PayPal-&gt;id; $order_relations-&gt;order_id = $order-&gt;id; $order_relations-&gt;save(); &#125; &#125; catch (Exception $e) &#123; DB::rollBack(); return 'something went wrong with DB'; &#125; DB::commit();&#125; 建立提交付款申請的 URL這邊會用到很多 PayPal 付款標準版 (PayPal Payment Standard) 的 變量 (variable)，各種變量的使用可以參考這篇文章另外，因為 Ray 在做這個案子時，前端的時間上比較吃緊，所以 Ray 將所以非必要的資料全部由後端這邊處理，前端只帶入先前已建立的使用者訂單，後端從資料庫內調出所有的資料並提供給 PayPal public function send(Array $toBeSavedInfo, Request $request, Recipient $recipient)&#123; // 如果你是使用測試環境的話，請選 true $enableSandbox = env('PAYPAL_SANDBOX_ENABLESANDBOX'); $paypalUrl = $enableSandbox ? 'https://www.sandbox.paypal.com/cgi-bin/webscr' : 'https://www.paypal.com/cgi-bin/webscr'; $data = []; // 設定PayPal 帳號, 請先到以下網址申請測試者帳號，商家跟一般用戶都要申請，這邊填入的是商家的帳號，所以買家付款後，金額會直接匯入這個帳號 // https://developer.paypal.com/developer/accounts/ // Set the PayPal account $data['business'] = env('PAYPAL_SANDBOX_MAIL'); // 此數值為前端帶入，使用者完成付款後，將可以經由此URL返回原本的服務中 // Set the PayPal return addresses, after the transaction is completed, the user could be back via this URL. $data['return'] = $toBeSavedInfo['ClintBackURL']; // 在付款過程中，使用者可以選擇取消，並且經由此URL回到我們的服務 // During the transaction process on PayPal's site, the user could cancel the transaction and go back via this URL. $data['cancel_return'] = env('PAYPAL_SANDBOX_CANCEL_URL'); // 在使用者完成交易之後， PayPal 會發一封 IPN 到我們在這邊指定的 listener ，然後我們可以依據此 IPN 來判定付款是否成功，然後做相對應的事 // After the transaction is completed, PayPal will send IPN message to this URL. $data['notify_url'] = env('PAYPAL_SANDBOX_NOFITY_URL'); // 這邊我們指定了每一樣商品的明細，包含單價，名稱，數量。 這邊要將這些明細顯示在 PayPal 的付款頁面上 // Set the details about the products being purchased, including the price for every individual // and currency so that these aren't overridden by the form data. $i = 1; foreach ($toBeSavedInfo['orders'] as $order) &#123; $data[\"item_name_$i\"] = $order-&gt;item_name; $data[\"item_number_$i\"] = $order-&gt;quantity; $data[\"amount_$i\"] = $order-&gt;total_amount; $i++; &#125; // 這邊指定了幣別，細節部分可以參考官網資料 // https://developer.paypal.com/docs/classic/api/currency_codes/ $data['currency_code'] = $toBeSavedInfo['mc_currency']; // 這邊我們可以帶一個任何我們想要的值過去給 PayPal ，然後 PayPal 會再回傳 IPN 時一併帶回來，以本篇例子，我帶入的是我金流訂單的編號 // Add any custom fields for the query string. $data['custom'] = $toBeSavedInfo['merchant_trade_no']; // 這邊我指定了收件人，否則 PayPal 會顯示測試帳號上的假的收件人資料。 在這邊設定後，我們可以在 PayPal 上顯示任何我們想要的收件人資料 // Add recipient's information $data['address_override'] = 1; $data['country'] = $recipient-&gt;country_code; $data['city'] = $recipient-&gt;city; $data['address1'] = $recipient-&gt;others; $data['zip'] = $recipient-&gt;postcode; $data['first_name'] = $recipient-&gt;name; // 這邊的設定允許了我們上傳多個商品到 PayPal 的購物車裡面，所以可以分成多個商品並且一次性結帳。 // This setting allow to add multiple items with IPN method $data['upload'] = '1'; $data['cmd'] = \"_cart\"; // Add charset $data['charset'] = 'utf-8'; // 產生 query string // Build the query string from the data. $queryString = http_build_query($data); // 產生最終的要在 PayPal 建立付款請求的 URL，我們只需要將此URL回傳給前端，前端就可以直接利用這個 URL 將使用者導向付款頁面 // Build the URL to PayPal $url = $paypalUrl . '?' . $queryString; return $url; &#125; 使用者付款 使用者經由我們上面產出的 URL 到達 PayPal 付款頁面，這邊請先去申請測試帳號 到達付款頁面 這邊可以看到我們指定的商品明細，以及金額，選擇繼續 這邊可以看到我們指定的住址 交易成功，這邊可以看到全部的細節 驗證付款狀態使用者完成付款程序後， PayPal 會發一封 IPN 給我們，有關於 IPN 的規格可以參考官方文件 首先，我們先安裝 PayPal 的 官方 IPN CODE SAMPLES git clone https://github.com/paypal/ipn-code-samples 進到 php 的資料夾內 cd ipn-code-samples/php 接下來，我們複製PaypalIPN.php到我們的專案內， Ray 是把它放到 App 底下。 接著，在把 ipn-code-samples 裡頭的 cert 整個資料夾也放到 App 底下，大概如下圖 再來，我們到composer.json檔案中，在autoload-dev底下的files加入PaypalIPN.php這個檔案，如果沒有files的可能要自己建一個 \"autoload-dev\": &#123; \"psr-4\": &#123; \"Tests\\\\\": \"tests/\" &#125;, \"files\": [ \"app/Helpers.php\", \"app/AllPay.Payment.Integration.php\", \"app/PaypalIPN.php\" ]&#125;, 重新執行composer，在terminal的專案資料夾底下，執行 composer install 萬事俱備，只欠東風！ 接下來讓我們將example_usage_advanced.php的檔案裡頭的內容複製到你想要的地方，可以是你的Controller，也可以是你的某個class下面的一個function，如下：下面的 code 有點長，可以不必全看，除了我中文有特別解釋的地方之外，大概跟原本的sample一樣。 public function listen(Request $request) &#123; // 因為官方sample是去接 $_POST，所以這邊直接將Laravel的輸入轉成 POST ，想要自己改的人也可以哦 $_POST = $request-&gt;post(); // 這個資訊代表是否該交易已付款 $payment_status = $_POST['payment_status']; // 還記得我們之前帶過去的金流訂單號碼嗎？ $merchant_trade_no = $_POST['custom']; // 很重要，等等會用到 $txn_id = $_POST['txn_id']; $txn_type = $_POST['txn_type']; // 付款時間 $payment_date = Carbon::parse($_POST['payment_date'])-&gt;setTimezone('UTC'); // 總付款金額 $mc_gross = $_POST['mc_gross']; // 幣別 $mc_currency = $_POST['mc_currency']; $enable_sandbox = env('PAYPAL_SANDBOX_ENABLESANDBOX');// 這邊表示收款人的email，如果IPN裡頭的收款人不在這個清單裡面的話，驗證將會失敗// Use this to specify all of the email addresses that you have attached to paypal: $my_email_addresses = array(env('PAYPAL_SANDBOX_MAIL'));// Set this to true to send a confirmation email: $send_confirmation_email = env('PAYPAL_SANDBOX_SEND_CONFIRMATION_EMAIL'); $confirmation_email_address = \"buybuybuygogo@gmail.com\"; $from_email_address = \"test@gmail.com\";// 選true的話，會自動記log// Set this to true to save a log file: $save_log_file = env('PAYPAL_SANDBOX_SAVE_LOG_FILE'); $log_file_dir = storage_path() . \"/app/payment_logs\";// Here is some information on how to configure sendmail:// http://php.net/manual/en/function.mail.php#118210// 這邊就是主要驗證的function $ipn = new PaypalIPN(); if ($enable_sandbox) &#123; $ipn-&gt;useSandbox(); &#125; $verified = $ipn-&gt;verifyIPN(); $data_text = \"\"; foreach ($_POST as $key =&gt; $value) &#123; $data_text .= $key . \" = \" . $value . \"\\r\\n\"; &#125; $test_text = \"\"; if ($_POST[\"test_ipn\"] == 1) &#123; $test_text = \"Test \"; &#125;// 上面提到的mail，就在這邊確認// Check the receiver email to see if it matches your list of paypal email addresses $receiver_email_found = false; foreach ($my_email_addresses as $a) &#123; if (strtolower($_POST[\"receiver_email\"]) == strtolower($a)) &#123; $receiver_email_found = true; break; &#125; &#125; date_default_timezone_set(\"America/Los_Angeles\"); list($year, $month, $day, $hour, $minute, $second, $timezone) = explode(\":\", date(\"Y:m:d:H:i:s:T\")); $date = $year . \"-\" . $month . \"-\" . $day; $timestamp = $date . \" \" . $hour . \":\" . $minute . \":\" . $second . \" \" . $timezone; $dated_log_file_dir = $log_file_dir . \"/\" . $year . \"/\" . $month; $paypal_ipn_status = \"VERIFICATION FAILED\"; if ($verified) &#123; // 進到下面的if之後，表示已經驗證成功了，我們可以在驗證成功之後做一些該做的事 $paypal_ipn_status = \"RECEIVER EMAIL MISMATCH\"; if ($receiver_email_found) &#123; $paypal_ipn_status = \"Completed Successfully\"; $PayPal = (new PayPal())-&gt;where('merchant_trade_no', $merchant_trade_no)-&gt;first(); // 這邊檢查了幾項，大概如下： // 1. 檢查txn_id，為了避免這筆交易之前就已經有處理過。所以資料庫裡面如果已經有這個txn_id，將不予理會 // 2. 檢查mc_gross，總金額必須與我們金流訂單裡頭的金額相等 // 3. 檢查幣別，幣別必須與我們金流訂單裡頭的幣別相同 // 4. 檢查payment_status，該交易必需已經付款完成 if ((!PayPal::checkIfTxnIdExists($txn_id)) &amp;&amp; ($mc_gross == $PayPal-&gt;total_amount) &amp;&amp; ($mc_currency == $PayPal-&gt;mc_currency) &amp;&amp; ($payment_status == 'Completed')) &#123; // 將該txd_id新增到該金流訂單內，並更新該訂單數據，主要可被識別為已結單。 $PayPal-&gt;update(['txn_id' =&gt; $txn_id, 'txn_type' =&gt; $txn_type, 'payment_date' =&gt; $payment_date, 'status' =&gt; 1, 'expiry_time' =&gt; null]); $recipient = $PayPal-&gt;recipient; $orderRelations = $PayPal-&gt;orderRelations-&gt;where('payment_service_id', 2); // 更新完金流訂單後，根據該金流訂單取得相對應的使用者訂單，並更新使用者訂單狀態。 Order::updateStatus($orderRelations, $recipient); // 付款完成，寄mail通知使用者 Helpers::mailWhenPaid($PayPal, $orderRelations); &#125; &#125; &#125; elseif ($enable_sandbox) &#123; if ($_POST[\"test_ipn\"] != 1) &#123; $paypal_ipn_status = \"RECEIVED FROM LIVE WHILE SANDBOXED\"; &#125; &#125; elseif ($_POST[\"test_ipn\"] == 1) &#123; $paypal_ipn_status = \"RECEIVED FROM SANDBOX WHILE LIVE\"; &#125; if ($save_log_file) &#123; // Create log file directory if (!is_dir($dated_log_file_dir)) &#123; if (!file_exists($dated_log_file_dir)) &#123; mkdir($dated_log_file_dir, 0777, true); if (!is_dir($dated_log_file_dir)) &#123; $save_log_file = false; &#125; &#125; else &#123; $save_log_file = false; &#125; &#125; // Restrict web access to files in the log file directory $htaccess_body = \"RewriteEngine On\" . \"\\r\\n\" . \"RewriteRule .* - [L,R=404]\"; if ($save_log_file &amp;&amp; (!is_file($log_file_dir . \"/.htaccess\") || file_get_contents($log_file_dir . \"/.htaccess\") !== $htaccess_body)) &#123; if (!is_dir($log_file_dir . \"/.htaccess\")) &#123; file_put_contents($log_file_dir . \"/.htaccess\", $htaccess_body); if (!is_file($log_file_dir . \"/.htaccess\") || file_get_contents($log_file_dir . \"/.htaccess\") !== $htaccess_body) &#123; $save_log_file = false; &#125; &#125; else &#123; $save_log_file = false; &#125; &#125; if ($save_log_file) &#123; // Save data to text file file_put_contents($dated_log_file_dir . \"/\" . $test_text . \"paypal_ipn_\" . $date . \".txt\", \"paypal_ipn_status = \" . $paypal_ipn_status . \"\\r\\n\" . \"paypal_ipn_date = \" . $timestamp . \"\\r\\n\" . $data_text . \"\\r\\n\", FILE_APPEND); &#125; &#125; if ($send_confirmation_email) &#123; // Send confirmation email mail($confirmation_email_address, $test_text . \"PayPal IPN : \" . $paypal_ipn_status, \"paypal_ipn_status = \" . $paypal_ipn_status . \"\\r\\n\" . \"paypal_ipn_date = \" . $timestamp . \"\\r\\n\" . $data_text, \"From: \" . $from_email_address); &#125;// Reply with an empty 200 response to indicate to paypal the IPN was received correctly header(\"HTTP/1.1 200 OK\"); &#125; 結語以上大概就是整個利用 PayPal 付款標準版 (Payment Standard) 來付款 ，然後經由 IPN 驗證的流程，流程大概如下： 買家完成付款 PayPal 發送 IPN Message 到 Listener Listener 回饋 HTTP 200 Response 到 PayPal Listener 將剛剛收到的 IPN Message 原封不動的回傳到 PayPal PayPal 驗證無誤後，回傳 Verified ，若驗證失敗，回傳 Invalid","link":"/zh-tw/implementATransactionViaPayPalIPN/"},{"title":"利用 Let's Encrypt 來自動簽署並更新 SSL 憑證 (wildcard)","text":"前言本篇主要分享，如何利用 Let&#39;s Encrypt 的 cert bot 來自動簽署以及更新 SSL 憑證 (wildcard)什麼是 wildcard? 比方說你的域名是 example.com, 那一個 wildcard 的憑證將會適用於以下的網站:abc.example.comaaa.example.comwhatever.example.com 總之不管前面是什麼，都可以適用。要使用 Certbot 來取得 wildcard 的 certificate 需要安裝 DNS 提供商的插件，或者其他的手動插件，本篇文章採用 DNS 提供商為 Google 的情況 參考網頁官網 環境 Server: NginX OS: Ubuntu 18.04 DNS Provider: Google 確認你的 DNS Provider 是否支援看你的 DNS Provider 有無被 Certbot 支援, 看這份清單 沒支援如果你的 DNS provider 沒有被支援，在這停下。 參考這份文件，使用手動插件運行 Certbot 有支援如果你的 DNS provider 有支援，順著以下的步驟繼續 SSH 到你的 ServerSSH 到你的 server, 該使用者須擁有 sudo 權限 加入 Certbot PPA你將需要把 Certbot PPA 加入到 repository 清單，執行以下指令來加入：sudo apt-get update; sudo apt-get install software-properties-common; sudo add-apt-repository universe; sudo add-apt-repository ppa:certbot/certbot; sudo apt-get update 安裝 Certbot執行以下指令來安裝 Certbotsudo apt-get install certbot python-certbot-nginx 安裝正確的 DNS 插件執行以下指令以安裝插件，本教程中使用的 DNS 提供商為 Google 範例sudo apt-get install python3-certbot-dns-&lt;PLUGIN&gt; 本教程情境sudo apt-get install python3-certbot-dns-google 設定 credentials你將需要設定 DNS credentials。依循各 DNS 提供商文件中的 “Credentials” 區塊來建立或存取適當的 credential 設定檔點擊這份文件 來尋找指定 DNS 提供商的 credential 教學。 設定 Google Credentials需要哪些權限？由 Certbot 的 Google 文件, 可以得知 Certbot 需要的權限如下：dns.changes.createdns.changes.getdns.managedZones.listdns.resourceRecordSets.createdns.resourceRecordSets.deletedns.resourceRecordSets.listdns.resourceRecordSets.update 建立 role從 Navigation menu &gt; IAM &amp; admin &gt; role , 進到 role 頁面後點擊 CRETE ROLE, 然後點擊 ADD PERMISSION 按鈕。 在 filter 欄位中，逐一輸入上面的權限來將需求的權限加入 全部都加入之後，請在 title 以及其他欄位依照個人需求填入名稱，若覺得預設挺好的，也可以保留預設即可。 選擇 CREATE, 共有七項。 建立 Service Account 從左側選單點擊 Navigation menu &gt; IAM &amp; admin &gt; Service accounts , 進到 Service accounts 頁面後，點擊上方 CREATE SERVICE ACCOUNT 按鈕。 依照個人喜好輸入 Service account name 以及 Service account description 選擇 role, 想當然爾，自然是輸入我們上一步建立的 role 啦！ 然後點擊 CONTINUE 最後是建立一把 json key, 點擊 CREATE KEY 最後點擊 DONE, 結束這一回合 選擇你想要怎麼樣執行 Certbot, 是單純拿到 certificate 或要安裝這邊官網有提供兩種方式，一種是全自動安裝，不只獲得憑證還幫你安裝，另外一種是只有安裝。不過我看過 Google 的插件之後，發現好像只有獲得憑證的選項，因此下面的指令會是單純獲得憑證的方式，若有人知道怎麼同時安裝的，也可以提供哦！ 下面指令為 Google 版的，其他版的請勿使用哦！ certbot certonly --dns-google --dns-google-credentials yourCredentailLocation -d *.example.com. -i nginx 上面的 yourCredentailLocation 為上面我的建立的 Google Service Account JSON Key, 假如我放在 /home/ray/serviceAccountKey.json, 那上面的指令將會如下： certbot certonly --dns-google --dns-google-credentials /home/ray/serviceAccountKey.json -d *.example.com. -i nginx 拿到憑證之後，我們可以設定一個測試站來看 wildcard 憑證是否有效 建立測試 site 檔案vim example.com server &#123; server_name abc.example.com; listen 80; # managed by Certbot listen 443 ssl; # managed by Certbot ssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem;&#125; 憑證的位置我們在上一步成功拿到憑證之後，輸出訊息會顯示憑證放置位置。 我們也可以把它放到任何我們想要的地方。 測試 syntax nginx -t 重啟 Nginx systemctl restart nginx.service 到域名服務商去新增 abc.example.com 這筆 A record, 然後 IP 為你 Server 的位置 給 DNS 一些時間來生效 在瀏覽器輸入 https://abc.example.com 來拜訪測試站，若成功的話可以看到 Welcome to nginx! 測試自動更新Certbot 套件附有 cron job 或是 systemd timer，可以在憑證過期前自動的更新你的憑證。 你將不需要再執行 Certbot, 除非你更動了你的設定。 你可以運行下面的指令來測試自動更新:sudo certbot renew --dry-run 自動更新 certbot 的指令安裝在以下位置：/etc/crontab//etc/cron.*/*systemctl list-timers 確認 Certbot 正確的設定我們的憑證拜訪你的網站，然後看左方鎖頭的圖案。如果你想看更多資訊，試試看這個網站故障排除請參考這份文件若需要更多客製化的設定，請參考這份文件若覺得 Certbot 不錯，也可以贊助","link":"/zh-tw/letsEncryptWildcard/"},{"title":"利用 Let's Encrypt 來自動簽署並更新 SSL 憑證","text":"前言本篇主要分享，如何利用 Let&#39;s Encrypt 的 cert bot 來自動簽署以及更新 SSL 憑證 參考網頁官網 環境 Server: NginX OS: Ubuntu 18.04DNS 設定先將 DNS 設定好, 建一個 A record, 將我們喜歡的 domain 指向我們的 IP 設定檔 這邊使用最簡單的設定, 反向代理 server 內的 9527 port, 若無反向代理需求，可以單純指向專案的 Document root 即可sudo vim /etc/nginx/sites-available/yourSiteName server &#123; listen 80; server_name yourDomainName; access_log /var/log/nginx/test_access_log; location / &#123; proxy_pass http://127.0.0.1:9527; &#125;&#125; 測試 syntax sudo nginx -t 啟用設定 sudo ln -s /etc/nginx/sites-available/yourSiteName /etc/nginx/sites-enabled/yourSiteName 設完之後，重啟 nginx sudo service nginx restart 測試設定設定好之後，如果我們 curl http://yourIPOrDomain/endpoint , 應該要可以存取服務 新增 cerbot PPA (Personal Package Archives)sudo apt-get update &amp;&amp; sudo apt-get install software-properties-common &amp;&amp; sudo add-apt-repository universe &amp;&amp; sudo add-apt-repository ppa:certbot/certbot 安裝 Let’s Encryptsudo apt-get install certbot python-certbot-nginx 運行 cerbot全自動模式如果你希望 cerbot 可以幫我們全自動完成設定，輸入sudo certbot --nginx 半自動模式如果你希望 cerbot 只幫我們拿到憑證，其他我們自己來的話，輸入sudo certbot certonly --nginx 測試自動更新到這裡，應該已經可以自動更新憑證了，輸入以下指令測試sudo certbot renew --dry-run cerbot 安裝在以下路徑之一: /etc/crontab/ /etc/cron.*/* systemctl list-timers 測試簽證是否成功測試網頁","link":"/zh-tw/letsencrypt/"},{"title":"如何將CSV檔，經由PHP導入MYSQL？","text":"大家好，我是Ray！我將跟大家分享如何使用PHP來將CSV檔案的內容導入MySQL資料庫。首先，一個CSV檔如下： 以下爲PHP腳本，請將csv的檔案跟腳本放在同一個資料夾內 &lt;?php// 連接資料庫$dbc = mysqli_connect('Your location', 'Your MySQL user_name', 'Your MySQL password', 'Your Database Name');// 設定編碼爲utf8mysqli_set_charset($dbc,\"utf8\");// 利用fopen功能讀取檔案$handle = fopen(\"The file name.csv\", \"r\");// 設定變數i，之後會用到$i=0;// 使用fgetcsv功能，配合while迴圈，可以拿到檔案內的每一行資料while (($data = fgetcsv($handle, 1000, ',')))&#123; //如圖片所示，第一行是行的名稱，我們不想要將這行導入資料庫，所以我們設定條件句， 當變數i爲0正是跑到第一行，進入條件句內，變數i變爲1，並且continue使迴圈將之後的code都跳掉， 直接回到迴圈的最上面在開始跑，此時變數i已經是1，所以將不會在進到條件句中。如此一來我們就完成我們的目標， 只跳掉第一行。 if($i == 0) &#123; $i++; continue; &#125; // 如csv的圖片所示，降雨量那一行中有出現非數字的NaN字串， // 但我們又想要將這一行的屬性設爲float或decimal方便之後若有需要用到計算。 // 要避免資料匯入出錯，我們必須將非數字的字串轉換爲數字， // 因此利用條件句，當$data array裏面的當三項爲NaN時，替換爲0 if($data[2] == 'NaN') &#123; $data[2] = 0; &#125; // 最後，將資料導入資料庫 $query = 'INSERT INTO rainfall (district, date, rainfall)VALUES (\"'.$data[0] . '\", \"' . $data[1] . '\", \"' . $data[2].'\")'; echo $query; $result = mysqli_query($dbc, $query); if ($result == false) &#123; echo 'Error description &lt;br/&gt;' . mysqli_error($dbc); &#125;&#125;?&gt; 最後，在終端機中執行該腳本，php -f 腳本名稱，完成！","link":"/zh-tw/importDataFromCSVIntoMySQLDatabaseViaPHP/"},{"title":"使用 Stackdriver 在 Kubernetes Engine 上做紀錄","text":"前言本篇主要是利用 Google 的 Qwiklab 平台學習的同時，做的一份學習筆記為避免翻譯誤解，專業術語在本篇將不會被翻譯，保留原文 概述Stackdriver Logging 可以讓你在所有的 GCP 資源，或是其他平台的資源做紀錄，然後針對紀錄以及指標做集中式的儲存。 紀錄被加總，並且可在提供的 Stackdriver Logging UI 內被檢視。 他們也可以被匯出到接收器來支援更多使用情境。 目前， Stackdriver Logging 支援匯出到下面的接收器: Cloud Storage Pub/Sub BigQuery 在這個教程，你將會部署一個簡單的 Kubernetes 應用，這個應用將轉發紀錄事件到 Stackdriver Logging 。 Terraform 一個強調基礎架構就是程式碼的工具， 可以使用配置檔來自動化部署，是雲端基礎架構的進化。 配置檔同時也會建立一個 Cloud Storage 儲存區，以及 BigQuery 資料組來接受被匯出的紀錄 本教程由 GKE Helmsman 的工程師所建立，為了讓你對 Stackdriver Logging 有更好地理解。 你可以在 Github 上檢視這個範例。 我們也鼓勵以及歡迎任何想對我們專案做出貢獻的開發者！ 架構Terraform 配置將會建立一個 Kubernetes Engine 叢集，這個叢集會產生可被 Stackdriver 處理的紀錄以及指標。 這個腳本也會同時建立紀錄的匯出接收器，有 CloudStorage, BigQuery, 以及 Cloud Pub/Sub。 這一切包含資料流，可參考下面的圖片 設定及要求 Qwiklabs setup在你按下 Start Lab 按鈕之前 詳讀所有的教學。Labs 是有時間限制的，而且你不可以停止時間倒數。倒數計時器在你按下 Start Lab 按鈕後開始倒數，上面顯示的時間為你還能使用 Cloud 資源的時間。 Quiklabs 的手把手環境，讓你可以在真實環境中來操作進行 Quiclabs 上提供的課程，而不是在一個模擬或是展示的環境。我們透過提供你一個全新的、暫時的帳號密碼，在計時器歸零之前，你可以用來登入並存取 Google Cloud Platform。 你需要什麼？ 要完成這個 lab ，你需要: 一個一般的網路瀏覽器（推薦 Chrome） 完成這個 lab 的時間 備註： 如果你已經有你自己的個人 GCP 帳號或專案，請不要使用在這一個 lab 現在你已經開始你的 lab, 你將會登入 Google Cloud Shell 主控台，然後開啟命令列工具 如何開始你的 lab ，然後登入 Console? 按下 Start Lab 按鈕。如果你需要付費，會有一個彈出視窗來讓你選擇付費的方式。在左方你會看到一個面板，上面有暫時的帳號密碼，你必須使用這些帳號密碼在此次 lab 複製 username , 然後點擊 Open Google Console。 Lab 會開啟另外一個視窗，顯示選擇帳號的頁面 tip: 開啟一個全新的視窗，然後跟原本的頁面並排 在選擇帳號頁面, 點擊 Use Another Account 登入頁面開啟，貼上之前複製的 username 以及 password ，然後貼上 重要：必須使用之前於 Connection Details 面板 取得的帳號密碼，不要使用你自己的 Qwiklabs 帳號密碼。 如果你有自己的 GCP 帳號，請不要用在這裡（避免產生費用） 點擊並通過接下來的頁面: 接受terms以及conditions 不要增加recovery optoins 或 two factor authentication (因為這只是一個臨時帳號) 不要註冊免費體驗 稍待一些時候， GCP 控制台將會在這個視窗開啟。 注意：按下左上方位於Google Cloud Platform 隔壁的 Navigation menu ，你可以瀏覽選單，裡面有一系列的 GCP 產品以及服務 啟動 Google Cloud ShellGoogle Cloud Shell 是載有開發工具的虛擬機器。它提供了5GB的 home 資料夾，並且運行在 Google Cloud 上。 Google Cloud Shell 讓你可以利用 command-line 存取 GCP 資源 在 GCP 控制台 ，右上的工具列，點擊 Open Cloud Shell 按鈕 在打開的對話框裡，按下 START CLOUD SHELL: 你可以立即按下 START CLOUD SHELL 當對話視窗打開。 連結並提供環境會需要一點時間。當你連結成功，這代表你已成功獲得授權，且此專案已被設為你的專案ID，例如： gcloud 是 Google Cloud Platform 的 command-line 工具，他已事先被安裝在 Cloud Shell 並且支援自動補齊 使用這個 command ,你可以列出有效帳戶名稱: gcloud auth list 輸出: Credentialed accounts: - &lt;myaccount&gt;@&lt;mydomain&gt;.com (active) 範例輸出: Credentialed accounts: - google1623327_student@qwiklabs.net 你可以使用以下 command 來列出專案 ID gcloud config list project 輸出： [core]project = &lt;project_ID&gt; 範例輸出： [core]project = qwiklabs-gcp-44776a13dea667a6 gcloud 的完整文件可以參閱 Google Cloud gcloud Overview Clone 範例clone 本教程需要的資源，執行以下指令git clone https://github.com/GoogleCloudPlatform/gke-logging-sinks-demo 進到專案內cd gke-logging-sinks-demo 設定你的 region 和 zone某些 Compute Engine 的資源位於 regions 以及 zones 。 region 是一個特定的地理位置，你只能在這個執行 region 運行你的資源, 每一個 region 有一個或多個 zone 如果你想要了解更多有關 region 以及 zone, 可以參考官方文件 執行以下指令來設定本教程中的 region 以及 zone (你可以使用對你來說最佳的 region 跟 zone) 部署遵從 程式碼及基本架構 以及 不可改變的基礎架構 , Terraform 支援利用陳述性的描述來決定理想的基礎架構狀態。 當述詞被採用， Terraform 使用 GCP APIs 來提供以及更新資源的狀態已符合述詞。 Terraform 比較想要的狀態以及目前的狀態，所以漸進式增加的變更不需要刪除任何東西，或者重新開始，即可被套用。 例如說，Terraform 可以建立 GCP 專案以及 compute 執行個體等等… 甚至是設定一個 Kubernetes Engine 叢集，並且部署應用到上面。 當要求改變了，敘詞可以被更新，然後 Terraform 將會相對應的更新雲端基礎設施 這個範例將會開始一個 Kubernetes Engine 叢集，然後部署一個簡單的範例應用上去。 預設， GCP Kubernetes Engine 叢集內建一個事先配置好的 Fluented 收集器，他會轉發記錄到 Stackdriver 更新 provider.tf 檔案 在 Terraform 的 provider.tf 腳本中，移除 provider 版本 編輯 provider.tf 腳本nano ~/gke-logging-sinks-demo/terraform/provider.tf 如果檔案含有 google 提供者的靜態版本字串，像下圖一樣，請移除 ....provider \"google\" &#123; project = var.project version = \"~&gt; 2.10.0\"&#125; 儲存檔案 部署叢集 本教程提供的範例檔案中，有三個 Teffaform 的配置檔。 第一個， main.tf ，是一個 Terraform 的起始點。 他描述了會使用到的功能，以及會被操縱到的資源，還有會輸出的結果。 第二個檔案是 provider.tf , 這個檔案顯示 Terraform 指令的目標是哪一個雲端提供者以及其版本，在這個範例中，是 GCP 。 最後一個檔案是 variables.tf ，它含有一個變數清單，用來當作 Terraform 的輸入。 任何沒有在 variables.tf 但有用在 main.tf 的變數都會在執行過程中跳出。 要建立環境，可以執行以下指令make create 備註： 如果你收到跟 zone 變數相關的廢棄警告，請無視，繼續本教程 驗證如果在部署過程中沒有顯示任何錯誤，在幾分鐘之後，你應該會在 GCP 主控台看到 Kubernetes Engine 叢集 到 Navigation menu &gt; Kubernetes Engine 來看同一個被部署的應用 若要驗證這個範例是否正確的部署，執行make validate 輸出看起來如下： 現在，應用已經被部署到 Kubernetes Engine, 它可以產生紀錄資料，然後可以使用 Stackdriver 或其他工具來檢視它 產生紀錄這個使用 Terraform 部署的範例應用提供一個簡單網頁的功能。 每次你在瀏覽器打開這個應用，這個應用將會發布紀錄事件到 Stackdriver Logging 。 重整頁面幾次來產生一些紀錄事件。 要取得應用頁面的 URL , 執行以下步驟: 在 GCP 主控台，從 Navigation menu, 移動到 Networking section, 然後點擊 Network services 在預設的 Load balancing 頁面，點擊已經設定好的 TCP load balancer 在 Load balancer detail 頁面，最上面已被下標籤 Fronted 複製 IP:Port URL, 打開一個新的瀏覽器然後貼上，瀏覽器應該會顯示類似以下的畫面： 在 Stackdiver 的紀錄Stackdriver 提供 UI 介面來檢視紀錄事件。 基本的搜尋以及篩選的功能都有提供，當在 Debug 系統問題時，這非常的有用。 Stackdriver Logging 最適合用來檢視比較近的紀錄事件，若對長期紀錄事件有要求的使用者，應該考慮其他一些工具，下面會介紹到 若要存取 Stackdriver Logging 主控台，執行以下的步驟： 在 GCP 主控台，從 Navigation menu Stackdriver 區塊，選擇 Logging 變更資源篩選器 GKE Container &gt; stackdriver-logging &gt; default ( stackdriver-logging 是叢集，而 default 是命名空間) 在這個頁面上，你可以展開紀錄來檢視紀錄數據更多的細節 在紀錄主控台，你可以執行任何類型的文字搜尋，或是嘗試很多紀錄類型的篩選器，事件等級，時間區間等等 檢視紀錄匯出Terraform 配置建立了兩個紀錄匯出接收器。 若要檢視接收器，執行以下的步驟: 你應該還在 Stackdriver -&gt; Logging 頁面 在左邊導航選單，點擊 Exports 選單選項 這會導引你到 Exports 頁面，在紀錄匯出的清單，你應該會看到兩個接收器 在接收器右手邊點擊 context 選單 (三個小點), 然後選擇 Edit sink, 你可以編輯/檢視這些接受器 另外，在導航視窗的頂部點擊 Create Export 選項，你可以建立額外的客制匯出接收器 在 Cloud Storage 的紀錄紀錄事件可以被儲存在 Cloud Storage, 這是一個適合用來儲存歸檔資料的物件儲存系統。 Cloud Storage 儲存區的政策可以被配置，舉例來說，久置的資料可變為過期，然後自動刪除，而新的資料可以依照不同的類別被儲存，類別會影響到價格以及可用性。 Terraform 配置檔建立了一個 Cloud Storage 儲存區，名為 Stackdriver-gke-logging-, 中長期的紀錄都會被匯出，然後儲存在這。 在這個範例中，儲存類別被定義為 Nearline, 因為正式環境中，紀錄中長期的紀錄不會經常性地被儲存（這將有助於管理中長期儲存成本）。 在正式環境中，儲存區也可以包含一個生命週期的政策，他可以將內容移動到 Coldline 儲存區，這樣對長期儲存記錄的成本會更低 要在 Cloud Storage 存取 Stackdriver 紀錄, 執行下面的步驟： 在 GCP 主控台， 從 Navigation menu 點擊 Storage 找到名為 stackdriver-gke-logging-&lt;random-Id&gt; 的儲存區，點擊名稱 你應會看到一系列與跑到叢集中的 pod 相對應的資料夾 (就是， autoscaler, dnsmasq, 等等) 你可以點擊任何一個資料夾來瀏覽特定的紀錄細節，像是 heapster, kubedns, sidecar, 等等… 在 BigQuery 的紀錄Stackdriver 紀錄事件可以被設定成發佈在 BigQuery, 一個快速的，精細的，供龐大資料查詢的資料儲存工具 Terraform 配置將會建立一個 BigQuery 資料組, 名為 gke_logs_dataset。 這個資料組將會被設定成包含所有與 Kubernetes Engine 相關的距今一個小時的紀錄 (設定預設的資料組表格過期時間)。 Stackdriver 匯出將會被建立且將 Kubernetes Engine 容器紀錄推送到資料組 若想要從 BigQuery 存取 Stackdriver 紀錄，執行下面的步驟： 在 GCP 主控台的 Navigation menu, 在 Big Data 的區塊點擊 BigQuery 在左邊的選單，點擊你的專案名稱。 你應會看到一個名為 gke_logs_dataset 的資料組。 展開這個資料組來檢視存在的表格 ( Note: 這個資料組會立即被建立，但表格會再當紀錄產生了，且新的表格有需要時建立) 點擊其中一個表格來檢視表格細節 檢視表格結構，並且注意到欄位的名稱以及他們的資料類型。 這些資訊在你下一步要對表格做查詢時會用到 點擊右上方 Query Table 來對表格執行客製化查詢 這會在查詢編輯器裡增加一個查詢，你它有一個語法錯誤 編輯這個查詢，在 after 之後增加一個星號 () 來從這個表格調出所有的細節。 備註: 一個 `Select ` 查詢通常是非常昂貴，且不建議的。 在本教程中，資料組被限制上最近一個小時的紀錄，所以整體上資料庫的相對小的。 點擊 Run 來執行查詢，並且從表格得到一些結果 結果視窗應該會顯示一些行和列，你可以捲動回傳的多行資料。如果你想要，執行一些客制的查詢從原本查詢的結果中篩選一些特定的資料 刪除安裝Qwiklabs 會將所有本教程中使用到的資源關掉，但是這邊可能需要你做的是清理你的環境來節省成果，當一個好雲端公民！make teardown 因為 Terraform 有對所有建立的資源做追蹤，所以他可以將他們全部清除 正式環境的故障排除執行 Terraform 時，安裝腳本失敗了，並且回傳 Permission denied。Terraform 使用的帳號沒有提供必須的權限來在選擇的專案中建立資源。 確保列在 gcloud config list 中的專案有必要的權限來建立資源。 如果它有，使用 gcloud auth application-default login 來重新產生應用預設帳號 Cloud Storage 儲存區沒有載入 。一旦 Terraform 配置已經完成，那 Cloud Storage 儲存區將會被建立。 但不是每次都會立即地將 Kubernetes Engine 叢集中的紀錄資料立即載入。 給這個程序一點時間，因為他可能會花上最多 2-3 個小時讓第一筆資料出現。 (參考資料) BigQuery 資料組中沒有表格一旦 Terraform 配置完成， BigQuery 資料組將自動被建立但表格不會總是在你檢視結果的時候就已經建立。 表格很少立即的載入資訊。 給這個程序一點時間，(最少 5 分鐘), 在你下可能出錯的判斷之前。 恭喜，你已完成本教程","link":"/zh-tw/loggingWithStackdriverOnKubernetesEngine/"},{"title":"Cloud Functions 上的監控與紀錄","text":"概述你可以在 GCP 主控台檢視你的 Cloud Functions 的執行時間，執行次數，記憶體用量。 這些指標在 Stackdriver Monitoring 上也有，你可以在這裡根據這些指標來設定你的客製化警告。 更多資訊請參考 Stackdriver Monitoring 文件 設定及要求 在你按下 Start Lab 按鈕之前 詳讀所有的教學。Labs 是有時間限制的，而且你不可以停止時間倒數。倒數計時器在你按下 Start Lab 按鈕後開始倒數，上面顯示的時間為你還能使用 Cloud 資源的時間。 Quiklabs 的手把手環境，讓你可以在真實環境中來操作進行 Quiclabs 上提供的課程，而不是在一個模擬或是展示的環境。我們透過提供你一個全新的、暫時的帳號密碼，在計時器歸零之前，你可以用來登入並存取 Google Cloud Platform。 你需要什麼？ 要完成這個 lab ，你需要: 一個一般的網路瀏覽器（推薦 Chrome） 完成這個 lab 的時間 備註： 如果你已經有你自己的個人 GCP 帳號或專案，請不要使用在這一個 lab 現在你已經開始你的 lab, 你將會登入 Google Cloud Shell 主控台，然後開啟命令列工具 如何開始你的 lab ，然後登入 Console? 按下 Start Lab 按鈕。如果你需要付費，會有一個彈出視窗來讓你選擇付費的方式。在左方你會看到一個面板，上面有暫時的帳號密碼，你必須使用這些帳號密碼在此次 lab 複製 username , 然後點擊 Open Google Console。 Lab 會開啟另外一個視窗，顯示選擇帳號的頁面 tip: 開啟一個全新的視窗，然後跟原本的頁面並排 在選擇帳號頁面, 點擊 Use Another Account 登入頁面開啟，貼上之前複製的 username 以及 password ，然後貼上 重要：必須使用之前於 Connection Details 面板 取得的帳號密碼，不要使用你自己的 Qwiklabs 帳號密碼。 如果你有自己的 GCP 帳號，請不要用在這裡（避免產生費用） 點擊並通過接下來的頁面: 接受terms以及conditions 不要增加recovery optoins 或 two factor authentication (因為這只是一個臨時帳號) 不要註冊免費體驗 稍待一些時候， GCP 控制台將會在這個視窗開啟。 注意：按下左上方位於Google Cloud Platform 隔壁的 Navigation menu ，你可以瀏覽選單，裡面有一系列的 GCP 產品以及服務 啟動 Google Cloud ShellGoogle Cloud Shell 是載有開發工具的虛擬機器。它提供了5GB的 home 資料夾，並且運行在 Google Cloud 上。 Google Cloud Shell 讓你可以利用 command-line 存取 GCP 資源 在 GCP 控制台 ，右上的工具列，點擊 Open Cloud Shell 按鈕 在打開的對話框裡，按下 START CLOUD SHELL: 你可以立即按下 START CLOUD SHELL 當對話視窗打開。 連結並提供環境會需要一點時間。當你連結成功，這代表你已成功獲得授權，且此專案已被設為你的專案ID，例如： gcloud 是 Google Cloud Platform 的 command-line 工具，他已事先被安裝在 Cloud Shell 並且支援自動補齊 使用這個 command ,你可以列出有效帳戶名稱: gcloud auth list 輸出: Credentialed accounts: - &lt;myaccount&gt;@&lt;mydomain&gt;.com (active) 範例輸出: Credentialed accounts: - google1623327_student@qwiklabs.net 你可以使用以下 command 來列出專案 ID gcloud config list project 輸出： [core]project = &lt;project_ID&gt; 範例輸出： [core]project = qwiklabs-gcp-44776a13dea667a6 gcloud 的完整文件可以參閱 Google Cloud gcloud Overview 建立 Stackdriver 工作區在 Navigation menu, 點擊 Monitoring 當你看到 Stackdriver 的主控台時， 工作區已準備完畢 在 Stackdriver 檢視 Cloud Functions 的紀錄 &amp; 指標現在你將會建立一個可以被監控的 Hello World 的 cloud function 回到主控台，在左邊的選單，點擊 Cloud Functions, 然後 Create function 使用以下的設定來建立你的 function: Name: qwiklabsDemo Trigger: HTTP Index.js tab: 將 placeholder 替換成下面的代碼 /** * Cloud Function. * * */exports.qwiklabsDemo = function qwiklabsDemo (req, res) &#123; res.send(`Hello $&#123;req.body.name || 'World'&#125;!`); console.log(req.body.name);&#125; Function to execute: qwiklabsDemo 當你準備好時，點擊 Create cloud function 將會自動部署，且部署完畢後你可以在 Overview 頁面看到它。 這會需要幾分鐘的時間。 當你可以在名字的旁邊看到一個綠色的確認符號，這代表 cloud function 已經部署完畢。 測試進度點擊 Check my progress 來確認目前的進度。如果你已經完成目前的進度，你將獲得一個評價分數。 在 Cloud Shell, 執行以下的代碼來下載一個叫做 vegeta 的工具，它可以讓我們傳送一些測試用流量到 cloud function wget 'https://github.com/tsenart/vegeta/releases/download/v6.3.0/vegeta-v6.3.0-linux-386.tar.gz' 輸入以下指令來解壓縮 vegetatar xvzf vegeta-v6.3.0-linux-386.tar.gz 在主控台，點擊 cloud function 的名字, 然後點擊 trigger, 最後點擊下面的 URL 如果新的視窗開啟，並且你有看到 Hello World!, 這代表 cloud function 正常運作中。 現在傳送一些流量到 cloud function 執行以下的代碼，將 YOUR_PROJECT_ID 替換成你的 Project IDecho \"GET https://us-central1-&lt;YOUR_PROJECT_ID&gt;.cloudfunctions.net/qwiklabsDemo\" | ./vegeta attack -duration=300s &gt; results.bin 建立基於紀錄的指標現在你將建立一個分佈類型 (Distribution type) 的紀錄指標，使用正則表達式，從記錄數據的 textPayload 欄位取得延遲的值 點擊 Navigation menu 回到左方選單，然後在 Stackdriver section 區塊點擊 Logging, 你將會被引導到紀錄畫面 從第一個下拉選單選擇 Cloud Function，然後從所有的紀錄下拉選項裡選擇 cloud-functions, 然後點擊 OK, 這樣我們只會看到 Cloud Function 的紀錄： 在 *Filter By… 的欄位，輸入 “function execution took” (包含雙引號) 來篩選你的紀錄 然後在畫面上方點擊 Create Metric 在指標編輯器： 將指標命名為 CloudFunctionLatency-Logs 將 Type 改為 Distribution Field Name 請輸入 textPayload 點擊位於 Extraction regular expression 欄位旁的 Build 在 Regular Expression 欄位裡，輸入以下的代碼： execution took (\\d+) 指標編輯器應該看起來像這樣： 點擊 Create Metric 現在你會看到這個使用者自定義的指標已經被加到 Logs-based Metric 頁面 測試進度點擊 Check my progress 來確認目前的進度。如果你已經完成目前的進度，你將獲得一個評價分數。 Metrics Explorer (指標探索器)接下來，使用指標探索器來檢視 cloud function 的資料 在 Stackdriver tab 的視窗，到 Resources &gt; Metrics Explorer 來檢視一些 Cloud Functions 的指標。 開始在欄位中輸入 execution, 然後從建議指標中選擇 Executions。 在圖表的上方的下拉選單，將圖表類型變更為 stacked bar 現在試試看不同的指標來看看有什麼其他的圖形選項。 點擊 Metric 旁邊的 X, 然後選擇 Execution times 圖表預設為 heatmap, 但你可以更改承認和你喜歡的類型 你也可以檢視不同的加總，例如百分位排名第 95 位： 客製化顯示面板客製化一個顯示面板是一個非常好的方式來儲存對你來說重要的指標圖表。 你將再次設定這些圖表，但這次他們會儲存在你的顯示面板 在 Stackdriver 主控台，點擊 Dashboards &gt; Create Dashboard 將這個顯示面板取名為 “Results”, 然後點擊 Add Chart 點擊到 Find resource type and metric 欄位，然後選擇我們在上面最後建立的表格的資源類型以及指標, 點擊 Add Chart 來建立下一個 在選擇指標後，圖表會自動被命名, 但你可以重新命名 當你完成這一切，你的圖表將會出現在你的顯示面板，提供一個快速的參考值來顯示目前資源的狀況 測試你的理解下面有多重選擇的問題來鞏固你對本教程概念的理解，盡你所能的回答吧： 恭喜！你已完成本教程","link":"/zh-tw/monitoringAndLoggingForCloudFunctions/"},{"title":"如何省略 git add?","text":"大家好，我是Ray! 今天要跟大家分享，git commit -am 如之前的文章跟大家分享的，每次在commit 之前，我們需要使用git add來明確要commit 的進度，然後commit的同時我們需要留下屬於該commit的訊息。 有些人覺得這樣的設計很好，然而有些則不然，他們覺得這樣有點麻煩。 不管您是屬於哪一派，今天我要跟大家分享，如何將這兩個步驟化為一個動作。 首先，讓我們新增一行code在我們現有的檔案example1.html，如下：&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;First example&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;This is the first example&lt;/p&gt;&lt;p&gt;We add a new paragraph on the first example&lt;/p&gt;&lt;p&gt;This is the example commit for git commit -am&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 現在輸入 git status 如下圖，example1.html已經被修改了，必且如果要commit，我們需要先git add來明確要commit的進度。 依照之前的文章分享，我們需要先git add，然後git commit，並留下屬於此次commit的訊息來完成這次的commit。 現在讓我們來試試看比較簡單一點的方法吧！ 輸入git commit -am &quot;example for git commit -am&quot; 輸入git status 確認狀況 輸入Git log 如下圖，我們已經成功的commit了！ 這邊要跟大家更進一步解釋一下git add的功能。 當我們今天新增一個新的檔案時，我們需要將該檔案加入“追蹤”的檔案清單中，我們使用git add 來達到這個功能。 當“已經入追蹤”的檔案有更改，且我們要做commit時，我們需要更新該檔案將被commit記錄下來的進度！簡單來說，就是訂出將被commit的資料範圍，而這時我們也是使用git add來更新這個進度。 所以說啦，如果今天我們新增一個檔案，且該檔案從未被加入“追蹤”清單中，那這個時候git commit -am 是不會對這個檔案起作用的！ 有一點請大家注意，-a 在這裡代表automatic，它會自動的更新”所有已經加入追蹤清單且有更改”的檔案！ 看完今天的分享，大家是不是對git有更進一步地瞭解了呢？ 我們明天見！","link":"/zh-tw/howToSkipGitAdd/"},{"title":"MySQL 筆記","text":"前言一份未整理的 MySQL 學習筆記 中文亂碼問題先確認 locale 狀態： 確認 charset 狀態, 在 mysql 當中: show variables like 'char%'; 確認 database locale 狀態： SELECT default_character_set_name FROM information_schema.SCHEMATA WHERE schema_name = \"databaseName\"; 確認 table locale 狀態： SELECT CCSA.character_set_name FROM information_schema.`TABLES` T, information_schema.`COLLATION_CHARACTER_SET_APPLICABILITY` CCSAWHERE CCSA.collation_name = T.table_collation AND T.table_schema = \"databaseName\" AND T.table_name = \"tableName\"; 確認 column locale 狀態： show full columns from tableName; 確認 collation show variables like 'collation%'; locale 設定 確認 mysql 設定檔位置mysql --help -verbose | grep 'my.cnf' 通常，檔案會在 /etc/mysql/my.cnf vim /etc/mysql/my.cnf 貼上：[client]default-character-set=utf8[mysql]default-character-set=utf8[mysqld]collation-server = utf8_unicode_ciinit-connect='SET NAMES utf8'character-set-server = utf8 修改 database locale ALTER DATABASE database_name CHARACTER SET utf8 COLLATE utf8_general_ci; 修改 table locale ALTER TABLE table_name CONVERT TO CHARACTER SET utf8; 完成以上設定之後，重啟 mysql service mysql restart 如果有用使用 PHP 的話，記得也將 PHP 那邊的 locale 設為 uft8, 可參考文章 mysqli_set_charset($dbc,\"utf8\"); 疑難雜症理論上，上面的都做完了，應該就不會有亂碼了，如果問題尚未解決，可以試試下面的方法 查看資料庫 locale 設定 show create database databaseName 查看 table locale 設定 show create table tableName 其餘設定 set names uft8; 密碼顯示密碼驗證相關show variables like &apos;validate_password%&apos;; 密碼驗證原則對照表 Policy Value Test Performed 0/Low length 1/MEDIUM length; numeric, lowercase/uppercase, and special characters 2/STRONG length; numeric, lowercase/uppercase, and special characters; dictionary file 確認驗證方式SELECT user,authentication_string,plugin,host FROM mysql.user; 更改 root 密碼ALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED WITH mysql_native_password BY &apos;password&apos;; FLUSH PRIVILEGES; 修改密碼長度規則set global validate_password_length=3; 修改密碼驗證原則set global validate_password_policy=0; 匯入大量資料從 sql 檔匯入mysql --max_allowed_packet=100M -u root -p database &lt; dump.sql 修改 my.cnf 或 my.ini 檔[mysqld]max_allowed_packet=100M 暫時性的變更set global net_buffer_length=1000000; set global max_allowed_packet=1000000000; 查單一資料庫 sizeSELECT table_schema &quot;databaseName&quot;, ROUND(SUM(data_length + index_length) / 1024 / 1024, 1) &quot;DB Size in MB&quot; FROM information_schema.tables where table_schema=&quot;databaseName&quot; GROUP BY table_schema; 建立資料庫CREATE DATABASE mydatabase CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;","link":"/zh-tw/mysql/"},{"title":"利用 Jenkins 在 AWS 上達到 CI","text":"前言以下為本篇記錄重點： 部署 jenkins 到 AWS EC2 的 Amazon Linux 2 AMI (HVM) 部署 jenkins 到 AWS EC2 的 Amazon Linux AMI 2018.03.0 (HVM) 當GitHub 上的進度有更新時，自動在 AWS EC2 執行 git pull 並與 GitHub 上的進度同步， 建立 EC2 instance 利用 SSH 連結到 AWS EC2 點擊 Connect ，並遵照指示操作 Amazon Linux 2 AMI (HVM)安裝sudo yum install java-1.8.0 sudo yum update –y sudo rpm --import https://pkg.jenkins.io/redhat/jenkins.io.key sudo yum install jenkins -y 設定sudo vim /etc/sysconfig/jenkins 並更改如右邊的參數 JENKINS_USER=&quot;root&quot; sudo service jenkins start sudo systemctl enable jenkins.service sudo vim /etc/sysconfig/jenkins 在瀏覽器設定 Jenkins 於瀏覽器輸入 http://yourPublicDNS:8080 於終端機輸入 sudo cat /var/lib/jenkins/secrets/initialAdminPassword 複製密碼以登入 安裝建議的插件 創立帳號 存檔並登入 到Jenkins管理頁面 安裝GitHub插件 開始一個自由專案 到設定的地方 輸入專案 url 選取 git , 並填入 git 資料夾的 url 勾選 GitHub hook trigger for GITScm polling 輸入客製化的shell script如果你的 jenkins 跟你的專案在同一台電腦的話 ssh -i /root/.ssh/yourKey.pem ec2-user@127.0.0.1 \"cd /var/www/html/yourProjectName;git reset @^ --hard;git pull;/usr/local/bin/composer install;php artisan migrate --force;\" 設定 GitHub 到 GitHub 的設定頁面 建立一個 webhook ，如下: Amazon Linux AMI 2018.03.0 (HVM)安裝sudo yum update –y sudo yum remove java-1.7.0-openjdk sudo yum install java-1.8.0 sudo wget -O /etc/yum.repos.d/jenkins.repo http://pkg.jenkins.io/redhat/jenkins.repo sudo rpm --import https://pkg.jenkins.io/redhat/jenkins.io.key sudo yum install jenkins -y 設定sudo vim /etc/sysconfig/jenkins 修改為 JENKINS_USER=&quot;root&quot; sudo service jenkins start 當 Server 重啟時，自動啟動 jenkinssudo chkconfig jenkins on 在瀏覽器設定 Jenkins 於瀏覽器輸入 http://yourPublicDNS:8080 於終端機輸入 sudo cat /var/lib/jenkins/secrets/initialAdminPassword 複製密碼以登入 安裝建議的插件 創立帳號 存檔並登入 到 Jenkins 管理頁面 安裝 GitHub 插件 開始一個自由專案 到設定的地方 輸入專案url 選取 git , 並填入 git 資料夾的 url 勾選 GitHub hook trigger for GITScm polling 輸入客製化的 shell script如果你的 jenkins 跟你的專案在同一台電腦的話 ssh -i /root/.ssh/yourKey.pem ec2-user@127.0.0.1 \"cd /var/www/html/yourProjectName;git reset @^ --hard;git pull;/usr/local/bin/composer install;php artisan migrate --force;\" 設定 GitHub 到 GitHub 的設定頁面 建立一個 webhook ，如下:","link":"/zh-tw/implementCIWithJenkinsOnAWS/"},{"title":"pm2 - 用法大全","text":"前言pm2 是什麼？ pm2 是一個 node 的程序管理器 pm2 解決什麼問題？ pm2 可以讓 node 服務 crash 掉之後，自動幫我們重啟 pm2 可以在 server 重啟之後，自動幫我們重啟 pm2 可利用 CPU 多核，開啟多程序，已達到類似負載平衡的效果 Graceful reload 可達成類似 rolling upgrade 的效果，0 downtime 升級 多程序多服務，可提升處理 request 的速度 可設定 cron 排程自動重啟時間 pm2 提供多項資訊，包含已重啟次數、 CPU 用量、 memory 用量, process id, 等等… pm2 可以在指定的條件下，自動幫我們重啟，條件可以是’up time’, ‘已使用多少 memory’, 等等…, pm2 可以幫我們整理 log, 讓 log 以我們想要的週期分割檔案，並保存我們想要的數量，若有超過，自動刪除。 pm2 提供簡單的部署方式，可一次性部署到多台 server pm2 可與 CD / CD 工具做結合， CI / CD 部署也沒有問題 好 pm2, 不用嗎？ 本篇將提到： 安裝 pm2 使用 CLI 啟動 pm2 使用 pm2 設定檔 ecosystem 啟動 pm2 使用 pm2 設定檔 ecosystem 部署 node 專案 使用 pm2 搭配 GitLab CI / CD Runner 部署 node 專案 安裝 全域安裝npm install pm2@latest -g pm2 with CLI可以使用 pm2 CLI 來啟動 node 專案, 範例如下：pm2 start location/fileName.js --name appName \\--watch true \\--max-memory-restart 500M \\--log ~/.pm2/logs/appName/ \\--time true \\--cron \"0 17 * * *\" \\--no-daemon true \\--merge-logs 以上範例中設定代表的意思，參考如下： 開始可以附加的參數 --name指定 app 一個名字 --watch檔案有變更時，會自動重新啟動 --max-memory-restartMemory 使用超過這個門檻時，會自動重啟 --log指定 log 的位址, 若要指定新位址，需將原本的 process 刪掉，再重新啟動指定 --output指定 output log 位址 --error指定 error log 位址 --log-date-format指定 log 的格式 --merge-logs同一個 app 跑多程序時，不要依據程序 id 去分割 log, 全部合在一起 --arg1 --arg2 --arg3指派額外的參數 --restart-delay自動重啟時，要 delay 多久 --time給 log 加上前綴 --no-autorestart不要自動重啟 --cron指定 cron 規律，強制重啟 --no-daemon無 daemon 模式， listen log 模式 叢集模式 pm2 自動偵測該機器的 CPU 數量，啟動最大能負荷的 process, 適用上面的選項, -i 後面接希望啟動 instance 的數量， 0 或 max 默認自動偵測 CPU 啟動最大值pm2 start app.js -i max 管理程序 直接 kill 掉 process, 再重新開始程序 pm2 restart app_name 如果是在 cluster mode, reload 會依序升級重啟每一個程序，達到 zero downtime 升級 pm2 reload app_name 停止服務 pm2 stop app_name 停止並刪除服務 pm2 delete app_name 除了 app_name 之外，你也可以指定all : 啟動所有程序id : 該程序 id 顯示管理程序狀態pm2 [list|ls|status] Logs 輸出 log pm2 logs 顯示指定行數 log (指定倒數 200 行) pm2 logs --lines 200 指定輸出程序 log pm2 logs id 指定輸出格式 pm2 logs --format pm2 logs --json 清空 log pm2 flush 取消 log可以利用指定 log 路徑為 /dev/null 來取消 log 輸出, log 參數用法請參考 ecosystem 範例 循環 log如果你看過 log 檔案超肥，幾年的 log 都寫在同一個檔案; 如果你打開 log 資料夾，發現裡面躺著幾百個 log 檔案; 如果你看過千奇百怪的 log 檔名; 如果你 du -h 發現 log 資料夾大的嚇死人如果你有以上的經驗，那恭喜你，你有救了 安裝pm2 install pm2-logrotate config 檔位置/home/user/.pm2/module_conf.json 參數 max_size (預設 10M):當 log 檔案達到多大時， logrotate module 會將它分割成另外一個檔案。 logrotate module 有可能在檢查檔案時，檔案已經超過指定的大小了，所以超過一些些是可能的。 單位可以自行指定, 10G, 10M, 10K retain (預設 30 個 log 檔案):預設最多保存的 log 數量，如果設定為 7 的話，將會保存目前的 log, 以及最多 7 個 log 檔案 compress (預設 false):壓縮所有循環 log 檔案 dateFormat (時間格式，預設 YYYY-MM-DD_HH-mm-ss) :檔案命名的時間格式 rotateModule (預設 true) :跟其他 apps 一樣，循環 pm2’s module workerInterval (預設 30 秒) :多久 logrotate 會檢查一次 log 檔案大小 rotateInterval (預設每天午夜循環, 範例 0 0 * ):除了設定檔案大小以外，我們也可以設定以時間為單位去循環，格式上採用 node-schedule TZ (預設為系統時間):檔案命名的時間會根據你所設定的時區而改變 圖示* * * * * *┬ ┬ ┬ ┬ ┬ ┬│ │ │ │ │ |│ │ │ │ │ └ day of week (0 - 7) (0 or 7 is Sun)│ │ │ │ └───── month (1 - 12)│ │ │ └────────── day of month (1 - 31)│ │ └─────────────── hour (0 - 23)│ └──────────────────── minute (0 - 59)└───────────────────────── second (0 - 59, OPTIONAL) terminal 監控面板pm2 monit pm2 ecosystemCLI 工具固然不錯，但只要是人難免手滑打錯或漏打參數。 pm2 ecosystem 解決了這個問題，只要好好的打上一次，以後除非設定有變更，否則啟動服務只需要短短幾個指令，而且 ecosystem 檔案還可以納入 git 控管，跟著專案跑 產生範例 ecosystem filepm2 ecosystem CLI跟前面介紹過的管理程序一樣，差別只是將 app.js 換成 ecosystem.js多個管理程序 CLI, 這邊就只列出 start, 其餘同上pm2 start ecosystem.config.js 從 ecosystem 中只啟動特定 app下面的 appName 為我們寫在 ecosystem.config.js 檔案中的 appNamepm2 start ecosystem.config.js --only yourApp 帶入參數拿下面的範例來說，如果我輸入 pm2 start ecosystem --only app1 --env production , 那麼 pm2 就會使用 NODE_ENV=production 這個環境變數 參數範例下面的參數有點多，我們肯定不會一次使用到這麼多的參數，所以可以視專案需求留下我們需要的參數即可module.exports = &#123; apps: [ // First application &#123; // App 名稱 name: 'app1', // 執行服務的入口檔案 script: './server.js', // 你的服務所在位置 cwd: 'var/www/yourApp/', // 分為 cluster 以及 fork 模式 exec_mode: 'cluster', // 只適用於 cluster 模式，程序啟動數量 instances: 0, // 適合開發時用，檔案一有變更就會自動重啟 watch: false, // 當佔用的 memory 達到 500M, 就自動重啟 max_memory_restart: '500M', // 可以指定要啟動服務的 node 版本 interpreter: '/root/.nvm/versions/node/v8.16.0/bin/node', // node 的額外參數 // 格式可以是 array, 像是 \"args\": [\"--toto=heya coco\", \"-d\", \"1\"], 或是 string, 像是 \"args\": \"--to='heya coco' -d 1\" interpreter_args: \"port=3001 sitename='first pm2 app'\", // 同上 node_args: \"port=3001 sitename='first pm2 app'\", // 'cron' 模式指定重啟時間，只支持 cluster 模式 cron_restart: \"0 17 * * *\", // log 顯示時間 time: true, // 可經由 CLI 帶入的參數 args: '-a 13 -b 12', // 想要被忽略的檔案或資料夾, 支援正則，指定的檔案或資料夾如果內容有變更，服務將不會重啟 // 格式可以是 array, 像是 \"args\": [\"--toto=heya coco\", \"-d\", \"1\"], 或是 string, 像是 \"args\": \"--to='heya coco' -d 1\" ignore_watch: [\"[\\/\\\\]\\./\", \"node_modules\"], // 支援 source_map, 預設 true, 細節可參考 // http://pm2.keymetrics.io/docs/usage/source-map-support/ // https://www.html5rocks.com/en/tutorials/developertools/sourcemaps/ source_map_support: true, // instance_var, 詳見以下連結 // http://pm2.keymetrics.io/docs/usage/environment/#specific-environment-variables instance_var: 'NODE_APP_INSTANCE', // log 的時間格式 log_date_format: 'YYYY-MM-DD HH:mm Z', // 錯誤 log 的指定位置 error_file: '/var/log', // 正常輸出 log 的指定位置 out_file: '/var/log', // 同一個 app 有多程序 id, 如果設定為 true 的話， 同 app 的 log 檔案將不會根據不同的程序 id 分割，會全部合在一起 combine_logs: true, // 同上 merge_logs: true, // pid file 指定位置, 預設 $HOME/.pm2/pid/app-pm_id.pid pid_file: 'user/.pm2/pid/app-pm_id.pid', // pm2 會根據此選項內的時間來判定程序是否有成功啟動 // 格式可使用 number 或 string, number 的話， 3000 代表 3000 ms。 string 的話, 可使用 '1h' 代表一個小時, '5m' 代表五分鐘, '10s' 代表十秒 min_uptime: '5', // 單位為 ms, 如果在該時間內 app 沒有聽 port 的話，強制重啟 listen_timeout: 8000, // 當執行 reload 時，因為 graceful reload 會等到服務都沒有被存取了才會斷開，如果超過這個時間，強制斷開重啟 // 細節可參考官方文件 http://pm2.keymetrics.io/docs/usage/signals-clean-restart/ kill_timeout: 1600, // 一般來說，服務等待 listen 事件觸發後，執行 reload, 若此選項為 true, 則等待 'ready' message // 細節可參考官方文件 http://pm2.keymetrics.io/docs/usage/signals-clean-restart/ wait_ready: false, // pm2 具有 crash 自動重啟的功能。 但若異常狀況重啟超過此選項的指定次數，則停止自動重啟功能。 異常與否的判定，預設為 1 秒，也就是說如果服務啟動不足一秒又立即重啟，則異常重啟次數 + 1。 若 min_uptime 選項有指定，則以 min_uptime 指定的最小正常啟動時間為標準來判斷是否為異常重啟 // 細節可參考官方文件 http://pm2.keymetrics.io/docs/usage/signals-clean-restart/ max_restarts: 10, // 單位為 ms, 預設為 0, 若有指定時間，則 app 會等待指定時間過後重啟 restart_delay: 4000, // 預設為 true, 若設為 false, pm2 將會關閉自動重啟功能, 也就是說 app crash 之後將不會自動重啟 autorestart: true, // 預設為 true, 預設執行 pm2 start app 時，只要 ssh key 沒問題， pm2 會自動比較 local 跟 remote, 看是否為最新的 commit，若否，會自動下載更新。 此功能有版本問題，需新版才支援 vizion: true, // 進階功能，當使用 Keymetrics 的 dashboard 執行 pull 或 update 操作後，可以觸發執行的一系列指令 post_update: [\"npm install\", \"echo launching the app\"], // defaults to false. if true, you can start the same script several times which is usually not allowed by PM2 // 預設為 false, 如果設定為 true, force: false, // 當不指定 env 時，會套用此 object 裡頭的環境變數, 例如 pm2 start ecosystem.js env: &#123; COMMON_VARIABLE: 'true', NODE_ENV: '', ID: '44' &#125;, // 當有指定 env 時，會套用此 object 裡頭的環境變數, 例如 pm2 start ecosystem.js --env production env_production: &#123; NODE_ENV: 'production', ID: '55' &#125;, // 同上 env_development: &#123; NODE_ENV: 'development' &#125; &#125;, // 第二個 app, 很多資訊上面有介紹過的就不再重複 &#123; name: 'app2', script: 'server.js', // 預設模式，可應用在其他語言, cluster 只可用在 node.js exec_mode: 'fork', instances: 0, watch: false, max_memory_restart: '500M', interpreter: '/root/.nvm/versions/node/v8.16.0/bin/node', time: true, env: &#123; COMMON_VARIABLE: 'true', NODE_ENV: '' &#125;, env_staging: &#123; NODE_ENV: 'staging' &#125;, env_test: &#123; NODE_ENV: 'test' &#125; &#125; ], // 這一個區塊是部署的部分 deploy: &#123; // production production: &#123; // 要登入執行 pm2 的 user user: 'root', // 支援多個 host 部署 host: ['host1', 'host2'], // remote 要檢查的 public key 的位置 key: 'path/to/some.pem', // 要部署的分支 ref: 'origin/master', // Git 倉庫位址 repo: 'git@gitlab.com:user/yourProject.git', // 要部署到 server 上的資料夾路徑 path: '/var/www/yourProjectName', // 如果 ssh 有設定好，從 local 連到 remote 端將不會再詢問是否將 remote 端的 public key 加到 known host \"ssh_options\": \"StrictHostKeyChecking=no\", // 在 pm2 要從 local 端連到 remote 端之前要執行的指令，可以多個指令，由 ; 分割，也可以指定 shell script 的檔案路徑 \"pre-setup\": 'apt update -y; apt install git -y', // 當 pm2 在 remote 機器上將專案 clone 下來之後會執行的指令，同上，可以多個指令，由 ; 分割，也可以指定 shell script 的檔案路徑 \"post-setup\": \"ls -la\", // 當 pm2 在 local 要連上 remote 部署之前 ，在 local 端所要執行的指令, 同上，可以多個指令，由 ; 分割，也可以指定 shell script 的檔案路徑 \"pre-deploy-local\" : \"echo 'This is a local executed command'\", // 部署完成後, 所要執行的指令 同上，可以多個指令，由 ; 分割，也可以指定 shell script 的檔案路徑 'post-deploy': 'sudo /root/.nvm/versions/node/v8.16.0/bin/npm install &amp;&amp; sudo /root/.nvm/versions/node/v8.16.0/bin/npm rebuild &amp;&amp; /root/.nvm/versions/node/v8.16.0/bin/pm2 reload ecosystem.config.js', env_production: &#123; NODE_ENV: 'production' &#125; &#125;, staging: &#123; user: 'root', host: ['host3', 'host4'], ref: 'origin/staging', repo: 'git@gitlab.com:user/yourProject.git', path: '/var/www/yourProjectName', \"ssh_options\": \"StrictHostKeyChecking=no\", \"pre-setup\": 'apt update -y; apt install git -y', \"post-setup\": \"ls -la\", \"pre-deploy-local\" : \"echo 'This is a local executed command'\", 'post-deploy': 'sudo /root/.nvm/versions/node/v8.16.0/bin/npm install &amp;&amp; sudo /root/.nvm/versions/node/v8.16.0/bin/npm rebuild &amp;&amp; /root/.nvm/versions/node/v8.16.0/bin/pm2 reload ecosystem.config.js', env_production: &#123; NODE_ENV: 'staging' &#125; &#125;, &#125;,&#125;; pm2 部署pm2 的部署功能，可以讓我們從本機直接部署到多台 server 上, 也可以結合 CI / CD 工具，在提交 commit 後自動部署 部署前的必要條件 首先要先確定，local 到 remote 端的 ssh key 有準備好了嗎？ local 到 remote server 的 ssh 連線是必要的哦！ 簡單來說，你需要在 local 放一把 private key, 然後在你的 remote server 放一把 public key, 這樣才能暢通無阻哦！ 這部分再麻煩 Google 一下哦！ 再來，因為 pm2 會 ssh 到 remote server 上，然後在 remote server 上從我們的專案處 GitHub 或 GitLab 將專案 clone 下來，所以務必確保 remote server 是可以從 GitHub 或 GitLab clone 我們的專案, 所以你要在 remote server 上放一把 clone 用的 private key, 然後將 public key 放在 GitLab 或 GitHub 上，這部分也是麻煩 Google 一下哦 由於首次 ssh 連線時會跳詢問是否將 public key 加入到 known host，這個 prompt 會讓 pm2 deploy 卡住，所以務必先將 remote server 設定好哦！ 可以先連線一次，也可以修改 ssh config, 取消這個 hostKey 的 確認功能。 echo -e \"Host *\\n\\tStrictHostKeyChecking no\\n\\n\" &gt; ~/.ssh/config 接下來，要將 ecosystem 設定檔寫好，這部分請參考上方的 deploy 範例 最後，請確認 remote server 的 ssh 通道 (預設 port 22) 不是關閉的哦！ 初始化遠端資料夾在部署之前, 先在 remote server 上初始化專案的資料夾, 可以帶入不同的參數讓 pm2 根據設定檔做相對應得部署pm2 deploy ecosystem.config.js production setup 部署 部署在初始化遠端資料夾之後，我們就可以使用 pm2 的部署功能了 pm2 deploy ecosystem.config.js production deploy 可使用的參數如下，也可使用 pm2 deploy help 查看 pm2 deploy &lt;configuration_file&gt; &lt;environment&gt; &lt;command&gt; Commands: setup 遠端初始化（第一次部署才會用到） update 更新到最新的 commit revert [n] 回復到上一次的 deployment curr[ent] 輸出目前上線中的 commit prev[ious] 輸出上一次部署的 commit exec|run &lt;cmd&gt; 執行指定的指令 list 列出包含目前，以及之前所部署的 commit [ref] 部署到指定的 ref 部署相關指令pm2 startOrRestart all.json # 重啟所有 apppm2 startOrReload all.json # 觸發 reload 強制重啟pm2 的部署，會要求 local 端先將變更推上 Git repository, 然後 pm2 會在 remote server 執行 git pull, 所以當 local 的變更尚未推上 Git 時，部署會失敗。這時候如果我們硬要部署，我們可以使用pm2 deploy ecosystem.json production --force CI / CD 部署 利用 GitLab 的 CI / CD Runner 配合 pm2 來跑自動部署, 以下為 gitlab.yml 檔案範例 # 使用輕量化 pm2 imageimage: keymetrics/pm2:latest-alpinestages:- deployDeploy: stage: deploy script: # 若 ssh-agent 未安裝，則安裝 - 'which ssh-agent || ( apk add --update openssh )' # 安裝 bash, 以執行 pm2 CLI 工具 - apk add --update bash # 安裝 git, pm2 要連過去時會用到 - apk add --update git # 執行 ssh agent - eval $(ssh-agent -s) # 將 ssh key 加到 ssh agent, 此 ssh key 為 GitLab 的 variable 選項 - echo \"$SSH_PRIVATE_KEY\" | ssh-add - # 執行 pm2 CLI - pm2 deploy ecosystem.config.js production update only: - master 設定好之後，只要 git push 到 master branch, 就會觸發 GitLab CI / CD Runner 自動完成 CI / CD 開機自動啟動 產生開機 script pm2 startup 取消開機自動重啟 pm2 unstartup 儲存下次重啟時，預設啟動的 process pm2 save 如果有更新 node 的版本，記得更新 script pm2 unstartup &amp;&amp; pm2 startup &amp;&amp; pm2 save 有變更時重啟監看該資料夾下的所有檔案，以及子資料夾，並且忽略 node_module 這個資料夾cd /path/to/my/apppm2 start env.js --watch --ignore-watch=\"node_modules\" 更新 PM2npm install pm2@latest -g &amp;&amp; pm2 update 常用指令# Fork 模式pm2 start app.js --name my-api # 指定程序名稱# Cluster 模式pm2 start app.js -i 0 # 會根據可用的 CPU 數量來啟動最大的程序數量，達到平衡負載的效果pm2 start app.js -i max # 跟上面一樣，但是廢除了pm2 scale app +3 # 增加三個 workerpm2 scale app 2 # 將 worker 更新成兩個# 狀態顯示pm2 list # 顯示所有程序狀態pm2 jlist # 將程序狀態使用 raw JSON 印出pm2 prettylist # 將程序狀態用美化的 JSON 印出pm2 describe 0 # 顯示特定程序的所有資訊pm2 monit # 監控所有程序# Logspm2 logs [--raw] # 以串流的方式顯示所有 logpm2 flush # 移除所有 log 檔案pm2 reloadLogs # 重新載入 logs# 操作pm2 stop all # 停止所有程序pm2 restart all # 重新開啟所有程序pm2 reload all # 重新載入服務pm2 stop 0 # 停止特定 id 的程序pm2 restart 0 # 重新啟動特定 id 程序pm2 delete 0 # 從 pm2 list 移除特定 id 程序, 但這並不會停止該程序pm2 delete all # 移除所有程序, 但這並不會停止這些程序# Miscpm2 reset &lt;process&gt; # 重置 meta datapm2 updatePM2 # 更新 pm2pm2 ping # Ensure pm2 daemon has been launchedpm2 sendSignal SIGUSR2 my-app # Send system signal to scriptpm2 start app.js --no-daemon # 不要背景執行pm2 start app.js --no-vizion # 不加這一行，預設執行 pm2 start app 時，只要 ssh key 沒問題， pm2 會自動比較 local 跟 remote, 看是否為最新的 commit，若否，會自動下載更新pm2 start app.js --no-autorestart # 不自動重啟 自動補齊 支援 pm2 指令可以打 tab 自動補齊pm2 completion install 疑難雜症遇到錯誤 Error: ENOENT: no such file or directory, uv_cwd意思是說， pm2 的工作目錄資料夾不存在，所謂的工作目錄資料夾就是我們第一次啟動 pm2 的位置。很可能是我們啟動之後，就不小心把它刪了，如果要尋找工作目錄資料夾在哪，可以使用下面的 command 找到 pm2 的 process id ps ax | grep PM2 然後查詢該 process 執行時所在的目錄（將上面得到的 process id 替換下面的 PM2_Process_ID ls -l /proc/PM2_Process_ID/cwd 公布結果 ls -l /proc/24016/cwd 結果應該會如下, 最後的 deleted 表示該目錄已經被刪除了lrwxrwxrwx 1 root root 0 Feb 4 17:04 /proc/24016/cwd -&gt; /home/nodejs/deploy(deleted) 現在知道原因了，那解決的方法呢？ 我們要先把目前的 process 砍掉，然後到一個安全一點的地方在開啟一次，以免下次又被誤刪了！ 殺掉 pm2 process id kill -9 processID 到一個安全不會再被意外砍掉的目錄再次啟動 pm2 cd ~ &amp;&amp; pm2 -v 參考資料pm2 官網pm2 logrotate","link":"/zh-tw/pm2/"},{"title":"My learning journey on Sequelize","text":"參考連結官方網站 安裝npm install --save sequelize or yarn add sequelize --save 以下手動安裝：npm install --save pg pg-hstorenpm install --save mysql2npm install --save mariadbnpm install --save sqlite3npm install --save tedious # Microsoft SQL Server or yarn add pg pg-hstore --saveyarn add mysql2 --saveyarn add mariadb --saveyarn add sqlite3 --saveyarn add tedious # Microsoft SQL Server --save Migration參考官方網站 安裝 Migration CLInpm install --save sequelize-cli or yarn add sequelize-cli --save 快速開始參考官方網站 npx sequelize-cli init 會自動建立以下資料夾: config: 連接資料庫的設定 models: 這個專案 Models 的存放位置 migrations: Migration 放置處 seeders: seeds 檔案 請把以下的 operationAliases 刪掉 config.json\"development\": &#123; \"username\": \"root\", \"password\": null, \"database\": \"database_development\", \"host\": \"127.0.0.1\", \"dialect\": \"mysql\", \"operatorsAliases\": false&#125;, 建立 migration參考官方網站 npx sequelize-cli model:generate --name User --attributes firstName:string,lastName:string,email:string name: Model 名稱 attributes: 欄位屬性 會做以下的事: 建立一個 user model 在 migration 資料夾，建立一個 migration 檔案，名稱像是 XXXXXXXXXXXXXX-create-user.js 執行 migration參考官方網站 npx sequelize-cli db:migrate 取消 migration參考官方網站 取消最新一個 migration npx sequelize-cli db:migrate:undo 取消全部的 migration, 然後重新 migrate 到指定的檔案 npx sequelize-cli db:migrate:undo:all --to XXXXXXXXXXXXXX-create-posts.js 變更設定檔位置，名稱如果: 你想要重新定義 migration, models, seeders, 或 config 的資料夾位置 你想要重新命名 config.json, 比如說, database.json 那： 建立 .sequelizerc 檔案 touch .sequelizerc 範例格式 const path = require('path');module.exports = &#123; 'config': path.resolve('config', 'database.json'), 'models-path': path.resolve('db', 'models'), 'seeders-path': path.resolve('db', 'seeders'), 'migrations-path': path.resolve('db', 'migrations')&#125; 以上的設定會告訴 CLI 使用 config/database.json 為設定檔 使用 `db/models/ 為 models 的資料夾 使用 db/seeders 為 seeders 資料夾 使用 db/migrations 為 migration 資料夾 有時我們會需要更改 config 檔案副檔名, 因為我們需要一些 json 無法提供的功能, 例如：const fs = require('fs'); production: &#123; username: process.env.DB_USERNAME, password: process.env.DB_PASSWORD, database: process.env.DB_NAME, host: process.env.DB_HOSTNAME, dialect: 'mysql', dialectOptions: &#123; ssl: &#123; ca: fs.readFileSync(__dirname + '/mysql-ca-master.crt') &#125; &#125;&#125;; 這時我們可以在 .sequelizerc 檔案中修改const path = require('path');module.exports = &#123; 'config': path.resolve('config', 'config.js')&#125; 最後別忘了修改 /models/index 中, config 的路徑 在 model 中增加 method'use strict';module.exports = (sequelize, DataTypes) =&gt; &#123; const User = sequelize.define('User', &#123; firstName: DataTypes.STRING, lastName: DataTypes.STRING, email: DataTypes.STRING &#125;, &#123;&#125;); User.associate = function(models) &#123; // associations can be defined here &#125;; User.prototype.useInstance = function () &#123; console.log('This is for new instance way'); &#125;; User.useStatic = function () &#123; console.log('This is for static way'); &#125;; return User;&#125;; 使用 async/await直接 await method 就可(async () =&gt; &#123; let result = await Data.findAll(&#123; attributes: [ 'host', 'upstream_cache_status', [Sequelize.fn('COUNT', Sequelize.col('request')), 'requests'], ], group: ['host', 'upstream_cache_status'] &#125;); console.log(result)&#125;)();","link":"/zh-tw/sequelize/"},{"title":"My learning note on SSH","text":"前言本篇為未整理的個人學習紀錄 正文 建立一組公私鑰? ssh-keygen -t rsa -b 4096 -C \"Ray@gmail.com\" 如何將指定的 key 加到 ssh-agent? ssh-add keyFile 當 private_key 的名稱不是預設的 id_rsa 時，何解？將指定的 key 加到 ssh-agent 如何打開 ssh-agent? eval \"$(ssh-agent -s)\" 在 macOS 上，當我們想要將目前這組 key 刪掉，但是新的 key 要沿用相同的檔案名稱，可能會遇到什麼問題？macOS 的 keychain 將舊的 key 記住了，導致怎麼樣都驗不過，驗到人都覺得厭世了 承上，何解？ ssh-add -K keyFile 承上，在 GCP 上何解？ ssh-add -D &amp;&amp; ssh-add keyFile GCP 上，如何安裝 ssh client ? apt-get update -y &amp;&amp; apt-get install openssh-client -y 如果我已經將 key 加到 ssh-agent, 那我還需要將 key 的實體檔案放在 .ssh 的資料夾內嗎？不需要的哦！ 如何查詢指定 Server 的公鑰？ ssh-keyscan to-be-conneted-instance-ip # 127.0.0.1 SSH-2.0-OpenSSH_6.6.1 127.0.0.1 ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCWBZ3XrIajPmnd6R+g/wcUuOPOiRBMOYjAl4Dv8SfcZtgHqKTK6Zb1EeG3u/uzRYxqXMctG/2A4iXRDG9mvg9H9bimCWbA3xtR79NImPYg4m7BNuH9C+OXRYYJwoOGpjVMs0rGLXkq3/WVkXvQreBuhVD8NI2pEPnQsT1J5abdVbCHlwFYG6wVCJQqFY6jdntJJlxQv5EJu6w4/+Fd4LvdjysH+ngqArac6HMJUxqSxLQjzMdCRWEQKp3ySwmnRp9rHYVaJnnsXeYPfnMN1iMjdIQJPzc89Mepg4ip1q2bCMbMcx2XFO3I7YjYRdcOameFNafMGY0q5RHzhvgnNnal # 127.0.0.1 SSH- 2.0-OpenSSH_6.6.1 127.0.0.1 ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBCPWoEQ7iCCYDrpyb5KeMmCaQ8aOnSfehqmrplZRkbqqnkS9++PdSX/eSLJ0tkFd5902/C+HTCqbDgso4mCKpMo= # 127.0.0.2 SSH-2.0-OpenSSH_6.6.1127.0.0.2 ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCWBZ3XrIajPmnd6R+g/wcUuOPOiRBMOYjAl4Dv8SfcZtgHqKTK6Zb1EeG3u/uzRYxqXMctG/2A4iXRDG9mvg9H9bimCWbA3xtR79NImPYg4m7BNuH9C+OXRYYJwoOGpjVMs0rGLXkq3/WVkXvQreBuhVD8NI2pEPnQsT1J5abdVbCHlwFYG6wVCJQqFY6jdntJJlxQv5EJu6w4/+Fd4LvdjysH+ngqArac6HMJUxqSxLQjzMdCRWEQKp3ySwmnRp9rHYVaJnnsXeYPfnMN1iMjdIQJPzc89Mepg4ip1q2bCMbMcx2XFO3I7YjYRdcOameFNafMGY0q5RHzhvgnNnal # 127.0.0.2 SSH-2.0-OpenSSH_6.6.1 127.0.0.2 ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBCPWoEQ7iCCYDrpyb5KeMmCaQ8aOnSfehqmrplZRkbqqnkS9++PdSX/eSLJ0tkFd5902/ C+HTCqbDgso4mCKpMo= 取最短的那組即可，例如：127.0.0.2 ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBCPWoEQ7iCCYDrpyb5KeMmCaQ8aOnSfehqmrplZRkbqqnkS9++PdSX/eSLJ0tkFd5902/ C+HTCqbDgso4mCKpMo= 當我們初次從 a 電腦 經由 ssh 連到 b 電腦時，當 a 電腦要將 b 電腦的公鑰加到 known_host 檔案時，會跳出詢問視窗 yes/no, 如何避免掉這個視窗？ ssh -o StrictHostKeyChecking=no 如何在 GitHub 以及 Gitlab 上使用不同的 key # GitLabHost gitlab.com Preferredauthentications publickey IdentityFile ~/.ssh/gitlab # GitHubHost github.com Preferredauthentications publickey IdentityFile ~/.ssh/github scp利用 config 檔案來驗證scp -F SSHconfig sourceFile targetUser@targetIP:targetLocation 如果是要傳資料夾過去scp -F SSHconfig -r sourceFile targetUser@targetIP:targetLocation 利用 private key 產生 public keyssh-keygen -y -f fileName 把公鑰傳到遠端主機ssh-copy-id -i key.pub user@IP","link":"/zh-tw/ssh/"},{"title":"在 PayPal 的 IPN 方式中，提交多個商品","text":"前言這篇文章將分享，當我們使用 PayPal 的 IPN 結帳方式時，如何提交多個商品，每個商品擁有各自的名稱，價格，以及數量。本文章是我從官網 複製下來的, 因為我不知道未來什麼時候會用到，而且我實在懶得再去找一次。 本文開始有些網站開發人員可能希望將PayPal付款處理集成到他們自己的第三方購物車上，而不是標準的PayPal購物車上。請使用以下說明為您的買家提供PayPal付款，以便他們在您的第三方購物車上添加購置物品後結賬時使用。 將您的第三方購物車與PayPal的付款流程集成目前有兩種方法。第一種方法是傳遞購物車付款總額，而不是單個物品金額。第二種方法是將所選物品詳情傳遞給PayPal，而不是總購物車數量。提示：按下述步驟粘貼必需的變量到PayPal時，可能需要在您的網站上執行某些腳本。 方法 1. 將總購物車數量傳遞給PayPal 方法 2. 將單個物品傳遞給PayPal 方法1. 將總購物車數量傳遞給PayPal如果願意，您可以累加整個購物車，將總數量傳遞給PayPal的立即購買按鈕代碼（也就是說，您需要粘貼整個購物車的單一名稱及其物品總價款，與購買單件物品一樣）。 該方法有一個不足之處，您的買家將無法查看其購物車中的單個物品。此外，您不能修改我們的變量名稱，也不能添加您自己的變量名稱。 查閱以下信息後如有其他技術問題，請訪問我們的 開發者服務網頁。欲知有關“立即購買”按鈕代碼或以下變量的附加信息，請查看網站付款標準版集成指南。 必需的變量向PayPal提交粘貼代碼時，應包括以下 4 個隱藏變量及一張圖片： 姓名 值 business 您的PayPal賬戶上的電子郵件地址 item_name 物品名稱（或購物車名稱） currency_code 定義幣種以標示貨幣變量（金額、運送費、運送費2、手續費、稅款）。值可以為”USD”、”EUR”、”GBP”、”CAD”、”JPY”。 amount 物品的價格（購物車中所有物品的總價格） image 按鈕圖片，您的買家按此按鈕開始PayPal付款程序。您可以將src 更換為圖片URL，以使用您自己的圖片 這就是說，您粘貼到PayPal的最短必需代碼應如下： &lt;form action=&quot;https://www.paypal.com/cgi-bin/webscr&quot; method=&quot;post&quot;&gt; &lt;input type=&quot;hidden&quot; name=&quot;cmd&quot; value=&quot;_xclick&quot;&gt; &lt;input type=&quot; hidden&quot; name=&quot;business&quot; value=&quot;you@youremail.com&quot;&gt; &lt;input type=&quot;hidden&quot; name=&quot;item_name&quot; value=&quot;Item Name&quot;&gt; &lt;input type=&quot;hidden&quot; name=&quot;currency_code&quot; value= &quot;USD&quot;&gt; &lt;input type=&quot;hidden&quot; name=&quot;amount&quot; value=&quot;0.00&quot;&gt; &lt;input type=&quot;image&quot; src=&quot;http://www.paypal.com/zh_XC/i/btn/x- click-but01.gif&quot; name=&quot;submit&quot; alt=&quot;Make payments with PayPal - it&apos;s fast, free and secure!&quot;&gt; &lt;/form&gt; PayPal提供附加變量，用於自定義您的Form Post。所有可用變量如下（變量名稱必須用小寫）： 可用變量 姓名 值 business 您的PayPal賬戶上的電子郵件地址 quantity 物品數量。大於1 時，會與金額相乘 item_name 物品名稱（或購物車名稱）。必須是字母數字字符，最多為127 個字符 item_number 用於跟踪付款的可選傳遞變量。必須是字母數字字符，最多為127 個字符 amount 物品的價格（購物車中所有物品的總價格） shipping 該物品的運送成本 shipping2 每增加一件物品所需的運送成本 handling 手續費 tax 基於交易的稅額。如果使用該變量，傳遞值將覆蓋所有用戶信息稅收設置（不管買家所在位置）。 no_shipping 送貨地址。如果設為”1”，則不會要求您的客戶提供送貨地址。該變量為可選項；如果省略或設為”0”，將提示您的客戶輸入送貨地址 cn 可選標籤，會在提示欄上顯示（最多40 個字符） no_note 為付款加入提示。如果設為”1”，則不會提示您的客戶輸入提示。該變量為可選項；如果省略或設為”0”，將提示您的客戶輸入提示。 on0 第一選項欄名稱。最多64 個字符 os0 第一組選項值。最多200 個字符。”on0” 必須定義，以便識別”os0”。 on1 第二選項欄名稱。最多64 個字符 os1 第二組選項值。最多200 個字符。”on1” 必須定義，以便識別”os1”。 custom 決不會向您的客戶顯示的可選轉遞變量。可用於跟踪庫存 invoice 決不會向您的客戶顯示的可選轉遞變量。可用於跟踪賬單號 notify_url 僅與IPN 一起使用。發送IPN Form Post 的互聯網URL return 您的客戶完成付款後將返回的互聯網URL cancel_return 您的客戶取消付款後將返回的互聯網URL image_url 您要用作圖標的圖片的互聯網URL，圖片大小為150 X 50 像素 cs 設置您的付款頁面的背景色。如果設為”1”，背景色將為黑色。該變量為可選項；如果省略或設為”0”，背景色將為白色 擴展變量 PayPal允許您粘貼擴展變量，條件是將改變以下”cmd”值： &lt;input type=&quot;hidden&quot; name=&quot;cmd&quot; value=&quot;_xclick&quot;&gt; 到： &lt;input type=&quot;hidden&quot; name=&quot;cmd&quot; value=&quot;_ext-enter&quot;&gt; &lt;input type=&quot;hidden&quot; name=&quot;redirect_cmd&quot; value=&quot;_xclick&quot;&gt; 通過上述”cmd” 值修改，您還可使用以下變量： 擴展變量 姓名 值 email 客戶的電子郵件地址 first_name 客戶的名。必須是字母數字字符，最多為32個字符 last_name 客戶的姓。必須是字母數字字符，最多為64個字符 address1 客戶地址所在國家或地區。必須是字母數字字符，最多為100個字符 address2 客戶地址第二行。必須是字母數字字符，最多為100 個字符 city 客戶地址所在城市。必須是字母數字字符，最多為100 個字符 state 客戶地址所在州。必須是正式的2 個字母縮寫 zip 客戶地址的郵政編碼 night_phone_a 客戶夜間聯繫電話號碼的區號 night_phone_b 客戶夜間聯繫電話號碼前三位 day_phone_a 客戶白天聯繫電話號碼的區號 day_phone_b 客戶白天聯繫電話號碼前三位 提示：若要更改“用戶信息”中的默認運費和手續費設置，請轉至您的用戶信息，編輯您的運費計算，然後點擊“允許採用基於交易的運費”複選框。 方法2. 將單個物品傳遞給PayPal如果您的第三方購物車可設置成向PayPal傳遞單個物品，有關物品的信息將加入買家和賣家的記錄日誌和系統通知中。要加入該物品的信息，您需要將HTML 格式元素粘貼至PayPal購物車流程的新版本。該過程與#1 節“將總購物車數量傳遞給PayPal”描述的非常相似，不同之處在於： 將”cmd”變量設置到”_cart”更換必要的HTML行 &lt;input type=&quot;hidden&quot; name=&quot;cmd&quot; value=&quot;_xclick&quot;&gt; 與&lt;input type=&quot;hidden&quot; name=&quot;cmd&quot; value=&quot;_cart&quot;&gt; 添加稱為”upload”的新變量 在&lt;表格&gt;和&lt;/表格&gt;標籤之間新增以下行： &lt;input type=&quot;hidden&quot; name=&quot;upload&quot; value=&quot;1&quot;&gt; 定義物品明細對於以下各特定物品參數，定義與通過您的合作商購物車購買的各物品對應的一組新值。將”_x”附加到變量名稱，其中x是物品號碼，從1開始，每加入一物品增加一。 姓名 值 item_name_x （物品#x 需要）購物車中物品#x 的名稱。必須是字母數字字符，最多為127 個字符 item_number_x 與購物車中物品#x 關聯的可選傳遞變量。必須是字母數字字符，最多為127 個字符 amount_x （物品#x 需要）物品#x 的價格 shipping_x 運送物品#x 的第一件（數量1）的成本 shipping2_x 每增加一件運送物品#x（數量2 或更多）所需的運送成本 handling_x 物品#x 的處理成本 on0_x 物品#x 的第一選項欄名稱。最多64 個字符 os0_x 物品#x 的第一組選項值。最多200 個字符。”on0_x” 必須定義，以便識別”os0_x”。 on1_x 物品#x 的第二選項欄名稱。最多64 個字符 os1_x 物品#x 的第二組選項值。最多200 個字符。”on1_x” 必須定義，以便識別”os1_x”。 為購物車中每件物品重複此設定為您的買家購物車中的各物品加入以上表格中的一組必需的變量和任何選項變量。購物車中的第一物品必須用以”_1”結束的參數定義，如”item_name_1”、”amount_1”等。同樣，第二物品應用變量”item_name_2”、”amount_2”等命名。提示：”_x”值必須以一為單位按序遞增，以便識別。如果從item #1跳到item #3而不定義item #2，則第三個物品會被忽略。要指定幣種：所有貨幣變量（金額、運費、運費2、手續費、稅款）將以粘貼在付款上的”currency_code”變量指定的幣種顯示。因為其不是隨物品不同的，無需向變量名稱附加”_x”。如果沒有粘貼”currency_code”變量，我們將假定所有貨幣變量值為美元。查閱以下信息後如有其他技術問題，請訪問我們的開發者支持網頁。欲知有關購物車代碼或以下變量的其他信息，請查看網站付款標準版集成指南。","link":"/zh-tw/submitMultipleItemsInPayPalIPNmethod/"},{"title":"在 MacOS 及 AWS 上部署 supervisor","text":"部署 supervisor前言本篇重點如下： 在 Mac OS 上安裝並部署 Supervisor 在 AWS 上安裝並部署 Supervisor Supervisor是什麼？Supervisor 是一套程序管理系統。因為 Ray 的專案有使用到 Laravel 的 queue ，而 queue 必須要常駐在背景執行，那要是不小心失敗或中斷了怎麼辦呢？ supervisor 可以確保當 queue 失敗中斷時，自動地幫我們重啟。 Mac OS安裝 安裝 Supervisorbrew install supervisor 配置 進到預設設定檔 vim /usr/local/etc/supervisord.ini 更改預設 include 目錄，到最後一行，修改如下 [include]files = /usr/local/etc/supervisor.d/*.conf 新增客製化配置目錄及檔案 mkdir /usr/local/etc/supervisor.d;vim /usr/local/etc/supervisor.d/processNameYouLike.conf; 輸入下面的設定 [program:programNameYouLike]process_name=%(program_name)s_%(process_num)02dcommand=php absoluteAddressOfYourProject/artisan queue:work sqs --sleep=3 --tries=3 --daemonautostart=trueautorestart=trueuser=raynumprocs=8redirect_stderr=truestdout_logfile=/absoluteAddressOfLocationYouWouldLikeToPutTheLog/worker.log 啟動 啟動服務 sudo supervisord -c /usr/local/etc/supervisord.ini 進到控制台 sudo supervisorctl -c /usr/local/etc/supervisord.ini 更新配置 update 查看狀態 status 看起來如下： AWSAmazon Linux 2 AMI本篇記錄使用的AWS型號如下： Amazon Linux 2 AMI (HVM), SSD Volume Type - ami-0f9ae750e8274075b t2.micro (Variable ECUs, 1 vCPUs, 2.5 GHz, Intel Xeon Family, 1 GiB memory, EBS only) 安裝 安裝 supervisorsudo yum install -y supervisor 配置 到預設設定檔 sudo vim /etc/supervisord.conf 更改最後一行 include 的目錄 [include]files = supervisord.d/*.conf 新增配置檔，如果資料夾不存在就創建 sudo mkdir /etc/supervisord.d;sudo vim /etc/supervisord.d/projectFileNameYouLike.conf 新增配置 [program:laravel-worker]process_name=%(program_name)s_%(process_num)02dcommand=sudo php absoluteAddressOfYourProject/artisan queue:work sqs --sleep=3 --tries=3 --daemonautostart=trueautorestart=trueuser=rootnumprocs=8redirect_stderr=truestdout_logfile=absoluteAddressOfYourProject/worker.log 啟動 啟動 supervisor sudo supervisord -c /etc/supervisord.conf 套用新的配置檔並查看狀態 sudo supervisorctl update;sudo supervisorctl status 配置自動重啟 增加重啟配置檔 sudo vim /etc/init.d/supervisord 輸入以下配置 #! /bin/sh### BEGIN INIT INFO# Provides: supervisord# Required-Start: $remote_fs# Required-Stop: $remote_fs# Default-Start: 2 3 4 5# Default-Stop: 0 1 6# Short-Description: Example initscript# Description: This file should be used to construct scripts to be# placed in /etc/init.d.### END INIT INFO# Author: Dan MacKinlay &lt;danielm@phm.gov.au&gt;# Based on instructions by Bertrand Mathieu# http://zebert.blogspot.com/2009/05/installing-django-solr-varnish-and.html# Do NOT &quot;set -e&quot;# PATH should only include /usr/* if it runs after the mountnfs.sh scriptPATH=/sbin:/usr/sbin:/bin:/usr/binDESC=&quot;Description of the service&quot;NAME=supervisordDAEMON=/usr/local/bin/supervisordDAEMON_ARGS=&quot;&quot;PIDFILE=/var/run/$NAME.pidSCRIPTNAME=/etc/init.d/$NAME# Exit if the package is not installed[ -x &quot;$DAEMON&quot; ] || exit 0# Read configuration variable file if it is present[ -r /etc/default/$NAME ] &amp;&amp; . /etc/default/$NAME# Load the VERBOSE setting and other rcS variables. /lib/init/vars.sh# Define LSB log_* functions.# Depend on lsb-base (&gt;= 3.0-6) to ensure that this file is present.. /lib/lsb/init-functions## Function that starts the daemon/service#do_start()&#123; # Return # 0 if daemon has been started # 1 if daemon was already running # 2 if daemon could not be started start-stop-daemon --start --quiet --pidfile $PIDFILE --exec $DAEMON --test &gt; /dev/null \\ || return 1 start-stop-daemon --start --quiet --pidfile $PIDFILE --exec $DAEMON -- \\ $DAEMON_ARGS \\ || return 2 # Add code here, if necessary, that waits for the process to be ready # to handle requests from services started subsequently which depend # on this one. As a last resort, sleep for some time.&#125;## Function that stops the daemon/service#do_stop()&#123; # Return # 0 if daemon has been stopped # 1 if daemon was already stopped # 2 if daemon could not be stopped # other if a failure occurred start-stop-daemon --stop --quiet --retry=TERM/30/KILL/5 --pidfile $PIDFILE --name $NAME RETVAL=&quot;$?&quot; [ &quot;$RETVAL&quot; = 2 ] &amp;&amp; return 2 # Wait for children to finish too if this is a daemon that forks # and if the daemon is only ever run from this initscript. # If the above conditions are not satisfied then add some other code # that waits for the process to drop all resources that could be # needed by services started subsequently. A last resort is to # sleep for some time. start-stop-daemon --stop --quiet --oknodo --retry=0/30/KILL/5 --exec $DAEMON [ &quot;$?&quot; = 2 ] &amp;&amp; return 2 # Many daemons don&apos;t delete their pidfiles when they exit. rm -f $PIDFILE return &quot;$RETVAL&quot;&#125;## Function that sends a SIGHUP to the daemon/service#do_reload() &#123; # # If the daemon can reload its configuration without # restarting (for example, when it is sent a SIGHUP), # then implement that here. # start-stop-daemon --stop --signal 1 --quiet --pidfile $PIDFILE --name $NAME return 0&#125;case &quot;$1&quot; in start) [ &quot;$VERBOSE&quot; != no ] &amp;&amp; log_daemon_msg &quot;Starting $DESC&quot; &quot;$NAME&quot; do_start case &quot;$?&quot; in 0|1) [ &quot;$VERBOSE&quot; != no ] &amp;&amp; log_end_msg 0 ;; 2) [ &quot;$VERBOSE&quot; != no ] &amp;&amp; log_end_msg 1 ;; esac ;; stop) [ &quot;$VERBOSE&quot; != no ] &amp;&amp; log_daemon_msg &quot;Stopping $DESC&quot; &quot;$NAME&quot; do_stop case &quot;$?&quot; in 0|1) [ &quot;$VERBOSE&quot; != no ] &amp;&amp; log_end_msg 0 ;; 2) [ &quot;$VERBOSE&quot; != no ] &amp;&amp; log_end_msg 1 ;; esac ;; #reload|force-reload) # # If do_reload() is not implemented then leave this commented out # and leave &apos;force-reload&apos; as an alias for &apos;restart&apos;. # #log_daemon_msg &quot;Reloading $DESC&quot; &quot;$NAME&quot; #do_reload #log_end_msg $? #;; restart|force-reload) # # If the &quot;reload&quot; option is implemented then remove the # &apos;force-reload&apos; alias # log_daemon_msg &quot;Restarting $DESC&quot; &quot;$NAME&quot; do_stop case &quot;$?&quot; in 0|1) do_start case &quot;$?&quot; in 0) log_end_msg 0 ;; 1) log_end_msg 1 ;; # Old process is still running *) log_end_msg 1 ;; # Failed to start esac ;; *) # Failed to stop log_end_msg 1 ;; esac ;; *) #echo &quot;Usage: $SCRIPTNAME &#123;start|stop|restart|reload|force-reload&#125;&quot; &gt;&amp;2 echo &quot;Usage: $SCRIPTNAME &#123;start|stop|restart|force-reload&#125;&quot; &gt;&amp;2 exit 3 ;;esac: script來源 增加權限 sudo chmod +x /etc/init.d/supervisord 將新增的開機重啟配置檔加到系統 sudo chkconfig --add supervisord 打開自動重啟功能，並開始 sudo chkconfig supervisord on;sudo service supervisord start Amazon Linux 2 AMI型號： Amazon Linux AMI 2018.03.0 (HVM), SSD Volume Type - ami-00a5245b4816c38e6 安裝 安裝 supervisor sudo easy_install supervisor 將 /usr/local/bin 加到 sudo path sudo vim /etc/sudoers Defaults secure_path = /sbin:/bin:/usr/sbin:/usr/bin:/usr/local/bin 配置 建立設定檔 sudo su -sudo echo_supervisord_conf &gt; /etc/supervisord.conf;sudo vim /etc/supervisord.conf 更改最後一行 include 的目錄 [include]files = /etc/supervisord.d/*.conf 新增配置檔，如果資料夾不存在就創建 sudo mkdir /etc/supervisord.d;sudo vim /etc/supervisord.d/projectFileNameYouLike.conf 新增配置 [program:laravel-worker]process_name=%(program_name)s_%(process_num)02dcommand=php absoluteAddressOfYourProject/artisan queue:work sqs --sleep=3 --tries=3 --daemonautostart=trueautorestart=trueuser=apachenumprocs=8redirect_stderr=truestdout_logfile=absoluteAddressOfYourProject/worker.log 啟動 啟動 supervisor sudo supervisord -c /etc/supervisord.conf 套用新的配置檔並查看狀態 sudo supervisorctl update;sudo supervisorctl status 配置自動重啟 增加重啟配置檔 sudo vim /etc/init.d/supervisord 輸入以下配置 #!/bin/bash## supervisord Startup script for the Supervisor process control system## Author: Mike McGrath &lt;mmcgrath@redhat.com&gt; (based off yumupdatesd)# Jason Koppe &lt;jkoppe@indeed.com&gt; adjusted to read sysconfig,# use supervisord tools to start/stop, conditionally wait# for child processes to shutdown, and startup later# Erwan Queffelec &lt;erwan.queffelec@gmail.com&gt;# make script LSB-compliant## chkconfig: 345 83 04# description: Supervisor is a client/server system that allows \\# its users to monitor and control a number of processes on \\# UNIX-like operating systems.# processname: supervisord# config: /etc/supervisord.conf# config: /etc/sysconfig/supervisord# pidfile: /var/run/supervisord.pid#### BEGIN INIT INFO# Provides: supervisord# Required-Start: $all# Required-Stop: $all# Short-Description: start and stop Supervisor process control system# Description: Supervisor is a client/server system that allows# its users to monitor and control a number of processes on# UNIX-like operating systems.### END INIT INFO# Source function library. /etc/rc.d/init.d/functions# Source system settingsif [ -f /etc/sysconfig/supervisord ]; then . /etc/sysconfig/supervisordfi# Path to the supervisorctl script, server binary,# and short-form for messages.supervisorctl=/usr/local/bin/supervisorctlsupervisord=$&#123;SUPERVISORD-/usr/local/bin/supervisord&#125;prog=supervisordpidfile=$&#123;PIDFILE-/tmp/supervisord.pid&#125;lockfile=$&#123;LOCKFILE-/var/lock/subsys/supervisord&#125;STOP_TIMEOUT=$&#123;STOP_TIMEOUT-60&#125;OPTIONS=\"$&#123;OPTIONS--c /etc/supervisord.conf&#125;\"RETVAL=0start() &#123; echo -n $\"Starting $prog: \" daemon --pidfile=$&#123;pidfile&#125; $supervisord $OPTIONS RETVAL=$? echo if [ $RETVAL -eq 0 ]; then touch $&#123;lockfile&#125; $supervisorctl $OPTIONS status fi return $RETVAL&#125;stop() &#123; echo -n $\"Stopping $prog: \" killproc -p $&#123;pidfile&#125; -d $&#123;STOP_TIMEOUT&#125; $supervisord RETVAL=$? echo [ $RETVAL -eq 0 ] &amp;&amp; rm -rf $&#123;lockfile&#125; $&#123;pidfile&#125;&#125;reload() &#123; echo -n $\"Reloading $prog: \" LSB=1 killproc -p $pidfile $supervisord -HUP RETVAL=$? echo if [ $RETVAL -eq 7 ]; then failure $\"$prog reload\" else $supervisorctl $OPTIONS status fi&#125;restart() &#123; stop start&#125;case \"$1\" in start) start ;; stop) stop ;; status) status -p $&#123;pidfile&#125; $supervisord RETVAL=$? [ $RETVAL -eq 0 ] &amp;&amp; $supervisorctl $OPTIONS status ;; restart) restart ;; condrestart|try-restart) if status -p $&#123;pidfile&#125; $supervisord &gt;&amp;/dev/null; then stop start fi ;; force-reload|reload) reload ;; *) echo $\"Usage: $prog &#123;start|stop|restart|condrestart|try-restart|force-reload|reload&#125;\" RETVAL=2 esac exit $RETVAL script來源 增加權限 sudo chmod +x /etc/init.d/supervisord 將新增的開機重啟配置檔加到系統 sudo chkconfig --add supervisord 打開自動重啟功能，並開始 sudo chkconfig supervisord on;sudo service supervisord start 在設定好配置檔之前，如何關閉 supervisord ? ps -ef | grep supervisord kill -s SIGTERM 29646 結論完成設定後，每次 reboot ， AWS 就會自動地重啟 supervisor","link":"/zh-tw/supervisor/"},{"title":"使用Laravel任務排程","text":"打開排程檔案打開yourProjectName/app/Console/Kernel.php 輸入你的排程排程範例如下： protected function schedule(Schedule $schedule)&#123; $schedule-&gt;call(function () &#123; Token::where(&apos;expiry_time&apos;, &apos;&lt;&apos;, time())-&gt;delete(); PaymentServiceOrders::deleteExpiredOrders(); Order::where(&apos;expiry_time&apos;, &apos;&lt;&apos;, Carbon::now())-&gt;delete(); &#125;)-&gt;daily();&#125; 我設定的任務排程，是每天固定刪除資料庫裡過期的訂單。 將Laravel排程加入到Linux的crontab中 sudo vim /etc/crontab * * * * * apache cd /var/www/html/yourProjectName &amp;&amp; php artisan schedule:run &gt;&gt; /dev/null 2&gt;&amp;1 前面的 * 依序分別代表 分(0-59) 時(0-23) 每月的第幾天(1-31) 月份(1-12) 每週的第幾天(0-6) apache表示使用者，這關乎權限問題，當執行的schedule中出現錯誤，log會由此使用者而建立，若權限沒有設好，之後的使用者都將無法讀取log，會造成，若我們本身有額外記log的話，會因為此log檔無法被開啟而造成錯誤 cd ray cd /var/www/html/yourProjectName到該目錄底下 php artisan schedule:run &gt;&gt; /dev/null 2&gt;&amp;1執行Laravel的排程指令 以上，這樣應該就可以順利地跑起來了！","link":"/zh-tw/taskSchedulingInLaravel/"},{"title":"使用MySQL- group by 來整理資料庫 2","text":"哈囉大家好，我是Ray！ 今天想要跟大家分享group by 的更進一步的操作，如何使用group by 配合select 相對應的選項，新建一個表格，並在新表格內將資料重新整理爲我們需要的row and column。 首先，延續昨天的進度，如下圖所示，我們將降雨量根據天來做分類，那如果說今天我們需要月的降雨量，或者年雨量總和呢？￼ 請參考以下的code: &lt;?php// SELECT後面的year(date)以及month(date)表示SELECT這兩項資料，// 括號後的year以及month表示顯示出來的欄位名稱，sum表示加總括號內欄位資料的總和,// 括號內的rainfall爲欄位名稱，括號後的表示顯示出來的欄位名稱，一樣使用group by，// 使資料以月份以及年分來做顯示，order by 表示依照先後順序由先到後作排列。$selectQuery = &apos;SELECT year(date) year, month(date) month, sum(rainfall) rainfall from rainfall_by_date group by month(date), year(date) order by year(date) asc, month(date) asc;&apos;;// 向資料庫作select 請求$selectResult = mysqli_query($dbc, $selectQuery);// 使用迴圈來重複請求，直到拿出所有位於$selectResult物件中的所有arraywhile ($selectRow = mysqli_fetch_array($selectResult))&#123; // 將我們從rainfall_by_date取得的資料insert進新表格rainfall_by_month $insertQuery = &apos;INSERT INTO rainfall_by_month (year, month, rainfall) VALUES(&quot;&apos; . $selectRow[&apos;year&apos;] . &apos;&quot;, &quot;&apos; . $selectRow[&apos;month&apos;] . &apos;&quot;, &quot;&apos; . $selectRow[&apos;rainfall&apos;] . &apos;&quot;)&apos;; // 作insert請求 $insertResult = mysqli_query($dbc, $insertQuery);&#125; 執行以上的script之後，可以得到新的表格，如下：￼","link":"/zh-tw/useGroupByToOrganiseYourDatabasePart2/"},{"title":"使用MySQL- group by 來整理資料庫","text":"大家好，我是Ray! 昨天跟大家分享如何正確的導入中文的資訊到資料庫裡，今天呢，我將分享如何使用MySQL的group by 來整理資料庫！ 在上圖我們可以看到，所有資料都以不同的地區來做劃分。假設右手邊的欄位資料爲降雨量好了，如果我們今天想要取得全地區的平均降雨量，該怎麼作呢？我們可以使用MySQL的group by 來達到我們的目的。 輸入以下code:select date, avg(rainfall) rainfall from rainfall group by date; 上面的date代表我日期欄位的名稱，avg代表平均值，rainfall代表降雨量欄位的名稱，而在括號後面又出現一次rainfall代表顯示在取得的資料表上的欄位的名稱，最後一個rainfall則是我這個表格的名稱。由於我select的項目裡並沒有地區，而最後的group by 表示資料將以date下去做重新整理，如果有相同天數的欄位就會自動重整，並使用我前面下的avg平均化處理。 得出的結果如下圖：￼ 我們下次見。","link":"/zh-tw/useGroupByToOrganiseYourDatabase/"},{"title":"使用 BigQuery 以及 Stackdriver 來分析 BigQuery 用量","text":"前言本篇主要是利用 Google 的 Qwiklab 平台學習的同時，做的一份學習筆記為避免翻譯誤解，專業術語在本篇將不會被翻譯，保留原文 概述Stackdriver Logging 讓你可以在 Google Cloud Platform 的服務上，針對紀錄作儲存，分析，搜尋，監控，以及警告還有事件，包含 BigQuery 服務。Stackdriver 也提供匯出特定記錄到接收器的功能，例如 Cloud Pub/Sub, Cloud Storage, 或 BigQuery 在本教程中，你將在 Stackdriver 中檢視 BigQuery 的紀錄，設定接收器來匯出記錄到 BigQuery, 然後使用 SQL 來分析這些紀錄 設定及要求 Qwiklabs setup在你按下 Start Lab 按鈕之前 詳讀所有的教學。Labs 是有時間限制的，而且你不可以停止時間倒數。倒數計時器在你按下 Start Lab 按鈕後開始倒數，上面顯示的時間為你還能使用 Cloud 資源的時間。 Quiklabs 的手把手環境，讓你可以在真實環境中來操作進行 Quiclabs 上提供的課程，而不是在一個模擬或是展示的環境。我們透過提供你一個全新的、暫時的帳號密碼，在計時器歸零之前，你可以用來登入並存取 Google Cloud Platform。 你需要什麼？ 要完成這個 lab ，你需要: 一個一般的網路瀏覽器（推薦 Chrome） 完成這個 lab 的時間 備註： 如果你已經有你自己的個人 GCP 帳號或專案，請不要使用在這一個 lab 現在你已經開始你的 lab, 你將會登入 Google Cloud Shell 主控台，然後開啟命令列工具 如何開始你的 lab ，然後登入 Console? 按下 Start Lab 按鈕。如果你需要付費，會有一個彈出視窗來讓你選擇付費的方式。在左方你會看到一個面板，上面有暫時的帳號密碼，你必須使用這些帳號密碼在此次 lab 複製 username , 然後點擊 Open Google Console。 Lab 會開啟另外一個視窗，顯示選擇帳號的頁面 tip: 開啟一個全新的視窗，然後跟原本的頁面並排 在選擇帳號頁面, 點擊 Use Another Account 登入頁面開啟，貼上之前複製的 username 以及 password ，然後貼上 重要：必須使用之前於 Connection Details 面板 取得的帳號密碼，不要使用你自己的 Qwiklabs 帳號密碼。 如果你有自己的 GCP 帳號，請不要用在這裡（避免產生費用） 點擊並通過接下來的頁面: 接受terms以及conditions 不要增加recovery optoins 或 two factor authentication (因為這只是一個臨時帳號) 不要註冊免費體驗 稍待一些時候， GCP 控制台將會在這個視窗開啟。 注意：按下左上方位於Google Cloud Platform 隔壁的 Navigation menu ，你可以瀏覽選單，裡面有一系列的 GCP 產品以及服務 啟動 Google Cloud ShellGoogle Cloud Shell 是載有開發工具的虛擬機器。它提供了5GB的 home 資料夾，並且運行在 Google Cloud 上。 Google Cloud Shell 讓你可以利用 command-line 存取 GCP 資源 在 GCP 控制台 ，右上的工具列，點擊 Open Cloud Shell 按鈕 在打開的對話框裡，按下 START CLOUD SHELL: 你可以立即按下 START CLOUD SHELL 當對話視窗打開。 連結並提供環境會需要一點時間。當你連結成功，這代表你已成功獲得授權，且此專案已被設為你的專案ID，例如： gcloud 是 Google Cloud Platform 的 command-line 工具，他已事先被安裝在 Cloud Shell 並且支援自動補齊 使用這個 command ,你可以列出有效帳戶名稱: gcloud auth list 輸出: Credentialed accounts: - &lt;myaccount&gt;@&lt;mydomain&gt;.com (active) 範例輸出: Credentialed accounts: - google1623327_student@qwiklabs.net 你可以使用以下 command 來列出專案 ID gcloud config list project 輸出： [core]project = &lt;project_ID&gt; 範例輸出： [core]project = qwiklabs-gcp-44776a13dea667a6 gcloud 的完整文件可以參閱 Google Cloud gcloud Overview 打開 BigQuery 打開 Big Query 主控台在 Google Cloud Console, 選擇 Navigation menu &gt; BigQuery Welcome to BigQuery in the Cloud Console 訊息視窗彈出。這個訊息視窗提供快速導覽的連結，以及一些更新訊息 點擊 Done BigQuery 主控台開啟 建立資料組 在 Resources 區塊中，點擊 qwiklabs-gcp- 開頭的資源 點擊 CREATE DATASET 設定 Dataset ID 到 bq_logs 點擊 Create dataset 執行一個查詢首先，執行一個簡單的查詢，在 Stackdriver 中產生一筆紀錄。 之後，你將使用這個紀錄來簡單設置匯出功能，從 Stackdriver 到 BigQuery 複製底下代碼，然後在 BigQuery 的查詢編輯器中貼上 SELECT current_date 點擊 Run 設定從 Stackdriver 匯出紀錄在 Stackdriver 檢視紀錄 在 Google Cloud Console 選擇 Navigation menu &gt; Logging &gt; Logs Viewer 在第一個下拉視窗的搜索框中，選擇 BigQuery 應會看到幾筆紀錄出現 尋找含有 “jobcompleted” 字串的紀錄 點擊位於左方，下圖中的三角箭頭來打開數據，然後在右手邊點擊 Expand all 這將以 JSON 格式來顯示數據，往下滑看看不一樣的欄位 回到剛剛的開頭處，點擊 ‘jobcompleted’ 然後選擇 Show Matching Entries 這將會完成正確的搜尋設定 建立匯出現在你有需要的紀錄了，很簡單的就可以設定匯出 在搜尋框上方，點擊 Create Export 在右手邊，依照下面給的資訊輸入 (1) Sink name: JobComplete (2) Sink Service: BigQuery (3) Sink Destination: bq_logs (我們之前設定的資料組) 點擊 Create Sink 點擊 CLOSE 之後任何的紀錄都會被匯出到這一個 bq_logs 資料組 執行範例查詢為了讓新的表格載入入一些紀錄，我們需要執行一些範例的查詢 移動到 Cloud Shell , 複製下面的代碼，然後貼到 Cloud Shell 上 bq query --location=us --use_legacy_sql=false --use_cache=false 'SELECT fullName, AVG(CL.numberOfYears) avgyearsFROM `bigquery-samples.nested.persons_living`, UNNEST(citiesLived) as CLGROUP BY fullname' bq query --location=us --use_legacy_sql=false --use_cache=false 'select month, avg(mean_temp) as avgtempfrom `bigquery-samples.weather_geo.gsod`where station_number = 947680and year = 2010group by monthorder by month' bq query --location=us --use_legacy_sql=false --use_cache=false 'select CONCAT(departure_airport, \"-\", arrival_airport) as route, count(*) as numberflightsfrom `bigquery-samples.airline_ontime_data.airline_id_codes` ac,`bigquery-samples.airline_ontime_data.flights` flwhere ac.code = fl.airline_codeand regexp_contains(ac.airline , r\"Alaska\")group by 1order by 2 descLIMIT 10' 你將會看到每筆查詢回應的結果 在 BigQuery 中檢視紀錄 移動到 BigQuery (Navigation menu &gt; BigQuery) 展開 qwiklabs-gcp- 開頭的資源，並且檢查 bq_logs 資料組 你應該可以看到一個表格 名字可能會跟下面的不太一樣，但看起來應該差不多“cloudaudit_googleapis_com_data_access_2019-06-19” 檢查表格的結構，然後注意到它有很大數量的欄位 如果你試著預覽，並且想知道為什麼它沒有顯示出你最近查詢的紀錄，那是因為紀錄是被串流到表格，這顯示新的資料可以被查詢但不會立即顯示在預覽 為了提高表格可用性，你可以建立 VIEW, 它可以取出子欄位的資料，然後執行一些計算來獲得查詢時間的指標 在 BigQuery 的查詢編輯器，將 替換成你的 project name (在 Qwiklab 視窗左手邊可以很簡單的複製) 後，執行以下的 SQL CREATE OR REPLACE VIEW bq_logs.v_querylogs ASSELECT resource.labels.project_id, protopayload_auditlog.authenticationInfo.principalEmail, protopayload_auditlog.servicedata_v1_bigquery.jobCompletedEvent.job.jobConfiguration.query.query, protopayload_auditlog.servicedata_v1_bigquery.jobCompletedEvent.job.jobConfiguration.query.statementType, protopayload_auditlog.servicedata_v1_bigquery.jobCompletedEvent.job.jobStatus.error.message, protopayload_auditlog.servicedata_v1_bigquery.jobCompletedEvent.job.jobStatistics.startTime, protopayload_auditlog.servicedata_v1_bigquery.jobCompletedEvent.job.jobStatistics.endTime, TIMESTAMP_DIFF(protopayload_auditlog.servicedata_v1_bigquery.jobCompletedEvent.job.jobStatistics.endTime, protopayload_auditlog.servicedata_v1_bigquery.jobCompletedEvent.job.jobStatistics.startTime, MILLISECOND)/1000 AS run_seconds, protopayload_auditlog.servicedata_v1_bigquery.jobCompletedEvent.job.jobStatistics.totalProcessedBytes, protopayload_auditlog.servicedata_v1_bigquery.jobCompletedEvent.job.jobStatistics.totalSlotMs, ARRAY(SELECT as STRUCT datasetid, tableId FROM UNNEST(protopayload_auditlog.servicedata_v1_bigquery.jobCompletedEvent.job.jobStatistics.referencedTables)) as tables_ref, protopayload_auditlog.servicedata_v1_bigquery.jobCompletedEvent.job.jobStatistics.totalTablesProcessed, protopayload_auditlog.servicedata_v1_bigquery.jobCompletedEvent.job.jobStatistics.queryOutputRowCount, severityFROM `&lt;YOUR-PROJECT-ID&gt;.bq_logs.cloudaudit_googleapis_com_data_access_*`ORDER BY startTime 現在可以查詢 VIEW, 執行以下指令 SELECT * FROM bq_logs.v_querylogs 檢視結果檢視你之前執行的三筆查詢，跟下圖類似 恭喜你已經完成本教程","link":"/zh-tw/usingBigQueryAndStackdriverToAnalyzeBigQuerryUsage/"},{"title":"Using Google Stackdriver Debug, Traces, Logging And Logpoints","text":"前言&lt;未完待續&gt;本篇主要是利用 Google 的 Qwiklab 平台學習的同時，做的一份學習筆記為避免翻譯誤解，專業術語在本篇將不會被翻譯，保留原文 概述這個教程將帶你好好走一趟 Google Stackdriver, 你將學到如何在你 Google Cloud Platform 的應用作以下的操作： 為運行在 App Engine, Compute Engine, Container Engine 的應用製作 Debug Snapshot(Debug 快照) 無需部署額外的 app 即可在 運行中的應用加入 log point (紀錄點)。 這是一個真正獨特的功能(且希望是有幫助的)。 追蹤 API calls並且獲取回應時間統計以及代碼內的潛在的瓶頸 檢視Application Logs (應用紀錄) 你將會從 0 開始做下面這些事: 建立一個 Google Cloud Platform 專案 (特別是 App Engine) 設定 Google Cloud platform 專案源碼倉庫 利用 Github 上可獲得的標準的 Guestbook Python Application 源碼 部署代碼 看如何在運行中的應用上獲得 Debug 快照 瞧瞧 Logging (紀錄) 以及 Application Call Traces (應用呼叫追蹤) 在目前運行的應用上加入 logpoints (紀錄點) 設定及要求 在你按下 Start Lab 按鈕之前 詳讀所有的教學。Labs 是有時間限制的，而且你不可以停止時間倒數。倒數計時器在你按下 Start Lab 按鈕後開始倒數，上面顯示的時間為你還能使用 Cloud 資源的時間。 Qwiklabs 的手把手環境，讓你可以在真實環境中來操作進行 Qwiklabs 上提供的課程，而不是在一個模擬或是展示的環境。我們透過提供你一個全新的、暫時的帳號密碼，在計時器歸零之前，你可以用來登入並存取 Google Cloud Platform。 你需要什麼？ 要完成這個 lab ，你需要: 一個一般的網路瀏覽器（推薦 Chrome） 完成這個 lab 的時間 備註： 如果你已經有你自己的個人 GCP 帳號或專案，請不要使用在這一個 lab 現在你已經開始你的 lab, 你將會登入 Google Cloud Shell 主控台，然後開啟命令列工具 如何開始你的 lab ，然後登入 Console? 按下 Start Lab 按鈕。如果你需要付費，會有一個彈出視窗來讓你選擇付費的方式。在左方你會看到一個面板，上面有暫時的帳號密碼，你必須使用這些帳號密碼在此次 lab 複製 username , 然後點擊 Open Google Console。 Lab 會開啟另外一個視窗，顯示選擇帳號的頁面 tip: 開啟一個全新的視窗，然後跟原本的頁面並排 在選擇帳號頁面, 點擊 Use Another Account 登入頁面開啟，貼上之前複製的 username 以及 password ，然後貼上 重要：必須使用之前於 Connection Details 面板 取得的帳號密碼，不要使用你自己的 Qwiklabs 帳號密碼。 如果你有自己的 GCP 帳號，請不要用在這裡（避免產生費用） 點擊並通過接下來的頁面: 接受terms以及conditions 不要增加recovery optoins 或 two factor authentication (因為這只是一個臨時帳號) 不要註冊免費體驗 稍待一些時候， GCP 控制台將會在這個視窗開啟。 注意：按下左上方位於Google Cloud Platform 隔壁的 Navigation menu ，你可以瀏覽選單，裡面有一系列的 GCP 產品以及服務 啟動 Google Cloud ShellGoogle Cloud Shell 是載有開發工具的虛擬機器。它提供了5GB的 home 資料夾，並且運行在 Google Cloud 上。 Google Cloud Shell 讓你可以利用 command-line 存取 GCP 資源 在 GCP 控制台 ，右上的工具列，點擊 Open Cloud Shell 按鈕 在打開的對話框裡，按下 START CLOUD SHELL: 你可以立即按下 START CLOUD SHELL 當對話視窗打開。 連結並提供環境會需要一點時間。當你連結成功，這代表你已成功獲得授權，且此專案已被設為你的專案ID，例如： gcloud 是 Google Cloud Platform 的 command-line 工具，他已事先被安裝在 Cloud Shell 並且支援自動補齊 使用這個 command ,你可以列出有效帳戶名稱: gcloud auth list 輸出: Credentialed accounts: - &lt;myaccount&gt;@&lt;mydomain&gt;.com (active) 範例輸出: Credentialed accounts: - google1623327_student@qwiklabs.net 你可以使用以下 command 來列出專案 ID gcloud config list project 輸出： [core]project = &lt;project_ID&gt; 範例輸出： [core]project = qwiklabs-gcp-44776a13dea667a6 gcloud 的完整文件可以參閱 Google Cloud gcloud Overview 建立 Stackdriver workspace (工作區)在 Navigation menu, 點擊 Monitoring 當你看到 Stackdriver dashboard (顯示面版)，代表你的工作區已經準備好了 測試進度點擊 Check my progress 來確認目前的進度。 設定並且加載你的私人 Git 倉庫每一個 Google Cloud Platform 都有提供私人的 Git 服務器，但首先你需要先建立一個預設的倉庫 回到主控台，並且到 Navigation menu &gt; Source Repositories &gt; Add Repository: 選擇 Create new repository, 然後選擇 Continue 將新的 repository 命名為 “DEFAULT”, 然後點擊 Create 測試完成任務 點擊 Check my progress 來確認目前的進度。 在 Cloud Shell, 利用以下的指令建立一個資料夾並且進入到這個資料夾內： mkdir stackdriver-demo cd stackdriver-demo/ 現在複製 DEFAULT repository gcloud source repos clone DEFAULT 你應該會看到輸出如下： Cloning into &apos;/home/gcp123_student/default&apos;...warning: You appear to have cloned an empty repository.Project [qwiklabs-gcp-1234abc1234] repository [default] was cloned to [/home/gcp123_student/default]. 對的，你沒有看錯，你複製了一個空的 repository - 沒錯。 現在花點時間來研究一下這已經設定好的 git remote, 然後你將會更了解背地裡發生了什麼事。 進到 DEFAULT 資料夾: cd DEFAULT 輸入 git remote -v 指令 git remote -v 你會看到類似以下輸出：origin https://source.developers.google.com/p/qwiklabs-gcp-1234abc1234/r/default (fetch)origin https://source.developers.google.com/p/qwiklabs-gcp-1234abc1234/r/default (push) 這指向了與你的 GCP 專案相關的 Git Repository 從 Github 上 Pull Guestbook 應用Guestbook 應用是可從官方 Google Cloud Platform 的 Github repository 上獲得的標準 App Engine 應用。 這個應用也是在 App Engine 上部署 Python 應用程式的官方文件一部分。 Github 專案可從此獲得：https://github.com/GoogleCloudPlatform/appengine-guestbook-python 運行以下指令來 Pull Guestbook 代碼到你的 Cloud Shell 實例git pull https://github.com/GoogleCloudPlatform/appengine-guestbook-python 輸出應該如下： remote: Enumerating objects: 493, done.remote: Total 493 (delta 0), reused 0 (delta 0), pack-reused 493Receiving objects: 100% (493/493), 437.58 KiB | 0 bytes/s, done.Resolving deltas: 100% (203/203), done.From https://github.com/GoogleCloudPlatform/appengine-guestbook-python * branch HEAD -&gt; FETCH_HEAD 現在你可以看到很多檔案都從 Github 專案 pull 下來了 利用 Cloud Shell 將目前的代碼 push 到 GCP 專案的 Git Repository利用 Cloud Shell 來將代碼 push 到 GCP 專案 Git repository, 所以你可以在你的代碼設定斷點。 但是我們並不一定要這麼做，因為我們還有其他的方法來連結源碼，像是直接與 Github 或從本地機器做整合 利用標準 git push 指令來 push 代碼 git push origin master 輸出應會如下：Counting objects: 485, done.Compressing objects: 100% (280/280), done.Writing objects: 100% (485/485), 436.42 KiB | 0 bytes/s, done.Total 485 (delta 195), reused 485 (delta 195)remote: Storing objects: 100% (485/485), done.remote: Processing commits: 100% (152/152), done.To https://source.developers.google.com/p/qwiklabs-gcp-1234abc1234/r/default* [new branch] master -&gt; master 現在，回到 GCP Cloud 主控台並重整頁面。 在 Source Repository, 點擊 Source Code, 你應該可以在 DEFAULT repository 中看到所有的專案檔案 部署並且使用 Guestbook 應用你已經完成部署前的工作，輸入 gcloud app deploy 指令來部署 Guestbook App Engine 應用gcloud app deploy --version 1 當被要求選擇一個 region, 選擇 us-east1 當跳出詢問視窗，選擇 “Y” 繼續 輸出應會如下 You are about to deploy the following services:— qwiklabs-gcp-1234abc1234/default/1 (from [/home/gcp123-student/default/app.yaml])Deployed URL: [https://qwiklabs-gcp-1234abc1234.appspot.com]Do you want to continue (Y/n)? YBeginning deployment of service [default]...File upload done.Updating service [default]...done.Deployed service [default] to https://qwiklabs-gcp-1234abc1234.appspot.com] 注意到我們提供了一個版本參數給 app deploy 的指令。 我們給了數值 &quot;1&quot; 測試進度 點擊 Check my progress 來確認目前的進度。 因為 Guestbook 應用使用 Google Cloud Datastore 來儲存，所以我們必須更新 Datastore 索引。 這個索引被指定在 index.yaml 檔案中 使用 gcloud datastore indexes create 指令:gcloud datastore indexes create index.yaml 控制台輸出應如下： Configurations to update:descriptor: [index.yaml]type: [datastore indexes]target project: [qwiklabs-gcp-39b46efbe8fc73bf]Do you want to continue (Y/n)? Y 詢問視窗中，輸入 Y 繼續 Datatore 的索引會耗費一些時間更新。 若要確認狀態，可到主控台中的 Navigation menu &gt; Datastore ，然後在左側面板點擊 Indexes 。 當索引正在被建立中時，你會看到狀態顯示為 “Indexing”: 測試進度點擊 Check my progress 來確認目前的進度。 你可以確認你的 App (version 1) 是否有部署成功且可用。 到 Navigation menu &gt; App Engine &gt; Versions: 現在應該一切都看起來 okay。 到 https://PROJECT_ID.appspot.com 看一下你的專案。 將 PROJECT_ID 替換成 Qwiklab 給的 ID 注意： 如果你看到 Internal Server Error, 一分鐘後再試一次，索引可能還在被建立中。 現在從 Guestbook 視窗，使用應用來建立一些數據 棒極了！ 現在你已經完成所有進到 Stackdriver 功能之前的準備工作 測試進度 點擊 Check my progress 來確認目前的進度。 Debug Snapshot (Debug 快照)當你想要 debug 一段特定的 code 時，或者你想要檢查一些變數，但你的應用還處於服務中，這時候快照將非常的有用。現在，當有任何人對你的首頁發請求，並且取得目前在 Datastore 中的問候清單時，你將要求一個快照。這段代碼位於 questbook.py 檔案。 並且，我們將開始在服務中檢查代表，當問候清單從 Datastore 被取得時。 這段代碼在 72 行結束，所以我們在 74 行設一個斷點，這樣我們能確定 72 行將會被執行。我們可以在主控台中使用 App Engine 檢視並且點擊 Tools 下拉選單，然後點擊 Debug 或者在 Stackdriver 瀏覽視窗，在左方面板點擊 Debug在左側面板點擊 guestbook.py, 然後點擊 74 行如下所示 訊息顯示，目前正在等待一個快照被觸發 現在，回到 Guestbook 視窗然後新增一筆數據。 回到 Debug 頁面，快照已被啟動，且 Variables 以及 Call Stack 區塊都被載入了。 你可以展開變數確認各自的值。 比方說，如果你展開 greetings 變數，你將會看到有一些記錄，且這些紀錄與我們之前建立 guestbook 數據的號碼相對應著。 有一個非常方便的功能，那就是我們可以隨時重新做一個快照。點擊照相機的圖示： 快照將會等待被觸發 你也可以使用 Expressions 欄位來追蹤特定的變數。 比方說，當快照被觸發時，我們要檢查一個變數在那一刻的值，我們可以在 Expressions 欄位內輸入變數的名稱 在 Expressions 欄位新增 “greetings”, 然後回到 Guestbook 視窗增加一個新的數據。 當快照被觸發時， greeting 的值將會被載入 如果你想要快照只在滿足特定條件時才被觸發的話，可以使用 Condition 欄位。 下方有個範例，意思是說當 greeting 的數量大於 1 時，快照才會被觸發。 你可以試試看！ 備註： 完整的 Stackdriver Debugger 文件在這:https://cloud.google.com/debugger/docs/ Logpoints (紀錄點)","link":"/zh-tw/usingGoogleStackdriverDebugTracesLoggingAndLogpoints/"},{"title":"Git log 裡面的東西是什麼？","text":"大家好，我是Ray! 今天想跟大家分享，git log 裡面的一些細節。 首先，我們先來看看下面的圖片： 我們可以看到，每一個commit後面都有一段非常長的隨機字串，那這是什麼呢？ 這是一串git 根據commit的內容，由SHA1生成的隨機驗證字串，也許你會問，什麼是SHA1? SHA1全名為security hash algorithm, 中文意思大概就是“安全加密演算法”。 諸如此類的演算法有好幾種，SHA系列的演算法是不可逆的，簡單來說，如果你拿到一串加密過的字串，就像上面那些驗證字串，你是沒有辦法透過將它逆轉回加密前的樣子。 有興趣的朋友可以google一下，這邊我們就不針對SHA多做討論！ 接下來介紹一個非常實用的指令，git log --oneline! 輸入git log --online 可以對照下圖，這是git log 與 git log --oneline的差別。 由上圖大家可以看到，git --oneline 拿掉了作者，日期相關資訊，並且只保留驗證字串的七碼！ 那我們之前提到的git checkout也可以使用這七碼來作切換嗎？ 輸入git checkout out cc92d2f (請輸入你電腦上的驗證字串，你的跟我的不一樣） 如上圖，我們已經成功的切換到前一個commit 輸入 git checkout master 輸入 git log --oneline 這樣就又切回來了！ 看完今天的文章，是不是對於git 有更深一層的理解了呢？ 我們明天見！","link":"/zh-tw/whatIsInGitLog/"},{"title":"為什麼我們要使用Git?","text":"大家好我是Ray! 今天要跟大家分享，為什麼要使用Git? 首先，你有沒有遇過，coding到一半忽然有急事要做（可能是你媽叫你，也可能是你忘記去接你女朋友） 然而很不巧的，當時你可能正在debug，又或者在開發一個新功能。 當你終於有空回去繼續coding時，靠！怎麼出錯啦～？ 滿滿的程式碼滿滿的邏輯不知道從何找起從何debug起～ 又或者，有時在開發新功能時，新功能不巧地影響到現有的功能，導致現有的功能也無法使用！ 當我們陷入一個無頭緒的狀態時，我們就想要回到還沒開始新功能的那一刻，很不巧的，我們早就已經養成定時存檔的良好習慣… 這些時候，就是Git出場的時候啦！ 當你在一些關鍵的時刻，又或者已經完成一個功能，而打算從這個功能為一個起點，開始一個新功能，這個時候你可以使用Git把它存檔起來，存檔後，你可以隨時回到你存擋的那一刻，這種回朔是跟你檔案本身存擋沒有關聯的，換句話說，就算你已經在編輯器或者是IDE上面存擋了，你也可以隨時地回到你使用Git設的存擋點！ 另外一個情況，除非你做的是一個人可以完成的小專案，否則只要是多人協作的專案都需要多人合作與配合，有沒有想過，當這麼多人來一起做一個案子甚至一個檔案，該如何有效地整合呢？畢竟coding是非常細緻的工作，就算你只錯了一個字也可以會造成整個功能無法使用啊！ 這個時候通常我們都會使用Git來整合，試想你的電腦上是一個你自己擁有的資料夾，當你在你的電腦上把你的部分完成之後，你把完成的部分上傳到一個公共的資料夾，而團隊內的其他成員也是用這種方式來上傳他們的部分，此時Git可以讓我們記錄所有人的部分並且將所有人的code合併已達到整合！ 所以對於一個coder來說，Git似乎是不可或缺的呢！","link":"/zh-tw/whyGitIsSoMuchRequired/"},{"title":"為什麼要使用VIM?","text":"哈囉大家好，我是Ray! 今天要來跟大家分享一款非常實用且歷史悠久的編輯器，它叫做Vim! 關於歷史來源背景，我這邊就不贅述了，在麻煩有興趣的讀者自行Google! Vim除了是一款專門爲coding而設計的編輯器之外，幾乎在所有有名的IDE，或者是Editor上，都可以找到Vim的插件，比如我所使用的PHPstorm，或者Subline。 在我們深入Vim之間，我們先來說說，爲什麼我們要使用Vim? 我個人在選擇成爲一名工程師之前，就已經使用標準指法，就是利用F以及J上的凸點來做定位而達到盲打，盲打就是蒙着眼睛也可以準確的打字哦！ 在開始寫程式之後，我最大的困擾並不是程式的語法或邏輯，而是我的手必須頻繁的在滑鼠、方向鍵、以及主鍵區之間作切換。 在我還未邂逅Vim之前，我一直在尋找可以自定義按鍵的鍵盤，因為我認為最理想的打字模式，就是我的手掌並不需要離開主鍵區而可以完成所有的操作。 理論上來說，如果兩個工程師有著同樣的經驗與邏輯，以及技術，打字速度較快的那個人肯定有著較高的輸出，意味著可以更快的完成任務。 如果你問我，那我沒事做那麼快做什麼？ 各位大大，時間就是金錢啊！！ 越快完成表示省下越多的時間，代表你可以運用的時間將越多！ 對於技術狂熱者，啊不對，是對技術有較高熱情的人來說，像是我，更多的時間表示可以學習更多的技術。 時間可以用來做非常多的事，說是比比特幣還珍貴也不為過！ 你可以用來陪家人、追劇、陪女朋友，阿～前提是你要先有女朋友，像我就沒有QQ。 Vim的最基本也最實用的功能，就是可以使用h, j, k, l四個鍵來當成上下左右，換言之，他已經解決我們最大的問題-需要在方向鍵區與主鍵區頻繁的移動。 Vim的功能區分為普通模式、輸入模式，以及選取模式，簡單來說，就是移動游標時會在普通模式，而輸入代碼時會在輸入模式，最後，當我們選取一整行要做複製或貼上甚至更複雜的動作時，會在選取模式。 看完以上的剖析，有沒有被Vim吸引到的感覺呢？ 今天的分享就到這裡，我們明天見！","link":"/zh-tw/whyWouldWeUseVIM/"},{"title":"My learning journey in Linux","text":"前言這是一份未整理過的 Linux 學習筆記OS 系統為 GCP 上的 Linux 18.04 LTS內容參考出處： 鳥哥的 Linux 的私房菜 Internet find 搜尋屬於特定 user 或 group 的檔案 find localtion -type f -user userName -group groupName -name fileName 搜尋屬於特定 user 或 group 的資料夾 find localtion -type d -user userName -group groupName -name fileName ps 列出系統正在執行的 process, 並且從中搜尋關鍵字ps -ef | node kill語法[root@study ~]# kill -signal %jobnumber[root@study ~]# kill -l選項與參數：-l ：這個是 L 的小寫，列出目前 kill 能夠使用的訊號 （signal） 有哪些？signal ：代表給予後面接的那個工作什麼樣的指示囉！用 man 7 signal 可知： -1 ：重新讀取一次參數的配置文件 （類似 reload）； -2 ：代表與由鍵盤輸入 [ctrl]-c 同樣的動作； -9 ：立刻強制刪除一個工作； -15：以正常的程序方式終止一項工作。與 -9 是不一樣的。 代號 名稱 內容 1 SIGHUP 啟動被終止的程序，可讓該 PID 重新讀取自己的配置文件，類似重新啟動 2 SIGINT 相當於用鍵盤輸入 [ctrl]-c 來中斷一個程序的進行 9 SIGKILL 代表強制中斷一個程序的進行，如果該程序進行到一半， 那麼尚未完成的部分可能會有“半產品”產生，類似 vim會有 .filename.swp 保留下來。 15 SIGTERM 以正常的結束程序來終止該程序。由於是正常的終止， 所以後續的動作會將他完成。不過，如果該程序已經發生問題，就是無法使用正常的方法終止時， 輸入這個 signal 也是沒有用的。 19 SIGSTOP 相當於用鍵盤輸入 [ctrl]-z 來暫停一個程序的進行 指令 立刻強制刪除一個工作kill -9 processID killall語法[root@study ~]# killall [-iIe] [command name]選項與參數：-i ：interactive 的意思，互動式的，若需要刪除時，會出現提示字符給使用者；-e ：exact 的意思，表示“後面接的 command name 要一致”，但整個完整的指令 不能超過 15 個字符。-I ：指令名稱（可能含參數）忽略大小寫。 ln 建立一個捷徑ln -s sourceAbsoluteLink targetAbsoluteLink du 查檔案大小du -sh fileOrFolder df 查硬碟空間使用率df -h [[]] 回傳 true or false[[ -f /.dockerenv ]] [[]] 會將裡頭的參數結果回傳 true or false-f 表示 file exists所以意思是，如果 /.dockerenv 存在，則回傳 true grep 搜尋內容並顯示附近的行數從 gcloud command 中取得資料，並且顯示 ssh-keys 後面的 5 行gcloud compute project-info describe | grep -A 5 ssh-keys groupdel 刪除 groupgroupdel groupName userdel 刪除 useruserdel userName useradduseradd [-u UID] [-g 初始群組] [-G 次要群組] [-mM]\\&gt; [-c 說明欄] [-d 主文件夾絕對路徑] [-s shell] 使用者帳號名選項與參數：-u ：後面接的是 UID ，是一組數字。直接指定一個特定的 UID 給這個帳號；-g ：後面接的那個群組名稱就是我們上面提到的 initial group 啦～ 該群組的 GID 會被放置到 /etc/passwd 的第四個字段內。-G ：後面接的群組名稱則是這個帳號還可以加入的群組。 這個選項與參數會修改 /etc/group 內的相關數據喔！-M ：強制！不要創建使用者主文件夾！（系統帳號默認值）-m ：強制！要創建使用者主文件夾！（一般帳號默認值）-c ：這個就是 /etc/passwd 的第五欄的說明內容啦～可以隨便我們設置的啦～-d ：指定某個目錄成為主文件夾，而不要使用默認值。務必使用絕對路徑！-r ：創建一個系統的帳號，這個帳號的 UID 會有限制 （參考 /etc/login.defs）-s ：後面接一個 shell ，若沒有指定則默認是 /bin/bash 的啦～-e ：後面接一個日期，格式為“YYYY-MM-DD”此項目可寫入 shadow 第八字段， 亦即帳號失效日的設置項目囉；-f ：後面接 shadow 的第七字段項目，指定密碼是否會失效。0為立刻失效， -1 為永遠不失效（密碼只會過期而強制於登陸時重新設置而已。） 完全參考默認值創建一個使用者，名稱為 Ray useradd Ray 建立一個 user, 並加到指定 group useradd -G groupName userName useradd 之後，系統會幫我們做哪些事？ 在 /etc/passwd 裡面創建一行與帳號相關的數據，包括創建 UID/GID/主文件夾等； 在 /etc/shadow 裡面將此帳號的密碼相關參數填入，但是尚未有密碼； 在 /etc/group 裡面加入一個與帳號名稱一模一樣的群組名稱； 在 /home 下面創建一個與帳號同名的目錄作為使用者主文件夾，且權限為 700 useradd 參考檔 這個數據其實是由 /etc/default/useradd 調用出來的 useradd -DGROUP=100 &lt;==默認的群組HOME=/home &lt;==默認的主文件夾所在目錄INACTIVE=-1 &lt;==密碼失效日，在 shadow 內的第 7 欄EXPIRE= &lt;==帳號失效日，在 shadow 內的第 8 欄SHELL=/bin/bash &lt;==默認的 shellSKEL=/etc/skel &lt;==使用者主文件夾的內容數據參考目錄CREATE_MAIL_SPOOL=yes &lt;==是否主動幫使用者創建郵件信箱（mailbox） GROUP=100：新建帳號的初始群組使用 GID 為 100 者系統上面 GID 為 100 者即是 users 這個群組，此設置項目指的就是讓新設使用者帳號的初始群組為 users 這一個的意思。 但是我們知道 CentOS 上面並不是這樣的，在 CentOS 上面默認的群組為與帳號名相同的群組。 舉例來說， vbird1 的初始群組為 vbird1 。怎麼會這樣啊？這是因為針對群組的角度有兩種不同的機制所致， 這兩種機制分別是： 私有群組機制：系統會創建一個與帳號一樣的群組給使用者作為初始群組。 這種群組的設置機制會比較有保密性，這是因為使用者都有自己的群組，而且主文件夾權限將會設置為 700 （僅有自己可進入自己的主文件夾） 之故。使用這種機制將不會參考 GROUP=100 這個設置值。代表性的 distributions 有 RHEL, Fedora, CentOS 等； 公共群組機制：就是以 GROUP=100 這個設置值作為新建帳號的初始群組，因此每個帳號都屬於 users 這個群組， 且默認主文件夾通常的權限會是“ drwxr-xr-x … username users … ”，由於每個帳號都屬於 users 群組，因此大家都可以互相分享主文件夾內的數據之故。代表 distributions 如 SuSE等。由於我們的 CentOS 使用私有群組機制，因此這個設置項目是不會生效的！不要太緊張啊！ HOME=/home：使用者主文件夾的基準目錄（basedir）使用者的主文件夾通常是與帳號同名的目錄，這個目錄將會擺放在此設置值的目錄後。所以 vbird1 的主文件夾就會在 /home/vbird1/ 了！很容易理解吧！ INACTIVE=-1：密碼過期後是否會失效的設置值我們在 shadow 文件結構當中談過，第七個字段的設置值將會影響到密碼過期後， 在多久時間內還可使用舊密碼登陸。這個項目就是在指定該日數啦！如果是 0 代表密碼過期立刻失效， 如果是 -1 則是代表密碼永遠不會失效，如果是數字，如 30 ，則代表過期 30 天后才失效。 EXPIRE=：帳號失效的日期就是 shadow 內的第八字段，你可以直接設置帳號在哪個日期後就直接失效，而不理會密碼的問題。 通常不會設置此項目，但如果是付費的會員制系統，或許這個字段可以設置喔！ SHELL=/bin/bash：默認使用的 shell 程序文件名系統默認的 shell 就寫在這裡。假如你的系統為 mail server ，你希望每個帳號都只能使用 email 的收發信件功能， 而不許使用者登陸系統取得 shell ，那麼可以將這裡設置為 /sbin/nologin ，如此一來，新建的使用者默認就無法登陸！ 也免去後續使用 usermod 進行修改的手續！ SKEL=/etc/skel：使用者主文件夾參考基準目錄這個咚咚就是指定使用者主文件夾的參考基準目錄囉～舉我們的範例一為例， vbird1 主文件夾 /home/vbird1 內的各項數據，都是由 /etc/skel 所複製過去的～所以呢，未來如果我想要讓新增使用者時，該使用者的環境變量 ~/.bashrc 就設置妥當的話，您可以到 /etc/skel/.bashrc 去編輯一下，也可以創建 /etc/skel/www 這個目錄，那麼未來新增使用者後，在他的主文件夾下就會有 www 那個目錄了！這樣瞭呼？ CREATE_MAIL_SPOOL=yes：創建使用者的 mailbox你可以使用“ ll /var/spool/mail/vbird1 ”看一下，會發現有這個文件的存在喔！這就是使用者的郵件信箱！ UID/GID 還有密碼參數 路徑 /etc/login.defsMAIL_DIR /var/spool/mail &lt;==使用者默認郵件信箱放置目錄 PASS_MAX_DAYS 99999 &lt;==/etc/shadow 內的第 5 欄，多久需變更密碼日數PASS_MIN_DAYS 0 &lt;==/etc/shadow 內的第 4 欄，多久不可重新設置密碼日數PASS_MIN_LEN 5 &lt;==密碼最短的字符長度，已被 pam 模塊取代，失去效用！PASS_WARN_AGE 7 &lt;==/etc/shadow 內的第 6 欄，過期前會警告的日數UID_MIN 1000 &lt;==使用者最小的 UID，意即小於 1000 的 UID 為系統保留UID_MAX 60000 &lt;==使用者能夠用的最大 UIDSYS_UID_MIN 201 &lt;==保留給使用者自行設置的系統帳號最小值 UIDSYS_UID_MAX 999 &lt;==保留給使用者自行設置的系統帳號最大值 UIDGID_MIN 1000 &lt;==使用者自訂群組的最小 GID，小於 1000 為系統保留GID_MAX 60000 &lt;==使用者自訂群組的最大 GIDSYS_GID_MIN 201 &lt;==保留給使用者自行設置的系統帳號最小值 GIDSYS_GID_MAX 999 &lt;==保留給使用者自行設置的系統帳號最大值 GIDCREATE_HOME yes &lt;==在不加 -M 及 -m 時，是否主動創建使用者主文件夾？UMASK 077 &lt;==使用者主文件夾創建的 umask ，因此權限會是 700USERGROUPS_ENAB yes &lt;==使用 userdel 刪除時，是否會刪除初始群組ENCRYPT_METHOD SHA512 &lt;==密碼加密的機制使用的是 sha512 這一個機制！ mailbox 所在目錄：使用者的默認 mailbox 文件放置的目錄在 /var/spool/mail，所以 vbird1 的 mailbox 就是在 /var/spool/mail/vbird1 囉！ shadow 密碼第 4, 5, 6 字段內容：通過 PASS_MAX_DAYS 等等設置值來指定的！所以你知道為何默認的 /etc/shadow 內每一行都會有“ 0:99999:7 ”的存在了嗎？^_^！不過要注意的是，由於目前我們登陸時改用 PAM 模塊來進行密碼檢驗，所以那個 PASS_MIN_LEN 是失效的！ UID/GID 指定數值：雖然 Linux 核心支持的帳號可高達 232 這麼多個，不過一部主機要作出這麼多帳號在管理上也是很麻煩的！ 所以在這裡就針對 UID/GID 的範圍進行規範就是了。上表中的 UID_MIN 指的就是可登陸系統的一般帳號的最小 UID ，至於 UID_MAX 則是最大 UID 之意。 要注意的是，系統給予一個帳號 UID 時，他是 （1）先參考 UID_MIN 設置值取得最小數值； （2）由 /etc/passwd 搜尋最大的 UID 數值， 將 （1） 與 （2） 相比，找出最大的那個再加一就是新帳號的 UID 了。我們上面已經作出 UID 為 1500 的 vbird2 ， 如果再使用“ useradd vbird4 ”時，你猜 vbird4 的 UID 會是多少？答案是： 1501 。 所以中間的 1004~1499 的號碼就空下來啦！ 而如果我是想要創建系統用的帳號，所以使用 useradd -r sysaccount 這個 -r 的選項時，就會找“比 201 大但比 1000 小的最大的 UID ”就是了。 ^_^ 使用者主文件夾設置值：為何我們系統默認會幫使用者創建主文件夾？就是這個“CREATE_HOME = yes”的設置值啦！這個設置值會讓你在使用 useradd 時， 主動加入“ -m ”這個產生主文件夾的選項啊！如果不想要創建使用者主文件夾，就只能強制加上“ -M ”的選項在 useradd 指令執行時啦！至於創建主文件夾的權限設置呢？就通過 umask 這個設置值啊！因為是 077 的默認設置，因此使用者主文件夾默認權限才會是“ drwx—— ”哩！ 使用者刪除與密碼設置值：使用“USERGROUPS_ENAB yes”這個設置值的功能是： 如果使用 userdel 去刪除一個帳號時，且該帳號所屬的初始群組已經沒有人隸屬於該群組了， 那麼就刪除掉該群組，舉例來說，我們剛剛有創建 vbird4 這個帳號，他會主動創建 vbird4 這個群組。 若 vbird4 這個群組並沒有其他帳號將他加入支持的情況下，若使用 userdel vbird4 時，該群組也會被刪除的意思。 至於“ENCRYPT_METHOD SHA512”則表示使用 SHA512 來加密密碼明文，而不使用舊式的 MD5。現在你知道啦，使用 useradd 這支程序在創建 Linux 上的帳號時，至少會參考： /etc/default/useradd/etc/login.defs/etc/skel/* usermodusermod [-cdegGlsuLU] username選項與參數：-c ：後面接帳號的說明，即 /etc/passwd 第五欄的說明欄，可以加入一些帳號的說明。-d ：後面接帳號的主文件夾，即修改 /etc/passwd 的第六欄；-e ：後面接日期，格式是 YYYY-MM-DD 也就是在 /etc/shadow 內的第八個字段數據啦！-f ：後面接天數，為 shadow 的第七字段。-g ：後面接初始群組，修改 /etc/passwd 的第四個字段，亦即是 GID 的字段！-G ：後面接次要群組，修改這個使用者能夠支持的群組，修改的是 /etc/group 囉～-a ：與 -G 合用，可“增加次要群組的支持”而非“設置”喔！-l ：後面接帳號名稱。亦即是修改帳號名稱， /etc/passwd 的第一欄！-s ：後面接 Shell 的實際文件，例如 /bin/bash 或 /bin/csh 等等。-u ：後面接 UID 數字啦！即 /etc/passwd 第三欄的數據；-L ：暫時將使用者的密碼凍結，讓他無法登陸。其實僅改 /etc/shadow 的密碼欄。-U ：將 /etc/shadow 密碼欄的 ! 拿掉，解凍啦！ 增加指定 user 的次要群組usermod -a -G groupName userName chmod 給予一個資料夾 SGID 屬性chmod 2777 folderName passwdpasswd [--stdin] [帳號名稱] &lt;==所有人均可使用來改自己的密碼[root@study ~]# passwd [-l] [-u] [--stdin] [-S] \\&gt; [-n 日數] [-x 日數] [-w 日數] [-i 日期] 帳號 &lt;==root 功能選項與參數：--stdin ：可以通過來自前一個管線的數據，作為密碼輸入，對 shell script 有幫助！-l ：是 Lock 的意思，會將 /etc/shadow 第二欄最前面加上 ! 使密碼失效；-u ：與 -l 相對，是 Unlock 的意思！-S ：列出密碼相關參數，亦即 shadow 文件內的大部分信息。-n ：後面接天數，shadow 的第 4 字段，多久不可修改密碼天數-x ：後面接天數，shadow 的第 5 字段，多久內必須要更動密碼-w ：後面接天數，shadow 的第 6 字段，密碼過期前的警告天數-i ：後面接“日期”，shadow 的第 7 字段，密碼失效日期 確認 OS 種類以及版本 使用 lsb_release ， 如果沒安裝的話，安裝它 sudo apt-get install lsb-release 查詢用法 lsb_release --help 輸出如下：-h, --help show this help message and exit-v, --version show LSB modules this system supports-i, --id show distributor ID-d, --description show description of this distribution-r, --release show release number of this distribution-c, --codename show code name of this distribution-a, --all show all of the above information-s, --short show requested information in short format 根據上面的資訊，想查詢明細的話lsb_release -a curl假設請求如下：curl -X POST \\ https://requestedURL \\ -H 'Content-Type: application/json' \\ -d '&#123;\"dataA\":\"content of data A\",\"dataB\":\"content of data B\"&#125;' -k -v -X 代表 request 的方式 ip 請由此查詢 -H 代表 header -d 代表傳送資料，等同於以 Content-Type: application/x-www-form-urlencoded 方式傳送 -k 若經由 https 發請求，需加上 -k -v 代表 verbose , 若要顯示回覆訊息，需加上 -v bash 環境配置文件bash 會根據有沒有登入來讀取相對應的環境配置文件 login shell /etc/profile /etc/profile.d/*.sh 被調用的條件如下： 在 /etc/profile.d/ 這個目錄內 擴展名為 .sh 使用者能夠具有 r 的權限 ~/.bash_profile or ~/.bash_login or ~/.profile (照順序讀，只會讀其中一個) ~/.bashrc (最終會讀取這一個文件) non-login shell ~/.bashrc etc/bashrc (會調用此文件) 流程圖 不小心刪除了 ~/.bashrc, 或是沒有這個文件，想創建怎麼辦？ 複製預設文件 cp /etc/skel/.bashrc ~/ 視需求修改 使立即生效source ~/.bashrc or . ~/.bashrc Base 64 decodebase64 --decode /tmp/encoded.txt &gt; /tmp/decoded.txt ncftpncftpput -u account -p password -P port -m -R ipOrDomain remoteLocation locationFileOrDirectory -u：指定登錄FTP服務器時使用的用戶名； -p：指定登錄FTP服務器時使用的密碼； -P：如果FTP服務器沒有使用默認的TCP協議的21端口，則使用此選項指定FTP服務器的端口號。 -m：在傳之前嘗試在目錄位置創建目錄(用於傳目錄的情況) -R：遞規傳子目錄 ufw 啟用防火牆服務 ufw enable 關閉防火牆服務 ufw disable 打開指定 port ufw allow port/tcp install 使用 install 指令，我們可以在創立一個 folder 或 file 的同時，指定 owner, group 以及 mode install -d -o &lt;user&gt; -g &lt;group&gt; -m &lt;mode&gt; &lt;path&gt; -d : directory -o : owner -g : group -m : mode 建立一個資料夾，並給予權限 install -d -o ray -g ray -m 2770 /tmp/ray 建立一個檔案，並給予權限 install -m 777 -o ray -g ray /dev/null filename.txt yumwhatprovides 找出有提供特定 command 的 packageyum whatprovides */commandYouAreLookingFor install 安裝特定的 packageyum insatll packageName regular expression特殊符號表 特殊符號 代表意義 [:alnum:] 代表英文大小寫字符及數字，亦即 0-9, A-Z, a-z [:alpha:] 代表任何英文大小寫字符，亦即 A-Z, a-z [:blank:] 代表空白鍵與 [Tab] 按鍵兩者 [:cntrl:] 代表鍵盤上面的控制按鍵，亦即包括 CR, LF, Tab, Del.. 等等 [:digit:] 代表數字而已，亦即 0-9 [:graph:] 除了空白字符 （空白鍵與 [Tab] 按鍵） 外的其他所有按鍵 [:lower:] 代表小寫字符，亦即 a-z [:print:] 代表任何可以被打印出來的字符 [:punct:] 代表標點符號 （punctuation symbol），亦即：” ‘ ? ! ; : # $… [:upper:] 代表大寫字符，亦即 A-Z [:space:] 任何會產生空白的字符，包括空白鍵, [Tab], CR 等等 [:xdigit:] 代表 16 進位的數字類型，因此包括： 0-9, A-F, a-f 的數字與字符 基礎正規表達式字符彙整 RE 字符 意義與範例 ^word 意義：待搜尋的字串（word）在行首！ 範例：搜尋行首為 # 開始的那一行，並列出行號 grep -n &#39;^#&#39; regular_express.txt word$ 意義：待搜尋的字串（word）在行尾！ 範例：將行尾為 ! 的那一行打印出來，並列出行號 grep -n &#39;!$&#39; regular_express.txt . 意義：代表“一定有一個任意字符”的字符！ 範例：搜尋的字串可以是 （eve） （eae） （eee） （e e）， 但不能僅有 （ee） ！亦即 e 與 e 中間“一定”僅有一個字符，而空白字符也是字符！ grep -n &#39;e.e&#39; regular_express.txt \\ 意義：跳脫字符，將特殊符號的特殊意義去除！ 範例：搜尋含有單引號 ‘ 的那一行！ grep -n \\&#39; regular_express.txt * 意義：重複零個到無窮多個的前一個 RE 字符 範例：找出含有 （es） （ess） （esss） 等等的字串，注意，因為 可以是 0 個，所以 es 也是符合帶搜尋字串。另外，因為 為重複“前一個 RE 字符”的符號， 因此，在 之前必須要緊接著一個 RE 字符喔！例如任意字符則為 “.” ！ grep -n &#39;ess*&#39; regular_express.txt [list] 意義：字符集合的 RE 字符，裡面列出想要擷取的字符！ 範例：搜尋含有 （gl） 或 （gd） 的那一行，需要特別留意的是，在 [] 當中“謹代表一個待搜尋的字符”， 例如“ a[afl]y ”代表搜尋的字串可以是 aay, afy, aly 即 [afl] 代表 a 或 f 或 l 的意思！ grep -n &#39;g[ld]&#39; regular_express.txt [n1-n2] 意義：字符集合的 RE 字符，裡面列出想要擷取的字符範圍！ 範例：搜尋含有任意數字的那一行！需特別留意，在字符集合 [] 中的減號 - 是有特殊意義的，他代表兩個字符之間的所有連續字符！但這個連續與否與 ASCII 編碼有關，因此，你的編碼需要設置正確（在 bash 當中，需要確定 LANG 與 LANGUAGE 的變量是否正確！） 例如所有大寫字符則為 [A-Z] grep -n &#39;[A-Z]&#39; regular_express.txt [^list] 意義：字符集合的 RE 字符，裡面列出不要的字串或範圍！ 範例：搜尋的字串可以是 （oog） （ood） 但不能是 （oot） ，那個 ^ 在 [] 內時，代表的意義是“反向選擇”的意思。 例如，我不要大寫字符，則為 [^A-Z]。但是，需要特別注意的是，如果以 grep -n [^A-Z] regular_express.txt 來搜尋，卻發現該文件內的所有行都被列出，為什麼？因為這個 [^A-Z] 是“非大寫字符”的意思， 因為每一行均有非大寫字符，例如第一行的 “Open Source” 就有 p,e,n,o…. 等等的小寫字 grep -n &#39;oo[^t]&#39; regular_express.txt {n,m} 意義：連續 n 到 m 個的“前一個 RE 字符” 意義：若為 {n} 則是連續 n 個的前一個 RE 字符， 意義：若是 {n,} 則是連續 n 個以上的前一個 RE 字符！ 範例：在 g 與 g 之間有 2 個到 3 個的 o 存在的字串，亦即 （goog）（gooog） grep -n &#39;go\\{2,3\\}g&#39; regular_express.txt crontab安裝 CentOS yum install cronie ubuntu 代表意義 代表意義 分鐘 小時 日期 月份 周 指令 數字範圍 0-59 0-23 1-31 1-1 0-7 呀就指令啊 比較有趣的是那個“周”喔！周的數字為 0 或 7 時，都代表“星期天”的意思！另外，還有一些輔助的字符，大概有下面這些： 特殊字符 代表意義 *（星號） 代表任何時刻都接受的意思！舉例來說，範例一內那個日、月、周都是 * ， 就代表著“不論何月、何日的禮拜幾的 12:00 都執行後續指令”的意思！ ,（逗號） 代表分隔時段的意思。舉例來說，如果要下達的工作是 3:00 與 6:00 時，就會是： 0 3,6 * * * command 時間參數還是有五欄，不過第二欄是 3,6 ，代表 3 與 6 都適用！ -（減號） 代表一段時間範圍內，舉例來說， 8 點到 12 點之間的每小時的 20 分都進行一項工作：20 8-12 * * * command仔細看到第二欄變成 8-12 喔！代表 8,9,10,11,12 都適用的意思！ /n（斜線） 那個 n 代表數字，亦即是“每隔 n 單位間隔”的意思，例如每五分鐘進行一次，則：*/5 * * * * command很簡單吧！用 * 與 /5 來搭配，也可以寫成 0-59/5 ，相同意思！ /etc/crontab[root@study ~]# cat /etc/crontabSHELL=/bin/bash &lt;==使用哪種 shell 接口PATH=/sbin:/bin:/usr/sbin:/usr/bin &lt;==可執行文件搜尋路徑MAILTO=root &lt;==若有額外STDOUT，以 email將數據送給誰# Example of job definition:# .---------------- minute （0 - 59）# | .------------- hour （0 - 23）# | | .---------- day of month （1 - 31）# | | | .------- month （1 - 12） OR jan,feb,mar,apr ...# | | | | .---- day of week （0 - 6） （Sunday=0 or 7） OR sun,mon,tue,wed,thu,fri,sat# | | | | |# * * * * * user-name command to be executed MAILTO=root： 當 /etc/crontab 這個文件中的例行性工作的指令發生錯誤時，或者是該工作的執行結果有 STDOUT/STDERR 時，會將錯誤訊息或者是屏幕顯示的訊息送的對象 默認是由系統直接寄發一封 mail 給 root 例如：MAILTO=dmtsai@my.host.name PATH=….：輸入可執行文件的搜尋路徑，使用默認的路徑設置就已經很足夠了！ “分 時 日 月 周 身份 指令”七個字段的設置 這個 /etc/crontab 可以設置的基本語法與 crontab -e 不太相同 前面同樣是分、時、日、月、週五個字段， 但是在五個字段後面接的並不是指令，就是“執行後面那串指令的身份” 這與使用者的 crontab -e 不相同。由於使用者自己的 crontab 並不需要指定身份 crond 服務讀取配置文件/etc/crontab/etc/cron.d/*/var/spool/cron/* 跟系統的運行比較有關係的兩個配置文件是放在 /etc/crontab 文件內以及 /etc/cron.d/* 目錄內的文件 跟用戶自己的工作比較有關的配置文件放在 /var/spool/cron/ 其他 輸入 crontab job crontab -e 確認 crontab 狀態 /etc/init.d/cron status 停止 crontab /etc/init.d/cron stop 啟動 crontab /etc/init.d/cron start anacron語法[root@study ~]# anacron [-sfn] [job]..[root@study ~]# anacron -u [job]..選項與參數：-s ：開始一連續的執行各項工作 （job），會依據時間記錄文件的數據判斷是否進行；-f ：強制進行，而不去判斷時間記錄文件的時間戳記；-n ：立刻進行未進行的任務，而不延遲 （delay） 等待時間；-u ：僅更新時間記錄文件的時間戳記，不進行任何工作。job ：由 /etc/anacrontab 定義的各項工作名稱。 配置檔[root@study ~]# cat /etc/anacrontabSHELL=/bin/shPATH=/sbin:/bin:/usr/sbin:/usr/binMAILTO=rootRANDOM_DELAY=45 # 隨機給予最大延遲時間，單位是分鐘START_HOURS_RANGE=3-22 # 延遲多少個小時內應該要執行的任務時間1 5 cron.daily nice run-parts /etc/cron.daily7 25 cron.weekly nice run-parts /etc/cron.weekly@monthly 45 cron.monthly nice run-parts /etc/cron.monthly天數 延遲時間 工作名稱定義 實際要進行的指令串# 天數單位為天；延遲時間單位為分鐘；工作名稱定義可自訂，指令串則通常與 crontab 的設置相同！[root@study ~]# more /var/spool/anacron/*::::::::::::::/var/spool/anacron/cron.daily::::::::::::::20150731::::::::::::::/var/spool/anacron/cron.monthly::::::::::::::20150703::::::::::::::/var/spool/anacron/cron.weekly::::::::::::::20150727# 上面則是三個工作名稱的時間記錄文件以及記錄的時間戳記 拿 /etc/cron.daily/ 那一行的設置來說明，那四個字段的意義分別是： 天數：anacron 執行當下與時間戳記 （/var/spool/anacron/ 內的時間紀錄檔） 相差的天數，若超過此天數，就準備開始執行，若沒有超過此天數，則不予執行後續的指令。 延遲時間：若確定超過天數導致要執行調度工作了，那麼請延遲執行的時間，因為擔心立即啟動會有其他資源衝突的問題吧！ 工作名稱定義：這個沒啥意義，就只是會在 /var/log/cron 裡頭記載該項任務的名稱這樣！通常與後續的目錄資源名稱相同即可。 實際要進行的指令串：有沒有跟 0hourly 很像啊！沒錯！相同的作法啊！通過 run-parts 來處理的！ anacron 的執行流程（以 cron.daily 為例) 由 /etc/anacrontab 分析到 cron.daily 這項工作名稱的天數為 1 天； 由 /var/spool/anacron/cron.daily 取出最近一次執行 anacron 的時間戳記； 由上個步驟與目前的時間比較，若差異天數為 1 天以上 （含 1 天），就準備進行指令； 若準備進行指令，根據 /etc/anacrontab 的設置，將延遲 5 分鐘 + 3 小時 （看 START_HOURS_RANGE 的設置）； 延遲時間過後，開始執行後續指令，亦即“ run-parts /etc/cron.daily ”這串指令；執行完畢後， anacron 程序結束。 如此一來，放置在 /etc/cron.daily/ 內的任務就會在一天後一定會被執行的！ 因為 anacron 是每個小時被執行一次嘛！ 所以如果隔了一陣子將 CentOS 開機，開機過後約 1 小時左右系統會有一小段時間的忙碌！硬盤會跑個不停！那就是因為 anacron 正在執行過去 /etc/cron.daily/, /etc/cron.weekly/, /etc/cron.monthly/ 裡頭的未進行的各項工作調度 cron 與 anacron 與目錄之間的關係 crond 會主動去讀取 /etc/crontab, /var/spool/cron/, /etc/cron.d/ 等配置文件，並依據“分、時、日、月、周”的時間設置去各項工作調度； 根據 /etc/cron.d/0hourly 的設置，主動去 /etc/cron.hourly/ 目錄下，執行所有在該目錄下的可執行文件； 因為 /etc/cron.hourly/0anacron 這個指令檔的緣故，主動的每小時執行 anacron ，並調用 /etc/anacrontab 的配置文件； 根據 /etc/anacrontab 的設置，依據每天、每週、每月去分析 /etc/cron.daily/, /etc/cron.weekly/, /etc/cron.monthly/ 內的可執行文件，以進行固定週期需要執行的指令。 如果你每個週日的需要執行的動作是放置於 /etc/crontab 的話，那麼該動作只要過期了就過期了，並不會被抓回來重新執行。 如果是放置在 /etc/cron.weekly/ 目錄下，那麼該工作就會定期，幾乎一定會在一週內執行一次 test 測試的標誌 代表意義 1. 關於某個文件名的“文件類型”判斷，如 test -e filename 表示存在否 -e 該“文件名”是否存在？（常用） -f 該“文件名”是否存在且為文件（file）？（常用） -d 該“文件名”是否存在且為目錄（directory）？（常用） -b 該“文件名”是否存在且為一個 block device 設備？ -c 該“文件名”是否存在且為一個 character device 設備？ -S 該“文件名”是否存在且為一個 Socket 文件？ -p 該“文件名”是否存在且為一個 FIFO （pipe） 文件？ -L 該“文件名”是否存在且為一個鏈接文件？ 2. 關於文件的權限偵測，如 test -r filename 表示可讀否 （但 root 權限常有例外） -r 偵測該文件名是否存在且具有“可讀”的權限？ -w 偵測該文件名是否存在且具有“可寫”的權限？ -x 偵測該文件名是否存在且具有“可執行”的權限？ -u 偵測該文件名是否存在且具有“SUID”的屬性？ -g 偵測該文件名是否存在且具有“SGID”的屬性？ -k 偵測該文件名是否存在且具有“Sticky bit”的屬性？ -s 偵測該文件名是否存在且為“非空白文件”？ 3. 兩個文件之間的比較，如： test file1 -nt file2 -nt （newer than）判斷 file1 是否比 file2 新 -ot （older than）判斷 file1 是否比 file2 舊 -ef 判斷 file1 與 file2 是否為同一文件，可用在判斷 hard link 的判定上。 主要意義在判定，兩個文件是否均指向同一個 inode 哩！ 4. 關於兩個整數之間的判定，例如 test n1 -eq n2 -eq 兩數值相等 （equal） -ne 兩數值不等 （not equal） -gt n1 大於 n2 （greater than） -lt n1 小於 n2 （less than） -ge n1 大於等於 n2 （greater than or equal） -le n1 小於等於 n2 （less than or equal） 5. 判定字串的數據 test -z string 判定字串是否為 0 ？若 string 為空字串，則為 true test -n string 判定字串是否非為 0 ？若 string 為空字串，則為 false。 -n 亦可省略 test str1 == str2 判定 str1 是否等於 str2 ，若相等，則回傳 true test str1 != str2 判定 str1 是否不等於 str2 ，若相等，則回傳 false 6. 多重條件判定，例如： test -r filename -a -x filename -a （and）兩狀況同時成立！例如 test -r file -a -x file，則 file 同時具有 r 與 x 權限時，才回傳 true。 -o （or）兩狀況任何一個成立！例如 test -r file -o -x file，則 file 具有 r 或 x 權限時，就可回傳 true。 ! 反相狀態，如 test ! -x file ，當 file 不具有 x 時，回傳 true 變量變量的設置 變量設置方式 str 沒有設置 str 為空字串 str 已設置非為空字串 var=${str-expr} var=expr var= var=$str var=${str:-expr} var=expr var=expr var=$str var=${str+expr} var= var=expr var=expr var=${str:+expr} var= var= var=expr var=${str=expr} str=expr var=expr var=expr var= str 不變 var=$str var=${str:=expr} str=expr var=expr str=expr var=expr str 不變 var=$str var=${str?expr} expr 輸出至 stderr var= var=$str var=${str:?expr} expr 輸出至 stderr expr 輸出至 stderr var=$str Script 變量帶入規則： script 名稱，如 /path/to/scriptname opt1 opt2 opt3 opt4 $0 $1 $2 $3 $4 可以在 script 裡面使用的特殊變量$# ：代表後接的參數“個數”，以上表為例這裡顯示為“ 4 ”；$@ ：代表“ “$1” “$2” “$3” “$4” ”之意，每個變量是獨立的（用雙引號括起來）；$* ：代表“ “$1c$2c$3c$4” ”，其中 c 為分隔字符，默認為空白鍵， 所以本例中代表“ “$1 $2 $3 $4” ”之意。 條件判斷單一判斷式if [ 條件判斷式 ]; then 當條件判斷式成立時，可以進行的指令工作內容；fi &lt;==將 if 反過來寫，就成為 fi 啦！結束 if 之意！ 以下 test 的方式可改編成條件判斷式 test 方式read -p \"Please input （Y/N）: \" yn[ \"$&#123;yn&#125;\" == \"Y\" -o \"$&#123;yn&#125;\" == \"y\" ] &amp;&amp; echo \"OK, continue\" &amp;&amp; exit 0[ \"$&#123;yn&#125;\" == \"N\" -o \"$&#123;yn&#125;\" == \"n\" ] &amp;&amp; echo \"Oh, interrupt!\" &amp;&amp; exit 0echo \"I don't know what your choice is\" &amp;&amp; exit 0 條件判斷式PATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:~/binexport PATHread -p \"Please input （Y/N）: \" ynif [ \"$&#123;yn&#125;\" == \"Y\" ] || [ \"$&#123;yn&#125;\" == \"y\" ]; then echo \"OK, continue\" exit 0fiif [ \"$&#123;yn&#125;\" == \"N\" ] || [ \"$&#123;yn&#125;\" == \"n\" ]; then echo \"Oh, interrupt!\" exit 0fiecho \"I don't know what your choice is\" &amp;&amp; exit 0 多重、複雜條件判斷式一個條件判斷，分成功進行與失敗進行 （else）if [ 條件判斷式 ]; then 當條件判斷式成立時，可以進行的指令工作內容；else 當條件判斷式不成立時，可以進行的指令工作內容；fi 多個條件判斷 （if … elif … elif … else） 分多種不同情況執行if [ 條件判斷式一 ]; then 當條件判斷式一成立時，可以進行的指令工作內容；elif [ 條件判斷式二 ]; then 當條件判斷式二成立時，可以進行的指令工作內容；else 當條件判斷式一與二均不成立時，可以進行的指令工作內容；fi 將以下的 test 方式改成條件判斷式 改前:read -p \"Please input （Y/N）: \" yn[ \"$&#123;yn&#125;\" == \"Y\" -o \"$&#123;yn&#125;\" == \"y\" ] &amp;&amp; echo \"OK, continue\" &amp;&amp; exit 0[ \"$&#123;yn&#125;\" == \"N\" -o \"$&#123;yn&#125;\" == \"n\" ] &amp;&amp; echo \"Oh, interrupt!\" &amp;&amp; exit 0echo \"I don't know what your choice is\" &amp;&amp; exit 0 改後:#!/bin/bash# Program:# This program shows the user's choice# History:# 2015/07/16 VBird First releasePATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:~/binexport PATHread -p \"Please input （Y/N）: \" ynif [ \"$&#123;yn&#125;\" == \"Y\" ] || [ \"$&#123;yn&#125;\" == \"y\" ]; then echo \"OK, continue\"elif [ \"$&#123;yn&#125;\" == \"N\" ] || [ \"$&#123;yn&#125;\" == \"n\" ]; then echo \"Oh, interrupt!\"else echo \"I don't know what your choice is\"fi 利用 case ….. esac 判斷 語法： case $變量名稱 in &lt;==關鍵字為 case ，還有變量前有錢字號 \"第一個變量內容\"） &lt;==每個變量內容建議用雙引號括起來，關鍵字則為小括號 ） 程序段 ;; &lt;==每個類別結尾使用兩個連續的分號來處理！ \"第二個變量內容\"） 程序段 ;; *） &lt;==最後一個變量內容都會用 * 來代表所有其他值 不包含第一個變量內容與第二個變量內容的其他程序執行段 exit 1 ;;esac &lt;==最終的 case 結尾！“反過來寫”思考一下！ 範例： #!/bin/bash# Program:# Show \"Hello\" from $1.... by using case .... esac# History:# 2015/07/16 VBird First releasePATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:~/binexport PATHcase $&#123;1&#125; in \"hello\"） echo \"Hello, how are you ?\" ;; \"\"） echo \"You MUST input parameters, ex&gt; &#123;$&#123;0&#125; someword&#125;\" ;; *） # 其實就相當於萬用字符，0~無窮多個任意字符之意！ echo \"Usage $&#123;0&#125; &#123;hello&#125;\" ;;esac 練習題使用判斷式寫一個 script, 要可以做到以下幾件事： 先讓使用者輸入他們的退伍日期； 驗證輸入格式； 由兩個日期的比較來顯示“還需要幾天”才能夠退伍的字樣。 解答如下：#!/bin/bash# Program:# You input your demobilization date, I calculate how many days before you demobilize.# History:# 2015/07/16 VBird First releasePATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:~/binexport PATH# 1. 告知使用者這支程序的用途，並且告知應該如何輸入日期格式？echo \"This program will try to calculate :\"echo \"How many days before your demobilization date...\"read -p \"Please input your demobilization date （YYYYMMDD ex&gt;20150716）: \" date2# 2. 測試一下，這個輸入的內容是否正確？利用正則表達式囉～date_d=$（echo $&#123;date2&#125; |grep '[0-9]\\&#123;8\\&#125;'） # 看看是否有八個數字if [ \"$&#123;date_d&#125;\" == \"\" ]; then echo \"You input the wrong date format....\" exit 1fi# 3. 開始計算日期囉～declare -i date_dem=$（date --date=\"$&#123;date2&#125;\" +%s） # 退伍日期秒數declare -i date_now=$（date +%s） # 現在日期秒數declare -i date_total_s=$（（$&#123;date_dem&#125;-$&#123;date_now&#125;）） # 剩餘秒數統計declare -i date_d=$（（$&#123;date_total_s&#125;/60/60/24）） # 轉為日數if [ \"$&#123;date_total_s&#125;\" -lt \"0\" ]; then # 判斷是否已退伍 echo \"You had been demobilization before: \" $（（-1*$&#123;date_d&#125;）） \" ago\"else declare -i date_h=$（（$（（$&#123;date_total_s&#125;-$&#123;date_d&#125;*60*60*24））/60/60）） echo \"You will demobilize after $&#123;date_d&#125; days and $&#123;date_h&#125; hours.\"fi netstat這個指令可以看到目前有哪些 port 是對外開放的, 有哪些是 Listen 的 語法netstat -[atunlp]選項與參數：-a ：將目前系統上所有的連線、監聽、Socket 數據都列出來-t ：列出 tcp 網絡封包的數據-u ：列出 udp 網絡封包的數據-n ：不以程序的服務名稱，以埠號 （port number） 來顯示；-l ：列出目前正在網絡監聽 （listen） 的服務；-p ：列出該網絡服務的程序 PID function語法：function fname（） &#123; 程序段 注意： 因為 shell script 的執行方式是由上而下，由左而右， 因此在 shell script 當中的 function 的設置一定要在程序的最前面 function 內也可置變量，但跟 shell script 的內置變量方式不同 範例： 一般 #!/bin/bash# Program:# Use function to repeat information.# History:# 2015/07/17 VBird First releasePATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:~/binexport PATHfunction printit（）&#123; echo -n \"Your choice is \" # 加上 -n 可以不斷行繼續在同一行顯示&#125;echo \"This program will print your selection !\"case $&#123;1&#125; in \"one\"） printit; echo $&#123;1&#125; | tr 'a-z' 'A-Z' # 將參數做大小寫轉換！ ;; \"two\"） printit; echo $&#123;1&#125; | tr 'a-z' 'A-Z' ;; \"three\"） printit; echo $&#123;1&#125; | tr 'a-z' 'A-Z' ;; *） echo \"Usage $&#123;0&#125; &#123;one|two|three&#125;\" ;;esac 內置變量#!/bin/bash# Program:# Use function to repeat information.# History:# 2015/07/17 VBird First releasePATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:~/binexport PATHfunction printit（）&#123; echo \"Your choice is $&#123;1&#125;\" # 這個 $1 必須要參考下面指令的下達&#125;echo \"This program will print your selection !\"case $&#123;1&#125; in \"one\"） printit 1 # 請注意， printit 指令後面還有接參數！ ;; \"two\"） printit 2 ;; \"three\"） printit 3 ;; *） echo \"Usage $&#123;0&#125; &#123;one|two|three&#125;\" ;;esac loopwhile do done, until do done （不定循環）while do done語法while [ condition ] &lt;==中括號內的狀態就是判斷式do &lt;==do 是循環的開始！ 程序段落done &lt;==done 是循環的結束 範例#!/bin/bash# Program:# Repeat question until user input correct answer.# History:# 2015/07/17 VBird First releasePATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:~/binexport PATHwhile [ \"$&#123;yn&#125;\" != \"yes\" -a \"$&#123;yn&#125;\" != \"YES\" ]do read -p \"Please input yes/YES to stop this program: \" yndoneecho \"OK! you input the correct answer.\" #!/bin/bash# Program:# Use loop to calculate \"1+2+3+...+100\" result.# History:# 2015/07/17 VBird First releasePATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:~/binexport PATHs=0 # 這是加總的數值變量i=0 # 這是累計的數值，亦即是 1, 2, 3....while [ \"$&#123;i&#125;\" != \"100\" ]do i=$（（$i+1）） # 每次 i 都會增加 1 s=$（（$s+$i）） # 每次都會加總一次！doneecho \"The result of '1+2+3+...+100' is ==&gt; $s\" until do done語法until [ condition ]do 程序段落done 範例#!/bin/bash# Program:# Repeat question until user input correct answer.# History:# 2015/07/17 VBird First releasePATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:~/binexport PATHuntil [ \"$&#123;yn&#125;\" == \"yes\" -o \"$&#123;yn&#125;\" == \"YES\" ]do read -p \"Please input yes/YES to stop this program: \" yndoneecho \"OK! you input the correct answer.\" for…do…done （固定循環）語法for var in con1 con2 con3 ...do 程序段done 範例 假設我有三種動物，分別是 dog, cat, elephant 三種， 我想每一行都輸出這樣：“There are dogs…”之類的字樣，則可以： #!/bin/bash# Program:# Using for .... loop to print 3 animals# History:# 2015/07/17 VBird First releasePATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:~/binexport PATHfor animal in dog cat elephantdo echo \"There are $&#123;animal&#125;s.... \"done 系統上面的各種帳號都是寫在 /etc/passwd 內的第一個字段，所以請通過管線命令的 cut 捉出單純的帳號名稱後，以 id 分別檢查使用者的識別碼與特殊參數 #!/bin/bash# Program# Use id, finger command to check system account's information.# History# 2015/07/17 VBird first releasePATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:~/binexport PATHusers=$（cut -d ':' -f1 /etc/passwd） # 擷取帳號名稱for username in $&#123;users&#125; # 開始循環進行！do id $&#123;username&#125;done 讓使用者輸入某個目錄文件名， 然後我找出某目錄內的文件名的權限 #!/bin/bash# Program:# User input dir name, I find the permission of files.# History:# 2015/07/17 VBird First releasePATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:~/binexport PATH# 1. 先看看這個目錄是否存在啊？read -p \"Please input a directory: \" dirif [ \"$&#123;dir&#125;\" == \"\" -o ! -d \"$&#123;dir&#125;\" ]; then echo \"The $&#123;dir&#125; is NOT exist in your system.\" exit 1fi# 2. 開始測試文件囉～filelist=$（ls $&#123;dir&#125;） # 列出所有在該目錄下的文件名稱for filename in $&#123;filelist&#125;do perm=\"\" test -r \"$&#123;dir&#125;/$&#123;filename&#125;\" &amp;&amp; perm=\"$&#123;perm&#125; readable\" test -w \"$&#123;dir&#125;/$&#123;filename&#125;\" &amp;&amp; perm=\"$&#123;perm&#125; writable\" test -x \"$&#123;dir&#125;/$&#123;filename&#125;\" &amp;&amp; perm=\"$&#123;perm&#125; executable\" echo \"The file $&#123;dir&#125;/$&#123;filename&#125;'s permission is $&#123;perm&#125; \"done for…do…done 的數值處理語法- 初始值：某個變量在循環當中的起始值，直接以類似 i=1 設置好； - 限制值：當變量的值在這個限制值的範圍內，就繼續進行循環。例如 i&lt;=100； - 執行步階：每作一次循環時，變量的變化量。例如 i=i+1。 for （（ 初始值; 限制值; 執行步階 ））do 程序段done 範例 #!/bin/bash# Program:# Try do calculate 1+2+....+$&#123;your_input&#125;# History:# 2015/07/17 VBird First releasePATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:~/binexport PATHread -p \"Please input a number, I will count for 1+2+...+your_input: \" nus=0for （（ i=1; i&lt;=$&#123;nu&#125;; i=i+1 ））do s=$（（$&#123;s&#125;+$&#123;i&#125;））doneecho \"The result of '1+2+3+...+$&#123;nu&#125;' is ==&gt; $&#123;s&#125;\" 搭配亂數與陣列的實驗範例#!/bin/bash# Program:# Try do tell you what you may eat.# History:# 2015/07/17 VBird First releasePATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:~/binexport PATHeat[1]=\"賣噹噹漢堡包\"eat[2]=\"肯爺爺炸雞\"eat[3]=\"彩虹日式便當\"eat[4]=\"越油越好吃大雅\"eat[5]=\"想不出吃啥學餐\"eat[6]=\"太師父便當\"eat[7]=\"池上便當\"eat[8]=\"懷念火車便當\"eat[9]=\"一起吃方便麵\"eatnum=9eated=0while [ \"$&#123;eated&#125;\" -lt 3 ]; do check=$（（ $&#123;RANDOM&#125; * $&#123;eatnum&#125; / 32767 + 1 ）） mycheck=0 if [ \"$&#123;eated&#125;\" -ge 1 ]; then for i in $（seq 1 $&#123;eated&#125; ） do if [ $&#123;eatedcon[$i]&#125; == $check ]; then mycheck=1 fi done fi if [ $&#123;mycheck&#125; == 0 ]; then echo \"your may eat $&#123;eat[$&#123;check&#125;]&#125;\" eated=$（（ $&#123;eated&#125; + 1 ）） eatedcon[$&#123;eated&#125;]=$&#123;check&#125; fidone``` ```bash#!/bin/bash# Program:# Try do tell you what you may eat.# History:# 2015/07/17 VBird First releasePATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:~/binexport PATHeat[1]=\"賣噹噹漢堡包\" # 寫下你所收集到的店家！eat[2]=\"肯爺爺炸雞\"eat[3]=\"彩虹日式便當\"eat[4]=\"越油越好吃大雅\"eat[5]=\"想不出吃啥學餐\"eat[6]=\"太師父便當\"eat[7]=\"池上便當\"eat[8]=\"懷念火車便當\"eat[9]=\"一起吃方便麵\"eatnum=9 # 需要輸入有幾個可用的餐廳數！check=$（（ $&#123;RANDOM&#125; * $&#123;eatnum&#125; / 32767 + 1 ））echo \"your may eat $&#123;eat[$&#123;check&#125;]&#125;\" loop arrayfor i in \"$&#123;array[@]&#125;\" shell script 的追蹤與 debug語法sh [-nvx] scripts.sh選項與參數：-n ：不要執行 script，僅查詢語法的問題；-v ：再執行 sccript 前，先將 scripts 的內容輸出到屏幕上；-x ：將使用到的 script 內容顯示到屏幕上，這是很有用的參數！ 範例 測試 dir_perm.sh 有無語法的問題？ sh -n dir_perm.sh 將 show_animal.sh 的執行過程全部列出來～ sh -x show_animal.sh 練習題 請創建一支 script ，當你執行該 script 的時候，該 script 可以顯示： 1. 你目前的身份 （用 whoami ） 2. 你目前所在的目錄 （用 pwd） #!/bin/bashecho -e \"Your name is ==&gt; $（whoami）\"echo -e \"The current directory is ==&gt; $（pwd）\" 請自行創建一支程序，該程序可以用來計算“你還有幾天可以過生日”啊？ #!/bin/bashread -p \"Pleas input your birthday （MMDD, ex&gt; 0709）: \" birnow=`date +%m%d`if [ \"$bir\" == \"$now\" ]; thenecho \"Happy Birthday to you!!!\"elif [ \"$bir\" -gt \"$now\" ]; thenyear=`date +%Y`total_d=$（（$（（`date --date=\"$year$bir\" +%s`-`date +%s`））/60/60/24））echo \"Your birthday will be $total_d later\"elseyear=$（（`date +%Y`+1））total_d=$（（$（（`date --date=\"$year$bir\" +%s`-`date +%s`））/60/60/24））echo \"Your birthday will be $total_d later\"fi 讓使用者輸入一個數字，程序可以由 1+2+3… 一直累加到使用者輸入的數字為止。 #!/bin/bashread -p \"Please input an integer number: \" numberi=0s=0while [ \"$i\" != \"$number\" ]doi=$（（$i+1））s=$（（$s+$i））doneecho \"the result of '1+2+3+...$number' is ==&gt; $s\" 撰寫一支程序，他的作用是: 1.） 先查看一下 /root/test/logical 這個名稱是否存在； 2.） 若不存在，則創建一個文件，使用 touch 來創建，創建完成後離開； 3.） 如果存在的話，判斷該名稱是否為文件，若為文件則將之刪除後創建一個目錄，文件名為 logical ，之後離開； 4.） 如果存在的話，而且該名稱為目錄，則移除此目錄！ #!/bin/bashif [ ! -e logical ]; thentouch logicalecho \"Just make a file logical\"exit 1elif [ -e logical ] &amp;&amp; [ -f logical ]; thenrm logicalmkdir logicalecho \"remove file ==&gt; logical\"echo \"and make directory logical\"exit 1elif [ -e logical ] &amp;&amp; [ -d logical ]; thenrm -rf logicalecho \"remove directory ==&gt; logical\"exit 1elseecho \"Does here have anything?\"fi 我們知道 /etc/passwd 裡面以 : 來分隔，第一欄為帳號名稱。請寫一隻程序，可以將 /etc/passwd 的第一欄取出，而且每一欄都以一行字串“The 1 account is “root” ”來顯示，那個 1 表示行數。 #!/bin/bashaccounts=`cat /etc/passwd | cut -d':' -f1`for account in $accountsdodeclare -i i=$i+1echo \"The $i account is \\\"$account\\\" \"done /etc/passwd 文件架構 帳號名稱： 需要用來對應 UID, 例如 root 的 UID 對應就是 0 (第三字段) 密碼： 早期 Unix 系統的密碼就是放在這字段上！但是因為這個文件的特性是所有的程序都能夠讀取，這樣一來很容易造成密碼數據被竊取， 因此後來就將這個字段的密碼數據給他改放到 /etc/shadow 中了。所以這裡你會看到一個“ x ” UID: 使用者識別碼！ Linux 對於 UID 有幾個限制: id 範圍 該 ID 使用者特性 0（系統管理員） 當 UID 是 0 時，代表這個帳號是“系統管理員”！ 所以當你要讓其他的帳號名稱也具有 root 的權限時，將該帳號的 UID 改為 0 即可。 這也就是說，一部系統上面的系統管理員不見得只有 root 喔！ 不過，很不建議有多個帳號的 UID 是 0 啦～容易讓系統管理員混亂！ 1~999（系統帳號） 保留給系統使用的 ID，其實除了 0 之外，其他的 UID 權限與特性並沒有不一樣。默認 1000 以下的數字讓給系統作為保留帳號只是一個習慣。 由於系統上面啟動的網絡服務或背景服務希望使用較小的權限去運行，因此不希望使用 root 的身份去執行這些服務， 所以我們就得要提供這些運行中程序的擁有者帳號才行。這些系統帳號通常是不可登陸的， 所以才會有我們在第十章提到的 /sbin/nologin 這個特殊的 shell 存在。 根據系統帳號的由來，通常這類帳號又約略被區分為兩種： 1~200：由 distributions 自行創建的系統帳號； 201~999：若使用者有系統帳號需求時，可以使用的帳號 UID。 1000~60000（可登陸帳號） 給一般使用者用的。事實上，目前的 linux 核心 （3.10.x 版）已經可以支持到 4294967295 （2^32-1） 這麼大的 UID 號碼喔！ GID： 這個與 /etc/group 有關！其實 /etc/group 的觀念與 /etc/passwd 差不多，只是他是用來規範群組名稱與 GID 的對應而已！ 使用者信息說明欄： 這個字段基本上並沒有什麼重要用途，只是用來解釋這個帳號的意義而已！不過，如果您提供使用 finger 的功能時， 這個字段可以提供很多的訊息呢！本章後面的 chfn 指令會來解釋這裡的說明。 主文件夾： 這是使用者的主文件夾，以上面為例， root 的主文件夾在 /root ，所以當 root 登陸之後，就會立刻跑到 /root 目錄裡頭啦！呵呵！ 如果你有個帳號的使用空間特別的大，你想要將該帳號的主文件夾移動到其他的硬盤去該怎麼作？ 沒有錯！可以在這個字段進行修改呦！默認的使用者主文件夾在 /home/yourIDname Shell： 我們在第十章 BASH 提到很多次，當使用者登陸系統後就會取得一個 Shell 來與系統的核心溝通以進行使用者的操作任務。那為何默認 shell 會使用 bash 呢？就是在這個字段指定的囉！ 這裡比較需要注意的是，有一個 shell 可以用來替代成讓帳號無法取得 shell 環境的登陸動作！那就是 /sbin/nologin 這個東西！這也可以用來製作純 pop 郵件帳號者的數據呢！ /etc/shadow 文件結構 帳號名稱：由於密碼也需要與帳號對應啊～因此，這個文件的第一欄就是帳號，必須要與 /etc/passwd 相同才行！ 密碼：這個字段內的數據才是真正的密碼，而且是經過編碼的密碼 （加密） 啦！ 你只會看到有一些特殊符號的字母就是了！需要特別留意的是，雖然這些加密過的密碼很難被解出來， 但是“很難”不等於“不會”，所以，這個文件的默認權限是“-rw——-”或者是“———-”，亦即只有 root 才可以讀寫就是了！你得隨時注意，不要不小心更動了這個文件的權限呢！另外，由於各種密碼編碼的技術不一樣，因此不同的編碼系統會造成這個字段的長度不相同。 舉例來說，舊式的 DES, MD5 編碼系統產生的密碼長度就與目前慣用的 SHA 不同[2]！SHA 的密碼長度明顯的比較長些。由於固定的編碼系統產生的密碼長度必須一致，因此“當你讓這個字段的長度改變後，該密碼就會失效（算不出來）”。 很多軟件通過這個功能，在此字段前加上 ! 或 * 改變密碼字段長度，就會讓密碼“暫時失效”了。 最近更動密碼的日期：這個字段記錄了“更動密碼那一天”的日期，不過，很奇怪呀！在我的例子中怎麼會是 16559 呢？呵呵，這個是因為計算 Linux 日期的時間是以 1970 年 1 月 1 日作為 1 而累加的日期，1971 年 1 月 1 日則為 366 啦！ 得注意一下這個數據呦！上述的 16559 指的就是 2015-05-04 那一天啦！瞭解乎？ 而想要了解該日期可以使用本章後面 chage 指令的幫忙！至於想要知道某個日期的累積日數， 可使用如下的程序計算： echo $（（$（date --date=\"2015/05/04\" +%s）/86400+1）） 上述指令中，2015/05/04 為你想要計算的日期，86400 為每一天的秒數， %s 為 1970/01/01 以來的累積總秒數。 由於 bash 僅支持整數，因此最終需要加上 1 補齊 1970/01/01 當天。 密碼不可被更動的天數：（與第 3 字段相比）第四個字段記錄了：這個帳號的密碼在最近一次被更改後需要經過幾天才可以再被變更！如果是 0 的話， 表示密碼隨時可以更動的意思。這的限制是為了怕密碼被某些人一改再改而設計的！如果設置為 20 天的話，那麼當你設置了密碼之後， 20 天之內都無法改變這個密碼呦！ 密碼需要重新變更的天數：（與第 3 字段相比）經常變更密碼是個好習慣！為了強制要求使用者變更密碼，這個字段可以指定在最近一次更改密碼後， 在多少天數內需要再次的變更密碼才行。你必須要在這個天數內重新設置你的密碼，否則這個帳號的密碼將會“變為過期特性”。 而如果像上面的 99999 （計算為 273 年） 的話，那就表示，呵呵，密碼的變更沒有強制性之意。 密碼需要變更期限前的警告天數：（與第 5 字段相比）當帳號的密碼有效期限快要到的時候 （第 5 字段），系統會依據這個字段的設置，發出“警告”言論給這個帳號，提醒他“再過 n 天你的密碼就要過期了，請儘快重新設置你的密碼呦！”，如上面的例子，則是密碼到期之前的 7 天之內，系統會警告該用戶。 密碼過期後的帳號寬限時間（密碼失效日）：（與第 5 字段相比）密碼有效日期為“更新日期（第3字段）”+“重新變更日期（第5字段）”，過了該期限後使用者依舊沒有更新密碼，那該密碼就算過期了。 雖然密碼過期但是該帳號還是可以用來進行其他工作的，包括登陸系統取得 bash 。不過如果密碼過期了， 那當你登陸系統時，系統會強制要求你必須要重新設置密碼才能登陸繼續使用喔，這就是密碼過期特性。 帳號失效日期：這個日期跟第三個字段一樣，都是使用 1970 年以來的總日數設置。這個字段表示： 這個帳號在此字段規定的日期之後，將無法再使用。 就是所謂的“帳號失效”，此時不論你的密碼是否有過期，這個“帳號”都不能再被使用！ 這個字段會被使用通常應該是在“收費服務”的系統中，你可以規定一個日期讓該帳號不能再使用啦！ 保留：最後一個字段是保留的，看以後有沒有新功能加入。 範例假如我的使用者的密碼欄如下所示： dmtsai:$6$M4IphgNP2TmlXaSS$B418YFroYxxmm....:16559:5:60:7:5:16679: 由於密碼幾乎僅能單向運算（由明碼計算成為密碼，無法由密碼反推回明碼），因此由上表的數據我們無法得知 dmstai 的實際密碼明文 （第二個字段）； 此帳號最近一次更動密碼的日期是 2015/05/04 （16559）； 能夠再次修改密碼的時間是 5 天以後，也就是 2015/05/09 以前 dmtsai 不能修改自己的密碼；如果使用者還是嘗試要更動自己的密碼，系統就會出現這樣的訊息： You must wait longer to change your passwordpasswd: Authentication token manipulation error畫面中告訴我們：你必須要等待更久的時間才能夠變更密碼之意啦！ 由於密碼過期日期定義為 60 天后，亦即累積日數為： 16559+60=16619，經過計算得到此日數代表日期為 2015/07/03。 這表示：“使用者必須要在 2015/05/09 （前 5 天不能改） 到 2015/07/03 之間的 60 天限制內去修改自己的密碼，若 2015/07/03 之後還是沒有變更密碼時，該密碼就宣告為過期”了！ 警告日期設為 7 天，亦即是密碼過期日前的 7 天，在本例中則代表 2015/06/26 ~ 2015/07/03 這七天。 如果使用者一直沒有更改密碼，那麼在這 7 天中，只要 dmtsai 登陸系統就會發現如下的訊息：Warning: your password will expire in 5 days 如果該帳號一直到 2015/07/03 都沒有更改密碼，那麼密碼就過期了。但是由於有 5 天的寬限天數， 因此 dmtsai 在 2015/07/08 前都還可以使用舊密碼登陸主機。 不過登陸時會出現強制更改密碼的情況，畫面有點像下面這樣： You are required to change your password immediately （password aged）WARNING: Your password has expired.You must change your password now and login again!Changing password for user dmtsai.Changing password for dmtsai（current） UNIX password: 你必須要輸入一次舊密碼以及兩次新密碼後，才能夠開始使用系統的各項資源。如果你是在 2015/07/08 以後嘗試以 dmtsai 登陸的話，那麼就會出現如下的錯誤訊息且無法登陸，因為此時你的密碼就失效去啦！ Your account has expired; please contact your system administrator 如果使用者在 2015/07/03 以前變更過密碼，那麼第 3 個字段的那個 16559 的天數就會跟著改變，因此， 所有的限制日期也會跟著相對變動喔！^_^ 無論使用者如何動作，到了 16679 （大約是 2015/09/01 左右） 該帳號就失效了～ 獲取 shadow 的加密機制 安裝 authconfig, 如果沒有裝的話 yum install authconfig-gtk* 查詢 authconfig --test | grep hashing 關於群組： 有效與初始群組、groups, newgrp/etc/group 文件結構如下：root:x:0:bin:x:1:daemon:x:2:sys:x:3: 群組名稱：就是群組名稱啦！同樣用來給人類使用的，基本上需要與第三字段的 GID 對應。 群組密碼：通常不需要設置，這個設置通常是給“群組管理員”使用的，目前很少有這個機會設置群組管理員啦！ 同樣的，密碼已經移動到 /etc/gshadow 去，因此這個字段只會存在一個“x”而已； GID：就是群組的 ID 啊。我們 /etc/passwd 第四個字段使用的 GID 對應的群組名，就是由這裡對應出來的！ 此群組支持的帳號名稱：我們知道一個帳號可以加入多個群組，那某個帳號想要加入此群組時，將該帳號填入這個字段即可。 舉例來說，如果我想要讓 dmtsai 與 alex 也加入 root 這個群組，那麼在第一行的最後面加上“dmtsai,alex”，注意不要有空格， 使成為“ root:x:0:dmtsai,alex ”就可以囉～ /etc/gshadow 文件結構 群組名稱 密碼欄，同樣的，開頭為 ! 表示無合法密碼，所以無群組管理員 群組管理員的帳號 （相關信息在 gpasswd 中介紹） 有加入該群組支持的所屬帳號 （與 /etc/group 內容相同！） /etc/passwd 與 /etc/group 與 /etc/shadow 示意圖談完了 /etc/passwd, /etc/shadow, /etc/group 之後，我們可以使用一個簡單的圖示來了解一下 UID / GID 與密碼之間的關係， 圖示如下。其實重點是 /etc/passwd 啦，其他相關的數據都是根據這個文件的字段去找尋出來的。 下圖中， root 的 UID 是 0 ，而 GID 也是 0 ，去找 /etc/group 可以知道 GID 為 0 時的群組名稱就是 root 哩。 至於密碼的尋找中，會找到 /etc/shadow 與 /etc/passwd 內同帳號名稱的那一行，就是密碼相關數據囉。 finger Login：為使用者帳號，亦即 /etc/passwd 內的第一字段； Name：為全名，亦即 /etc/passwd 內的第五字段（或稱為註解）； Directory：就是主文件夾了； Shell：就是使用的 Shell 文件所在； Never logged in.：figner 還會調查使用者登陸主機的情況喔！ No mail.：調查 /var/spool/mail 當中的信箱數據； No Plan.：調查 ~vbird1/.plan 文件，並將該文件取出來說明！ chfnchfn [-foph] [帳號名]選項與參數：-f ：後面接完整的大名；-o ：您辦公室的房間號碼；-p ：辦公室的電話號碼；-h ：家裡的電話號碼！ chage 更詳細的密碼參數顯示功能 可讓使用者在第一次登陸時， 強制她們一定要更改密碼後才能夠使用系統資源 語法chage [-ldEImMW] 帳號名選項與參數：-l ：列出該帳號的詳細密碼參數；-d ：後面接日期，修改 shadow 第三字段（最近一次更改密碼的日期），格式 YYYY-MM-DD-E ：後面接日期，修改 shadow 第八字段（帳號失效日），格式 YYYY-MM-DD-I ：後面接天數，修改 shadow 第七字段（密碼失效日期）-m ：後面接天數，修改 shadow 第四字段（密碼最短保留天數）-M ：後面接天數，修改 shadow 第五字段（密碼多久需要進行變更）-W ：後面接天數，修改 shadow 第六字段（密碼過期前警告日期） 範例範例一：列出 vbird2 的詳細密碼參數[root@study ~]# chage -l vbird2Last password change : Jul 20, 2015Password expires : Sep 18, 2015Password inactive : Sep 28, 2015Account expires : neverMinimum number of days between password change : 0Maximum number of days between password change : 60Number of days of warning before password expires : 7 chsh語法：chsh [-ls]選項與參數：-l ：列出目前系統上面可用的 shell ，其實就是 /etc/shells 的內容！-s ：設置修改自己的 Shell 囉 範例範例一：用 vbird1 的身份列出系統上所有合法的 shell，並且指定 csh 為自己的 shell[vbird1@study ~]$ chsh -l/bin/sh/bin/bash/sbin/nologin &lt;==所謂：合法不可登陸的 Shell 就是這玩意！/usr/bin/sh/usr/bin/bash/usr/sbin/nologin/bin/tcsh/bin/csh &lt;==這就是 C shell 啦！# 其實上面的信息就是我們在 bash 中談到的 /etc/shells 啦！[vbird1@study ~]$ chsh -s /bin/csh; grep vbird1 /etc/passwdChanging shell for vbird1.Password: &lt;==確認身份，請輸入 vbird1 的密碼Shell changed.vbird1:x:1003:1004:VBird Tsai test,DIC in KSU,06-2727175#356,06-1234567:/home/vbird1:/bin/csh[vbird1@study ~]$ chsh -s /bin/bash# 測試完畢後，立刻改回來！[vbird1@study ~]$ ll $（which chsh）-rws--x--x. 1 root root 23856 Mar 6 13:59 /bin/chsh groupadd語法groupadd [-g gid] [-r] 群組名稱選項與參數：-g ：後面接某個特定的 GID ，用來直接給予某個 GID ～-r ：創建系統群組啦！與 /etc/login.defs 內的 GID_MIN 有關。 範例範例一：新建一個群組，名稱為 group1[root@study ~]# groupadd group1[root@study ~]# grep group1 /etc/group /etc/gshadow/etc/group:group1:x:1503:/etc/gshadow:group1:!::# 群組的 GID 也是會由 1000 以上最大 GID+1 來決定！ groupmod語法groupmod [-g gid] [-n group_name] 群組名選項與參數：-g ：修改既有的 GID 數字；-n ：修改既有的群組名稱 範例範例一：將剛剛上個指令創建的 group1 名稱改為 mygroup ， GID 為 201[root@study ~]# groupmod -g 201 -n mygroup group1[root@study ~]# grep mygroup /etc/group /etc/gshadow/etc/group:mygroup:x:201:/etc/gshadow:mygroup:!:: groupdel語法groupdel [groupname] gpasswd語法系統管理員 (root)gpasswd groupname[root@study ~]# gpasswd [-A user1,...] [-M user3,...] groupname[root@study ~]# gpasswd [-rR] groupname選項與參數： ：若沒有任何參數時，表示給予 groupname 一個密碼（/etc/gshadow）-A ：將 groupname 的主控權交由後面的使用者管理（該群組的管理員）-M ：將某些帳號加入這個群組當中！-r ：將 groupname 的密碼移除-R ：讓 groupname 的密碼欄失效 群組管理員 (Group administrator)gpasswd [-ad] user groupname選項與參數：-a ：將某位使用者加入到 groupname 這個群組當中！-d ：將某位使用者移除出 groupname 這個群組當中。 範例範例一：創建一個新群組，名稱為 testgroup 且群組交由 vbird1 管理：[root@study ~]# groupadd testgroup &lt;==先創建群組[root@study ~]# gpasswd testgroup &lt;==給這個群組一個密碼吧！Changing the password for group testgroupNew Password:Re-enter new password:# 輸入兩次密碼就對了！[root@study ~]# gpasswd -A vbird1 testgroup &lt;==加入群組管理員為 vbird1[root@study ~]# grep testgroup /etc/group /etc/gshadow/etc/group:testgroup:x:1503:/etc/gshadow:testgroup:$6$MnmChP3D$mrUn.Vo.buDjObMm8F2emTkvGSeuWikhRzaKHxpJ...:vbird1:# 很有趣吧！此時 vbird1 則擁有 testgroup 的主控權喔！身份有點像板主啦！ 範例二：以 vbird1 登陸系統，並且讓他加入 vbird1, vbird3 成為 testgroup 成員[vbird1@study ~]$ iduid=1003（vbird1） gid=1004（vbird1） groups=1004（vbird1） ...# 看得出來，vbird1 尚未加入 testgroup 群組喔！[vbird1@study ~]$ gpasswd -a vbird1 testgroup[vbird1@study ~]$ gpasswd -a vbird3 testgroup[vbird1@study ~]$ grep testgroup /etc/grouptestgroup:x:1503:vbird1,vbird3 ACLsetfacl setfacl ：設置某個目錄/文件的 ACL 規範。 語法setfacl [-bkRd] [&#123;-m|-x&#125; acl參數] 目標文件名選項與參數：-m ：設置後續的 acl 參數給文件使用，不可與 -x 合用；-x ：刪除後續的 acl 參數，不可與 -m 合用；-b ：移除“所有的” ACL 設置參數；-k ：移除“默認的” ACL 參數，關於所謂的“默認”參數於後續範例中介紹；-R ：遞迴設置 acl ，亦即包括次目錄都會被設置起來；-d ：設置“默認 acl 參數”的意思！只對目錄有效，在該目錄新建的數據會引用此默認值 getfacl語法getfacl filename選項與參數：# 請列出剛剛我們設置的 acl_test1 的權限內容：[root@study ~]# getfacl acl_test1# file: acl_test1 &lt;==說明文檔名而已！# owner: root &lt;==說明此文件的擁有者，亦即 ls -l 看到的第三使用者字段# group: root &lt;==此文件的所屬群組，亦即 ls -l 看到的第四群組字段user::rwx &lt;==使用者列表欄是空的，代表文件擁有者的權限user:vbird1:r-x &lt;==針對 vbird1 的權限設置為 rx ，與擁有者並不同！group::r-- &lt;==針對文件群組的權限設置僅有 r mask::r-x &lt;==此文件默認的有效權限 （mask）other::r-- &lt;==其他人擁有的權限囉！-m ：設置後續的 acl 參數給文件使用，不可與 -x 合用；-x ：刪除後續的 acl 參數，不可與 -m 合用；-b ：移除“所有的” ACL 設置參數；-k ：移除“默認的” ACL 參數，關於所謂的“默認”參數於後續範例中介紹；-R ：遞迴設置 acl ，亦即包括次目錄都會被設置起來；-d ：設置“默認 acl 參數”的意思！只對目錄有效，在該目錄新建的數據會引用此默認值 顯示的數據前面加上 # 的，代表這個文件的默認屬性，包括文件名、文件擁有者與文件所屬群組。user, group, mask, other 則是屬於不同使用者、群組與有效權限（mask）的設置值。 su語法su [-lm] [-c 指令] [username]選項與參數：- ：單純使用 - 如“ su - ”代表使用 login-shell 的變量文件讀取方式來登陸系統； 若使用者名稱沒有加上去，則代表切換為 root 的身份。-l ：與 - 類似，但後面需要加欲切換的使用者帳號！也是 login-shell 的方式。-m ：-m 與 -p 是一樣的，表示“使用目前的環境設置，而不讀取新使用者的配置文件”-c ：僅進行一次指令，所以 -c 後面可以加上指令喔！ sudo語法sudo [-b] [-u 新使用者帳號]選項與參數：-b ：將後續的指令放到背景中讓系統自行執行，而不與目前的 shell 產生影響-u ：後面可以接欲切換的使用者，若無此項則代表切換身份為 root 。 sudoers更改設置visodu root ALL=（ALL） ALL &lt;==找到這一行，大約在 98 行左右vbird1 ALL=（ALL） ALL &lt;==這一行是你要新增的！ 使用者帳號 登陸者的來源主機名稱=（可切換的身份） 可下達的指令root ALL=（ALL） ALL &lt;==這是默認值 “使用者帳號”：系統的哪個帳號可以使用 sudo 這個指令的意思； “登陸者的來源主機名稱”：當這個帳號由哪部主機連線到本 Linux 主機，意思是這個帳號可能是由哪一部網絡主機連線過來的， 這個設置值可以指定用戶端計算機（信任的來源的意思）。默認值 root 可來自任何一部網絡主機 “（可切換的身份）”：這個帳號可以切換成什麼身份來下達後續的指令，默認 root 可以切換成任何人； “可下達的指令”：可用該身份下達什麼指令？這個指令請務必使用絕對路徑撰寫。 默認 root 可以切換任何身份且進行任何指令之意。那個 ALL 是特殊的關鍵字，代表任何身份、主機或指令的意思。所以，我想讓 vbird1 可以進行任何身份的任何指令， 就如同上表特殊字體寫的那樣，其實就是複製上述默認值那一行，再將 root 改成 vbird1 即可啊！ 此時“vbird1 不論來自哪部主機登陸，他可以變換身份成為任何人，且可以進行系統上面的任何指令”之意。 修改完請儲存後離開 vi，並以 vbird1 登陸系統後，進行如下的測試看看： visudo更改默認編輯器update-alternatives --config editor PAM 模塊設置語法程序與 PAM 的關係圖 程序調用 PAM 的流程 使用者開始執行 /usr/bin/passwd 這支程序，並輸入密碼； passwd 調用 PAM 模塊進行驗證； PAM 模塊會到 /etc/pam.d/ 找尋與程序 （passwd） 同名的配置文件； 依據 /etc/pam.d/passwd 內的設置，引用相關的 PAM 模塊逐步進行驗證分析； 將驗證結果 （成功、失敗以及其他訊息） 回傳給 passwd 這支程序； passwd 這支程序會根據 PAM 回傳的結果決定下一個動作 （重新輸入新密碼或者通過驗證！） 配置文件內容cat /etc/pam.d/passwd#%PAM-1.0 &lt;==PAM版本的說明而已！auth include system-auth &lt;==每一行都是一個驗證的過程account include system-authpassword substack system-auth-password optional pam_gnome_keyring.so use_authtokpassword substack postlogin驗證類別 控制標準 PAM 模塊與該模塊的參數 驗證類別 (type)驗證類別主要分為四種，分別說明如下： auth是 authentication （認證） 的縮寫，所以這種類別主要用來檢驗使用者的身份驗證，這種類別通常是需要密碼來檢驗的， 所以後續接的模塊是用來檢驗使用者的身份。 accountaccount （帳號） 則大部分是在進行 authorization （授權），這種類別則主要在檢驗使用者是否具有正確的使用權限， 舉例來說，當你使用一個過期的密碼來登陸時，當然就無法正確的登陸了。 sessionsession 是會議期間的意思，所以 session 管理的就是使用者在這次登陸 （或使用這個指令） 期間，PAM 所給予的環境設置。 這個類別通常用在記錄使用者登陸與登出時的信息！例如，如果你常常使用 su 或者是 sudo 指令的話， 那麼應該可以在 /var/log/secure 裡面發現很多關於 pam 的說明，而且記載的數據是“session open, session close”的信息！ passwordpassword 就是密碼嘛！所以這種類別主要在提供驗證的修訂工作，舉例來說，就是修改/變更密碼啦！這四個驗證的類型通常是有順序的，不過也有例外就是了。 會有順序的原因是，（1）我們總是得要先驗證身份 （auth） 後， （2）系統才能夠藉由使用者的身份給予適當的授權與權限設置 （account），而且（3）登陸與登出期間的環境才需要設置， 也才需要記錄登陸與登出的信息 （session）。如果在運行期間需要密碼修訂時，（4）才給予 password 的類別。這樣說起來， 自然是需要有點順序吧！ 驗證的控制旗標 （control flag）那麼“驗證的控制旗標（control flag）”又是什麼？簡單的說，他就是“驗證通過的標準”啦！ 這個字段在管控該驗證的放行方式，主要也分為四種控制方式： required此驗證若成功則帶有 success （成功） 的標誌，若失敗則帶有 failure 的標誌，但不論成功或失敗都會繼續後續的驗證流程。 由於後續的驗證流程可以繼續進行，因此相當有利於數據的登錄 （log） ，這也是 PAM 最常使用 required 的原因。 requisite若驗證失敗則立刻回報原程序 failure 的標誌，並終止後續的驗證流程。若驗證成功則帶有 success 的標誌並繼續後續的驗證流程。 這個項目與 required 最大的差異，就在於失敗的時候還要不要繼續驗證下去？由於 requisite 是失敗就終止， 因此失敗時所產生的 PAM 信息就無法通過後續的模塊來記錄了。 sufficient若驗證成功則立刻回傳 success 給原程序，並終止後續的驗證流程；若驗證失敗則帶有 failure 標誌並繼續後續的驗證流程。 這玩意兒與 requisits 剛好相反！ optional這個模塊控制項目大多是在顯示訊息而已，並不是用在驗證方面的。如果將這些控制旗標以圖示的方式配合成功與否的條件繪圖，會有點像下面這樣： 程序運行過程中遇到驗證時才會去調用 PAM ，而 PAM 驗證又分很多類型與控制，不同的控制旗標所回報的訊息並不相同。 如上圖所示， requisite 失敗就回報了並不會繼續，而 sufficient 則是成功就回報了也不會繼續。 至於驗證結束後所回報的信息通常是“succes 或 failure ”而已，後續的流程還需要該程序的判斷來繼續執行才行。 jobs語法[root@study ~]# jobs [-lrs]選項與參數：-l ：除了列出 job number 與指令串之外，同時列出 PID 的號碼；-r ：僅列出正在背景 run 的工作；-s ：僅列出正在背景當中暫停 （stop） 的工作。 fg語法[root@study ~]# fg %jobnumber選項與參數：%jobnumber ：jobnumber 為工作號碼（數字）。注意，那個 % 是可有可無的！ ps語法[root@study ~]# ps aux &lt;==觀察系統所有的程序數據[root@study ~]# ps -lA &lt;==也是能夠觀察所有系統的數據[root@study ~]# ps axjf &lt;==連同部分程序樹狀態選項與參數：-A ：所有的 process 均顯示出來，與 -e 具有同樣的效用；-a ：不與 terminal 有關的所有 process ；-u ：有效使用者 （effective user） 相關的 process ；x ：通常與 a 這個參數一起使用，可列出較完整信息。輸出格式規劃：l ：較長、較詳細的將該 PID 的的信息列出；j ：工作的格式 （jobs format）-f ：做一個更為完整的輸出。 觀察自己的 bash 相關程序ps -l 輸出如下： F S UID PID PPID C PRI NI ADDR SZ WCHAN TTY TIME CMD4 S 0 14830 13970 0 80 0 - 52686 poll_s pts/0 00:00:00 sudo4 S 0 14835 14830 0 80 0 - 50511 wait pts/0 00:00:00 su4 S 0 14836 14835 0 80 0 - 29035 wait pts/0 00:00:00 bash0 R 0 15011 14836 0 80 0 - 30319 - pts/0 00:00:00 ps# 還記得鳥哥說過，非必要不要使用 root 直接登陸吧？從這個 ps -l 的分析，你也可以發現，# 鳥哥其實是使用 sudo 才轉成 root 的身份～否則連測試機，鳥哥都是使用一般帳號登陸的！ 詳解： 系統整體的程序運行是非常多的，但如果使用 ps -l 則僅列出與你的操作環境 （bash） 有關的程序而已， 亦即最上層的父程序會是你自己的 bash 而沒有延伸到 systemd （後續會交待！） 這支程序去！那麼 ps -l 秀出來的數據有哪些呢？ 我們就來觀察看看： F：代表這個程序旗標 （process flags），說明這個程序的總結權限，常見號碼有： 若為 4 表示此程序的權限為 root ； 若為 1 則表示此子程序僅進行複製（fork）而沒有實際執行（exec）。 S：代表這個程序的狀態 （STAT），主要的狀態有： R （Running）：該程序正在運行中； S （Sleep）：該程序目前正在睡眠狀態（idle），但可以被喚醒（signal）。 D ：不可被喚醒的睡眠狀態，通常這支程序可能在等待 I/O 的情況（ex&gt;打印） T ：停止狀態（stop），可能是在工作控制（背景暫停）或除錯 （traced） 狀態； Z （Zombie）：殭屍狀態，程序已經終止但卻無法被移除至內存外。 UID/PID/PPID：代表“此程序被該 UID 所擁有/程序的 PID 號碼/此程序的父程序 PID 號碼” C：代表 CPU 使用率，單位為百分比； PRI/NI：Priority/Nice 的縮寫，代表此程序被 CPU 所執行的優先順序，數值越小代表該程序越快被 CPU 執行。詳細的 PRI 與 NI 將在下一小節說明。 ADDR/SZ/WCHAN：都與內存有關，ADDR 是 kernel function，指出該程序在內存的哪個部分，如果是個 running 的程序，一般就會顯示“ - ” / SZ 代表此程序用掉多少內存 / WCHAN 表示目前程序是否運行中，同樣的， 若為 - 表示正在運行中。 TTY：登陸者的終端機位置，若為遠端登陸則使用動態終端接口 （pts/n）； TIME：使用掉的 CPU 時間，注意，是此程序實際花費 CPU 運行的時間，而不是系統時間； CMD：就是 command 的縮寫，造成此程序的觸發程序之指令為何。 所以你看到的 ps -l 輸出訊息中，他說明的是：“bash 的程序屬於 UID 為 0 的使用者，狀態為睡眠 （sleep）， 之所以為睡眠因為他觸發了 ps （狀態為 run） 之故。此程序的 PID 為 14836，優先執行順序為 80 ， 下達 bash 所取得的終端接口為 pts/0 ，運行狀態為等待 （wait） 。”這樣已經夠清楚了吧？ 您自己嘗試解析一下那麼 ps 那一行代表的意義為何呢？ ^_^接下來讓我們使用 ps 來觀察一下系統內所有的程序狀態吧！ 觀察系統所有程序ps aux 輸出： USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 1 0.0 0.2 60636 7948 ? Ss Aug04 0:01 /usr/lib/systemd/systemd ...root 2 0.0 0.0 0 0 ? S Aug04 0:00 [kthreadd].....（中間省略）.....root 14830 0.0 0.1 210744 3988 pts/0 S Aug04 0:00 sudo su -root 14835 0.0 0.1 202044 2996 pts/0 S Aug04 0:00 su -root 14836 0.0 0.1 116140 2960 pts/0 S Aug04 0:00 -bash.....（中間省略）.....root 18459 0.0 0.0 123372 1380 pts/0 R+ 00:25 0:00 ps aux 詳解： 你會發現 ps -l 與 ps aux 顯示的項目並不相同！在 ps aux 顯示的項目中，各字段的意義為： USER：該 process 屬於那個使用者帳號的？ PID ：該 process 的程序識別碼。 %CPU：該 process 使用掉的 CPU 資源百分比； %MEM：該 process 所佔用的實體內存百分比； VSZ ：該 process 使用掉的虛擬內存量 （KBytes） RSS ：該 process 佔用的固定的內存量 （KBytes） TTY ：該 process 是在那個終端機上面運行，若與終端機無關則顯示 ?，另外， tty1-tty6 是本機上面的登陸者程序，若為 pts/0 等等的，則表示為由網絡連接進主機的程序。 STAT：該程序目前的狀態，狀態顯示與 ps -l 的 S 旗標相同 （R/S/T/Z） START：該 process 被觸發啟動的時間； TIME ：該 process 實際使用 CPU 運行的時間。 COMMAND：該程序的實際指令為何？一般來說，ps aux 會依照 PID 的順序來排序顯示，我們還是以 14836 那個 PID 那行來說明！該行的意義為“ root 執行的 bash PID 為 14836，佔用了 0.1% 的內存容量百分比，狀態為休眠 （S），該程序啟動的時間為 8 月 4 號，因此啟動太久了， 所以沒有列出實際的時間點。且取得的終端機環境為 pts/0 。”與 ps aux 看到的其實是同一個程序啦！這樣可以理解嗎？ 讓我們繼續使用 ps 來觀察一下其他的信息吧！ top相對於 ps 是擷取一個時間點的程序狀態， top 則可以持續偵測程序運行的狀態！使用方式如下： 語法[root@study ~]# top [-d 數字] | top [-bnp]選項與參數：-d ：後面可以接秒數，就是整個程序畫面更新的秒數。默認是 5 秒；-b ：以批次的方式執行 top ，還有更多的參數可以使用喔！ 通常會搭配數據流重導向來將批次的結果輸出成為文件。-n ：與 -b 搭配，意義是，需要進行幾次 top 的輸出結果。-p ：指定某些個 PID 來進行觀察監測而已。在 top 執行過程當中可以使用的按鍵指令： ? ：顯示在 top 當中可以輸入的按鍵指令； P ：以 CPU 的使用資源排序顯示； M ：以 Memory 的使用資源排序顯示； N ：以 PID 來排序喔！ T ：由該 Process 使用的 CPU 時間累積 （TIME+） 排序。 k ：給予某個 PID 一個訊號 （signal） r ：給予某個 PID 重新制訂一個 nice 值。 q ：離開 top 軟件的按鍵。 pstree語法[root@study ~]# pstree [-A|U] [-up]選項與參數：-A ：各程序樹之間的連接以 ASCII 字符來連接；-U ：各程序樹之間的連接以萬國碼的字符來連接。在某些終端接口下可能會有錯誤；-p ：並同時列出每個 process 的 PID；-u ：並同時列出每個 process 的所屬帳號名稱。 nice語法[root@study ~]# nice [-n 數字] command選項與參數：-n ：後面接一個數值，數值的範圍 -20 ~ 19。 renice語法[root@study ~]# renice [number] PID選項與參數：PID ：某個程序的 ID 啊！ free觀察內存使用情況 語法[root@study ~]# free [-b|-k|-m|-g|-h] [-t] [-s N -c N]選項與參數：-b ：直接輸入 free 時，顯示的單位是 KBytes，我們可以使用 b（Bytes）, m（MBytes） k（KBytes）, 及 g（GBytes） 來顯示單位喔！也可以直接讓系統自己指定單位 （-h）-t ：在輸出的最終結果，顯示實體內存與 swap 的總量。-s ：可以讓系統每幾秒鐘輸出一次，不間斷的一直輸出的意思！對於系統觀察挺有效！-c ：與 -s 同時處理～讓 free 列出幾次的意思～ 備註[root@study ~]# free -m total used free shared buff/cache availableMem: 2848 346 1794 8 706 2263Swap: 1023 0 1023 名稱 意義 swap 內存交換空間的量 total 總量 used 已被使用的量 free 剩餘可用的量 shared/buffers/cached 已被使用的量中，用來作為緩衝及高速緩存的量。 這些用量中，在系統比較忙碌時，可以被釋出而繼續利用 uname查閱系統與核心相關信息 語法[root@study ~]# uname [-asrmpi]選項與參數：-a ：所有系統相關的信息，包括下面的數據都會被列出來；-s ：系統核心名稱-r ：核心的版本-m ：本系統的硬件名稱，例如 i686 或 x86_64 等；-p ：CPU 的類型，與 -m 類似，只是顯示的是 CPU 的類型！-i ：硬件的平臺 （ix86）範例一：輸出系統的基本信息[root@study ~]# uname -aLinux study.centos.vbird 3.10.0-229.el7.x86_64 #1 SMP Fri Mar 6 11:36:42 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux uptime觀察系統啟動時間與工作負載這個指令很單純: 顯示出目前系統已經開機多久的時間 1, 5, 15 分鐘的平均負載這個 uptime 可以顯示出 top 畫面的最上面一行 netstat追蹤網絡或插槽檔 語法[root@study ~]# uname [-asrmpi]選項與參數：-a ：所有系統相關的信息，包括下面的數據都會被列出來；-s ：系統核心名稱-r ：核心的版本-m ：本系統的硬件名稱，例如 i686 或 x86_64 等；-p ：CPU 的類型，與 -m 類似，只是顯示的是 CPU 的類型！-i ：硬件的平臺 （ix86） 備註[root@study ~]# netstatActive Internet connections （w/o servers） &lt;==與網絡較相關的部分Proto Recv-Q Send-Q Local Address Foreign Address Statetcp 0 0 172.16.15.100:ssh 172.16.220.234:48300 ESTABLISHEDActive UNIX domain sockets （w/o servers） &lt;==與本機的程序自己的相關性（非網絡）Proto RefCnt Flags Type State I-Node Pathunix 2 [ ] DGRAM 1902 @/org/freedesktop/systemd1/notifyunix 2 [ ] DGRAM 1944 /run/systemd/shutdownd....（中間省略）....unix 3 [ ] STREAM CONNECTED 25425 @/tmp/.X11-unix/X0unix 3 [ ] STREAM CONNECTED 28893unix 3 [ ] STREAM CONNECTED 21262 在上面的結果當中，顯示了兩個部分: 網絡的連線 linux 上面的 socket 程序相關性部分 我們先來看看網際網絡連線情況的部分： Proto ：網絡的封包協定，主要分為 TCP 與 UDP 封包，相關數據請參考服務器篇； Recv-Q：非由使用者程序鏈接到此 socket 的複製的總 Bytes 數； Send-Q：非由遠端主機傳送過來的 acknowledged 總 Bytes 數； Local Address ：本地端的 IP:port 情況 Foreign Address：遠端主機的 IP:port 情況 State ：連線狀態，主要有創建（ESTABLISED）及監聽（LISTEN）； 我們看上面僅有一條連線的數據，他的意義是：“通過 TCP 封包的連線，遠端的 172.16.220.234:48300 連線到本地端的 172.16.15.100:ssh ，這條連線狀態是創建 （ESTABLISHED） 的狀態！”至於更多的網絡環境說明， 就得到鳥哥的另一本服務器篇查閱囉！ socket file: 插槽檔 溝通兩個程序之間的信息 上表中 socket file 的輸出字段: Proto ：一般就是 unix 啦； RefCnt：連接到此 socket 的程序數量； Flags ：連線的旗標； Type ：socket 存取的類型。主要有確認連線的 STREAM 與不需確認的 DGRAM 兩種； State ：若為 CONNECTED 表示多個程序之間已經連線創建。 Path ：連接到此 socket 的相關程序的路徑！或者是相關數據輸出的路徑。 dmesg分析核心產生的訊息 系統在開機的時候，核心會去偵測系統的硬件，你的某些硬件到底有沒有被捉到，那就與這個時候的偵測有關。 dmesg 可以顯示這些偵測的過程 範例範例一：輸出所有的核心開機時的信息dmesg | less 範例二：搜尋開機的時候，硬盤的相關信息為何？dmesg | grep -i vda 輸出：[ 0.758551] vda: vda1 vda2 vda3 vda4 vda5 vda6 vda7 vda8 vda9[ 3.964134] XFS （vda2）: Mounting V4 Filesystem....（下面省略）.... vmstat偵測系統資源變化vmstat 可以偵測“ CPU / 內存 / 磁盤輸入輸出狀態 ”等等 語法[root@study ~]# vmstat [-a] [延遲 [總計偵測次數]] &lt;==CPU/內存等信息[root@study ~]# vmstat [-fs] &lt;==內存相關[root@study ~]# vmstat [-S 單位] &lt;==設置顯示數據的單位[root@study ~]# vmstat [-d] &lt;==與磁盤有關[root@study ~]# vmstat [-p 分區] &lt;==與磁盤有關選項與參數：-a ：使用 inactive/active（活躍與否） 取代 buffer/cache 的內存輸出信息；-f ：開機到目前為止，系統複製 （fork） 的程序數；-s ：將一些事件 （開機至目前為止） 導致的內存變化情況列表說明；-S ：後面可以接單位，讓顯示的數據有單位。例如 K/M 取代 Bytes 的容量；-d ：列出磁盤的讀寫總量統計表-p ：後面列出分區，可顯示該分區的讀寫總量統計表 範例範例一：統計目前主機 CPU 狀態，每秒一次，共計三次！vmstat 1 3 範例輸出： 範例二：系統上面所有的磁盤的讀寫狀態vmstat -d 範例輸出： 利用 vmstat 甚至可以進行追蹤喔！你可以使用類似“ vmstat 5 ”代表每五秒鐘更新一次，且無窮的更新！直到你按下 [ctrl]-c 為止。如果你想要實時的知道系統資源的運行狀態，這個指令就不能不知道！那麼上面的表格各項字段的意義為何？ 基本說明如下： 程序字段 （procs） 的項目分別為： r ：等待運行中的程序數量； b：不可被喚醒的程序數量。這兩個項目越多，代表系統越忙碌 （因為系統太忙，所以很多程序就無法被執行或一直在等待而無法被喚醒之故）。 內存字段 （memory） 項目分別為： swpd：虛擬內存被使用的容量； free：未被使用的內存容量； buff：用於緩衝內存； cache：用於高速緩存內存。 這部份則與 free 是相同的。 內存交換空間 （swap） 的項目分別為： si：由磁盤中將程序取出的量； so：由於內存不足而將沒用到的程序寫入到磁盤的 swap 的容量。 如果 si/so 的數值太大，表示內存內的數據常常得在磁盤與內存之間傳來傳去，系統性能會很差！ 磁盤讀寫 （io） 的項目分別為： bi：由磁盤讀入的區塊數量； bo：寫入到磁盤去的區塊數量。如果這部份的值越高，代表系統的 I/O 非常忙碌！ 系統 （system） 的項目分別為： in：每秒被中斷的程序次數； cs：每秒鐘進行的事件切換次數；這兩個數值越大，代表系統與周邊設備的溝通非常頻繁！ 這些周邊設備當然包括磁盤、網卡、時間鍾等。 CPU 的項目分別為： us：非核心層的 CPU 使用狀態； sy：核心層所使用的 CPU 狀態； id：閒置的狀態； wa：等待 I/O 所耗費的 CPU 狀態； st：被虛擬機 （virtual machine） 所盜用的 CPU 使用狀態 （2.6.11 以後才支持）。 /proc基本上，目前主機上面的各個程序的 PID 都是以目錄的型態存在於 /proc 當中。 舉例來說，我們開機所執行的第一支程序 systemd 他的 PID 是 1 ， 這個 PID 的所有相關信息都寫入在 /proc/1/* 當中！若我們直接觀察 PID 為 1 的數據好了，他有點像這樣： 文件內容 文件名 文件內容 /proc/cmdline 載入 kernel 時所下達的相關指令與參數！查閱此文件，可瞭解指令是如何啟動的！ /proc/cpuinfo 本機的 CPU 的相關信息，包含頻率、類型與運算功能等 /proc/devices 這個文件記錄了系統各個主要設備的主要設備代號，與 mknod 有關呢！ /proc/filesystems 目前系統已經載入的文件系統囉！ /proc/interrupts 目前系統上面的 IRQ 分配狀態。 /proc/ioports 目前系統上面各個設備所配置的 I/O 位址。 /proc/kcore 這個就是內存的大小啦！好大對吧！但是不要讀他啦！ /proc/loadavg 還記得 top 以及 uptime 吧？沒錯！上頭的三個平均數值就是記錄在此！ /proc/meminfo 使用 free 列出的內存信息，嘿嘿！在這裡也能夠查閱到！ /proc/modules 目前我們的 Linux 已經載入的模塊列表，也可以想成是驅動程序啦！ /proc/mounts 系統已經掛載的數據，就是用 mount 這個指令調用出來的數據啦！ /proc/swaps 到底系統掛載入的內存在哪裡？呵呵！使用掉的 partition 就記錄在此啦！ /proc/partitions 使用 fdisk -l 會出現目前所有的 partition 吧？在這個文件當中也有紀錄喔！ /proc/uptime 就是用 uptime 的時候，會出現的信息啦！ /proc/version 核心的版本，就是用 uname -a 顯示的內容啦！ /proc/bus/* 一些總線的設備，還有 USB 的設備也記錄在此喔！ fuser藉由文件（或文件系統）找出正在使用該文件的程序 語法[root@study ~]# fuser [-umv] [-k [i] [-signal]] file/dir選項與參數：-u ：除了程序的 PID 之外，同時列出該程序的擁有者；-m ：後面接的那個文件名會主動的上提到該文件系統的最頂層，對 umount 不成功很有效！-v ：可以列出每個文件與程序還有指令的完整相關性！-k ：找出使用該文件/目錄的 PID ，並試圖以 SIGKILL 這個訊號給予該 PID；-i ：必須與 -k 配合，在刪除 PID 之前會先詢問使用者意願！-signal：例如 -1 -15 等等，若不加的話，默認是 SIGKILL （-9） 囉！ 範例範例一：找出目前所在目錄的使用 PID/所屬帳號/權限 為何？[root@study ~]# fuser -uv . USER PID ACCESS COMMAND/root: root 13888 ..c.. （root）bash root 31743 ..c.. （root）bash``` ```bash範例二：找到所有使用到 /proc 這個文件系統的程序吧！[root@study ~]# fuser -uv /proc/proc: root kernel mount （root）/proc rtkit 768 .rc.. （rtkit）rtkit-daemon# 數據量還不會很多，雖然這個目錄很繁忙～沒關係！我們可以繼續這樣作，看看其他的程序！[root@study ~]# fuser -mvu /proc USER PID ACCESS COMMAND/proc: root kernel mount （root）/proc root 1 f.... （root）systemd root 2 ...e. （root）kthreadd.....（下面省略）.....# 有這幾支程序在進行 /proc 文件系統的存取喔！這樣清楚了嗎？ 範例三：找到所有使用到 /home 這個文件系統的程序吧！[root@study ~]# echo $$31743 # 先確認一下，自己的 bash PID 號碼吧！[root@study ~]# cd /home[root@study home]# fuser -muv . USER PID ACCESS COMMAND/home: root kernel mount （root）/home dmtsai 31535 ..c.. （dmtsai）bash root 31571 ..c.. （root）passwd root 31737 ..c.. （root）sudo root 31743 ..c.. （root）bash # 果然，自己的 PID 在啊！[root@study home]# cd ~[root@study ~]# umount /homeumount: /home: target is busy. （In some cases useful info about processes that use the device is found by lsof（8） or fuser（1））# 從 fuser 的結果可以知道，總共有五隻 process 在該目錄下運行，那即使 root 離開了 /home，# 當然還是無法 umount 的！那要怎辦？哈哈！可以通過如下方法一個一個刪除～[root@study ~]# fuser -mki /home/home: 31535c 31571c 31737c # 你會發現， PID 跟上面查到的相同！Kill process 31535 ? （y/N） # 這裡會問你要不要刪除！當然不要亂刪除啦！通通取消！ 那個 ACCESS 的項目，那個項目代表的意義為： c ：此程序在當前的目錄下（非次目錄）； e ：可被觸發為執行狀態； f ：是一個被打開的文件； r ：代表頂層目錄 （root directory）； F ：該文件被打開了，不過在等待迴應中； m ：可能為分享的動態函數庫； lsof列出被程序所打開的文件文件名 語法lsof [-aUu] [+d]選項與參數：-a ：多項數據需要“同時成立”才顯示出結果時！-U ：僅列出 Unix like 系統的 socket 文件類型；-u ：後面接 username，列出該使用者相關程序所打開的文件；+d ：後面接目錄，亦即找出某個目錄下面已經被打開的文件！ pidof找出某支正在執行的程序的 PID 語法pidof [-sx] program_name選項與參數：-s ：僅列出一個 PID 而不列出所有的 PID-x ：同時列出該 program name 可能的 PPID 那個程序的 PID systemdsystemd 的配置文件放置目錄/usr/lib/systemd/system/：每個服務最主要的啟動腳本設置，有點類似以前的 /etc/init.d 下面的文件；/run/systemd/system/：系統執行過程中所產生的服務腳本，這些腳本的優先序要比 /usr/lib/systemd/system/ 高！/etc/systemd/system/：管理員依據主機系統的需求所創建的執行腳本，其實這個目錄有點像以前 /etc/rc.d/rc5.d/Sxx 之類的功能！執行優先序又比 /run/systemd/system/ 高喔！ systemd 服務類型 擴展名 主要服務功能 .service 一般服務類型 （service unit）：主要是系統服務，包括服務器本身所需要的本機服務以及網絡服務都是！比較經常被使用到的服務大多是這種類型！ 所以，這也是最常見的類型了！ .socket 內部程序數據交換的插槽服務 （socket unit）：主要是 IPC （Inter-process communication） 的傳輸訊息插槽檔 （socket file） 功能。 這種類型的服務通常在監控訊息傳遞的插槽檔，當有通過此插槽檔傳遞訊息來說要鏈接服務時，就依據當時的狀態將該用戶的要求傳送到對應的 daemon， 若 daemon 尚未啟動，則啟動該 daemon 後再傳送用戶的要求。使用 socket 類型的服務一般是比較不會被用到的服務，因此在開機時通常會稍微延遲啟動的時間 （因為比較沒有這麼常用嘛！）。一般用於本機服務比較多，例如我們的圖形界面很多的軟件都是通過 socket 來進行本機程序數據交換的行為。 （這與早期的 xinetd 這個 super daemon 有部份的相似喔！） .target 執行環境類型 （target unit）：其實是一群 unit 的集合，例如上面表格中談到的 multi-user.target 其實就是一堆服務的集合～也就是說， 選擇執行 multi-user.target, 就是執行一堆其他 .service 或/及 .socket 之類的服務就是了！ .mount .automount 文件系統掛載相關的服務 （automount unit / mount unit）：例如來自網絡的自動掛載、NFS 文件系統掛載等與文件系統相關性較高的程序管理。 .path 偵測特定文件或目錄類型 （path unit）：某些服務需要偵測某些特定的目錄來提供佇列服務，例如最常見的打印服務，就是通過偵測打印佇列目錄來啟動打印功能！ 這時就得要 .path 的服務類型支持了！ .timer 循環執行的服務 （timer unit）：這個東西有點類似 anacrontab 喔！不過是由 systemd 主動提供的，比 anacrontab 更加有彈性！ systemctl管理單一服務 （service unit） 的啟動/開機啟動與觀察狀態 語法systemctl [command] [unit]command 主要有：start ：立刻啟動後面接的 unitstop ：立刻關閉後面接的 unitrestart ：立刻關閉後啟動後面接的 unit，亦即執行 stop 再 start 的意思reload ：不關閉後面接的 unit 的情況下，重新載入配置文件，讓設置生效enable ：設置下次開機時，後面接的 unit 會被啟動disable ：設置下次開機時，後面接的 unit 不會被啟動status ：目前後面接的這個 unit 的狀態，會列出有沒有正在執行、開機默認執行否、登錄等信息等！is-active ：目前有沒有正在運行中is-enable ：開機時有沒有默認要啟用這個 unitis-enable ：開機時有沒有默認要啟用這個 unit systemctl [command] [--type=TYPE] [--all]command: list-units ：依據 unit 列出目前有啟動的 unit。若加上 --all 才會列出沒啟動的。 list-unit-files ：依據 /usr/lib/systemd/system/ 內的文件，將所有文件列表說明。--type=TYPE：就是之前提到的 unit type，主要有 service, socket, target 等 unit 狀態systemctl list-units UNIT LOAD ACTIVE SUB DESCRIPTION proc-sys-fs-binfmt_mis… loaded active waiting Arbitrary Executable File Formats File System sys-devices-pc…:0:1:… loaded active plugged QEMU_HARDDISK sys-devices-pc…0:1-0… loaded active plugged QEMU_HARDDISK sys-devices-pc…0:0-1… loaded active plugged QEMU_DVD-ROM …..（中間省略）…..vsftpd.service loaded active running Vsftpd ftp daemon …..（中間省略）…..cups.socket loaded failed failed CUPS Printing Service Sockets…..（中間省略）….. LOAD = Reflects whether the unit definition was properly loaded. ACTIVE = The high-level unit activation state, i.e. generalization of SUB. SUB = The low-level unit activation state, values depend on unit type. 141 loaded units listed. Pass –all to see loaded but inactive units, too. To show all installed unit files use ‘systemctl list-unit-files’. 列出的項目中，主要的意義是： UNIT ：項目的名稱，包括各個 unit 的類別 （看擴展名） LOAD ：開機時是否會被載入，默認 systemctl 顯示的是有載入的項目而已喔！ ACTIVE ：目前的狀態，須與後續的 SUB 搭配！就是我們用 systemctl status 觀察時，active 的項目！ DESCRIPTION ：詳細描述囉 cups 比較有趣，因為剛剛被我們玩過，所以 ACTIVE 竟然是 failed 的喔！被玩死了！ ^_^ 另外，systemctl 都不加參數，其實默認就是 list-units 的意思！ active 狀態 狀態 解釋 active （running） 正有一隻或多隻程序正在系統中執行的意思，舉例來說，正在執行中的 vsftpd 就是這種模式。 active （exited） 僅執行一次就正常結束的服務，目前並沒有任何程序在系統中執行。 舉例來說，開機或者是掛載時才會進行一次的 quotaon 功能，就是這種模式！ quotaon 不須一直執行～只須執行一次之後，就交給文件系統去自行處理囉！通常用 bash shell 寫的小型服務，大多是屬於這種類型 （無須常駐內存）。 active （waiting） 正在執行當中，不過還再等待其他的事件才能繼續處理。舉例來說，打印的佇列相關服務就是這種狀態！ 雖然正在啟動中，不過，也需要真的有佇列進來 （打印工作） 這樣他才會繼續喚醒打印機服務來進行下一步打印的功能。 inactive 這個服務目前沒有運行的意思。 daemon 默認狀態 狀態 解釋 enabled 這個 daemon 將在開機時被執行 disabled 這個 daemon 在開機時不會被執行 static 這個 daemon 不可以自己啟動 （enable 不可），不過可能會被其他的 enabled 的服務來喚醒 （相依屬性的服務） mask 這個 daemon 無論如何都無法被啟動！因為已經被強制註銷 （非刪除）。可通過 systemctl unmask 方式改回原本狀態 管理不同的操作環境systemctl list-units --type=target --all UNIT LOAD ACTIVE SUB DESCRIPTIONbasic.target loaded active active Basic Systemcryptsetup.target loaded active active Encrypted Volumesemergency.target loaded inactive dead Emergency Modefinal.target loaded inactive dead Final Stepgetty.target loaded active active Login Promptsgraphical.target loaded active active Graphical Interfacelocal-fs-pre.target loaded active active Local File Systems （Pre）local-fs.target loaded active active Local File Systemsmulti-user.target loaded active active Multi-User Systemnetwork-online.target loaded inactive dead Network is Onlinenetwork.target loaded active active Networknss-user-lookup.target loaded inactive dead User and Group Name Lookupspaths.target loaded active active Pathsremote-fs-pre.target loaded active active Remote File Systems （Pre）remote-fs.target loaded active active Remote File Systemsrescue.target loaded inactive dead Rescue Modeshutdown.target loaded inactive dead Shutdownslices.target loaded active active Slicessockets.target loaded active active Socketssound.target loaded active active Sound Cardswap.target loaded active active Swapsysinit.target loaded active active System Initializationsyslog.target not-found inactive dead syslog.targettime-sync.target loaded inactive dead System Time Synchronizedtimers.target loaded active active Timersumount.target loaded inactive dead Unmount All FilesystemsLOAD = Reflects whether the unit definition was properly loaded.ACTIVE = The high-level unit activation state, i.e. generalization of SUB.SUB = The low-level unit activation state, values depend on unit type.26 loaded units listed.To show all installed unit files use 'systemctl list-unit-files'. graphical.target：就是文字加上圖形界面，這個項目已經包含了下面的 multi-user.target 項目！ multi-user.target：純文本模式！ rescue.target：在無法使用 root 登陸的情況下，systemd 在開機時會多加一個額外的暫時系統，與你原本的 系統無關。這時你可以取得 root 的權限來維護你的系統。 但是這是額外系統，因此可能需要動到 chroot 的方式來取得你原有的系統喔！ emergency.target：緊急處理系統的錯誤，還是需要使用 root 登陸的情況，在無法使用 rescue.target 時，可以嘗試使用這種模式！ shutdown.target：就是關機的流程。 getty.target：可以設置你需要幾個 tty 之類的，如果想要降低 tty 的項目，可以修改這個東西的配置文件！ 取得目前的操作環境以及修改systemctl [command] [unit.target]選項與參數：command: get-default ：取得目前的 target set-default ：設置後面接的 target 成為默認的操作模式 isolate ：切換到後面接的模式 範例範例一：我們的測試機器默認是圖形界面，先觀察是否真為圖形模式，再將默認模式轉為文字界面[root@study ~]# systemctl get-default graphical.target # 果然是圖形界面喔！[root@study ~]# systemctl set-default multi-user.target[root@study ~]# systemctl get-default multi-user.target 範例二：在不重新開機的情況下，將目前的操作環境改為純文本模式，關掉圖形界面[root@study ~]# systemctl isolate multi-user.target 範例三：若需要重新取得圖形界面呢？[root@study ~]# systemctl isolate graphical.target 要注意，改變 graphical.target 以及 multi-user.target 是通過 isolate 來處理的。 在正常的切換情況下，使用上述 isolate 的方式即可。不過為了方便起見， systemd 也提供了數個簡單的指令給我們切換操作模式之用喔！ 大致上如下所示： systemctl 針對機器操作的幾個簡單指令[root@study ~]# systemctl poweroff 系統關機[root@study ~]# systemctl reboot 重新開機[root@study ~]# systemctl suspend 進入暫停模式[root@study ~]# systemctl hibernate 進入休眠模式[root@study ~]# systemctl rescue 強制進入救援模式[root@study ~]# systemctl emergency 強制進入緊急救援模式 suspend：暫停模式會將系統的狀態數據保存到內存中，然後關閉掉大部分的系統硬件，當然，並沒有實際關機喔！ 當使用者按下喚醒機器的按鈕，系統數據會重內存中回覆，然後重新驅動被大部分關閉的硬件，就開始正常運行！喚醒的速度較快。 hibernate：休眠模式則是將系統狀態保存到硬盤當中，保存完畢後，將計算機關機。當使用者嘗試喚醒系統時，系統會開始正常運行， 然後將保存在硬盤中的系統狀態恢復回來。因為數據是由硬盤讀出，因此喚醒的性能與你的硬盤速度有關。 通過 systemctl 分析各服務之間的相依性[root@study ~]# systemctl list-dependencies [unit] [--reverse]選項與參數：--reverse ：反向追蹤誰使用這個 unit 的意思！ 範例範例一：列出目前的 target 環境下，用到什麼特別的 unit [root@study ~]# systemctl get-defaultmulti-user.target[root@study ~]# systemctl list-dependenciesdefault.target├─abrt-ccpp.service├─abrt-oops.service├─vsftpd.service├─basic.target│ ├─alsa-restore.service│ ├─alsa-state.service.....（中間省略）.....│ ├─sockets.target│ │ ├─avahi-daemon.socket│ │ ├─dbus.socket.....（中間省略）.....│ ├─sysinit.target│ │ ├─dev-hugepages.mount│ │ ├─dev-mqueue.mount.....（中間省略）.....│ └─timers.target│ └─systemd-tmpfiles-clean.timer├─getty.target│ └─getty@tty1.service└─remote-fs.target 如果要查出誰會用到 multi-user.target 呢？systemctl list-dependencies --reversedefault.target└─graphical.target graphical.target 又使用了多少的服務呢？systemctl list-dependencies graphical.targetgraphical.target├─accounts-daemon.service├─gdm.service├─network.service├─rtkit-daemon.service├─systemd-update-utmp-runlevel.service└─multi-user.target ├─abrt-ccpp.service ├─abrt-oops.service.....（下面省略）..... process substitution &lt;( command ) or &gt;( command )如果使用 &gt;(list), 那帶入的值將會作為 list 的輸入。 若使用 &lt;(list), 那將會是 list 的輸出 語法&lt;(list) 或是 &gt;(list) logrotate那個 logrotate.conf 才是主要的參數文件，至於 logrotate.d 是一個目錄， 該目錄裡面的所有文件都會被主動的讀入 /etc/logrotate.conf 當中來進行！另外，在 /etc/logrotate.d/ 裡面的文件中，如果沒有規定到的一些細部設置，則以 /etc/logrotate.conf 這個文件的規定來指定為默認值！ logrotate 這個程序的參數配置文件位置/etc/logrotate.conf/etc/logrotate.d/ 語法logrotate [-vf] logfile選項與參數：-v ：啟動顯示模式，會顯示 logrotate 運行的過程喔！-f ：不論是否符合配置文件的數據，強制每個登錄文件都進行 rotate 的動作！範例一：執行一次 logrotate 看看整個流程為何？[root@study ~]# logrotate -v /etc/logrotate.confreading config file /etc/logrotate.conf &lt;==讀取主要配置文件including /etc/logrotate.d &lt;==調用外部的設置reading config file chrony &lt;==就是外部設置啊！....（中間省略）....Handling 18 logs &lt;==共有 18 個登錄文件被記錄....（中間省略）....rotating pattern: /var/log/cron/var/log/maillog/var/log/messages/var/log/secure/var/log/spooler weekly （52 rotations）empty log files are not rotated, old logs are removedconsidering log /var/log/cron log does not need rotatingconsidering log /var/log/maillog log does not need rotatingconsidering log /var/log/messages &lt;==開始處理 messages log does not need rotating &lt;==因為時間未到，不需要更動！....（下面省略）....範例二：強制進行 logrotate 的動作[root@study ~]# logrotate -vf /etc/logrotate.conf....（前面省略）....rotating log /var/log/messages, log-&gt;rotateCount is 52dateext suffix '-20150820'glob pattern '-[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]'compressing log with: /bin/gzip....（下面省略）....# 看到否？整個 rotate 的動作就是這樣一步一步進行的～[root@study ~]# ll /var/log/messages*; lsattr /var/log/messages-rw-------. 1 root root 143 Aug 20 01:45 /var/log/messages-rw-------. 1 root root 167125 Aug 20 01:40 /var/log/messages-20150820-----a---------- /var/log/messages &lt;==主動加入 a 的隱藏屬性囉！ [root@study ~]# vim /etc/logrotate.conf# 下面的設置是 \"logrotate 的默認設置值\" ，如果個別的文件設置了其他的參數，# 則將以個別的文件設置為主，若該文件沒有設置到的參數則以這個文件的內容為默認值！weekly &lt;==默認每個禮拜對登錄文件進行一次 rotate 的工作rotate 4 &lt;==保留幾個登錄文件呢？默認是保留四個！create &lt;==由於登錄文件被更名，因此創建一個新的來繼續儲存之意！dateext &lt;==就是這個設置值！可以讓被輪替的文件名稱加上日期作為文件名喔！#compress &lt;==被更動的登錄文件是否需要壓縮？如果登錄文件太大則可考慮此參數啟動include /etc/logrotate.d# 將 /etc/logrotate.d/ 這個目錄中的所有文件都讀進來執行 rotate 的工作！/var/log/wtmp &#123; &lt;==僅針對 /var/log/wtmp 所設置的參數 monthly &lt;==每個月一次，取代每週！ create 0664 root utmp &lt;==指定新建文件的權限與所屬帳號/群組 minsize 1M &lt;==文件大小一定要超過 1M 後才進行 rotate （略過時間參數） rotate 1 &lt;==僅保留一個，亦即僅有 wtmp.1 保留而已。&#125;# 這個 wtmp 可記錄登陸者與系統重新開機時的時間與來源主機及登陸期間的時間。# 由於具有 minsize 的參數，因此不見得每個月一定會進行一次喔！要看文件大小。# 由於僅保留一個登錄文件而已，不滿意的話可以將他改成 rotate 5 吧！ 範例/root/.pm2/logs/run-checkEdgeAlive.log &#123; daily dateext missingok rotate 14 compress notifempty&#125; command || true patten目前大部分的系統遵循 set -e (Exit immediately if a command exits with a non-zero status.) 規則，所以為了避免一些小錯誤中斷了 command 的執行，所以使用 command || true patten例如 rmdir ... || true, 這樣就算 remove directory 失敗了， command 也不會中斷執行。","link":"/zh-tw/Linux/"}],"tags":[{"name":"Apache","slug":"Apache","link":"/zh-tw/tags/Apache/"},{"name":"MySQL","slug":"MySQL","link":"/zh-tw/tags/MySQL/"},{"name":"Composer","slug":"Composer","link":"/zh-tw/tags/Composer/"},{"name":"Laravel","slug":"Laravel","link":"/zh-tw/tags/Laravel/"},{"name":"PHP","slug":"PHP","link":"/zh-tw/tags/PHP/"},{"name":"GCP Essentials","slug":"GCP-Essentials","link":"/zh-tw/tags/GCP-Essentials/"},{"name":"QWIKLABS","slug":"QWIKLABS","link":"/zh-tw/tags/QWIKLABS/"},{"name":"GCP Essential","slug":"GCP-Essential","link":"/zh-tw/tags/GCP-Essential/"},{"name":"Google Load Balancers","slug":"Google-Load-Balancers","link":"/zh-tw/tags/Google-Load-Balancers/"},{"name":"GCP Compute Engine","slug":"GCP-Compute-Engine","link":"/zh-tw/tags/GCP-Compute-Engine/"},{"name":"GCP Marketplace","slug":"GCP-Marketplace","link":"/zh-tw/tags/GCP-Marketplace/"},{"name":"Google Load Baalancers","slug":"Google-Load-Baalancers","link":"/zh-tw/tags/Google-Load-Baalancers/"},{"name":"Google Kubernetes","slug":"Google-Kubernetes","link":"/zh-tw/tags/Google-Kubernetes/"},{"name":"Laravel Transaction","slug":"Laravel-Transaction","link":"/zh-tw/tags/Laravel-Transaction/"},{"name":"Laravel Log","slug":"Laravel-Log","link":"/zh-tw/tags/Laravel-Log/"},{"name":"ngrok","slug":"ngrok","link":"/zh-tw/tags/ngrok/"},{"name":"Laravel Middleware","slug":"Laravel-Middleware","link":"/zh-tw/tags/Laravel-Middleware/"},{"name":"GCP Kubernetes","slug":"GCP-Kubernetes","link":"/zh-tw/tags/GCP-Kubernetes/"},{"name":"Linux","slug":"Linux","link":"/zh-tw/tags/Linux/"},{"name":"MongoDB","slug":"MongoDB","link":"/zh-tw/tags/MongoDB/"},{"name":"Node.js","slug":"Node-js","link":"/zh-tw/tags/Node-js/"},{"name":"AWS SQS","slug":"AWS-SQS","link":"/zh-tw/tags/AWS-SQS/"},{"name":"Laravel Queue","slug":"Laravel-Queue","link":"/zh-tw/tags/Laravel-Queue/"},{"name":"Google Stackdriver","slug":"Google-Stackdriver","link":"/zh-tw/tags/Google-Stackdriver/"},{"name":"Baseline: Infrastructure","slug":"Baseline-Infrastructure","link":"/zh-tw/tags/Baseline-Infrastructure/"},{"name":"Laravel blade","slug":"Laravel-blade","link":"/zh-tw/tags/Laravel-blade/"},{"name":"Laravel template","slug":"Laravel-template","link":"/zh-tw/tags/Laravel-template/"},{"name":"Laravel view","slug":"Laravel-view","link":"/zh-tw/tags/Laravel-view/"},{"name":"Hexo","slug":"Hexo","link":"/zh-tw/tags/Hexo/"},{"name":"minos","slug":"minos","link":"/zh-tw/tags/minos/"},{"name":"GCP Cloud Functions","slug":"GCP-Cloud-Functions","link":"/zh-tw/tags/GCP-Cloud-Functions/"},{"name":"class","slug":"class","link":"/zh-tw/tags/class/"},{"name":"object","slug":"object","link":"/zh-tw/tags/object/"},{"name":"GCP IAM","slug":"GCP-IAM","link":"/zh-tw/tags/GCP-IAM/"},{"name":"Google Cloud Storage","slug":"Google-Cloud-Storage","link":"/zh-tw/tags/Google-Cloud-Storage/"},{"name":"GCP-Baseline:Infrastructure","slug":"GCP-Baseline-Infrastructure","link":"/zh-tw/tags/GCP-Baseline-Infrastructure/"},{"name":"GCP Storage","slug":"GCP-Storage","link":"/zh-tw/tags/GCP-Storage/"},{"name":"Laravel Image","slug":"Laravel-Image","link":"/zh-tw/tags/Laravel-Image/"},{"name":"Laravel package Intervention","slug":"Laravel-package-Intervention","link":"/zh-tw/tags/Laravel-package-Intervention/"},{"name":"Docker Image","slug":"Docker-Image","link":"/zh-tw/tags/Docker-Image/"},{"name":"Docker Container","slug":"Docker-Container","link":"/zh-tw/tags/Docker-Container/"},{"name":"Docker Swarm","slug":"Docker-Swarm","link":"/zh-tw/tags/Docker-Swarm/"},{"name":"Docker Multi Stage","slug":"Docker-Multi-Stage","link":"/zh-tw/tags/Docker-Multi-Stage/"},{"name":"Docker Compose","slug":"Docker-Compose","link":"/zh-tw/tags/Docker-Compose/"},{"name":"Docker Service","slug":"Docker-Service","link":"/zh-tw/tags/Docker-Service/"},{"name":"Docker Rolling Update","slug":"Docker-Rolling-Update","link":"/zh-tw/tags/Docker-Rolling-Update/"},{"name":"Docker Push","slug":"Docker-Push","link":"/zh-tw/tags/Docker-Push/"},{"name":"Docker Deployment","slug":"Docker-Deployment","link":"/zh-tw/tags/Docker-Deployment/"},{"name":"gcloud shell","slug":"gcloud-shell","link":"/zh-tw/tags/gcloud-shell/"},{"name":"vsftpd","slug":"vsftpd","link":"/zh-tw/tags/vsftpd/"},{"name":"ftp","slug":"ftp","link":"/zh-tw/tags/ftp/"},{"name":"Stackdriver Logging","slug":"Stackdriver-Logging","link":"/zh-tw/tags/Stackdriver-Logging/"},{"name":"GCP Stackdriver","slug":"GCP-Stackdriver","link":"/zh-tw/tags/GCP-Stackdriver/"},{"name":"git rebase -i","slug":"git-rebase-i","link":"/zh-tw/tags/git-rebase-i/"},{"name":"git rebase -i --onto","slug":"git-rebase-i-onto","link":"/zh-tw/tags/git-rebase-i-onto/"},{"name":"git reset --hard","slug":"git-reset-hard","link":"/zh-tw/tags/git-reset-hard/"},{"name":"git reset @^ --hard","slug":"git-reset-hard","link":"/zh-tw/tags/git-reset-hard/"},{"name":"git checkout -b","slug":"git-checkout-b","link":"/zh-tw/tags/git-checkout-b/"},{"name":"git flow","slug":"git-flow","link":"/zh-tw/tags/git-flow/"},{"name":"PayPal REST API","slug":"PayPal-REST-API","link":"/zh-tw/tags/PayPal-REST-API/"},{"name":"git revert","slug":"git-revert","link":"/zh-tw/tags/git-revert/"},{"name":"Facebook Graph API","slug":"Facebook-Graph-API","link":"/zh-tw/tags/Facebook-Graph-API/"},{"name":"GCP virtual machine","slug":"GCP-virtual-machine","link":"/zh-tw/tags/GCP-virtual-machine/"},{"name":"Daemon","slug":"Daemon","link":"/zh-tw/tags/Daemon/"},{"name":"SSH","slug":"SSH","link":"/zh-tw/tags/SSH/"},{"name":"Gitlab pusher","slug":"Gitlab-pusher","link":"/zh-tw/tags/Gitlab-pusher/"},{"name":"GCP Pub/Sub","slug":"GCP-Pub-Sub","link":"/zh-tw/tags/GCP-Pub-Sub/"},{"name":"GCP-Baseline: Infrastructure","slug":"GCP-Baseline-Infrastructure","link":"/zh-tw/tags/GCP-Baseline-Infrastructure/"},{"name":"git init","slug":"git-init","link":"/zh-tw/tags/git-init/"},{"name":"git tag -a","slug":"git-tag-a","link":"/zh-tw/tags/git-tag-a/"},{"name":"git checkout","slug":"git-checkout","link":"/zh-tw/tags/git-checkout/"},{"name":"git log --oneline","slug":"git-log-oneline","link":"/zh-tw/tags/git-log-oneline/"},{"name":"git config","slug":"git-config","link":"/zh-tw/tags/git-config/"},{"name":"git config --global user.name","slug":"git-config-global-user-name","link":"/zh-tw/tags/git-config-global-user-name/"},{"name":"git config --global user.email","slug":"git-config-global-user-email","link":"/zh-tw/tags/git-config-global-user-email/"},{"name":"AWS","slug":"AWS","link":"/zh-tw/tags/AWS/"},{"name":"garbles","slug":"garbles","link":"/zh-tw/tags/garbles/"},{"name":"AWS SES","slug":"AWS-SES","link":"/zh-tw/tags/AWS-SES/"},{"name":"Ngrok","slug":"Ngrok","link":"/zh-tw/tags/Ngrok/"},{"name":"Laravel Mail","slug":"Laravel-Mail","link":"/zh-tw/tags/Laravel-Mail/"},{"name":"git add","slug":"git-add","link":"/zh-tw/tags/git-add/"},{"name":"git commit","slug":"git-commit","link":"/zh-tw/tags/git-commit/"},{"name":"git commit -a","slug":"git-commit-a","link":"/zh-tw/tags/git-commit-a/"},{"name":"Japanese","slug":"Japanese","link":"/zh-tw/tags/Japanese/"},{"name":"Let's Encrypt","slug":"Let-s-Encrypt","link":"/zh-tw/tags/Let-s-Encrypt/"},{"name":"SSL","slug":"SSL","link":"/zh-tw/tags/SSL/"},{"name":"GCP Kubernetes Engine","slug":"GCP-Kubernetes-Engine","link":"/zh-tw/tags/GCP-Kubernetes-Engine/"},{"name":"Jenkins","slug":"Jenkins","link":"/zh-tw/tags/Jenkins/"},{"name":"CI/CD","slug":"CI-CD","link":"/zh-tw/tags/CI-CD/"},{"name":"PayPal Payment Standard","slug":"PayPal-Payment-Standard","link":"/zh-tw/tags/PayPal-Payment-Standard/"},{"name":"PayPal IPN","slug":"PayPal-IPN","link":"/zh-tw/tags/PayPal-IPN/"},{"name":"CSV","slug":"CSV","link":"/zh-tw/tags/CSV/"},{"name":"pm2","slug":"pm2","link":"/zh-tw/tags/pm2/"},{"name":"GitLab CI / CD","slug":"GitLab-CI-CD","link":"/zh-tw/tags/GitLab-CI-CD/"},{"name":"Sequelize","slug":"Sequelize","link":"/zh-tw/tags/Sequelize/"},{"name":"ssh-add","slug":"ssh-add","link":"/zh-tw/tags/ssh-add/"},{"name":"ssh-agent","slug":"ssh-agent","link":"/zh-tw/tags/ssh-agent/"},{"name":"Supervisor","slug":"Supervisor","link":"/zh-tw/tags/Supervisor/"},{"name":"MacOS","slug":"MacOS","link":"/zh-tw/tags/MacOS/"},{"name":"multiple items","slug":"multiple-items","link":"/zh-tw/tags/multiple-items/"},{"name":"variables","slug":"variables","link":"/zh-tw/tags/variables/"},{"name":"Laravel Task Scheduling","slug":"Laravel-Task-Scheduling","link":"/zh-tw/tags/Laravel-Task-Scheduling/"},{"name":"Linux crontab","slug":"Linux-crontab","link":"/zh-tw/tags/Linux-crontab/"},{"name":"group by","slug":"group-by","link":"/zh-tw/tags/group-by/"},{"name":"GCP BigQuery","slug":"GCP-BigQuery","link":"/zh-tw/tags/GCP-BigQuery/"},{"name":"git log","slug":"git-log","link":"/zh-tw/tags/git-log/"},{"name":"VIM","slug":"VIM","link":"/zh-tw/tags/VIM/"},{"name":"GCP Cloud Shell","slug":"GCP-Cloud-Shell","link":"/zh-tw/tags/GCP-Cloud-Shell/"},{"name":"GCP Cloud Storage","slug":"GCP-Cloud-Storage","link":"/zh-tw/tags/GCP-Cloud-Storage/"},{"name":"Facebook 長期權杖","slug":"Facebook-長期權杖","link":"/zh-tw/tags/Facebook-長期權杖/"},{"name":"Facebook 永不過期權杖","slug":"Facebook-永不過期權杖","link":"/zh-tw/tags/Facebook-永不過期權杖/"},{"name":"歐付寶","slug":"歐付寶","link":"/zh-tw/tags/歐付寶/"},{"name":"歐付寶 付款","slug":"歐付寶-付款","link":"/zh-tw/tags/歐付寶-付款/"},{"name":"歐付寶 退款","slug":"歐付寶-退款","link":"/zh-tw/tags/歐付寶-退款/"},{"name":"PayPal 退款","slug":"PayPal-退款","link":"/zh-tw/tags/PayPal-退款/"},{"name":"PayPal 授權","slug":"PayPal-授權","link":"/zh-tw/tags/PayPal-授權/"},{"name":"PayPal 請款","slug":"PayPal-請款","link":"/zh-tw/tags/PayPal-請款/"},{"name":"PayPal 取消授權","slug":"PayPal-取消授權","link":"/zh-tw/tags/PayPal-取消授權/"},{"name":"PayPal 建立授權訂單","slug":"PayPal-建立授權訂單","link":"/zh-tw/tags/PayPal-建立授權訂單/"},{"name":"PayPal 款項凍結","slug":"PayPal-款項凍結","link":"/zh-tw/tags/PayPal-款項凍結/"},{"name":"多語","slug":"多語","link":"/zh-tw/tags/多語/"},{"name":"多語系","slug":"多語系","link":"/zh-tw/tags/多語系/"},{"name":"雙語","slug":"雙語","link":"/zh-tw/tags/雙語/"},{"name":"部落格","slug":"部落格","link":"/zh-tw/tags/部落格/"},{"name":"GCP Persistent Disk","slug":"GCP-Persistent-Disk","link":"/zh-tw/tags/GCP-Persistent-Disk/"}],"categories":[{"name":"GCP","slug":"GCP","link":"/zh-tw/categories/GCP/"},{"name":"Facebook","slug":"Facebook","link":"/zh-tw/categories/Facebook/"},{"name":"Node.js","slug":"Node-js","link":"/zh-tw/categories/Node-js/"},{"name":"Laravel","slug":"Laravel","link":"/zh-tw/categories/Laravel/"},{"name":"Hexo","slug":"Hexo","link":"/zh-tw/categories/Hexo/"},{"name":"OOP","slug":"OOP","link":"/zh-tw/categories/OOP/"},{"name":"Git","slug":"Git","link":"/zh-tw/categories/Git/"},{"name":"PHP","slug":"PHP","link":"/zh-tw/categories/PHP/"},{"name":"Languages","slug":"Languages","link":"/zh-tw/categories/Languages/"},{"name":"ssh","slug":"ssh","link":"/zh-tw/categories/ssh/"},{"name":"MySQL","slug":"MySQL","link":"/zh-tw/categories/MySQL/"},{"name":"VIM","slug":"VIM","link":"/zh-tw/categories/VIM/"},{"name":"部署","slug":"部署","link":"/zh-tw/categories/部署/"},{"name":"金流","slug":"金流","link":"/zh-tw/categories/金流/"},{"name":"資料庫","slug":"資料庫","link":"/zh-tw/categories/資料庫/"}]}