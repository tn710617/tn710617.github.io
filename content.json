{"pages":[{"title":"About Me","text":"I’m a backend programmerOnce I was a career soldier. During the drills, I took sky as my quilt, and the earth as my bed, sitting on the meadow next to my comrades, exchanging knowing smiles, looking up the sky dotted with stars without light pollution, and of course, without taking a bath for over 1 week. It’s such an unforgettable experience. Sometimes I lapsed into this kind of reminiscence. however, which, I don’t want to experience anymore in the rest of my life. I was an international salesman. I found that there was some uncannily striking resemblance between the insistence of Japanese on SOP, and that of Jew on cost.Actually, office staff in US does not get overtime pay either.The first time I met Dutch face to face, the first impression I got was if they were descended from The GiantIn the battle, Jew has to wait for the first shot from their enemy and so they could fire back. “What if you got shot at the first shot from your enemy?” I asked. “Oh, that would be your fate” The Jew replied.Currently I am a programmer. How lucky I am, I had a serendipity with coding. I like any form of languages. When I feel like talking to people, I speak human language. When I prefer to be alone, I speak machine language. I’m enamoured with the contrast between the delicacy and strictness of machine language. The nonstop developing technology constantly surprises me while fulfilling my great appetite for knowledge. I do not need an alarm every morning. The scalding blood in my vein wakes me up, and the excitement for a new day dissipates the sleepiness, because on this new day, I can think, I can learn, and convert my logic and idea into a sophisticated, elegant, and exquisite language.","link":"/about/index.html"},{"title":"archives","text":"","link":"/archives/index.html"},{"title":"categories","text":"","link":"/categories/index.html"},{"title":"Friends","text":"","link":"/friends/index.html"},{"title":"Schedule","text":"2019/9/15The target I set today Task: Working on logParsing API Take a rest because you are having a cold. Complete translated course so far Post an article Linux English Japanese The result of today’s target Task: Working on logParsing API Take a rest because you are having a cold. Complete translated course so far Post an article Linux English Japanese 2019/9/14The target I set today Task: Working on logParsing API Take a rest because you are having a cold. Post one article Linux English Japanese The result of today’s target Task: Working on logParsing API Take a rest because you are having a cold. Post one article Linux English Japanese 2019/9/13The target I set today Task: Working on logParsing API Take a rest because you are having a cold. Post one article Finish one Qwiklab course Make a Qwiklab lesson documentation Linux English Japanese The result of today’s target Task: Working on logParsing API Take a rest because you are having a cold. Post one article Finish one Qwiklab course Make a Qwiklab lesson documentation Linux English Japanese 2019/9/12The target I set today Task: Working on logParsing API Linux English Japanese The result of today’s target Task: Working on logParsing API Working on SSH issue Linux English Japanese 2019/9/11The target I set today Task: Working on logParsing API Linux English Japanese The result of today’s target Task: Working on logParsing API Linux English Japanese 2019/9/11the result of my target yesterday Task: Working on logParsing API Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on logParsing API Linux English Japanese 2019/9/10the result of my target yesterday Task: Working on logParsing API Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on logParsing API Linux English Japanese 2019/9/9the result of my target yesterday Task: Finish one course of GCP Post an article Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on logParsing API Linux English Japanese 2019/9/8the result of my target yesterday Task: Finish one course of GCP Post an article Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Finish one course of GCP Post an article Linux English Japanese 2019/9/7the result of my target yesterday Task: Working on logParsing Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Finish one course of GCP Post an article Linux English Japanese 2019/9/6the result of my target yesterday Task: Working on logParsing Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on logParsing Linux English Japanese 2019/9/5the result of my target yesterday Task: Working on logParsing Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on logParsing Linux English Japanese 2019/9/4the result of my target yesterday Task: Working on logParsing Still working on it Stackdriver Logging - Logging with Stackdriver on Kubernetes Engine No time for it Learn Node course 3 No time for it One interesting thing Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on logParsing Linux English Japanese 2019/9/3the result of my target yesterday Task: Working on logParsing Still working on it Stackdriver Logging - Logging with Stackdriver on Kubernetes Engine No time for it Learn Node course 3 No time for it One interesting thing No time for it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on logParsing Stackdriver Logging - Logging with Stackdriver on Kubernetes Engine Learn Node course 3 One interesting thing Linux English Japanese 2019/9/2the result of my target yesterday Task: Stackdriver Logging - Logging with Stackdriver on Kubernetes Engine Completed document Documentation building - Baseline: Infrastructure - Cloud IAM: Qwik Start Learn Node course 3 One interesting thing Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on logParsing Stackdriver Logging - Logging with Stackdriver on Kubernetes Engine Learn Node course 3 One interesting thing Linux English Japanese 2019/9/1the result of my target yesterday Task: Working on Stackdriver Logging - Using BigQuery and Stackdriver to Analyze BigQuery Usage Documentation building - Baseline: Infrastructure - Cloud IAM: Qwik Start Still working Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Stackdriver Logging - Logging with Stackdriver on Kubernetes Engine Documentation building - Baseline: Infrastructure - Cloud IAM: Qwik Start Learn Node course 3 One interesting thing Linux English Japanese History","link":"/schedule/index.html"},{"title":"tags","text":"","link":"/tags/index.html"},{"title":"History","text":"2019AugustJulyJuneMayAprilMarchFebruaryJanuary 2018DecemberNovember","link":"/schedule/History/index.html"},{"title":"August 2019","text":"2019/8/31the result of my target yesterday Task: Working on logParsing and inserting project Still working on it Working on Stackdriver course 2 Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on Stackdriver Logging - Using BigQuery and Stackdriver to Analyze BigQuery Usage Documentation building - Baseline: Infrastructure - Cloud IAM: Qwik Start Linux English Japanese 2019/8/30the result of my target yesterday Task: Working on logParsing and inserting project Still working on it Working on Stackdriver course 2 Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on logParsing and inserting project Working on Stackdriver course 2 Linux English Japanese 2019/8/29the result of my target yesterday Task: Finish Netdata Finish Stackdriver course 1 Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on logParsing and inserting project Working on Stackdriver course 2 Linux English Japanese 2019/8/28the result of my target yesterday Task: Finish Netdata Still working on it Finish Stackdriver course 1 Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Finish Netdata Finish Stackdriver course 1 Linux English Japanese 2019/8/27the result of my target yesterday Task: Finish Netdata Still working on it Finish Stackdriver course 1 Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Finish Netdata Finish Stackdriver course 1 Linux English Japanese 2019/8/26the result of my target yesterday Task: Start a new Quest on QwikLab Finish Cloud FUnction document Not yet, do Stackdriver first. Finish Node course episode 2 Not yet, haven’t finished Stackdriver Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Finish Netdata Finish Stackdriver course 1 Linux English Japanese 2019/8/25the result of my target yesterday Task: Finish QwikLab Baseline: Infrastructure Finish The Wondering presentation next week Post at least an article of QwikLab Improve my resume Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Start a new Quest on QwikLab Finish Cloud FUnction document Finish Node course episode 2 Linux English Japanese 2019/8/24the result of my target yesterday Task: Working on Netdata and MongoDB Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Finish QwikLab Baseline: Infrastructure Finish The Wondering presentation next week Post at least an article of QwikLab Improve my resume Linux English Japanese 2019/8/23the result of my target yesterday Task: Working on customer-dashboard Was assigned to do another work Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on Netdata and MongoDB Linux English Japanese 2019/8/22the result of my target yesterday Task: Working on customer-dashboard Still working on it Finish GCP Cloud IAM: Qwik Start Still no time for it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on customer-dashboard Linux English Japanese 2019/8/21the result of my target yesterday Task: Working on customer-dashboard Still working on it Finish GCP Cloud IAM: Qwik Start Still no time for it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on customer-dashboard Finish GCP Cloud IAM: Qwik Start Linux English Japanese 2019/8/20the result of my target yesterday Task: Working on customer-dashboard Still working on it Finish GCP Cloud IAM: Qwik Start No time for it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on customer-dashboard Finish GCP Cloud IAM: Qwik Start Linux English Japanese 2019/8/19the result of my target yesterday Task: Post GCP Cloud Storage Qwiklab start: SDK/CLI Finish GCP Cloud IAM: Qwik Start Still haven’t finished yet Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on customer-dashboard Finish GCP Cloud IAM: Qwik Start Linux English Japanese 2019/8/18the result of my target yesterday Task: Post GCP Storage Qwiklab start: Console Finish GCP Storage Qwiklab start: SDK/CLI Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Post GCP Cloud Storage Qwiklab start: SDK/CLI Finish GCP Cloud IAM: Qwik Start Linux English Japanese 2019/8/17the result of my target yesterday Task: Release checkEdgeAlive asynchronous beta version Release checkEdgeAlive process-block-proof shell script Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Post GCP Storage Qwiklab start: Console Finish GCP Storage Qwiklab start: SDK/CLI Linux English Japanese 2019/8/16the result of my target yesterday Task: Build new site with SSL certificate Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Release checkEdgeAlive asynchronous beta version Release checkEdgeAlive process-block-proof shell script Linux English Japanese 2019/8/15the result of my target yesterday Task: Optimise checkEdgeAlive to reduce the Datastore read time Add a time response on DNS Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Build new site with SSL certificate Linux English Japanese 2019/8/14the result of my target yesterday Task: GCP QwikLab - Baseline: Infrastructure Optimise checkEdgeAlive to reduce the Datastore read time Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Optimise checkEdgeAlive to reduce the Datastore read time Add a time response on DNS Linux English Japanese 2019/8/13the result of my target yesterday Task: GCP QwikLab - Baseline: Infrastructure Still working on it Optimise checkEdgeAlive to reduce the Datastore read time Initially completed the cost part, and going to remove unnecessary code Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: GCP QwikLab - Baseline: Infrastructure Optimise checkEdgeAlive to reduce the Datastore read time Linux English Japanese 2019/8/12the result of my target yesterday Task: GCP QwikLab - Baseline: Infrastructure Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: GCP QwikLab - Baseline: Infrastructure Optimise checkEdgeAlive to reduce the Datastore read time Linux English Japanese 2019/8/11the result of my target yesterday Task: GCP QwikLab - Baseline: Infrastructure Not yet QQ Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: GCP QwikLab - Baseline: Infrastructure Linux English Japanese 2019/8/10the result of my target yesterday Task: Refactor checkEdgeAlive Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: GCP QwikLab - Baseline: Infrastructure Linux English Japanese 2019/8/9the result of my target yesterday Task: Figure out how logParser works Suspended temporarily Completed logrotate documentation Suspended temporarily Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Refactor checkEdgeAlive Linux English Japanese 2019/8/8the result of my target yesterday Task: Figure out how deploy works Will focus on logParser first Completed logrotate documentation No time for it yet Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Figure out how logParser works Completed logrotate documentation Linux English Japanese 2019/8/7the result of my target yesterday Task: Figure out what lerna is Completed Figure out what yarn workspace is Completed Completed logrotate documentation No time for it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Figure out how deploy works Completed logrotate documentation Linux English Japanese 2019/8/6the result of my target yesterday Task: Figure out what lerna is Still working on it Figure out what yarn workspace is Still working on it Completed logrotate documentation Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Figure out what lerna is Figure out what yarn workspace is Completed logrotate documentation Linux English Japanese 2019/8/5the result of my target yesterday Task: Figure out what lerna is Still working on it Figure out what yarn workspace is Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Figure out what lerna is Figure out what yarn workspace is Completed logrotate documentation Linux English Japanese 2019/8/4the result of my target yesterday Task: Organise GCP Load Balancer Finally completed it Figure out what lerna is Still working on it Figure out what yarn workspace is Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Figure out what lerna is Figure out what yarn workspace is Linux English Japanese 2019/8/3the result of my target yesterday Task: Organise GCP Load Balancer Still working on it Figure out what lerna is Still working on it Figure out what yarn workspace is Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Organise GCP Load Balancer Figure out what lerna is Figure out what yarn workspace is Linux English Japanese 2019/8/2the result of my target yesterday Task: Organise GCP Load Balancer Still working on it Figure out how to use logRotate Completed Figure out what lerna is Still working on it Figure out what yarn workspace is Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Organise GCP Load Balancer Figure out what lerna is Figure out what yarn workspace is Linux English Japanese 2019/8/1the result of my target yesterday Task: Organise GCP Load Balancer Still working on it Figure out how to use logRotate Teh result is to be seen Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Organise GCP Load Balancer Figure out how to use logRotate Figure out what lerna is Figure out what yarn workspace is Linux English Japanese","link":"/schedule/2019/August/index.html"},{"title":"April 2019","text":"2019/4/30The result of my target yesterday node.js Implementing MVC on Express.js docker English Japanese achieved except for set target yesterdaydescriptiontoday’s target node.js docker English Japanese 2019/4/29The result of my target yesterday English docker Japanese Node.js Working on documentation of GCP Mountain hiking achieved except for set target yesterdaydescriptiontoday’s target node.js docker English Japanese 2019/4/28The result of my target yesterday English docker Japanese Node.js Working on documentation of GCP IWD worker achieved except for set target yesterdaydescriptiontoday’s target node.js docker English Japanese 2019/4/27The result of my target yesterday English docker Japanese Node.js Build an app server with express.js achieved except for set target yesterdaydescriptiontoday’s target node.js docker English Japanese 2019/4/26The result of my target yesterday English Japanese Node.js Go deeper into event loop What’s event loop Every phase in event loop timers I/O callbacks idle, prepare poll check close callbacks achieved except for set target yesterdaydescriptiontoday’s target node.js docker English Japanese 2019/4/25The result of my target yesterday English Japanese Node.js Parsing request bodies Understanding the concept of event driven Blocking and Non-Blocking Code Roughly reading through event loop achieved except for set target yesterdaydescriptiontoday’s target node.js docker English Japanese 2019/4/24The result of my target yesterday English Japanese Node.js module create a rudimentary server end a loop get information we want from request define response rudimentary request routing achieved except for set target yesterdaydescriptiontoday’s target node.js docker English Japanese 2019/4/23The result of my target yesterday English Japanese Get deeper into Docker Write down current progressAchieved except for set target yesterdayDescriptionToday’s target English Japanese Node.js 2019/4/22The result of my target yesterday English Japanese Get deeper into Docker Completed my first image made by Docker commitAchieved except for set target yesterdayDescriptionToday’s target English Japanese Get deeper into Docker 2019/4/21The result of my target yesterday English Japanese Get deeper into Docker Docker commit Achieved except for set target yesterdayDescriptionToday’s target English Japanese Get deeper into Docker 2019/4/20The result of my target yesterday English Japanese Get deeper into Docker docker tag, docker push, docker volume, docker save Achieved except for set target yesterdayDescriptionToday’s target English Japanese Get deeper into Docker 2019/4/19The result of my target yesterday English Japanese Finish Inboxer project Get deeper into Docker Create a MySQL container and connect to it while another MySQL is installed locally. That is, I could connect to two MySQLs in the server. Achieved except for set target yesterdayDescriptionToday’s target English Japanese Get deeper into Docker 2019/4/18The result of my target yesterday English Japanese Finish Inboxer project Still wait for DNS to update for SSL signature Achieved except for set target yesterdayDescriptionToday’s target English Japanese Finish Inboxer project Get deeper into Docker 2019/4/17The result of my target yesterday English Japanese Complete CentOS document with Docker Achieved except for set target yesterdayDescriptionToday’s target English Japanese Finish Inboxer project 2019/4/16The result of my target yesterday English Japanese Inboxer project Quote the translation feeAchieved except for set target yesterdayDescriptionToday’s target English Japanese Complete CentOS document with Docker 2019/4/15The result of my target yesterday English Japanese Inboxer project Initially completed deploying and send-mail function Achieved except for set target yesterdayDescriptionToday’s target English Japanese Inboxer project Quote the translation fee 2019/4/14The result of my target yesterday English Japanese GCP event Achieved except for set target yesterdayDescriptionToday’s target English Japanese Inboxer project 2019/4/13The result of my target yesterday English Japanese GCP Essentials review Working on docker-compose Achieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Event 2019/4/12The result of my target yesterday English Japanese GCP Essentials review Working on docker-compose Achieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Essentials review Kubernetes and Load Balance 2019/4/11The result of my target yesterday English Japanese GCP Essentials review Working on docker-compose Achieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Essentials review Go deeper into Docker 2019/4/10The result of my target yesterday English Japanese GCP Essentials review Go deeper into docker-compose Achieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Essentials review Go deeper into Docker 2019/4/9The result of my target yesterday English Japanese GCP Essentials review Docker-compose Achieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Essentials review Go deeper into Docker 2019/4/8The result of my target yesterday English Japanese GCP Essentials review Go deeper into Docker - Overlay Network Achieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Essentials review Go deeper into Docker 2019/4/7The result of my target yesterday English Japanese GCP Essentials review Go deeper into Docker - Swarm and Service Achieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Essentials review Go deeper into Docker 2019/4/6The result of my target yesterday English Japanese GCP Essentials review Docker - containerAchieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Essentials review Go deeper into Docker 2019/4/5The result of my target yesterday English Japanese GCP Essentials review Docker - image Achieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Essentials review Go deeper into Docker 2019/4/4The result of my target yesterday English Japanese GCP Essentials review Go deeper into Docker Achieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Essentials review Go deeper into Docker 2019/4/3The result of my target yesterday English Japanese GCP Essentials review Achieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Essentials review Go deeper into Docker 2019/4/2The result of my target yesterday English Japanese GCP Essentials review 1~3 Laracasts-Laravel_5.7_From_Scratch No time for it Achieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Essentials review 2019/4/1The result of my target yesterday English Japanese GCP Essentials - Kubernetes Quick Start Laracasts-Laravel_5.7_From_Scratch Achieved except for set target yesterdayDescriptionToday’s target English Japanese GCP Essentials review Laracasts-Laravel_5.7_From_Scratch","link":"/schedule/2019/April/index.html"},{"title":"July 2019","text":"2019/7/31the result of my target yesterday Task: Organise GCP Load Balancer Completed testing, and going to write a documentation Figure out how to use logRotate No time for it Optimise CICD on api-server project Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Organise GCP Load Balancer Figure out how to use logRotate Linux English Japanese 2019/7/30the result of my target yesterday Task: Organise GCP Load Balancer Still working on it Work on CostDown Initially completed Figure out how to use logRotate No time for it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Organise GCP Load Balancer Figure out how to use logRotate Optimise CICD on api-server project Linux English Japanese 2019/7/29the result of my target yesterday Task: Organise GCP Load Balancer Still working on it Work on CostDown Still working on it Figure out how to use logRotate No time for it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Organise GCP Load Balancer Work on CostDown Figure out how to use logRotate Linux English Japanese 2019/7/28the result of my target yesterday Task: Organise GCP Load Balancer Still working on it Work on CostDown Still working on it Figure out how to use logRotate No time for it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Organise GCP Load Balancer Work on CostDown Figure out how to use logRotate Linux English Japanese 2019/7/27the result of my target yesterday Task: Organise GCP Load Balancer Still working on it Work on CostDown Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Organise GCP Load Balancer Work on CostDown Figure out how to use logRotate Linux English Japanese 2019/7/26the result of my target yesterday Task: Organise GCP Load Balancer Still working on it Work on CostDown Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Organise GCP Load Balancer Work on CostDown Linux English Japanese 2019/7/25the result of my target yesterday Task: Organise GCP Load Balancer Still working on it Work on CostDown We’ve got some progress Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Organise GCP Load Balancer Work on CostDown Linux English Japanese 2019/7/24the result of my target yesterday Task: Build new sites Organise pm2 config Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Organise GCP Load Balancer Work on CostDown Linux English Japanese 2019/7/23the result of my target yesterday Task: Trace edgeOnline API Initially found the issue, going to test it Organise pm2 config No time for it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Build new sites Organise pm2 config Linux English Japanese 2019/7/22the result of my target yesterday Task: Organise GCP Load Balance No time for it Organise pm2 config Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Trace edgeOnline API Organise pm2 config Linux English Japanese 2019/7/21the result of my target yesterday Task: Organise GCP Load Balance No time for it Organise pm2 config Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Organise GCP Load Balance Organise pm2 config Linux English Japanese 2019/7/20the result of my target yesterday Task: Observe new LB, and if every thing goes well, delete all previous VMs Build CICD for all of the projects Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Organise GCP Load Balance Organise pm2 config Linux English Japanese 2019/7/19the result of my target yesterday Task: Optimise the number of VM instance from 8 VMs to 2 VMs Initially completed, and going to observe it further Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Observe new LB, and if every thing goes well, delete all previous VMs Build CICD for all of the projects Linux English Japanese 2019/7/18the result of my target yesterday Task: Optimise the number of VM instance from 8 VMs to 2 VMs Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Optimise the number of VM instance from 8 VMs to 2 VMs Linux English Japanese 2019/7/17the result of my target yesterday Task: Optimise the number of VM instance from 8 VMs to 2 VMs Still working on it Shutdown qcdn-job and move the job to another VM Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Optimise the number of VM instance from 8 VMs to 2 VMs Linux English Japanese 2019/7/16the result of my target yesterday Task: Optimise the number of VM instance from 8 VMs to 2 VMs still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Optimise the number of VM instance from 8 VMs to 2 VMs Shutdown qcdn-job and move the job to another VM Linux English Japanese 2019/7/15the result of my target yesterday Task: Optimise the number of VM instance from 8 VMs to 2 VMs Still working on it Fix eon_v3 DNS issue Initially completed, but still have something to discuss with Raymond before closing this issue Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Optimise the number of VM instance from 8 VMs to 2 VMs Fix eon_v3 DNS issue Linux English Japanese 2019/7/14the result of my target yesterday Task: Optimise the number of VM instance from 8 VMs to 2 VMs Still working on it Fix eon_v3 DNS issue Initially fixed it, but still have some problems to discuss Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Optimise the number of VM instance from 8 VMs to 2 VMs Fix eon_v3 DNS issue Linux English Japanese 2019/7/13the result of my target yesterday Task: Optimise the number of VM instance from 8 VMs to 2 VMs Still working on it Fix eon_v3 DNS issue Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Optimise the number of VM instance from 8 VMs to 2 VMs Fix eon_v3 DNS issue Linux English Japanese 2019/7/12the result of my target yesterday Task: Optimise the number of VM instance from 8 VMs to 2 VMs Still working on it Added a feature sending event notification to Slack channel Completed Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Optimise the number of VM instance from 8 VMs to 2 VMs Linux English Japanese 2019/7/11the result of my target yesterday Task: Trace customer-api code to find out what might cause huge Datastore read It seems that either cloud-api and cloud-customer-api is not the cause of this issue. Optimise the number of VM instance from 8 VMs to 2 VMs Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Optimise the number of VM instance from 8 VMs to 2 VMs Linux English Japanese 2019/7/10the result of my target yesterday Task: Trace customer-api code to find out what might cause huge Datastore read Still working on it Optimise the number of VM instance from 8 VMs to 2 VMs Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Trace customer-api code to find out what might cause huge Datastore read Optimise the number of VM instance from 8 VMs to 2 VMs Linux English Japanese 2019/7/9the result of my target yesterday Task: Optimise CI with pm2 Still working on it Publish my article regarding pm2 Still working on it Trace customer-api code to find out what might cause huge Datastore read still tracing Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Trace customer-api code to find out what might cause huge Datastore read Optimise the number of VM instance from 8 VMs to 2 VMs Linux English Japanese 2019/7/8the result of my target yesterday Task: Optimise CI with pm2 Still working on it Publish my article regarding pm2 Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Optimise CI with pm2 Publish my article regarding pm2 Trace customer-api code to find out what might cause huge Datastore read Linux English Japanese 2019/7/7the result of my target yesterday Task: Change CI with pm2 Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Optimise CI with pm2 Publish my article regarding pm2 Linux English Japanese 2019/7/6the result of my target yesterday Task: Change CI with pm2 Still working on it Turn off loadAccessLog, bandwidthUsage, and emptyGzLogRemover API Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Change CI with pm2 Linux English Japanese 2019/7/5the result of my target yesterday Task: Change CI with pm2 Still working on it Keep off checkEdgeAlive API until 10 pm, and check the bill tomorrow Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Change CI with pm2 Turn off loadAccessLog, bandwidthUsage, and emptyGzLogRemover API Linux English Japanese 2019/7/4the result of my target yesterday Task: Change CI with pm2 Analyse the bill Keep off checkEdgeAlive API until 10 pm, and check the bill tomorrow Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Change CI with pm2 Keep off checkEdgeAlive API until 10 pm, and check the bill tomorrow Linux English Japanese 2019/7/3the result of my target yesterday Task: Configure ShadowSocks client setting Change CI with pm2 Make ShadowSocks automatically restart after reboot and shutdown the instance Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Change CI with pm2 Analyse the bill Keep off checkEdgeAlive API until 10 pm, and check the bill tomorrow Linux English Japanese 2019/7/2the result of my target yesterday Task: Configure ShadowSocks sever setting Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Configure ShadowSocks client setting Change CI with pm2 Make ShadowSocks automatically restart after reboot and shutdown the instance Linux English Japanese 2019/7/1the result of my target yesterday Task: Make a pm2 document Still working on it Make a Let’s Encrypt document and publish it Linux English Japanese JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: TBD Linux English Japanese","link":"/schedule/2019/July/index.html"},{"title":"November 2018","text":"2018/11/30The result of my target yesterday ‘The Wondering’ sharing was perfectily done. having learnt the purpose of $remote_addr and $proxy_add_x_forwarded_forAchieved except for set target yesterdayDescription Today’s target go deeper into apache and nginx config git linux 2018/11/29The result of my target yesterday having learnt how to use apache with php-fpmAchieved except for set target yesterday having completed backend challenge of second roundDescription Today’s target go deeper into apache and nginx config share git in ‘The Wondering’ 2018/11/28The result of my target yesterday backend challenge was completedAchieved except for set target yesterday DescriptionToday’s target go deeper into apache config 2018/11/27The result of my target yesterdayAchieved except for set target yesterdayDescriptionToday’s target aws ec2, eip, security group server default environment apache, nginx installation and config","link":"/schedule/2018/November/index.html"},{"title":"December 2018","text":"2018/12/31The result of my target yesterday [ ] linux: 鳥哥的linux基礎篇 i read some book not related to coding yesterday. i was guilty! [ ] git: pro git i read some book not related to coding yesterday. i was guilty! [x] challenge20181217 rewriting paymentdetail function getachievedachievement function getpossessions function profile function DescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git challenge20181217 rewriting deposit achievement 2018/12/30The result of my target yesterday [ ] linux: 鳥哥的linux基礎篇 i read some book not related to coding yesterday. i was guilty! [ ] git: pro git i read some book not related to coding yesterday. i was guilty! [x] challenge20181217 rewriting shop system function rewriting DescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git challenge20181217 rewriting getachievedachievement getachievedachievement function getpossessions function profile function 2018/12/29The result of my target yesterday [x] linux: 鳥哥的linux基礎篇 head -n number filename tail -f filename cat -n filename | tail -n [x] git: pro git how to revert a merged commit and undo all the changes introduced by the branch being merged?git revert -m 1 commitid if i reverted a merged commit and chose the parent, what if i want to merge it again?revert the reverted commit when merging, how to skip mamually resolving and just choose the side we choose? git merge branchname -xours or git merge branchname -xtheirs challenge20181217 rewriting shop system function rewriting went to a movie theater. DescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git challenge20181217 rewriting shop system function rewriting 2018/12/28The result of my target yesterday [x] linux: 鳥哥的linux基礎篇 nl -ba filename nl -bt filename nl -w filename nl -nln filename nl -nrn filename nl -nrz filename [x] git: pro git git merge -xignore-all-space git merge -xignore-space-change git log --oneline --left-right --merge -p (option) challenge20181217 rewriting readability of achievement function shop system function rewriting to be completed today DescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git challenge20181217 rewriting shop system function rewriting 2018/12/27The result of my target yesterday linux: 鳥哥的linux基礎篇 cat -a cat -b cat -e cat -n cat -t cat -v [x] git: pro git git filter-branch --subdirectory-filter directoryname head git filter-branch --commit-filter &apos; if [ &quot;$git_author_email&quot; = &quot;currentemail&quot; ] ; then git_author_name=&quot;newauthornameyouwanttobe&quot;; git_author_email=&quot;newemailyouwanttobe&quot;; git commit-tree &quot;$@&quot;; else git commit-tree &quot;$@&quot;; fi&apos; head rewrite challenge20181217 achievement function achievement function was completed, but need to improvie its readability Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git challenge20181217 rewriting readability of achievement function shop system function rewriting2018/12/26 The result of my target yesterday linux: 鳥哥的linux基礎篇 went to ktv instead git: pro git went to ktv instead rewrite challenge20181217 getachievementlist &amp; getitemlist api was completed Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git i think i need to focus on my challenge code rework until i finish it 2018/12/25The result of my target yesterday linux: 鳥哥的linux基礎篇辦事項 git: pro git git commit –amend –no-edit git commit filter-branch –tree-filter –all ‘rm -f file’ head laracast: the_php_practitioner recap 23 rameke my git presentation from keynote to hackmd (2/5) rewrite challenge20181217 redesign tables Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git i think i need to focus on my challenge code rework until i finish it 2018/12/24The result of my target yesterday linux: 鳥哥的linux基礎篇辦事項 git: pro git - git grep filename -n &amp; git grep filename -n laracast: the_php_practitioner recap 23 rameke my git presentation from keynote to hackmd (1/5) Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git laracast: the_php_practitioner recap 23 rameke my git presentation from keynote to hackmd (2/5) 2018/12/23The result of my target yesterday figure out how to use moment of js to covert the timezone from utc to where you are - not completed yet wondering presentation - completed Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git laracast: the_php_practitioner recap 23 rameke my git presentation from keynote to hackmd (1/5) 2018/12/22The result of my target yesterday challenge 20181221 passed figure out how to use moment of js to covert the timezone from utc to where you are - not completed yet Achieved except for set target yesterdayDescriptionToday’s target wondering presentation 2018/12/21The result of my target yesterday challenge 20181220 passed Achieved except for set target yesterdayDescriptionToday’s target don’t special game challenge 20181221 2018/12/20The result of my target yesterday challenge 20181219 passed Achieved except for set target yesterdayDescriptionToday’s target challenge 20181220 2018/12/19The result of my target yesterday challenge 20181218 passed Achieved except for set target yesterdayDescriptionToday’s target challenge 20181219 2018/12/18The result of my target yesterday challenge 20181217 passed Achieved except for set target yesterdayDescriptionToday’s target challenge 20181218 2018/12/17The result of my target yesterdaylaravel warming up laravel warm up Achieved except for set target yesterdayDescriptionToday’s target challenge 20181217 2018/12/16The result of my target yesterdaylaracast focus on laravel warming up first laravel warming up laravel_5.7_from_scratch series (9~12/36) linux: focus on laravel warming up first git git add -i revert git add -p git reset -p git stash apply –index git stash –keep-index git add -i update Achieved except for set target yesterdayDescriptionToday’s target laravel- warming up for challenge next week 2018/12/15The result of my target yesterdaylaracast recap the php practitioner series (22/25) laravel warming up laravel_5.7_from_scratch series (4~8/36) linux: what’s cp -s? waht’s cp -r? waht’s cp -u? waht’s cp –preserve=all? if there are two sources when placing cp command, what the destination should be? waht’s cp –preserve=all? git git log origin/master..head git log master..test git log ^master test git log test –not master git log test develop ^master git log test develop –not master Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git laracast: the_php_practitioner recap 23 laravel- warming up for challenge next week 2018/12/14The result of my target yesterdaylaracast recap the php practitioner series (21/25) laravel warming up laravel_5.7_from_scratch series (1~3/36) linux: what’s cp -a? what’s cp -d? what’s cp -f? what’s cp -i? what’s cp -l? what’s cp -p? git git rebase -i ‘wondering’ presentation perfectly done Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git laracast: the_php_practitioner recap 22 laravel- warming up for challenge next week 2018/12/13The result of my target yesterdaylaracast the php practitioner series (19~20/25) linux: what’s in /var/spool folder of linux? what’s ls -a? what’s ls -f? what’s ls -h? what’s ls -i? what’s ls -n? what’s ls -r? what’s ls -r? what’s ls -s? what’s ls -t? what’s ls –full-time? challenge 20181212 passed git git rebase -i Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git laracast: the_php_practitioner recap 21 ‘wondering’ presentation laravel- warming up for challenge next week 2018/12/12The result of my target yesterdaylaracast no time for it. linux: what’s in /var/spool folder of linux? what’s nfs in full name? what’s lsb in full name? how to show true path rather than link path when using pwd? how to create folders through multipal layers? how to give authority when creating a folder? how to show $path? how to add a folder into $path? what’s ls -a? challenge 20181211 passed adaptor make every single book an object how to pass outside variable into closure git github notification flicked through github api and github hooks Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git laracast: the_php_practitioner recap 18~? challenge 20181212 ‘wondering?’ rehersal 2018/12/11The result of my target yesterdaylaracast have completed recapping of 15~17 linux: what’s in /include folder of linux? what’s in /libexec folder of linux? what’s in /usr/src folder of linux? what’s in /var folder of linux? what’s in /var/cache folder of linux? what’s in /var/lib folder of linux? what’s in /var/lock folder of linux? what’s in /var/log folder of linux? what’s in /var/mail folder of linux? what’s in /usr folder of linux? what’s in /usr/bin folder of linux? challenge 20181210 passed git how to fetch all pull-requests without adding them as remotesfetch = +refs/pull//head:refs/remotes/origin/pr/ Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git laracast: the_php_practitioner recap 18~? challenge 20181211 2018/12/10The result of my target yesterdaylaracast the_php_practitioner series (25/25) was completed. have recapped the_php_practitioner 1~15. linux: what’s in /usr folder of linux? what’s in /usr/bin folder of linux? what’s in /usr/lib folder of linux? what’s in /usr/local folder of linux? what’s in /usr/sbin folder of linux? what’s in /usr/share folder of linux? what’s in /usr/games folder of linux? what’s in /home folder of linux? what’s in /lib qual folder of linux? what’s in /root qual folder of linux? what’s in /proc qual folder of linux? what’s in /sys folder of linux? git if you see something like pull request does not merge cleanly in github, what should you do?① add the original repository as a remote named “upstream”② fetch the newest work from that remote③ merge the main branch of that repository into your topic branch④ fix the conflict that occurred⑤ push back up to the same topic branch how could we reference issue or pull-request on github?## how to use task list on github? write the code write all the tests document the code Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git laracast: the_php_practitioner recap challenge 20181210 2018/12/9The result of my target yesterdaylaracast having completed episode 24, and will recap it again and push it to github linux: what’s in /home folder of linux? what’s in /lib qual folder of linux? what’s in /root folder of linux? what’s in /lost+found folder of linux? what’s in /proc folder of linux? what’s in /sys folder of linux? git what are the steps to create a pull-request on github?① clone our fork of the project locally② create a descriptive topic branch③ make our change to the code④ check that the change is good⑤ commit our change to the topic branch⑥ push our new topic branch back up to our github fork how to condense a whole feature branch into a single commit and push it to master branch as production branch. Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git laracast: the_php_practitioner (24/25) recap and (25/25) 2018/12/8The result of my target yesterdaylaracast having completed episode 23 and pushed it to github linux: what’s in /media folder of linux? what’s in /mnt folder of linux? what’s in /opt folder of linux? what’s in /run folder of linux? what’s in /sbin folder of linux? what’s in /srv folder of linux? what’s in /tmp folder of linux? The Wondering having completed presentation for ‘wondering’ next week. git i didn’t have time for it yesterday. Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git laracast: the_php_practitioner (24/25) 2018/12/7The result of my target yesterdaylaracast yesterday i didn’t watch it at all, my goodness. i must finish it today and move on! linux: what’s in /bin folder of linux? what’s in /boot folder of linux? what’s in /dev folder of linux? what’s in /etc folder of linux? what’s in /lib folder of linux? The Wondering both rehersal and presentation were perfectly done. Achieved except for set target yesterday sharing what i learnt from the deployment event at tuesday night with the whole backend team. DescriptionToday’s target presentation for The Wondering next week, or perhaps the week after that. linux: 鳥哥的linux基礎篇 git: pro git laracast: the php practitioner(23/25) recap, and push every step of it on github 2018/12/6The result of my target yesterdaylaracast finally, i finished episode (23/25) yesterday. i will try to recap it again and push each step on github linux: when installing package, why it shows 403 forbidden? the limit of length of the name of files and repositories in linux. fhs - filesystem hierarchy standard the purpose of fhs four types of repositories in linux explanation of four types of repositories - shareable, unshareable, static, variable three defaultly defined repositries by fhs The Wondering i have finished rehersal one time, and am going to do that again before presentation.Achieved except for set target yesterdayDescriptionToday’s target The Wondering rehersal before presentation linux: 鳥哥的linux基礎篇 laracast: the php practitioner(23/25) recap, and push every step of it on github 2018/12/5The result of my target yesterdaylaracast still stuck on the_php_practitioner episode 23. maybe bacause i stayed up late the night before last night with whole backend working server deployment, yesterday i was too groggy to figure it out. i have to finish it today!git: gpg security keys for git tag signituressl: having completed ssl hand-on experiment. linux: recap authority command with jett and soj. i was supposed to read linux book last night, however, i passed out as soon as i took a shower. Achieved except for set target yesterdayDescriptionToday’s target laracast: the php practitioner(23/25) The Wondering rehersal linux: 鳥哥的linux基礎篇 2018/12/4The result of my target yesterdaylaracast the php practitioner (23/25). i was scheduled to finish episode 23 yesterday. however, the whole backend team and i were working on server configuration and deployment all day long, and i will manage to finish it today. git: as above mentioned, i counldn’t manage any time for git yesterday. linux: what’s link file what’s data file what’s device file what are block and character of device file what’s socket file what’s fifo file Achieved except for set target yesterday ssl signature frontend and backend deployment on server with apache.DescriptionToday’s target laracast: the php practitioner(23/25) git: pro git linux: 鳥哥的linux基礎篇 ssl signature hand-on experiment.2018/12/3 The result of my target yesterdaylaracast the php practitioner (23/25), i’ve recapped the logic, and ready to go further. git: hand-on experiment on rerere function linux: chmod ugoa, +-=, rwx rules of authority for files and repositories regular file: ascii, data, binary how to read data file - last how to read ascii file - cat The Wondering completed Achieved except for set target yesterdayDescriptionToday’s target laracast: the php practitioner(23/25) git: pro git linux: 鳥哥的linux基礎篇2018/12/2 The result of my target yesterdaylaracast the php practitioner (23/25): i spent a lot of time recaping what i’d leart before backend challenge. i think i will need more time to retrive the logic before getting later episode. git: merging work flow large-merging workflow git config –global rerere.enabled true linux: chgrp [-r] groupname filename chown [-r] user:group filenameorrepositoryname chmod [-r] xyz filenameorrepositoryname docker: create a dockerfile build a dockerfile run a dockerfile push a dockerfile rough concept of docker Achieved except for set target yesterdayDescriptionToday’s target laracast: the php practitioner series git linux presentation of The Wondering for next week. 2018/12/1The result of my target yesterdayapache and nginx: having learnt how to use either apache or nginx as reverse proxy and proxy_pass to webserver with whatever headers that are required. git: create a branch based off another branch - git branch thebranchyouwant thebranchyouwouldliketobebasedoff will git reflog be pushed? - no can i pull from repositories that haven’t been added as remote? - yes how to pull from repositories that haven’t been saved as remote - git pull theurl, append –allow-unrelated-histories if not related. it shows only the work your current topic branch has introduced since its common ancestor with master - git diff master…meatlinux: drwxrwxrwx, what does d mean? -rwxrwxrwx, what does - mean? lrwxrwxrwx, what does l mean? brwxrwxrwx, what does b mean? crwxrwxrwx, what does c mean?DescriptionToday’s target laracast: the php practitioner series attending docker speech held on good idea studio git linux","link":"/schedule/2018/December/index.html"},{"title":"June 2019","text":"2019/6/30the result of my target yesterday Task: Complete FTP server document and publish it Linux English Japanese JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: Make a pm2 document Make a Let’s Encrypt document and publish it Linux English Japanese JavaScript 2019/6/29the result of my target yesterday Task: Make PM2 document, and optimise every VM Still working on it Made a FTP server for internal deployment Linux English Japanese JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: Complete FTP server document and publish it Linux English Japanese JavaScript 2019/6/28the result of my target yesterday Task: Auto sign three sites with Let&#39;s Encrypt Linux English Japanese JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: Make PM2 document, and optimise every VM Linux English Japanese JavaScript 2019/6/27the result of my target yesterday Task: Figure out how pm2 works and optimise VMs with pm2 Partially Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Auto sign three sites with Let&#39;s Encrypt Linux English Japanese JavaScript 2019/6/26the result of my target yesterday Task: Understand how Cloud Function works Linux English Japanese JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: Figure out how pm2 works and optimise VMs with pm2 Linux English Japanese JavaScript 2019/6/25the result of my target yesterday Task: Optimise VMs Re-purged failed edges Linux English Japanese JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: Understand how Cloud Function works Linux English Japanese JavaScript 2019/6/24the result of my target yesterday Task: Linux English Japanese JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: TBD Linux English Japanese JavaScript 2019/6/23the result of my target yesterday Task: Linux English Japanese JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: Linux English Japanese JavaScript 2019/6/22the result of my target yesterday Task: Made eov_v3 work Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Linux English Japanese JavaScript 2019/6/21the result of my target yesterday Task: Working on EON_V3 Make domain column accepts array Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: TBD Linux English Japanese 2019/6/20the result of my target yesterday Task: Working on EON_V3 Completed CI Completed revising, the service is working now. Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on EON_V3 Make domain column accepts array Linux English Japanese 2019/6/19the result of my target yesterday Task: The handover of the work with Eddie I was told to work on project EON_V3 first Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on EON_V3 Linux English Japanese 2019/6/18the result of my target yesterday Task: The handover of the work with Eddie Linux English Japanese JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: The handover of the work with Eddie Linux English Japanese 2019/6/17the result of my target yesterday Task: Linux English Japanese JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: TBD Linux English Japanese JavaScript 2019/6/16the result of my target yesterday Task: Linux English Japanese JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: Linux English Japanese JavaScript 2019/6/15the result of my target yesterday Task: Edge and Site API Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Linux English Japanese JavaScript 2019/6/14the result of my target yesterday Task: Working on DNS function Completed Working on Site and Edge API Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Edge and Site API Linux English Japanese 2019/6/13the result of my target yesterday Task: Working on DNS function Still working on it Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on DNS function Linux English Japanese 2019/6/12the result of my target yesterday Task: Working on DNS function Finished GCP Cloud DNS Service part Linux English Japanese JavaScript No time for it achieved except for set target yesterdaydescriptiontoday’s target Task: Working on DNS function Linux English Japanese 2019/6/11the result of my target yesterday Task: Have a meeting with ST, Raymond, and OY Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on DNS function Linux English Japanese JavaScript 2019/6/10the result of my target yesterday Task: Figured out how to add a Load-Balancing with gcloud Got stuck on SSH issue instead. However, I learnt something from it. Linux English Japanese JavaScript The Principles of Object-Oriented JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: Have a meeting with ST, Raymond, and OY Linux English Japanese 2019/6/9the result of my target yesterday Task: Figured out how to add a Load-Balancing with gcloud Linux English Japanese JavaScript The Principles of Object-Oriented JavaScript Today I will go out with friends for dinner, I hope that I will still finish my schedule achieved except for set target yesterdaydescriptiontoday’s target Task: Figured out how to add a Load-Balancing with gcloud Linux English Japanese JavaScript The Principles of Object-Oriented JavaScript 2019/6/8the result of my target yesterday Task: Transfer the drawing from HackMD to Draw.io Figured out how to add a Load-Balancing with gcloud Linux English Japanese JavaScript The Principles of Object-Oriented JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: Figured out how to add a Load-Balancing with gcloud Linux English Japanese JavaScript The Principles of Object-Oriented JavaScript Today I will go out with friends for dinner, I hope that I will still finish my schedule 2019/6/7the result of my target yesterday Task: Discuss with Raymond to finalize initial version, and discuss with ST Linux English Japanese JavaScript The Principles of Object-Oriented JavaScript achieved except for set target yesterdaydescriptiontoday’s target Task: Transfer the drawing from HackMD to Draw.io Figured out how to add a Load-Balancing with gcloud Linux English Japanese JavaScript The Principles of Object-Oriented JavaScript 2019/6/6the result of my target yesterday Task: Discuss with Raymond to finalize initial version of programming process drawing and make it with draw.io Raymond pointed out some errors, to be revised and resubmitted Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Discuss with Raymond to finalize initial version, and discuss with ST Linux English Japanese JavaScript The Principles of Object-Oriented JavaScript 2019/6/5the result of my target yesterday Task: Revised the data path according to the discussion yesterday. Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Discuss with Raymond to finalize initial version of programming process drawing and make it with draw.io Linux English Japanese 2019/6/4the result of my target yesterday Task: Completed logic part and compare with ST’s data path Completed first version of scratch, and had a discussion with Raymond Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Revised the data path according to the discussion yesterday. Linux English Japanese 2019/6/3the result of my target yesterday Task: Add new Japanese vocabulary card Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Completed logic part and compare with ST’s data path Linux English Japanese 2019/6/2the result of my target yesterday task: add new japanese vocabulary card Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Add new Japanese vocabulary card Linux English Japanese 2019/6/1the result of my target yesterday Task: Working on architecture of Cloud API Initially finished Ready Pool and Bootstrap Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: add new japanese vocabulary card Linux English Japanese","link":"/schedule/2019/June/index.html"},{"title":"May 2019","text":"2019/5/31the result of my target yesterday Task: Working on architecture of Cloud API Started working on Discover Service Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on architecture of Cloud API Linux English Japanese 2019/5/30the result of my target yesterday Task: Working on architecture of Cloud API Initially completed Ready Pool and Bootstrap Help Raymond to check edge condition Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on architecture of Cloud API Linux English Japanese 2019/5/29the result of my target yesterday Task: A meeting in Hsinchu Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Working on architecture of Cloud API Linux English Japanese 2019/5/28the result of my target yesterday Task: Completed edge-ip-revising API Still working on GCP Cloud DNS documentation Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: A meeting in Hsinchu Linux English Japanese 2019/5/27the result of my target yesterday Task: Completed a course in Qwiklab Watch Game of Thrones instead, I was guilty! Fix my windows computer Containerise HX-API Watch Game of Thrones instead, I was guilty! Linux English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task: Completed edge-ip-revising API Linux English Japanese 2019/5/26the result of my target yesterday Task add getting new ip feature to monitor api Organising what I have learnt those weeks English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task Completed a course in Qwiklab Fix my windows computer Containerise HX-API Linux English Japanese 2019/5/25the result of my target yesterday Task review merge request of monitor api add getting new ip feature to monitor api working on onedgeipchange api English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task add getting new ip feature to monitor api Organising what I have learnt those weeks English Japanese 2019/5/24the result of my target yesterday Task figured out how edge dns works English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task review merge request of monitor api add getting new ip feature to monitor api working on onedgeipchange api English Japanese 2019/5/23The result of my target yesterday Task Comment issue 302~310 Have a meeting with Raymond English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task Working on API developing and refactoring. English Japanese 2019/5/22The result of my target yesterday Task Added new feature into monitor API English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task Comment issue 302~310 Have a meeting with Raymond English Japanese 2019/5/21The result of my target yesterday Task English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task Added new feature into monitor API English Japanese 2019/5/20The result of my target yesterday Task English Japanese achieved except for set target yesterdaydescriptiontoday’s target Organise what I learnt those weeks English Japanese 2019/5/19The result of my target yesterday Organise what I learnt those weeks Completed gitlac CI/CD on GCP virtual machine document organisation English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task Figure out checkEdgeAlive API Complete issue 302~310 English Japanese 2019/5/18The result of my target yesterday Organise what I learnt those weeks Organised Gitlab CI/CD English Japanese achieved except for set target yesterdaydescriptiontoday’s target Organise what I learnt those weeks English Japanese 2019/5/17The result of my target yesterday Task I would like to complete API support feature of the healthCheck function, however, it depends on the task English Japanese achieved except for set target yesterdaydescriptiontoday’s target Organise what I learnt those weeks English Japanese 2019/5/16The result of my target yesterday Task Understand the logic of checkEdgeAlive API - Then, we optimise the healthCheck function instead. English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task I would like to complete API support feature of the healthCheck function, however, it depends on the task English Japanese 2019/5/15The result of my target yesterday Task Come out with a solution for checkEdgeAlive issue: Completed a health check program to check the health per 10 minutes for temporary solution. English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task Understand the logic of checkEdgeAlive API English Japanese 2019/5/15The result of my target yesterday Task Initially fixed issue from 302 to 310 English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task Come out with a solution for checkEdgeAlive issue English Japanese 2019/5/14The result of my target yesterday Task Understand the logic of API implementation of QCDN. English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task Solve issue 302~310 English Japanese 2019/5/13The result of my target yesterday Task Understand the logic of API implementation of QCDN. Deploy Node.js project on Google App Engine English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task Understand the logic of API implementation of QCDN. English Japanese 2019/5/12The result of my target yesterday Task Figured out how to use breakpoint feature in PHPStorm. English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task Understand the logic of API implementation of QCDN. English Japanese 2019/5/11The result of my target yesterday Task Have initially completed the database organising, however, still have to change the logic of API implementation. English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task Figure out how to use IDE breakpoint feature English Japanese 2019/5/10The result of my target yesterday Task Have figured out the logic, still working on it. English Japanese achieved except for set target yesterdaydescriptiontoday’s target Task Fix siteEdge unmatched data issue English Japanese 2019/5/9The result of my target yesterday English Japanese Task Got siteEdge.host unmatched from either site.host or site.cname Learnt how to build a site achieved except for set target yesterdaydescriptiontoday’s target Task Fix siteEdge unmatched data issue English Japanese 2019/5/8The result of my target yesterday English Japanese node.js How to insert data into datastore achieved except for set target yesterdaydescriptiontoday’s target Task English Japanese 2019/5/7The result of my target yesterday English Japanese A go over with Eddie and Raymond achieved except for set target yesterdaydescriptiontoday’s target node.js English Japanese 2019/5/6The result of my target yesterday English Japanese Gitlab CI Load Balance achieved except for set target yesterdaydescriptiontoday’s target node.js English Japanese 2019/5/5The result of my target yesterday English Japanese Gitlab CI Load Balance achieved except for set target yesterdaydescriptiontoday’s target node.js English Japanese 2019/5/4The result of my target yesterday node.js English Japanese Gitlab CI achieved except for set target yesterdaydescriptiontoday’s target node.js English Japanese 2019/5/3The result of my target yesterday node.js English Japanese Gitlab CI achieved except for set target yesterdaydescriptiontoday’s target node.js English Japanese 2019/5/2The result of my target yesterday node.js add a new route in Express.js make different routes with different prefixes in Express.js send status code in Express.js docker English Japanese achieved except for set target yesterdaydescriptiontoday’s target node.js docker English Japanese Gitlab CI 2019/5/1The result of my target yesterday node.js Implementing mass delete and get function in GCP Datastore docker English Japanese achieved except for set target yesterdaydescriptiontoday’s target node.js docker English Japanese","link":"/schedule/2019/May/index.html"},{"title":"February 2018","text":"2019/2/28The result of my target yesterday Write down how to use PayPal payment service One more section of my Git Course Optimize FB online selling project Make recipient information only required when a order is paid Achieved except for set target yesterday Solve the problem that the canvas-nest special effect doesn’t work properly on Schedule page DescriptionToday’s target Write down how to use PayPal payment service One more section of my Git Course Optimize FB online selling project Restructure WebSocket 2019/2/27The result of my target yesterday One more section of my Git course Write down an article - how to build a multilingual blog with Hexo Optimize FB online selling project Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service One more section of my Git Course Optimize FB online selling project Make recipient information only required when a order is paid 2019/2/26The result of my target yesterday My blog - improve the layout Achieved except for set target yesterdayDescriptionToday’s target One more section of my Git course Write down an article - how to build a multilingual blog with Hexo Optimize FB online selling project 2019/2/25The result of my target yesterday Working on the blog, I would like to make a bilingual version Achieved except for set target yesterdayDescriptionToday’s target My blog - improve the layout 2019/2/24The result of my target yesterday Fix the decoded garble problem of my blog Completed a bit, but still working on it Achieved except for set target yesterdayDescriptionToday’s target Working on the blog, I would like to make a bilingual version 2019/2/23The result of my target yesterday Challenge: Facebook optimized selling system - keep optimizing Git course: The presentation Finished first course Write down how to make PayPal payment service work Working on my blog instead Achieved except for set target yesterdayDescriptionToday’s target Fix the decoded garble problem of my blog 2019/2/22The result of my target yesterday Challenge: Facebook optimized selling system Optimize and debug Demo Achieved except for set target yesterdayDescriptionToday’s target Challenge: Facebook optimized selling system - keep optimizing Git course: The presentation Write down how to make PayPal payment service work 2019/2/21The result of my target yesterday Challenge: Facebook optimized selling system - Optimize and debug Optimize images upload function with Laravel way Reorganise and write down how to make PayPal payment service works Achieved except for set target yesterday Challenge: Facebook optimized selling system Added new function that when an order is paid, the buyer will receive a notification email DescriptionToday’s target Challenge: Facebook optimized selling system optimize and debug demo 2019/2/20The result of my target yesterday challenge: facebook optimized selling system - optimize and debug added email update function in update-user-info function Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system - optimize and debug optimize images upload function with laravel way reorganise and write down how to make paypal payment service works 2019/2/19The result of my target yesterday challenge: facebook optimized selling system - paypal payment service finally app site is able to use it Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system - optimize and debug 2019/2/18 gcp quiklab training course stackdriver: qwik start set up network and http load balancers The result of my target yesterdayAchieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system - paypal payment service 2019/2/17The result of my target yesterday gcp quiklab training course completed lessons 6 Achieved except for set target yesterdayDescriptionToday’s target gcp quiklab training course 2019/2/16The result of my target yesterday gcp quiklab training course completed lessons 1~5 Achieved except for set target yesterdayDescriptionToday’s target gcp quiklab training course 2019/2/15 challenge: facebook optimized selling system - paypal payment service completed paypal payment service function The result of my target yesterdayAchieved except for set target yesterdayDescriptionToday’s target gcp quiklab training course 2019/2/14 challenge: facebook optimized selling system - paypal payment service still working on it The result of my target yesterdayAchieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system - paypal payment service 2019/2/13 challenge: facebook optimized selling system - paypal payment service still working on it The result of my target yesterdayAchieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system - paypal payment service 2019/2/12 challenge: facebook optimized selling system paypal payment service The result of my target yesterdayAchieved except for set target yesterday api revise create new api- get user status DescriptionToday’s target challenge: facebook optimized selling system - paypal payment service 2019/2/11 challenge: facebook optimized selling system write an article about how to get user’s basic information via token got from fb paypal payment service still working on it. The result of my target yesterdayAchieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system paypal payment service 2019/2/10 challenge: facebook optimized selling system write an article about how to get user’s basic information via token got from fb paypal payment service still working on it The result of my target yesterdayAchieved except for set target yesterday challenge: facebook optimized selling system debug optimize DescriptionToday’s target challenge: facebook optimized selling system write an article about how to get user’s basic information via token got from fb paypal payment service 2019/2/9 challenge: facebook optimized selling system write an article about how to handle allpay payment service paypal payment service still working on it git pro 鳥哥的linux The result of my target yesterdayAchieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system write an article about how to get user’s basic information via token got from fb paypal payment service 2019/2/8The result of my target yesterday challenge: facebook optimized selling system write down how to use task scheduling of laravel with crontab to routinely delete expired orders the presentation of hackmd for ‘the wondering’ on 14 february 2019 paypal payment service git pro git object 鳥哥的linux Achieved except for set target yesterday adopted task scheduling of laravel with crontab to routinely delete expired orders DescriptionToday’s target challenge: facebook optimized selling system write an article about how to handle allpay payment service paypal payment service git pro 鳥哥的linux 2019/2/7The result of my target yesterday challenge: facebook optimized selling system write down how to use aws ses find out why ngrok doesn’t work with aws ses it’s caused by the port. Achieved except for set target yesterday adopted task scheduling of laravel with crontab to routinely delete expired orders DescriptionToday’s target challenge: facebook optimized selling system write down how to use task scheduling of laravel with crontab to routinely delete expired orders the presentation of hackmd for ‘the wondering’ on 14 february 2019 paypal payment service git pro 鳥哥的linux 2019/2/6The result of my target yesterday challenge: facebook optimized selling system mail notification system via ses and laravel Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system write down how to use aws ses find out why ngrok doesn’t work with aws ses 2019/2/5The result of my target yesterday challenge: facebook optimized selling system optimize order system for allpay payment service Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system mail notification system via ses and laravel 2019/2/4The result of my target yesterday challenge: facebook optimized selling system third party payment service, allpay Achieved except for set target yesterday git pro: git hash-object -w stdin git cat-file -p checksum DescriptionToday’s target challenge: facebook optimized selling system optimize order system for allpay payment service 2019/2/3The result of my target yesterday challenge: facebook optimized selling system still working on third party payment service, allpay git pro no time for it = = 鳥哥的linux no time for it = = Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system third party payment service, allpay 2019/2/2The result of my target yesterday challenge: facebook optimized selling system still working on it git pro no time for it 鳥哥的linux no time for it Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system third party payment service git pro 鳥哥的linux 2019/2/1The result of my target yesterday [ ] challenge: facebook optimized selling system ‘the wondering presentation’ instead [x] git pro step into plumbing’s world 鳥哥的linux no time for it Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system third party payment service git pro 鳥哥的linux","link":"/schedule/2019/February/index.html"},{"title":"January 2019","text":"2019/1/31The result of my target yesterday challenge: facebook optimized selling system revised api instead git pro prepared ‘the wondering’ rehearsal 鳥哥的linux prepared ‘the wondering’ rehearsal Achieved except for set target yesterday block chain knowledgeDescriptionToday’s target challenge: facebook optimized selling system third party payment service git pro 鳥哥的linux 2019/1/30The result of my target yesterday challenge: facebook optimized selling system completed api (26/26) git course outline provided to howard Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system third party payment service git pro 鳥哥的linux2019/1/29 The result of my target yesterday challenge: facebook optimized selling system commpleted api (23/25) git pro prepared git course outline instead 鳥哥的linux prepared git course outline instead Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system git course outline 2019/1/28The result of my target yesterday challenge: facebook optimized selling system commpleted api (22/25) introduction of my blog Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system git pro 鳥哥的linux2019/1/27 The result of my target yesterday ‘the wondering’ presentation next week challenge: facebook optimized selling system completed 3 api Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system introduction of my blog 2019/1/26The result of my target yesterday challenge: facebook optimized selling system working on my blog and linkedin instead. Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system ‘the wondering’ presentation next week 2019/1/25The result of my target yesterday challenge: facebook optimized selling system working on ci with jenkins instead Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system 2019/1/24The result of my target yesterday challenge: facebook optimized selling system completed three apis Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system 2019/1/23The result of my target yesterday challenge: facebook optimized selling system completed three apis Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system 2019/1/22The result of my target yesterday challenge: facebook optimized selling system completed three apis Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system 2019/1/21The result of my target yesterday challenge: facebook optimized selling system completed six apis Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system 2019/1/20The result of my target yesterday challenge: facebook optimized selling system completed three api Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system 2019/1/19The result of my target yesterday challenge: facebook optimized selling system initially completed api document Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system 2019/1/18The result of my target yesterday challenge: facebook optimized selling system intially confirmed the specification Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system2019/1/17 The result of my target yesterday challenge: facebook optimized selling system initially discussed the feature Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system 2019/1/16The result of my target yesterdayAchieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system 2019/1/15The result of my target yesterday linux: 鳥哥的linux基礎篇 git: pro git build my own blog in github with hexo almost complete personal configuration Achieved except for set target yesterdayDescriptionToday’s target challenge: facebook optimized selling system 2019/1/14The result of my target yesterday [x] linux: 鳥哥的linux基礎篇 suid full name suid’s function and limit [x] git: pro git how to configure your git to save your credentials? what are three level of git configurations? where is the configuration file that git looks for when it comes to system level configuration? where is the configuration file that git looks for when it comes to global level configuration? how to ignore files globaly in git? [x] build my own blog in github with hexo i’m still working on it, still some issues to be solved. Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git build my own blog in github with hexo 2019/1/13The result of my target yesterday iron man award ceremony Achieved except for set target yesterday completed presentation for ‘the wondering’ on 17 january 2019DescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git reorganize those presentations i’ve made from keynote to hackmd the first commit 沒遇到這些事之前，我也覺得我git超屌 episode 1 沒遇到這些事之前，我也覺得我git超屌 episode 2 沒遇到這些事之前，我也覺得我git超屌 episode 3 沒遇到這些事之前，我也覺得我git超屌 episode 4 2019/1/12The result of my target yesterday challenge20181217 rewriting optimize readme the wondering organize git presentation that i’ve shared in ‘the wondering’ presentation for ‘the wondering’ next week 鳥哥的Linux基礎篇 git: pro git Achieved except for set target yesterday build opendata project on aws and so my team members could use it for their interviews in the future.DescriptionToday’s target iron man award ceremony 2018/1/11The result of my target yesterday challenge20181217 rewriting add status code to all the functions revise api document accordingly to restful api. Achieved except for set target yesterday git: if you create a new branch, add a submodule there, and then switch back to a branch without that submodule, what will happen?DescriptionToday’s target challenge20181217 rewriting optimize readme the wondering organize git presentation that i’ve shared in ‘the wondering’ presentation for ‘the wondering’ next week linux: 鳥哥的linux基礎篇 git: pro git 2019/1/10The result of my target yesterday linux: 鳥哥的linux基礎篇 working on swagger api [ ] git: pro git working on swagger api [x] challenge20181217 rewriting added customized status code on register, login, and get profile api revise api document accordingly to restful api Achieved except for set target yesterdayDescriptionToday’s target challenge20181217 rewriting add status code to all the functions revise api document accordingly to restful api.2019/1/9 The result of my target yesterday linux: 鳥哥的linux基礎篇 working on swagger api [ ] git: pro git working on swagger api [x] challenge20181217 rewriting complete register and login function api with swagger Achieved except for set target yesterdayDescriptionToday’s target challenge20181217 rewriting make api document with swagger2019/1/8 The result of my target yesterday linux: 鳥哥的linux基礎篇 working on challenge20190107 - how to upload a file to aws-s3 via a pre-signed url instead. [x] git: pro git how to stash all the work in all our submodules? how to create a new branch and switch to it in all our submodules? how to use ‘git diff’ in your main project and all your submodules? [ ] challenge20181217 rewriting working on challenge20190107 - how to upload a file to aws-s3 via a pre-signed url instead. Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git challenge20181217 rewriting revise api document learn how to use swagger 2019/1/7The result of my target yesterday had a wonderful getaway yesterday.Achieved except for set target yesterdayDescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git challenge20181217 rewriting revise api document 2019/1/6The result of my target yesterday [ ] linux: 鳥哥的linux基礎篇 [x] git: pro git practice submodule [x] challenge20181217 rewriting complete transferring to restful apiAchieved except for set target yesterdayDescriptionToday’s target have a getaway today. 2019/1/5The result of my target yesterday [ ] linux: 鳥哥的linux基礎篇 [x] git: pro git practice submodule [x] challenge20181217 rewriting publish api document on github page, and sign ssl certificateAchieved except for set target yesterday how to build a blog with hexo DescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git challenge20181217 rewriting optimize api to restful api 2019/1/4The result of my target yesterday [x] linux: 鳥哥的linux基礎篇 what’s chattr [+-=] [asacdistu] how to search placed command in lunux? [x] git: pro git how to check if we find a bug after a lot of commits made, and we have no idea when and where the code went wrong? how to revise submodule url? what does 160000 mode means when commit a submodule? how to make a submodule? a better diff for submodule? [x] challenge20181217 rewriting complete ‘aws deployment’ DescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git challenge20181217 rewriting publish the api document on github page 2019/1/3The result of my target yesterday [x] linux: 鳥哥的linux基礎篇 how to execute cat command with value got previously in linux? [x] git: pro git what’s the progress of cloning project with submodule in? if, in master branch, i reset with a sha1 from develop branch, what would happen? how to specify lines with git blame? how to show where it’s originally copied from with git blame? [x] challenge20181217 rewriting complete ‘optimizing payment controller’ DescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git challenge20181217 rewriting deploy on aws2019/1/2 The result of my target yesterday [ ] linux: 鳥哥的linux基礎篇 ‘wondering’ rehearsal instead [ ] git: pro git ‘wondering’ rehearsal instead [x] challenge20181217 rewriting complete ‘deposit common achievement’ DescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git challenge20181217 rewriting optimize payment controller2019/1/1 The result of my target yesterday [x] linux: 鳥哥的linux基礎篇 what’s default authority when creating a file? what’s the default umask? so what’s the final default authority? how to see default umask? how to set umask? what’s the correct way of calculating final authority after deducting umask? [ ] git: pro git challenge20181217 rewriting do a linebot challenge held by howard instead DescriptionToday’s target linux: 鳥哥的linux基礎篇 git: pro git challenge20181217 rewriting deposit achievement","link":"/schedule/2019/January/index.html"},{"title":"November 2018","text":"2019/3/31The result of my target yesterday Deploy jenkins for openData Laracasts-Laravel_5.7_From_Scratch Achieved except for set target yesterdayDescriptionToday’s target GCP Essentials - Kubernetes Laracasts-Laravel_5.7_From_Scratch 2019/3/30The result of my target yesterday Write down how to do jenkins deployment Deploy ‘backendOfMobileGames’ and ‘openData’ Achieved except for set target yesterdayDescriptionToday’s target Deploy jenkins for openData Laracasts-Laravel_5.7_From_Scratch 2019/3/29The result of my target yesterday AWS Deployment: jenkins deployment Achieved except for set target yesterdayDescriptionToday’s target Write down how to do jenkins deployment Deploy ‘backendOfMobileGames’ and ‘openData’ 2019/3/28The result of my target yesterday AWS Deployment Completed supervisor and queue setting Achieved except for set target yesterdayDescriptionToday’s target AWS Deployment: jenkins deployment 2019/3/27The result of my target yesterday AWS Deployment Still working on it Achieved except for set target yesterdayDescriptionToday’s target AWS Deployment 2019/3/26The result of my target yesterday Laracasts-Laravel_5.7_From_Scratch Episode 6-11 Achieved except for set target yesterdayDescriptionToday’s target AWS Deployment 2019/3/25The result of my target yesterday Laracasts-Laravel_5.7_From_Scratch Episode 1~5 Achieved except for set target yesterdayDescriptionToday’s target Laracasts-Laravel_5.7_From_Scratch 2019/3/24The result of my target yesterday Write down how to use queue with sqs Prepare interview tonight Well, the interview was rescheduled because the interviewer was indisposed. Achieved except for set target yesterdayDescriptionToday’s target Laracasts-Laravel_5.7_From_Scratch 2019/3/23The result of my target yesterday Write down how to use Supervisor to manage queue work with sqs Completed Supervisor part, and will work on sqs part today. Prepare interview tonight The interview time was changed to tonight. Achieved except for set target yesterdayDescriptionToday’s target Write down how to use queue with sqs Prepare interview tonight 2019/3/22The result of my target yesterday Figure out how to use Supervisor to manage queue work Write down how to use Supervisor to manage queue work ‘The Wondering’ presentation Achieved except for set target yesterdayDescriptionToday’s target Write down how to use Supervisor to manage queue work with sqs Prepare interview tonight 2019/3/21The result of my target yesterday Figure out how to use SQS to send email Recap GCP Essentials Achieved except for set target yesterdayDescriptionToday’s target Figure out how to use Supervisor to manage queue work Write down how to use Supervisor to manage queue work ‘The Wondering’ presentation 2019/3/20The result of my target yesterday Complete FB selling side project’s ReadMe Recap GCP Essentials Achieved except for set target yesterdayDescriptionToday’s target Figure out how to use SQS to send email Recap GCP Essentials 2019/3/19The result of my target yesterday Write down Ray’s git flow Complete FB selling side project’s ReadMe Not yet completed, but working on it. Achieved except for set target yesterdayDescriptionToday’s target Complete FB selling side project’s ReadMe Recap GCP Essentials 2019/3/18The result of my target yesterday The Wondering presentation. Optimize FB online selling project Achieved except for set target yesterdayDescriptionToday’s target Write down Ray’s git flow Complete FB selling side project’s ReadMe 2019/3/17The result of my target yesterday The Wondering presentation. Optimize FB online selling project Phone validation and address validation Mail system Achieved except for set target yesterdayDescriptionToday’s target The Wondering presentation. Optimize FB online selling project 2019/3/16The result of my target yesterday Optimize FB online selling project Still working on the mail system for refund Achieved except for set target yesterdayDescriptionToday’s target The Wondering presentation. Optimize FB online selling project Phone validation and address validation Mail system 2019/3/15The result of my target yesterday Write down how to use PayPal payment service I’ve done it! Optimize FB online selling project If possible, I will go validation today! Achieved except for set target yesterdayDescriptionToday’s target Optimize FB online selling project Phone validation and address validation 2019/3/14The result of my target yesterday Write down how to use PayPal payment service I’m working on it! Optimize FB online selling project Have added refund function on both PayPal and AllPay Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service Finish it! Optimize FB online selling project If possible, I will go validation today! 2019/3/13The result of my target yesterday Write down how to use PayPal payment service Finished the refund function of PayPal. Optimize FB online selling project Finished the refund function of PayPal. Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service Will start to write this article after AllPay system refund function is completed. Optimize FB online selling project Finish refund function of AllPay 2019/3/12The result of my target yesterday Write down how to use PayPal payment service Almost finished refund function Optimize FB online selling project Almost finished PayPal refund function Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service Optimize FB online selling project 2019/3/11The result of my target yesterday Write down how to use PayPal payment service Completed capture authorization function. Optimize FB online selling project Completed capture authorization function. Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service Optimize FB online selling project 2019/3/10The result of my target yesterday Write down how to use PayPal payment service Nearly finished a basic transaction with REST API of PayPal Optimize FB online selling project Nearly finished a basic transaction with REST API of PayPal Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service Optimize FB online selling project 2019/3/9The result of my target yesterday Write down how to use PayPal payment service Still working on new features Optimize FB online selling project Working on refund feature Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service Optimize FB online selling project 2019/3/8The result of my target yesterday Write down how to use PayPal payment service Still working on new features Optimize FB online selling project Working on refund feature Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service Optimize FB online selling project 2019/3/7The result of my target yesterday Write down how to use PayPal payment service Already figured out how to use REST API, and now working on how to integrate it into my system Optimize FB online selling project Restructure Currently working on refund function WebSocket Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service Optimize FB online selling project Restructure WebSocket 2019/3/6The result of my target yesterday Write down how to use PayPal payment service still working on figuring out how rest API works Optimize FB online selling project Restructure WebSocket Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service Optimize FB online selling project Restructure WebSocket 2019/3/5The result of my target yesterday Write down how to use PayPal payment service Completed Payment Standard and IPN Message method Optimize FB online selling project Refine payment service Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service Optimize FB online selling project Restructure WebSocket 2019/3/4The result of my target yesterday Write down how to use PayPal payment service Still working on it, it’s a epic task! Optimize FB online selling project Restructure Make PayPal page show items and recipient in detail WebSocket Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service Optimize FB online selling project Restructure WebSocket 2019/3/3The result of my target yesterday Write down how to get long-lived and forever token from FB One more section of my Git Course Basically, it’s completed Optimize FB online selling project Restructure WebSocket Achieved except for set target yesterdayDescriptionToday’s target Write down how to use PayPal payment service Optimize FB online selling project Restructure WebSocket 2019/3/2The result of my target yesterday Write down how to use PayPal payment service One more section of my Git Course Optimize FB online selling project Added long-lived token function Achieved except for set target yesterdayDescriptionToday’s target Write down how to get long-lived and forever token from FB One more section of my Git Course Optimize FB online selling project Restructure WebSocket 2019/3/1The result of my target yesterday Write down how to use PayPal payment service One more section of my Git Course Optimize FB online selling project- Restructure - WebSocket Achieved except for set target yesterdayDescription Went to help 日安 carry the new counter she bought Went to KTV with Lester Today’s target Write down how to use PayPal payment service One more section of my Git Course Optimize FB online selling project- Restructure - WebSocket","link":"/schedule/2019/March/index.html"}],"posts":[{"title":"Getting Started with Cloud Shell & gcloud","text":"Refer to QWIKLABS","link":"/CloudShellAndgcloud/"},{"title":"GCP-Essentials","text":"Refer to QUIKLABS","link":"/GCP-Essentials/"},{"title":"gcloud shell","text":"IntroductionSorry that there is no English version for gcloud shell because I don’t think I could do any better than it website","link":"/GCP/"},{"title":"Deploy Laravel project on Server","text":"IntroductionThis article is mainly about how to deploy Laravel on AWS EC2Here are some points: LAMP deployment Composer deployment Laravel deployment Specification Amazon Linux AMI 2018.03.0 (HVM), SSD Volume Type LAMPPHP PHP Installation sudo yum install php72;php -v Install PHP Extension sudo yum install php72-mbstring sudo yum install php72-bcmath sudo yum install php72-pdo sudo yum install php72-mysqlnd sudo yum install php72-gd.x86_64 Apache Install Apache sudo yum install httpd24 Launch Apache sudo service httpd start Set up automatic start after reboot sudo chkconfig httpd on Check if httpd is enabled chkconfig --list httpd Set AWS security inbound Test Apache by visiting the IP Install SSL module sudo yum install mod24_ssl MySQL Install MySQL sudo yum install mysql57-server Launch MySQL sudo service mysqld start Set up MySQL to automatic start after reboot sudo chkconfig mysqld on 執行 mysql_secure_installation sudo mysql_secure_installation Set up MySQL to support remote connection with Sequel Pro CREATE USER 'root'@'%' IDENTIFIED BY '';GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' WITH GRANT OPTION;FLUSH PRIVILEGES; Set up authority Add your user (in this case, ec2-user) to the apache group. sudo usermod -a -G apache ec2-user Log out and then log back in again to pick up the new group, and then verify your membership. Log out (use the exit command or close the terminal window): exit To verify your membership in the apache group, reconnect to your instance, and then run the following command: groups Change the group ownership of /var/www and its contents to the apache group. sudo chown -R ec2-user:apache /var/www To add group write permissions and to set the group ID on future subdirectories, change the directory permissions of /var/www and its subdirectories. sudo chmod 2775 /var/wwwfind /var/www -type d -exec sudo chmod 2775 &#123;&#125; \\; To add group write permissions, recursively change the file permissions of /var/www and its subdirectories: find /var/www -type f -exec sudo chmod 0664 &#123;&#125; \\; Test LAMP Web server Create a PHP file in the Apache document root. echo \"&lt;?php phpinfo(); ?&gt;\" &gt; /var/www/html/phpinfo.php In a web browser, type the URL of the file that you just created. This URL is the public DNS address of your instance followed by a forward slash and the file name. For example:http://my.public.dns.amazonaws.com/phpinfo.php Delete the phpinfo.php file. Although this can be useful information, it should not be broadcast to the internet for security reasons. rm /var/www/html/phpinfo.php Composer Install Composer php -r \"copy('https://getcomposer.org/installer', 'composer-setup.php');\"php -r \"if (hash_file('sha384', 'composer-setup.php') === '48e3236262b34d30969dca3c37281b3b4bbe3221bda826ac6a9a62d6444cdb0dcd0615698a5cbe587c3f0fe57a54d8f5') &#123; echo 'Installer verified'; &#125; else &#123; echo 'Installer corrupt'; unlink('composer-setup.php'); &#125; echo PHP_EOL;\"php composer-setup.phpphp -r \"unlink('composer-setup.php');\" Make composer global sudo mv composer.phar /usr/local/bin/composer Git Install Gitsudo yum install -y git Deploy project Clone project git clone repositoryAddress Deploy .env file cp .env.example .env Install Composer composer install Generate key php artisan key:generate Create database mysql -urootcreate database databaseName; Create tables php artisan migrate If it lacks memory, you could assign some hard-drive to memory. sudo dd if=/dev/zero of=/swapfile bs=1M count=2000;sudo chmod 600 /swapfile;sudo mkswap /swapfile;sudo swapon /swapfile;swapon -s;sudo vim /etc/fstab; Add the following code/swapfile swap swap defaults 0 0 Change teh default document root locationsudo vim /etc/httpd/conf/httpd.conf &lt;Direction \"/var/www/html\"&gt; Allow Override All&lt;/Direction&gt; The above is normal process. You could also refer to lazy version as follows: Lazy versionsudo yum install -y php72;sudo yum install -y php72-mbstring;sudo yum install -y php72-bcmath;sudo yum install -y php72-pdo;sudo yum install php72-gd.x86_64sudo yum install -y php72-mysqlnd;sudo yum install -y httpd24;sudo service httpd start;sudo chkconfig httpd on;sudo yum install -y mod24_ssl;sudo yum install -y mysql57-server;sudo service mysqld start;sudo chkconfig mysqld on;sudo usermod -a -G apache ec2-user;sudo chown -R ec2-user:apache /var/www;sudo chmod 2775 /var/wwwfind /var/www -type d -exec sudo chmod 2775 &#123;&#125; \\;find /var/www -type f -exec sudo chmod 0664 &#123;&#125; \\;php -r \"copy('https://getcomposer.org/installer', 'composer-setup.php');\"php -r \"if (hash_file('sha384', 'composer-setup.php') === '48e3236262b34d30969dca3c37281b3b4bbe3221bda826ac6a9a62d6444cdb0dcd0615698a5cbe587c3f0fe57a54d8f5') &#123; echo 'Installer verified'; &#125; else &#123; echo 'Installer corrupt'; unlink('composer-setup.php'); &#125; echo PHP_EOL;\"php composer-setup.php;php -r \"unlink('composer-setup.php');\";sudo mv composer.phar /usr/local/bin/composer;sudo yum install -y git;sudo php -v Set AWS security inbound Test Apache by visiting the IP Execute mysql_secure_installation sudo mysql_secure_installation Set up MySQL to support Sequel Pro remote connection CREATE USER 'root'@'%' IDENTIFIED BY 'yourPassword';GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' WITH GRANT OPTION;FLUSH PRIVILEGES; Log out and then log back in again to pick up the new group, and then verify your membership. Log out (use the exit command or close the terminal window): exit; To verify your membership in the apache group, reconnect to your instance, and then run the following command: groups Create a PHP file in the Apache document root. echo \"&lt;?php phpinfo(); ?&gt;\" &gt; /var/www/html/phpinfo.php In a web browser, type the URL of the file that you just created. This URL is the public DNS address of your instance followed by a forward slash and the file name. For example:http://my.public.dns.amazonaws.com/phpinfo.php Delete the phpinfo.php file. Although this can be useful information, it should not be broadcast to the internet for security reasons. rm /var/www/html/phpinfo.php Clone project git clone repositoryAddress Deploy .env file cp .env.example .env Install Composer composer install Generate key php artisan key:generate Create database mysql -urootcreate database databaseName; Create tables php artisan migrate If it lacks memory, you could assign some hard-drive to memory. sudo dd if=/dev/zero of=/swapfile bs=1M count=2000;sudo chmod 600 /swapfile;sudo mkswap /swapfile;sudo swapon /swapfile;swapon -s;sudo vim /etc/fstab; Add the following code/swapfile swap swap defaults 0 0 Change teh default document root locationsudo vim /etc/httpd/conf/httpd.conf &lt;Direction \"/var/www/html\"&gt; Allow Override All&lt;/Direction&gt; Restart Apachesudo service httpd restart Check your OS version in Linux Use lsb_release , If it shows command not found, install it sudo apt-get install lsb-release Get its usage lsb_release --help Example output：-h, --help show this help message and exit-v, --version show LSB modules this system supports-i, --id show distributor ID-d, --description show description of this distribution-r, --release show release number of this distribution-c, --codename show code name of this distribution-a, --all show all of the above information-s, --short show requested information in short format Per the information above, if you would like to check the detail: lsb_release -a If you just want to know the version of the Kernel: uname -r","link":"/AWSLaravelDeployment/"},{"title":"Handle AllPay third party payment service with Laravel","text":"Create Laravel ProjectLaravel new AllPay Let’s initialize git, it’s a must be!git init Download AllPay SDK, in this article, we will use AllPay PHP SDKgit clone https://github.com/o-pay/Payment_PHP Move SDK Laravel’s app foldercp Payment_PHP/sdk/AllPay.Payment.Integration.php AllPay/app/ Create a testing controllerphp artisan make:controller PaymentsController Move the example in the SDK package to our Controller as follows:/****/ //SDK address(You could manage it yourself) include('AllPay.Payment.Integration.php'); try &#123; $obj = new AllInOne(); //Service parameters $obj-&gt;ServiceURL = \"https://payment-stage.opay.tw/Cashier/AioCheckOut/V5\"; //Service location $obj-&gt;HashKey = '5294y06JbISpM5x9' ; //Testing Hashkey, in real case, please use the one provided by AllPay $obj-&gt;HashIV = 'v77hoKGq4kWxNNIS' ; //Testing HashIV, in real case, please use the one provided by AllPay $obj-&gt;MerchantID = '2000132'; //Testing MerchantID, in real case, please use the one provided by AllPay $obj-&gt;EncryptType = EncryptType::ENC_SHA256; //CheckMacValue encrypted type, please stay 1, using SHA256 //Basic parameters(It depends on your need) $MerchantTradeNo = \"Test\".time(); $obj-&gt;Send['ReturnURL'] = 'http://localhost/simple_ServerReplyPaymentStatus.php' ; //The URL AllPay will return after the payment is paid $obj-&gt;Send['MerchantTradeNo'] = $MerchantTradeNo; $obj-&gt;Send['MerchantTradeDate'] = date('Y/m/d H:i:s'); $obj-&gt;Send['TotalAmount'] = 2000; $obj-&gt;Send['TradeDesc'] = \"good to drink\"; $obj-&gt;Send['ChoosePayment'] = PaymentMethod::ALL; //Items information array_push($obj-&gt;Send['Items'], array('Name' =&gt; \"歐付寶黑芝麻豆漿\", 'Price' =&gt; (int)\"2000\", 'Currency' =&gt; \"元\", 'Quantity' =&gt; (int) \"1\", 'URL' =&gt; \"dedwed\")); # E-Invoice parameters /* $obj-&gt;Send['InvoiceMark'] = InvoiceState::Yes; $obj-&gt;SendExtend['RelateNumber'] = $MerchantTradeNo; $obj-&gt;SendExtend['CustomerEmail'] = 'test@opay.tw'; $obj-&gt;SendExtend['CustomerPhone'] = '0911222333'; $obj-&gt;SendExtend['TaxType'] = TaxType::Dutiable; $obj-&gt;SendExtend['CustomerAddr'] = '台北市南港區三重路19-2號5樓D棟'; $obj-&gt;SendExtend['InvoiceItems'] = array(); // Add item into list of e-invoice foreach ($obj-&gt;Send['Items'] as $info) &#123; array_push($obj-&gt;SendExtend['InvoiceItems'],array('Name' =&gt; $info['Name'],'Count' =&gt; $info['Quantity'],'Word' =&gt; '個','Price' =&gt; $info['Price'],'TaxType' =&gt; TaxType::Dutiable)); &#125; $obj-&gt;SendExtend['InvoiceRemark'] = '測試發票備註'; $obj-&gt;SendExtend['DelayDay'] = '0'; $obj-&gt;SendExtend['InvType'] = InvType::General; */ //Create order $obj-&gt;CheckOut(); &#125; catch (Exception $e) &#123; echo $e-&gt;getMessage(); &#125; Let’s move some sensitive information into .env file$obj-&gt;HashKey = env('HASHKEY'); $obj-&gt;HashIV = env('HASHIV'); $obj-&gt;MerchantID = env('MERCHANTID'); $obj-&gt;Send['ReturnURL'] = env('ALLPAYRETURNURL');$obj-&gt;Send['ClientBackURL'] = $request-&gt;ClintBackURL; In .env:ALLPAYRETURNURL=https://163be100.ngrok.io/api/paymentsResponseHASHKEY=5294y06JbISpM5x9HASHIV=v77hoKGq4kWxNNISMERCHANTID=2000132 Use use to replace include Delete include('AllPay.Payment.Integration.php'); Add it in AllPay.Payment.Integration.php到composer.json file \"autoload-dev\": &#123; \"psr-4\": &#123; \"Tests\\\\\": \"tests/\" &#125;, \"files\": [ \"app/Helpers.php\", \"app/AllPay.Payment.Integration.php\" ] In terminal, under AllPay project composer dump-autoload In the PaymentsController, use all those required classes namespace App\\Http\\Controllers;use AllInOne;use EncryptType;use Exception;use Illuminate\\Http\\Request;use PaymentMethod; Create payment order (It depends on your need.)$totalAmount = Order::getTotalAmountForPayments($orders);$ordersName = Order::getOrdersNameForPayments($orders);$MerchantTradeNo = time() . Helpers::createAUniqueNumber();$MerchantTradeDate = date('Y/m/d H:i:s');$TradeDesc = 'BuyBuyGo';$quantity = 1;//Because I am going to insert data into two tables at a time, so I use //Transaction of Laravel to prevent the possible inconsistency of two tables//start transactionDB::beginTransaction();//All those scripts below should be executed without errors, otherwise the whole action rollbacktry&#123; $payment_service_order = new PaymentServiceOrders(); $payment_service_order-&gt;user_id = User::getUserID($request); //Payment service ID $payment_service_order-&gt;payment_service_id = $thirdPartyPaymentService-&gt;id; $payment_service_order-&gt;expiry_time = (new Carbon())-&gt;now()-&gt;addDay(1)-&gt;toDateTimeString(); $payment_service_order-&gt;MerchantID = env('MERCHANTID'); $payment_service_order-&gt;MerchantTradeNo = $MerchantTradeNo; $payment_service_order-&gt;MerchantTradeDate = $MerchantTradeDate; $payment_service_order-&gt;TotalAmount = $totalAmount; $payment_service_order-&gt;TradeDesc = $TradeDesc; //Item order number $payment_service_order-&gt;ItemName = $ordersName; $payment_service_order-&gt;save(); foreach ($orders as $order) &#123; $order_relations = new OrderRelations(); $order_relations-&gt;payment_service_id = $thirdPartyPaymentService-&gt;id; $order_relations-&gt;payment_service_order_id = $payment_service_order-&gt;id; $order_relations-&gt;order_id = $order-&gt;id; $order_relations-&gt;save(); &#125; //Once any errors occur, the whole action stops and rollback, and provide customized error message&#125; catch (Exception $e)&#123; DB::rollBack(); return Helpers::result('false', 'Something went wrong with DB', 400);&#125;//If no errors occur, the whole action commitDB::commit(); Create an API for PaymentsController Add new route in api.php under routes folder Route::post('pay', 'PaymentsController@pay'); Create a simplest HTML You could simply revise the content of default welcome.blade page as follows: &lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Facebook Login JavaScript Example&lt;/title&gt; &lt;meta charset=\"UTF-8\"&gt;&lt;/head&gt;&lt;body&gt;// 這邊需輸入PaymentsController的API&lt;form action=\"/api/pay\" method=\"POST\"&gt; @csrf() &lt;input type=\"checkbox\" value=\"1\" name=\"order_id[]\"&gt; &lt;input type=\"checkbox\" value=\"2\" name=\"order_id[]\"&gt; &lt;input type=\"checkbox\" value=\"3\" name=\"order_id[]\"&gt; &lt;input type=\"hidden\" value=\"https://64b30ea0.ngrok.io/\" name=\"ClintBackURL\"&gt; &lt;button type=\"submit\"&gt;Submit&lt;/button&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; Simple test Now we are on the default page of Laravel, it should change to the simple form we just created Check nothing, go summit Yes, we successfully arrived payment page Create a log In order to get what AllPay will send to us after the payment is made, we need to use Log to see what we will receive. Is there some place that all requests and responses will have to go through where we could have full accessibility? It seems to be a perfect one for logging We could make a middleware, and use Log function of Laravel therein to log whatever it goes through Make a middleware, in the terminal under the AllPay project php artisan make:middleware TestLog 註冊middleware In/app/Http/Kernel.php，register the middleware we just made protected $middleware = [ \\App\\Http\\Middleware\\CheckForMaintenanceMode::class, \\Illuminate\\Foundation\\Http\\Middleware\\ValidatePostSize::class, \\App\\Http\\Middleware\\TrimStrings::class, \\Illuminate\\Foundation\\Http\\Middleware\\ConvertEmptyStringsToNull::class, \\App\\Http\\Middleware\\TrustProxies::class, \\App\\Http\\Middleware\\TestLog::class,]; Create Log In the TestLog file that we just made, and added: $response = $next($request);log::info([$request-&gt;header(),$request-&gt;getMethod(),$request-&gt;getRequestUri(),$request-&gt;all(),$response-&gt;getStatusCode(),$response-&gt;getContent()]);return $response; Actually, what you might log varies upon different cases Create a public url We need to get the response from third party, so we need a public url to get it We could use ngrok to create the public url Install ngrok, please refer to its official website Change ngrok to be globally executable mv ngrok /usr/local/bin Get public url ngrok http 8000 In terminal under AllPay project php artisan serve 8000 Copy the public url produced by ngrok Create receive function We are going to catch the response from AllPay, firstly we need to create a function, and after catching it, we could do things there. In PaymentsController, we create a function receive as follows:public function receive()&#123; &#125; Make an API for itRoute::post('pay', 'PaymentsController@pay');Route::post('receive', 'PaymentsController@receive'); Set up client return url In .env, if you’ve been following what I taught, there should be this parameter, just simply paste the public url there ALLPAYRETURNURL=https://163be100.ngrok.io/api/recevie Your link will be different from mine, don’t paste mine. Test payment Let’s connect AllPay payment page again Login the testing buyer account provided by AllPay Account：stageuser001 Password：test1234 Use the testing credit card provided by AllPay Number：4311-9522-2222-2222 Expiry Date：12 / 20 or later than current date Security number：222 After payment, let’s check log to see if there is a response from AllPay, in terminal under AllPay project cat storage/logs/laravel-2019-02-08.log On, we’ve got the response. 'MerchantID' =&gt; '2000132', 'MerchantTradeNo' =&gt; 'Test1549597724', 'PayAmt' =&gt; '2000', 'PaymentDate' =&gt; '2019/02/08 11:49:03', 'PaymentType' =&gt; 'Credit_CreditCard', 'PaymentTypeChargeFee' =&gt; '20', 'RedeemAmt' =&gt; '0', 'RtnCode' =&gt; '1', 'RtnMsg' =&gt; '交易成功', 'SimulatePaid' =&gt; '0', 'TradeAmt' =&gt; '2000', 'TradeDate' =&gt; '2019/02/08 11:48:44', 'TradeNo' =&gt; '1902081148440800', 'CheckMacValue' =&gt; '5B1EE24B0E9D600C65578DD82D3168E2ED56799453577E17E1EBEFC536BD7EAF', Validation Think about it, if your API was accidentally leaked, and some developer knew it. He bought some items from your service, and called your API, how could you tell? So, there is a specific mechanism that only applicable between you and third party payment service The validation mechanism is like a formula every column goes in and out will be calculated with which is only applicable between you and third party, if you’ve been paying attention, you should notice that in the last column of the response we’ve received from AllPay. If you are interested in the formula in detail, you could check it on AllPay’s website. Since in this article, we use AllPay SDK, so we are going to share how to use official SDK to validate the information. Firstly, let’s check a class called CheckMacValue in app/AllPay.Payment.Integration.php Secondly, you could find a function called generate, and you could check it, which it the formula of the CheckMacValue So, we could calculate the received information with this formula, and it should exactly the same as what we’ve got from third party Let’s get all those information except for CheckMacValue from AllPay, we could use the following code. $parameters = $paymentResponse-&gt;except(&apos;CheckMacValue&apos;); And then, we assign a variable with the CheckMacValue we’ve got from AllPay $receivedCheckMacValue = $paymentResponse-&gt;CheckMacValue; Then, we calculate the $parameters with function generate to produce correct CheckMacValue $calculatedCheckMacValue = CheckMacValue::generate($parameters, env(&apos;HASHKEY&apos;), env(&apos;HASHIV&apos;), EncryptType::ENC_SHA256); Finally, we compare if two values are identical, if so, it proves the validity of its source. If not, we shouldn’t give any credibility to this information if($receivedCheckMacValue == $calculatedCheckMacValue) return true;return false; What’s next? After validating the source, we could do things accordingly For example, if payment is successfully made, what we are going to do, and if not, what then? In this article, we mark the orders as paid and notify the buyers via email after the payment is made. if (PaymentServiceOrders::checkIfCheckMacValueCorrect($request) &amp;&amp; PaymentServiceOrders::checkIfPaymentPaid($request-&gt;RtnCode))&#123; $paymentServiceOrder = (new PaymentServiceOrders)-&gt;where('MerchantTradeNo', $request-&gt;MerchantTradeNo)-&gt;first(); $paymentServiceOrder-&gt;update(['status' =&gt; 1, 'expiry_time' =&gt; null]); $orderRelations = $paymentServiceOrder-&gt;where('MerchantTradeNo', $request-&gt;MerchantTradeNo)-&gt;first()-&gt;orderRelations; Order::updateStatus($orderRelations); $payerEmail = $paymentServiceOrder-&gt;user-&gt;email; if ($payerEmail !== null) Mail::to($payerEmail)-&gt;send(new PaymentReceived($paymentServiceOrder, $orderRelations)); return '1|OK';&#125; At the end, don’t forget to return ‘1|OK’ to let AllPay knows that we’ve received the message. Those I didn’t mentioned With the testing buyer account provided by AllPay, except for credit card, is also supports multiple payment method With convenient store pay or bank transferring method, you could login with a testing backed account provided by AllPay, which could simulate making the payment. Account：StageTest Password：test1234 Refund Refund example as follows: public static function refund($order, $paymentServiceInstance, $orderRelation)&#123; try &#123; $obj = new AllInOne(); $obj-&gt;ServiceURL = &quot;https://payment-stage.opay.tw/Cashier/AioChargeback&quot;; // endpoint $obj-&gt;HashKey = env(&apos;HASHKEY&apos;); // Hash key provided by AllPay $obj-&gt;HashIV = env(&apos;HASHIV&apos;); // Hash IV provided by AllPay $obj-&gt;MerchantID = env(&apos;MERCHANTID&apos;); // Merchant ID provided by AllPay $obj-&gt;EncryptType = EncryptType::ENC_SHA256; // CheckMacValue type. Stay 1 as SHA256 $obj-&gt;ChargeBack[&apos;MerchantTradeNo&apos;] = $paymentServiceInstance-&gt;MerchantTradeNo; // The trade number you provided to AllPay $obj-&gt;ChargeBack[&apos;TradeNo&apos;] = $paymentServiceInstance-&gt;TradeNo; // The trade no provided by AllPay $obj-&gt;ChargeBack[&apos;ChargeBackTotalAmount&apos;] = $order-&gt;total_amount; // Refunded amount $obj-&gt;AioChargeback(); &#125; catch (Exception $e) &#123; // If something wrong, return. return Helpers::result(true, &apos;Something wrong happened&apos;, 200); // Debug mode, print out the error echo $e-&gt;getMessage(); &#125;&#125; You could refer to official document for required parameters","link":"/AllPayPaymentService/"},{"title":"Understand how GCP Load Balancer works and build one","text":"IntroductionWhy Load Balancer? It split the traffic of multiple services among multiple machines When one node dies, you still have another one It supports auto-scaling when pre-set benchmark is reached (Not covered in this article) With proper CI / CD and health-check, it could achieve rolling upgrade In this article, we are going to build a unmanaged Load Balancer, the easiest one. Detailed explanation for every componentThe concept in Graph (Image source： Google )： Users from IPv4 and IPv6 make requests to our service The IPv4 and IPv6 forwarding rules lead the request to HTTP(s) proxy When requests reach HTTP(S) proxy, it will be led to some backend-service according to the url-map we set. For example, the request with domain ‘test1’ would be led to backend-service 1, and ‘test2’ would be led to backend-service 2 backend-service consist of instance group. For example, we could specify that backend-service A lead the request to port 8000 of instance group A, and backend-service B lead the request to port 6000 of instance group B instance group, as its name, consist of instance. If we set up instance group and backend-service properly, request will reach backend-service, and be led to designated port of instance via instance group and its balance condition Every backend-service could have a health-check, and health-check would periodically prob specified port and get response. If there is no response, or the response is slower than the benchmark we’ve set, then the instacnce will be diagnosed as unhealthy. Request would not be led to unhealthy instance If SSL is needed, SSL certificate could be created and added in HTTPS proxy Let’s get our hands dirty now! Google Cloud SDK InstallationIn this article, we are going to use Google Cloud SDK on every section, so before we start, let’s install it first.Installation way varies per your Operating System. We could refer to Official Documentation Create an instance Build two instancesgcloud compute instances create test-01 \\--image-project=ubuntu-os-cloud \\--image-family=ubuntu-1804-lts \\--boot-disk-size=30GB \\--boot-disk-type=pd-standard \\--machine-type=f1-micro \\--tags=test-01,http-server,https-server \\--zone=asia-east1-c gcloud compute instances create test-02 \\--image-project=ubuntu-os-cloud \\--image-family=ubuntu-1804-lts \\--boot-disk-size=30GB \\--boot-disk-type=pd-standard \\--machine-type=f1-micro \\--tags=test-02,http-server,https-server \\--zone=asia-east1-c Build two machines, named test-01 and test-02 Boot-drive capacity is 30 GB Pull image from ubuntu-os-cloud Use ubuntu-1804-lts as version of the image The disk-types type is pd-standard, you could also check all disk-types by running gcloud compute disk-types The machine-types is f1-micro, you could also check all machine-types by running gcloud compute machine-types list As a identifier of instance, which we are going to use with later when creating firewall-rules zone specify the zone of the instance. Be aware that some resources are limited with zone and region Reference official documentation Instance Environment InstallationThe followings are about instance environment. You could simply skip it because it doesn’t have much to do with our subject.apt-get update -y &amp;&amp; apt-get install curl -y &amp;&amp; curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.34.0/install.sh | bash &amp;&amp; export NVM_DIR=\"$HOME/.nvm\" &amp;&amp; [ -s \"$NVM_DIR/nvm.sh\" ] &amp;&amp; \\. \"$NVM_DIR/nvm.sh\" &amp;&amp; [ -s \"$NVM_DIR/bash_completion\" ] &amp;&amp; \\. \"$NVM_DIR/bash_completion\" &amp;&amp; nvm install yourNodeVersion &amp;&amp; apt-get install npm -y &amp;&amp; npm install pm2 -g &amp;&amp; pm2 update &amp;&amp; apt-get install git -y &amp;&amp; apt-get install build-essential Create firewall-rulesWe need to create firewall-rules per the port you use and so request could be led to the instance. We could refer to official documentation gcloud compute firewall-rules create test-01 --allow tcp:123,tcp:456,tcp:789 --target-tags test-01 gcloud compute firewall-rules create test-02 --allow tcp:123,tcp:456,tcp:789 --target-tags test-02 Static External IPWe are going to create a static IP for further usage, we could refer to official documentationgcloud compute addresses create lb-test \\ --ip-version=IPV4 \\ --global Instance groupInstance group can consist of multiple instance, and it the bulk of backend-service, we could refer to official documentation With instance group, we could create different backend-service later on Load Balancer gcloud compute instance-groups unmanaged create test --description 'run test project' --zone asia-east1-c Set named port, which could be used on different backend-service gcloud compute instance-groups unmanaged set-named-ports test --named-ports port1:3000,port2:6000,port3:9000,port4:12000,port5:15000 --zone asia-east1-c Add existing instance into instance group gcloud compute instance-groups unmanaged add-instances test \\ --instances test-01,test-02 \\ --zone asia-east1-c Health checkhealth-check could prob specified port with specified frequency. If there is no response from specified port, health-check would diagnose this port as unhealthy, and backend-service would not send request to unhealthy destination. We could refer to official documentation gcloud compute health-checks create tcp test-tcp-3000 \\ --description='test tcp 3000'\\ --port=3000 gcloud compute health-checks create tcp test-tcp-6000 \\ --description='test tcp 6000'\\ --port=6000 gcloud compute health-checks create tcp test-tcp-9000 \\ --description='test tcp 9000'\\ --port=9000 gcloud compute health-checks create tcp test-tcp-12000 \\ --description='test tcp 12000'\\ --port=12000 gcloud compute health-checks create tcp test-tcp-15000 \\ --description='test tcp 15000'\\ --port=15000 Backend serviceThe --port-name here is what we set up above. In this example, different backend-service would send request to different port. instance group has not been mentioned yet? Don’t worry, in next step, we will add instance group into backend-service Also, health-check will be added into backend-service because backend-service is going to decide which instance the request should be sent to.We could refer to the official documentation Build backend-servicegcloud compute backend-services create backend-service-port1 \\ --protocol http \\ --port-name port1 \\ --health-checks test-tcp-3000 \\ --global gcloud compute backend-services create backend-service-port2 \\ --protocol http \\ --port-name port2 \\ --health-checks test-tcp-6000 \\ --global gcloud compute backend-services create backend-service-port3 \\ --protocol http \\ --port-name port3 \\ --health-checks test-tcp-9000 \\ --global gcloud compute backend-services create backend-service-port4 \\ --protocol http \\ --port-name port4 \\ --health-checks test-tcp-12000 \\ --global gcloud compute backend-services create backend-service-port5 \\ --protocol http \\ --port-name port5 \\ --health-checks test-tcp-15000 \\ --global Next, we are going to add instance group into the backend-service we just built. Since we’ve designated port when creating backend-service, backend-service would lead requests to the designated port of the instance group Besides setting which port the request to be sent, we are going to set up the benchmark of instance utilisation. UTILIZATION means the percentage of usage. When it reaches 80%, backend-service would stop sending request to this instance capacity-scaler means 1 * 0.8, so if you have multiple backend-service using one instance-group, and you want to keep more utilisation capacity for some other backend-service, then you could give a lower capacity-scaler. So when this backend-service already use capacity-scaler * max-utilization, request from this backend-service would not be sent to this instance-group, which save the utilisation capacity of the instance-group for other backend-service We could refer to the example below, and also the official documentation Add instance group into backend-servicegcloud compute backend-services add-backend backend-service-port1 \\ --balancing-mode UTILIZATION \\ --max-utilization 0.8 \\ --capacity-scaler 1 \\ --instance-group test \\ --instance-group-zone asia-east1-c \\ --global gcloud compute backend-services add-backend backend-service-port2 \\ --balancing-mode UTILIZATION \\ --max-utilization 0.8 \\ --capacity-scaler 1 \\ --instance-group test \\ --instance-group-zone asia-east1-c \\ --global gcloud compute backend-services add-backend backend-service-port3 \\ --balancing-mode UTILIZATION \\ --max-utilization 0.8 \\ --capacity-scaler 1 \\ --instance-group test \\ --instance-group-zone asia-east1-c \\ --global gcloud compute backend-services add-backend backend-service-port4 \\ --balancing-mode UTILIZATION \\ --max-utilization 0.8 \\ --capacity-scaler 1 \\ --instance-group test \\ --instance-group-zone asia-east1-c \\ --global gcloud compute backend-services add-backend backend-service-port5 \\ --balancing-mode UTILIZATION \\ --max-utilization 0.8 \\ --capacity-scaler 1 \\ --instance-group test \\ --instance-group-zone asia-east1-c \\ --global URL mapWe’ve covered backend-service above, and url-map is what leads request to backend-service Firstly, let’s create a url-map, and specify a default backend-service. It means that if destination is not specified, request would be sent to this default backend-service We could refer to the example below, also the official documentation Create a url-mapgcloud compute url-maps create web-map \\ --default-service backend-service-port1 After we created a url-map, and specified a default backend-service, now we could specify more rules with which the request should be led to backend-service We should use path-matcher to specify the path as example below: path-matcher: create a path-matcher and specify the rule new-hosts: The request requesting the host sunday.com.tw is going to be applied for this rule. It said that the request requesting sunday.com.tw would be led to backend-service-port1 We could refer to the example below, also the official documentation Add path-matchergcloud compute url-maps add-path-matcher web-map \\ --default-service backend-service-port1 \\ --path-matcher-name pathmap-port1 \\ --new-hosts=sunday.com.tw Here you could find a new component called path-rules When requested host is monday.com.tw, and the default path is /, the request would be sent to backend-service-port2 When the requested path is happy, like monday.com.tw/happy, the request would be sent to backend-service-port1 When the requested path is unhappy, like monday.com.tw/unhappy, the request would be sent to backend-service-port2 When the requested path is sad, like monday.com.tw/sad, the request would be sent to backend-service-port3 gcloud compute url-maps add-path-matcher web-map \\ --default-service backend-service-port2 \\ --path-matcher-name pathmap-port2 \\ --path-rules=/happy=backend-service-port1,/unhappy=backend-service-port2,/sad=backend-service-port3 \\ --new-hosts=monday.com.tw example same as above, the request to tuesday.com.tw would be sent to backend-service-port3gcloud compute url-maps add-path-matcher web-map \\ --default-service backend-service-port3 \\ --path-matcher-name pathmap-port3 \\ --new-hosts=tuesday.com.tw Create a SSL certificateIn order to let our service support HTTPS, we need to create ssl-certificates. It could be either self-managed or google-managed self-managed means the ssl certificate managed on your own. In the following example, we will use google-managed We could refer to official documentation gcloud beta compute ssl-certificates create www-ssl-cert \\ --domains sunday.com.tw,monday.com.tw,tuesday.com.tw HTTP proxyAll the HTTP request will get here, and be sent to backend-service via url-map We could refer to official documentation Create a HTTP proxygcloud compute target-http-proxies create http-lb-proxy \\ --url-map web-map HTTPS proxyAll the HTTPS request will get here, and be sent to backend-service via url-map Also, we are going to add the ssl-certificates we just created here so target-https-proxies can support HTTPS 可參考官方文件We could refer to official documentation Create HTTPS proxygcloud compute target-https-proxies create https-lb-proxy \\--url-map web-map \\--ssl-certificates www-ssl-cert Check Static External IPList the addresses we’ve created We could refer to official documentation gcloud compute addresses list Forwarding rulesWhen the requested address and port match the forwarding-rules, lead the request to designated target-http-proxy Replace the [LB_IP_ADDRESS] below with the static external IP we just created We could refer to the official documentation Create HTTP forwarding-rulesgcloud compute forwarding-rules create http-content-rule \\ --address [LB_IP_ADDRESS] \\ --global \\ --target-http-proxy http-lb-proxy \\ --ports 80 When the requested address and port match the forwarding-rules, lead the request to designated target-https-proxy Replace the [LB_IP_ADDRESS] below with the static external IP we just created We could refer to the official documentation Create HTTPS forwarding-rulesgcloud compute forwarding-rules create https-content-rule \\ --address [LB_IP_ADDRESS] \\ --global \\ --target-https-proxy https-lb-proxy \\ --ports 443 ConclusionAbove-mentioned is the flow of Load Balancer of GCP as follows:request =&gt; forwarding-rules =&gt; target-http(s)-proxy =&gt; url-map =&gt; backend-service =&gt; instance-group =&gt; instance Follow the example above, you should be able to run services on your instance and get, process, respond requests properly. I spent quite a lot of time writing this article, hoping it will help whoever in need. If you’ve got here, I would like to thank you for it. Finally, if you find this article is helpful, your clap is the best reward to me. Also, if you find anything incorrect, feel free to let me know.","link":"/GCPLoadBalancer/"},{"title":"Get Facebook long-lived token and never expired token","text":"IntroductionIn this article, I’m going to share how to get Facebook’s long lived token and never expired token via either PHP or Facebook’s Graph API Explorer.Currently I’m working on a Facebook live-stream selling optimized system, and found that the short lived token for web is only effective for not longer than 2 hours, far shorter than 3 months on Android, and 2 months on iOS.Although it will be okay if we just set our script properly, I spent some time figuring out how to get long lived token and never expired token Facebook Graph API Explorerlong lived tokenFirstly, let’s get long lived token via Facebook’s Graph API Explorer Let’s create some Test Users Get token from Test Users On Graph API Explorer Enter the token we just got Press submit Press the exclamation mark beside token，and press Open In Access Token Tool Click Extend Access Token on bottom left corner got long lived token Never expired tokenNow, let’s get never expired token through Graph API Tool Firstly, let’s login with Test User account, and create a fan page Secondly, let’s repeat all the process mentioned above, and then we will get a never expired token PHPlong lived tokenNow let’s get long lived token via calling Facebook’s API with PHP Call Facebook’s API with PHP’s function file_get_contents public static function getLongLivedToken($token)&#123; $url = 'https://graph.facebook.com/oauth/access_token?grant_type=fb_exchange_token&amp;client_id=yourClientID&amp;client_secret=yourClientSecret&amp;fb_exchange_token=shortLivedToken; return json_decode(file_get_contents($url), true);&#125; You will get information below: &#123; \"result\": true, \"response\": &#123; \"access_token\": \"EAAEpKfFACZA8BAGyTFU29VFIlEjhDaUe66eliyWdGQDfVTBUUdFZBZAGeZBEgTEwxgthvdABuzECYi1ahqm8ZCYNRSV9YMnegq7XxCouP1sR8kXMdnNFysGb2IHZBhSB3KENeTZCBzHrFSJ9BJLt9k6xkuWkJsVHnG0KahmFmybKTG6pVaFoZATN\", \"expires_in\": 5182393 &#125;&#125; ConclusionAs to how to get never expired token via PHP, it seems like we will need to pass the APP review and get more permission, so I’m not able to test it for now.","link":"/FacebookLongLivedToken/"},{"title":"Provision Services with GCP Marketplace","text":"Refer to QUIKLABS","link":"/GCPMarketplace/"},{"title":"Set Up Network and HTTP Load Balancers","text":"Refer to QUIKLABS","link":"/HTTPAndNetworkLoadBalancer/"},{"title":"Hello Kubernetes!","text":"Refer to QWIKLABS","link":"/Kubernetes/"},{"title":"My learning journey in Linux","text":"IntroductionThis page is my learning note on Linux, and it’s unorganised, so currently there is no English version.","link":"/Linux/"},{"title":"My learning note of MongoDB","text":"IntroductionSince it’s a unorganised learning note, I’m sorry that there may not be a English version.","link":"/MongoDB/"},{"title":"My learning journey in Node.js","text":"IntroductionThis is the notes I take during my learning, and it’s still unorganised, so there will no be English version of this article","link":"/Node-js/"},{"title":"Kubernetes Engine - Quick Start","text":"Refer to QWIKLABS","link":"/KubernetesEngineQuickStart/"},{"title":"Implement Laravel Queue with AWS SQS","text":"IntroductionHere is about this article: Send Email with Laravel Queue Use AWS SQS So why do we need to use queue?When we execute some jobs that require longer time, like sending Emails, or uploading photos or videos, let users to wait until the jobs are completed is just not so practical.So when users request some time consuming jobs, we need to use queue to line them, and execute them on the background, and so the users could be released from current request immediately. Apply AWS SQS service Firstly, you need an AWS account Apply SQS on AWS Refer to official document to complete the setting. Keep the information below for further usage. On up-right corner, click your account, and choose My Security Credentials Click Users to create a new user Give user id, and check Programmic access, and next Click Create group as photo below Add the user we just created into this newly created group Then Add tags is optional, you could skip it Now we have Access key ID and Secret access key. If you are afraid of forgetting them, you could download them. By the way, Secret access key will only be accessible this time, you will need to reproduce it if you forget it. Implement Laravel QueueConfigure AWS SQS The following operation is referred to official document Install AWS official SDK as referred in official document，under the repository: composer require aws/aws-sdk-php Configure .env file QUEUE_CONNECTION=sqsSQS_KEY=theKeyWeGotAboveSQS_SECRET=theSecretKeyWeGotAboveSQS_QUEUE=testSQSSQS_REGION=ap-northeast-1SQS_PREFIX=theURLAboveWithoutQueueName Create jobsphp artisan make:job ProcessPodcast job example:&lt;?phpnamespace App\\Jobs;use App\\Helpers;use Illuminate\\Bus\\Queueable;use Illuminate\\Queue\\SerializesModels;use Illuminate\\Queue\\InteractsWithQueue;use Illuminate\\Contracts\\Queue\\ShouldQueue;use Illuminate\\Foundation\\Bus\\Dispatchable;class SendMailWhenOrderPlaced implements ShouldQueue&#123; use Dispatchable, InteractsWithQueue, Queueable, SerializesModels; protected $job; // The maximum attempts of this job public $tries = 5; /** * Create a new job instance. * * @return void */ public function __construct($order, $FB_email, $Local_email) &#123; $this-&gt;order = $order; $this-&gt;FB_email = $FB_email; $this-&gt;Local_email = $Local_email; $this-&gt;job = Helpers::mailWhenOrderPlaced($order, $FB_email, $Local_email); &#125; /** * Execute the job. * * @return void */ public function handle() &#123; return $this-&gt;job; &#125;&#125; The example above is to execute a function of sending Email called mailWhenOrderPlaced with queue in Ray’s project. Use dispatch Wherever we want to execute this job, we use dispatchSendMailWhenOrderPlaced::dispatch($order, $FB_email, $Local_email); Execute queue Under the projectphp artisan queue:work Test Now, when the dispatch is executed, it will send Email with queue ConclusionIt’s so easy, isn’t it?By the way, because we use queue, so we have to make sure that qeeue works well. In this case, if the queue fails, then the Email function will fail too.To guarantee that queue works well, and automatically restart after fails, we need to use Supervisor to help us monitor and manage processes.If you are interested in Supervisor, you could take a look on Ray’s another article hereIf you are also interested in how to use Laravel Mail and AWS SES, to send mail, you could take a look on Ray’s another article here as well","link":"/LaravelQueueWithSQS/"},{"title":"Use `Laravel` `template` and `blade`","text":"IntroductionThis article is a learning record of Laravel, mainly about how to use Laravel blade. Here are some points: Create and reuse template Use yield and section Pass data to view What {{ }} does for us? Create template Create a template named layout as follows:&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; // Set range of title with yield, and set 'Laracasts' as its default value. If value of title is not specified, default value will be applied &lt;title&gt;@yield('title', 'Laracasts')&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;ul&gt; &lt;li&gt;&lt;a href=\"/\"&gt;Welcome&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=\"/about\"&gt;About&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=\"/contact\"&gt;contact&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;// Set range of section named content with yield@yield('content')&lt;/body&gt;&lt;/html&gt; Use section we could directly use the template we created above// We directly apply the 'template' named 'layout'@extends('layout')// Use section, insert value we want into the area we've set in template. We insert value into 'title' section@section('title', 'Welcome Page')// Use section to insert value into section named 'content'@section('content') &lt;h1&gt;Welcome here&lt;/h1&gt;// Use endsection to specify the range of section named 'content'@endsection Repeat the operation above, we apply this templete to multiple pages Pass value to view To pass value to view, actually there is a couple of ways. I will list 4 of them below: 1. Route::get(&apos;/&apos;, function () &#123; $task = [ &apos;Go to the school&apos;, &apos;Go to the market&apos;, &apos;Go to work&apos; ]; return view(&apos;welcome&apos;, compact(&apos;task&apos;) );&#125;); 2. Route::get(&apos;/&apos;, function () &#123; $task = [ &apos;Go to the school&apos;, &apos;Go to the market&apos;, &apos;Go to work&apos; ]; return view(&apos;welcome&apos;, [&apos;tasks&apos; =&gt; $task] ); Route::get(&apos;/&apos;, function () &#123; return view(&apos;welcome&apos;, [&apos;tasks&apos; =&gt; [ &apos;Go to the school&apos;, &apos;Go to the market&apos;, &apos;Go to work&apos; ]]);&#125;); Route::get(&apos;/&apos;, function () &#123; return view(&apos;welcome&apos;)-&gt;withTasks([ &apos;Go to the school&apos;, &apos;Go to the market&apos;, &apos;Go to work&apos; ]);&#125;); 4 of them above, Ray would like to use the first one. Catch the value in view Catch the value in view and render @extends(&apos;layout&apos;)@section(&apos;title&apos;, &apos;Welcome Page&apos;)@section(&apos;content&apos;) &lt;h1&gt;Welcome here&lt;/h1&gt; &lt;ul&gt; @foreach ($tasks as $task) &lt;li&gt; &#123;&#123; $task &#125;&#125; &lt;/li&gt; @endforeach &lt;/ul&gt;@endsection In blade file of Laravel, we would fetch variables within {{ }} As follows: What blade {{ }} does for us? Besides for fetching passed data, {{ }} also execute function of PHP called htmlspecialchars to prevent XSS attack Let’s make an experiment with bladeRoute::get(&apos;/&apos;, function () &#123; $test = &apos;&lt;script&gt;alert(&quot;test&quot;)&lt;/script&gt;&apos;; return view(&apos;welcome&apos;)-&gt;withTasks([ &apos;Go to the school&apos;, &apos;Go to the market&apos;, &apos;Go to work&apos; ])-&gt;withTest($test);&#125;); @extends(&apos;layout&apos;)@section(&apos;title&apos;, &apos;Welcome Page&apos;)@section(&apos;content&apos;) &lt;h1&gt;&#123;&#123; $test &#125;&#125;&lt;/h1&gt; &lt;ul&gt; @foreach ($tasks as $task) &lt;li&gt; &#123;&#123; $task &#125;&#125; &lt;/li&gt; @endforeach &lt;/ul&gt;@endsection As what shows above, the browser render the variable with script tag as follows: Let’s have another experiment. We could deactivate htmlspecialchars by using {!! !!}, but be careful with this feature.@extends(&apos;layout&apos;)@section(&apos;title&apos;, &apos;Welcome Page&apos;)@section(&apos;content&apos;) &lt;h1&gt;&#123;!! $test !!&#125;&lt;/h1&gt; &lt;ul&gt; @foreach ($tasks as $task) &lt;li&gt; &#123;&#123; $task &#125;&#125; &lt;/li&gt; @endforeach &lt;/ul&gt;@endsection The rendered result is as follows: It shows that the script was executed without escaping ConclusionThere are still a lot of usage about blade, I might update this article in the future.","link":"/LaravelView/"},{"title":"OOP-Class and Object","text":"Hello everyone, it’s Ray! Today I’m going to share with you what class is, and what object is, also the relationship between them. It’s hard to skip object when it comes to class, and vice versa, which is often what keep people from understanding. Simply speaking, class is the code template that generates objects. Talking is easy, let’s have some hand-on experiment first! We could name a class with arbitrary name, which could be a combination of letters and numbers, and it must not begin with a number. Please take a look on the example below:class ＭyAccessories&#123; // class body&#125; The stuff above doesn’t look like a useful thing though, it’s a totally legal class. As above mentioned, class is a template that generates objects. Now let’s create some objects as code below:$accessory1 = MyAccessories();$accessory2 = MyAccessories(); We use class “MyAccessories” to create two objects, and due to the same class that they come from, they share with the same functionality and type. And you might ask, are they the same? The answer is NO! Although they are the same in functionality or type, they are indeed different objects I know that you might still be confusing. Okay, let’s print them out. Add the following code:var_dump($accessory1);var_dump($accessory2); I assume that you will print the stuff below, and you could see the number that follows pound sign, which represent their uniqueness. “Maybe the script shows the number in orders” You might say.object(MyAccessories)#1 (0) &#123;&#125;object(MyAccessories)#2 (0) &#123;&#125; Okay, let’s have another experiment to make it crystal clear. We switch the name of objects within var_dump braces, and if the script just shows the number in order, theorectically the number that follows pound sign will not change, will it?var_dump($accessory2);var_dump($accessory1); I suppose that you will print something as follows:object(MyAccessories)#2 (0) &#123;&#125;object(MyAccessories)#1 (0) &#123;&#125; See! The number after pound sign changed, which means the fact that even though they are generated with the same class, they have their own number that represent their uniqueness. That said each object is unique. If you still have some confusion, let’s make an analogy as follows: You could think of class as the a mould that produce a lot of castings, and objects are the castings that produced by the mould. They could be keycaps, or earphones. Despite the fact that they look identical on appearance, they are different. You might spot some serial number on them, and it’s like the number we printed earlier after pound sign. Do you have more understanding on class and object after reading through this article?","link":"/OOP-ClassAndObject/"},{"title":"Build a multi-lingual blog with Hexo","text":"IntroductionI spent a lot of time recently trying to build a bilingual blog.Except for programming, I am also enamoured with languages, like English, Japanese. So I’ve been thinking of building a blog with multi-lingual support, making my article reached by more people, and also practicing languages.After consulting Google master for endless time, here are some feasible way to achieve that:Use i18n along with revising source code2. Build two sites, one for Chinese, and another for English3. Use one of Hexo’s themes called ‘Minos’After some research, I’ve made my decision for the third one, because:Originally I use Next theme. However, unfortunately it doesn’t support multi-language, and I do have difficulty revising the source code.It means I would have to maintain two sites. Once one is revised, the other will need to be done so. and more languages version you have, the more things you will have to do.So In this article, I will share how to achieve it with Minos Install Hexo install NodeJS, and it will install npm automatically. brew install node Install Hexo with npm npm install hexo-cli -g Build whatever required for building a site within a designated directory. hexo init folderName Install minos theme Go into the folder cd folderName Clone it from official GitHub https://github.com/ppoffice/hexo-theme-minos.git themes/minos Start configuringConfigure Hexo config After installing, we can only find the file _config.yml.example, so we need to copy or rename it to _config.yml， and then search theme, and then set it to minos There are two kinds of config files, one for Hexo, and the other for the theme. Let’s go for Hexo configuration first. Here are some options that must be set, and you could leave others as default language: [&apos;en&apos;, &apos;zh-tw&apos;] //It means set English as default, and Taiwan as the second. url: https://tn710617.github.io/ (Your site address) permalink: :title/ deploy: type: git repo: https://github.com/tn710617/tn710617.github.io.git (It&apos;s the clone address of your GitHub project) branch: master Some settings in config file has nothing to do with language stuff we are taking about, so I will just leave them for your own exploration Language config for website After config file for Hexo, we need to build a language config for our own countries. If there already is, then you will not have to. In this case, I need a Taiwan language config, and there is not, so I will need to make one on my own. The function of this config file is that Hexo will render your page according to the language in this file when certain language is chosen. Create a file called zh-tw.yml in a folder called languages in minos theme The content is just like that of other countries as follows:name: &apos;繁體中文&apos;common: archives: &apos;歸檔&apos; category: &apos;分類&apos; tag: &apos;標籤&apos; categories: &apos;分類&apos; tags: &apos;標籤&apos;nav: next: &apos;下一頁&apos; prev: &apos;上一頁&apos; search: &apos;搜尋&apos; toc: &apos;目錄&apos;article: read_more: &apos;點擊閱讀&apos; read: &apos;讀完&apos; about: &apos;大概&apos; words: &apos;字&apos; comments: &apos;留言&apos; contents: &apos;目錄&apos;search: hint: &apos;站內搜尋&apos;insight: hint: &apos;站內搜尋&apos; posts: &apos;文章&apos; pages: &apos;頁面&apos; categories: &apos;分類&apos; tags: &apos;標籤&apos; untitled: &apos;(無標題)&apos; Config language mapping file After setting up the language config, we copy the theme config file and make another two as follows. The function of those files is that when certain languages is chosen, Hexo will open the page according to the address you designate in those config files. For example, Chinese will open Chinese page, and English will do so too. _config.zh-tw.yml _config.en.yml Let’s config ‘en’ config file first. // The configuration here depends on your needmenu: Archives: /archives Categories: /categories Tags: /tags Schedule: /schedule About: /about Friends: /friends And then, we config ‘zh-tw’ file as follows: menu: 歸檔: /zh-tw/archives 分類: /zh-tw/categories 標籤: /zh-tw/tags 行程: /zh-tw/schedule 關於: /zh-tw/about 好友: /zh-tw/friends You may notice that the same configuration overlaps on three config files. Here is the rule. When we go for certain language page, the setting of its config file will be adopted, and if the setting option is not found, the one in theme config file will automatically be adopted. So you could config your setting in a very flexible way. Config view part Now we start config view files. The rule is, except for the source code, how many languages you have, how many duplicates with different languages you will have. It makes sense, right? Otherwise would you dare post an article translated via machine? Now let’s config files under source directory _postsThe photo above is easy to understand, right? Simply speaking, those under _posts folder are the ones for default language. In this case, it should store articles of English version. And then we build a zh-tw folder for storing articles with Chinese version. The others:The file structure is like photo above, it’s unbearably easy, isn’t it? Change the position of language switchPersonally, when I enter a website, if it shows in some language I don’t know, I will look for the language switch (if there is). Per the current version of the theme Ray is using, the default position of the langauge switch menu is at the bottom of the screen, so I would like it to be somewhere more noticeable. In footer.ejs, find the code below: &lt;%- partial(&apos;common/languages&apos;) %&gt; Cut it and paste it in the bottom of the file called navbar.ejs within &lt;body&gt; tag If now you have the page refresh, you should see that the language switch has already been moved to the top of the screen, however, it turns out that the menu open upwards, and therefore we can’t choosee the language options. We will need to make some changes. In languages.ejs file under layout folder, find the following code and add style=&quot;top:100%&quot;. &lt;div class=\"dropdown-menu has-text-left\" role=\"menu\" style=\"top:100%\"&gt; ConclusionBy following the configuration above, I believe that you will make your multilingual-support-blog wish come true. You could go to my blog to check how it looks. If I’ve make some mistakes, feel free to point it out and let me know!You are free to share this article somewhere else, however, kindly append the origin, thanks!","link":"/buildABilingualBlog/"},{"title":"Cloud Functions:Qwik Start","text":"Refer to QWIKLABS","link":"/cloudFunctionsQwikStartConsole/"},{"title":"Cloud IAM:Qwik Start","text":"Refer to QWIKLABS","link":"/cloudIAMQwikStart/"},{"title":"Cloud Storage:QwikStart-CLI/SDK","text":"Refer to QWIKLABS","link":"/cloudStorageQwikStartCLISDK/"},{"title":"Cloud Storage:QwikStart-Console","text":"Refer to QWIKLABS","link":"/cloudStorageQwikStartConsole/"},{"title":"Create a persistent disk in GCP","text":"Refer to official link","link":"/createAPersistentDisk/"},{"title":"Create a virtual machine on GCP","text":"Refer to official link","link":"/createAVirtualMachineInGCP/"},{"title":"My learning journey in Docker","text":"IntroductionHello! It’s my learning note on Docker, and it’s still unorganised, so I’m sorry that there is not a English version yet.","link":"/docker/"},{"title":"Stackdriver-quick start","text":"Refer to QWIKLABS","link":"/Stackdriver/"},{"title":"Save and resize images in Laravel","text":"IntroductionThis article is my learning log of saving images and resize it afterwards with Laravel and its package Internention Install package InterventionPlease refer to the installing guide on its official GitHubcomposer require intervention/image Findconfig/app.php, and add Intervention\\Image\\ImageServiceProvider::class in array $providers, and add &apos;Image&apos; =&gt; Intervention\\Image\\Facades\\Image::class in array aliases Build the link between external folder and internal folder where we are going to save images in. Following the official website and build the link Type the follows In terminalphp artisan storage:link After the command, the project/storage/app/public and project/public/storage will be linked and so shared with each other When you save files, please save it to project/storage/app/public/(anySubdirectoryYouWant) If you want to produce externally accessible URL, use project/public/storage/(anySubdirectoryYouWant)/fileName, because from external, the default accessible folder is public, so please use asset(&#39;storage/(anySubdirectoryYouWant/fileName)&#39;) Validate if the image is brought// Because we don't need a lot of stuff, so we could only take what's in $request array.$parameters = request()-&gt;all();if (request()-&gt;hasFile('image'))&#123; // The file exists, so we save it to project/storage/app/public, and get the URL. In case, we will get 'public/fileName' $imageURL = request()-&gt;file('image')-&gt;store('public'); // However, we only want to insert pure file name into the database, so we remove the 'public' and only leave 'fileName' $parameters['image'] = substr($imageURL, 7);&#125; Re-organise the size of the image We are going to do resizing, so we will need the package intervention. Below namespace, adduse Intervention\\Image\\ImageManagerStatic as Image; // Get the instance of the item I just inserted$item = Item::update($parameters);// Set the driverImage::configure(array('driver' =&gt; 'gd'));// If we simply dd(storage_path), we will get 'project/store/', but it's not what we want.// So we append 'app/public/', that's the internal file address// Note that when resizing images, the target is in internal directory// Also, after resizing, we save it with the same name in the same place.Image::make(storage_path('app/public/' . $item-&gt;image))-&gt;resize(300, 300)-&gt;save(storage_path('app/public/' . $item-&gt;image)); Delete the image upon the user’s requestif ($request-&gt;imageDelete == true)&#123; Storage::delete($item-&gt;images); $item-&gt;update(['images' =&gt; null]);&#125; Produce publicly accessible URL// When returning publicly accessible URL, it will have to be external address.return asset(&apos;storage/&apos; . $parameters[&apos;image&apos;]);","link":"/UploadAndResizeImagesWithLaravel/"},{"title":"Fundamentals Of Stackdriver Logging","text":"Refer to QWIKLABS","link":"/fundamentalsOfStackdriverLogging/"},{"title":"Build a FTP Server on GCP VM with vsftpd","text":"IntroductionHere are what this tutorial will cover How to config vsftpd Build a specific user that the FTP user only allows for accessing. Config firewall-rules with gcloud shell Environment GCP VM ubuntu 18.04 Install vsftpdsudo apt install vsftpd Config Open config file sudo vim /etc/vsftpd.conf The configuration # Example config file /etc/vsftpd.conf## The default compiled in settings are fairly paranoid. This sample file# loosens things up a bit, to make the ftp daemon more usable.# Please see vsftpd.conf.5 for all compiled in defaults.## READ THIS: This example file is NOT an exhaustive list of vsftpd options.# Please read the vsftpd.conf.5 manual page to get a full idea of vsftpd's# capabilities.### Run standalone? vsftpd can run either from an inetd or as a standalone# daemon started from an initscript.listen=YES## This directive enables listening on IPv6 sockets. By default, listening# on the IPv6 \"any\" address (::) will accept connections from both IPv6# and IPv4 clients. It is not necessary to listen on *both* IPv4 and IPv6# sockets. If you want that (perhaps because you want to listen on specific# addresses) then you must run two copies of vsftpd with two configuration# files.listen_ipv6=NO## Allow anonymous FTP? (Disabled by default).anonymous_enable=NO## Uncomment this to allow local users to log in.local_enable=YES## Uncomment this to enable any form of FTP write command.write_enable=YES## Default umask for local users is 077. You may wish to change this to 022,# if your users expect that (022 is used by most other ftpd's)local_umask=002## Uncomment this to allow the anonymous FTP user to upload files. This only# has an effect if the above global write enable is activated. Also, you will# obviously need to create a directory writable by the FTP user.#anon_upload_enable=YES## Uncomment this if you want the anonymous FTP user to be able to create# new directories.#anon_mkdir_write_enable=YES## Activate directory messages - messages given to remote users when they# go into a certain directory.dirmessage_enable=YES## If enabled, vsftpd will display directory listings with the time# in your local time zone. The default is to display GMT. The# times returned by the MDTM FTP command are also affected by this# option.use_localtime=YES## Activate logging of uploads/downloads.xferlog_enable=YES## Make sure PORT transfer connections originate from port 20 (ftp-data).connect_from_port_20=NO##Set to NO if you want to disallow the PASV method of obtaining a data connection.#Default: YESpasv_enable=YES# If you want, you can arrange for uploaded anonymous files to be owned by# a different user. Note! Using \"root\" for uploaded files is not# recommended!#chown_uploads=YES#chown_username=whoever## You may override where the log file goes if you like. The default is shown# below.xferlog_file=/var/log/vsftpd.log## If you want, you can have your log file in standard ftpd xferlog format.# Note that the default log file location is /var/log/xferlog in this case.xferlog_std_format=YES## You may change the default value for timing out an idle session.#idle_session_timeout=600## You may change the default value for timing out a data connection.#data_connection_timeout=120## It is recommended that you define on your system a unique user which the# ftp server can use as a totally isolated and unprivileged user.#nopriv_user=ftpsecure## Enable this and the server will recognise asynchronous ABOR requests. Not# recommended for security (the code is non-trivial). Not enabling it,# however, may confuse older FTP clients.#async_abor_enable=YES## By default the server will pretend to allow ASCII mode but in fact ignore# the request. Turn on the below options to have the server actually do ASCII# mangling on files when in ASCII mode.# Beware that on some FTP servers, ASCII support allows a denial of service# attack (DoS) via the command \"SIZE /big/file\" in ASCII mode. vsftpd# predicted this attack and has always been safe, reporting the size of the# raw file.# ASCII mangling is a horrible feature of the protocol.#ascii_upload_enable=YES#ascii_download_enable=YES## You may fully customise the login banner string:ftpd_banner=\"Welcome to QCDN's FTP server, feel free to upload whatever you would like to deploy on Website.\"## You may specify a file of disallowed anonymous e-mail addresses. Apparently# useful for combatting certain DoS attacks.#deny_email_enable=YES# (default follows)#banned_email_file=/etc/vsftpd.banned_emails## You may restrict local users to their home directories. See the FAQ for# the possible risks in this before using chroot_local_user or# chroot_list_enable below.#chroot_local_user=YES## You may specify an explicit list of local users to chroot() to their home# directory. If chroot_local_user is YES, then this list becomes a list of# users to NOT chroot().# (Warning! chroot'ing can be very dangerous. If using chroot, make sure that# the user does not have write access to the top level directory within the# chroot)chroot_local_user=YESchroot_list_enable=YES# (default follows)chroot_list_file=/etc/vsftpd.chroot_list## You may activate the \"-R\" option to the builtin ls. This is disabled by# default to avoid remote users being able to cause excessive I/O on large# sites. However, some broken FTP clients such as \"ncftp\" and \"mirror\" assume# the presence of the \"-R\" option, so there is a strong case for enabling it.#ls_recurse_enable=YES## Customization## Some of vsftpd's settings don't fit the filesystem layout by# default.## This option should be the name of a directory which is empty. Also, the# directory should not be writable by the ftp user. This directory is used# as a secure chroot() jail at times vsftpd does not require filesystem# access.secure_chroot_dir=/var/run/vsftpd/empty## This string is the name of the PAM service vsftpd will use.pam_service_name=vsftpd## This option specifies the location of the RSA certificate to use for SSL# encrypted connections.rsa_cert_file=/etc/ssl/certs/ssl-cert-snakeoil.pemrsa_private_key_file=/etc/ssl/private/ssl-cert-snakeoil.keyssl_enable=NO# Uncomment this to indicate that vsftpd use a utf8 filesystem.#utf8_filesystem=YES##This option is useful is conjunction with virtual users. It is used to automatically generate a home directory for each virtual user, based#on a template. For example, if the home directory of the real user specified via guest_username is /home/virtual/$USER, and user_sub_token is#set to $USER, then when virtual user fred logs in, he will end up (usually chroot()'ed) in the directory /home/virtual/fred. This option#also takes affect if local_root contains #Default: (none)user_sub_token=$USER#This option represents a directory which vsftpd will try to change into after a local (i.e. non-anonymous) login. Failure is silently#ignored.#Default: (none)local_root=/home/$USER/ftp#If vsftpd is in standalone mode, this is the port it will listen on for incoming FTP #Default: 21listen_port=21212#The minimum port to allocate for PASV style data connections. Can be used to specify a narrow port range to assist firewalling.#Default: 0 (use any port)pasv_min_port=40000#The maximum port to allocate for PASV style data connections. Can be used to specify a narrow port range to assist firewalling.#Default: 0 (use any port)pasv_max_port=50000#If enabled, vsftpd will load a list of usernames, from the filename given by userlist_file. If a user tries to log in using a name in this#file, they will be denied before they are asked for a password. This may be useful in preventing cleartext passwords being transmitted. See#also userlist_deny.#Default: NOuserlist_enable=YES#This option is the name of the file loaded when the userlist_enable option is active.#Default: /etc/vsftpd.user_listuserlist_file=/etc/vsftpd.userlist#This option is examined if userlist_enable is activated. If you set this setting to NO, then users will be denied login unless they are#explicitly listed in the file specified by userlist_file. When login is denied, the denial is issued before the user is asked for a pass‐#word.#Default: YESuserlist_deny=NO#The maximum data transfer rate permitted, in bytes per second, for local authenticated users.#Default: 0 (unlimited)local_max_rate=10000000#Allow chroot have write permissionallow_writeable_chroot=YES#If vsftpd is in standalone mode, this is the maximum number of clients which may be connected. Any additional clients connecting will get an#error message.#Default: 0 (unlimited)max_clients=50#If vsftpd is in standalone mode, this is the maximum number of clients which may be connected from the same source internet address. A client#will get an error message if they go over this limit.#Default: 0 (unlimited)max_per_ip=5#If enabled, and vsftpd was compiled with tcp_wrappers support, incoming connections will be fed through tcp_wrappers access control. Further‐#more, there is a mechanism for per-IP based configuration. If tcp_wrappers sets the VSFTPD_LOAD_CONF environment variable, then the vsftpd#session will try and load the vsftpd configuration file specified in this variable.#Default: NOtcp_wrappers=YES#If enabled, two log files are generated in parallel, going by default to /var/log/xferlog and /var/log/vsftpd.log. The former is a wu-ftpd#style transfer log, parseable by standard tools. The latter is vsftpd's own style log.#Default: NOdual_log_enable=YES#This option is the name of the file to which we write the vsftpd style log file. This log is only written if the option xferlog_enable is#set, and xferlog_std_format is NOT set. Alternatively, it is written if you have set the option dual_log_enable. One further complication -#if you have set syslog_enable, then this file is not written and output is sent to the system log instead.#Default: /var/log/vsftpd.logvsftpd_log_file=/var/log/vsftpd.log Create a usersudo adduser test And then enter the password, in this tutorial, 1234 Create relative config filesudo touch /etc/vsftpd.chroot_list &amp;&amp; sudo mkdir /home/test/ftp &amp;&amp; sudo touch /etc/vsftpd.userlist &amp;&amp; sudo touch /var/log/vsftpd.log Authority I built this FTP server for my Frontend coworker and so they could upload the file as deployment, and that’s why I would put www-data in the mutual group. You could skip this part as it doesn’t has much to do with FTP set up. Build a mutual groupThe ftp folder is supposed to be accessed by only www-data, and user test sudo groupadd ftp_access Add user test and www-data into this group sudo usermod -a -G ftp_access test &amp;&amp; sudo usermod -a -G ftp_access www-data Set up authority sudo find /home/test/ftp -type d -exec chmod 2770 &#123;&#125; \\; &amp;&amp; sudo find /home/test/ftp -type f -exec chmod 0664 &#123;&#125; \\; &amp;&amp; sudo chmod /home/test/ftp test:ftp_access Specify user with accessecho 'test' &gt; /etc/vsftpd.userlist GCP firewall-rules configurationAdd tag to VM Personally, I prefer gcloud shell to manage the instances, there are two ways to get started Install SDK via official Or you could use gcloud shell web version provided by Google, 快速教學 在此 If you are not familiar with gcloud, you could also config firewall-rules via website UI interface I will skip instance creating and login because they are not covered in this tutorial Add tags to VMgcloud compute instances add-tags instanceName \\--tags test Config firewall-rules Create new firewall-rules per tag, so the firewall-rule will not be effective to all VMs Create communication port gcloud compute firewall-rules create ftp-communication --allow tcp:21212 --target-tags test Create rules for passive port range gcloud compute firewall-rules create ftp-dataportrange --allow tcp:40000-50000 --target-tags test FTP connectionInstall mac brew install inetutils ubuntuIt should be already accessible Connectionftp -p yourIP 21212 Key in user: test Key in password: 1234 Try to upload a fileput whateverFile ConclusionI enjoy in the quest for technology. However, sometimes I want to kill myself when I get stuckI mentioned www-data and did some config on it because actually why I built this FTP server was for simple deployment on Frontend. I would config my NginX to point to this folder as kind of reverse proxy.However, I think it should not be covered in this tutorial, so I would skip the NginX part Reference The Linux guru in Asiahttp://linux.vbird.org/linux_server/0410vsftpd.php The guru from Digital Ocean communityhttps://www.digitalocean.com/community/questions/proper-permissions-for-web-server-s-directory","link":"/ftpServer/"},{"title":"A flexible git flow","text":"IntroductionToday I’m going to share a git flow with the following qualities: In development, you could make arbitrary commits. After testing, you could turn the arbitrary commits which are more friendly in development into commits compliant with production standard. The content of two branches are exactly the same, however, with totally different commit history. In Ray’s case, when developing, I am used to write down the process, and list every possible logic that I think is feasible, and then try it. Normally a big function may consist of many small logic, and this git flow enables me to make all of them many individual commits in a feature branch. And finally after they are tested and there is no problem there, they could be turned into the commit with production standard as a big function.In the process of implementing this git flow, I am more and more familiar with git rebase and some other advanced features of Git, and train myself to make each commit in a more strict style.Here are some advantages that Ray personally think this git flow could provide: Because every commit is small with single logic, it features unspeakable convenience no matter in experiment or debug stage. Record your logic in this small-commit way helps clean your mind, on the other hand, makes the logic of each function explicit. Though the process looks a bit complicated, actually it only takes a little to organise branches once you are familiar with Git, and you could be more familiar with the advanced operation of Git Because of the small commit, you could train yourself to make commits in a more strict way. An ideal commitThe git flow I am going to demonstrate today is just an example, and it doesn’t suit everyone. However, the point is the concept it takes to achieve this operation. When we do commit locally, we hope that the commit can be as small as possible, because the smaller, the more specific and more precise function orientated the commit is, the more helpful and useful it will be when it comes to debug or experiment and validation of your logic. For instance?Let’s make it more specific! Let’s say that you were debugging, and you found that the thing you printed out was different from your expectation, so you were trying different ways to get the result you wanted. If your commit is compliant with the above mentioned principles, in this case, you will not need anoying and troublesome revising after each failed try. All that takes is a simplegit reset --hard Even though the whoEven though the whole logic of a commit is wrong. If the function of this commit is specific enough, all you need is a simplegit reset @^ --hard What exactly we want?However, the git flow of production doesn’t allow us to do so. Each pushed commit in production git flow is required to run properly and towards designated function. That said, possibly, a designated function of production git flow would consist of many so called small commit we just mentioned. What we need in a list In development: We need the absolute flexibility, able to make a commit as functional specific as possible. In production: We need to make each commit compliant with the requirement of company, running errorlessly on designated function Which one could we have?They say, you can’t have a cake and eat it, is that true?Could we have both? List the physical needLet’s list and conclude more specifically what we need We need a develop branch for local development where we could make a commit whenever we feel comfortable We need a master branch for production. In this branch, each commit represents a designated function by the company. The content of above mentioned two branches should be exactly the same (Optional)We would like to keep the respective history of both branches What it actually look like?develop branch:As the photo below. What’s on the left side is the content, while on the right is commit. Take a look and then you could find that each file represents a single commit named small function. It’s just an example, denoting a concept of smallest commit that I’m trying to convey master branch:Now let’s take a look on master branch. You could see that through the photo below, we only have 4 commits, and each of them contains 4 files(except for .gitignore commit). It’s just an example, denoting that the actual commit compliant with production standard is always bigger than the ideal commit. Example Hand-on practiceThe very beginning.gitignore is always the very beginning of everything. Create .gitignore file with vim, and then key in those files we would like to ignore, and then type :wq and leave. vim .gitignore Complete the first commit git add .ignore; git commit -m 'Added .gitignore'; develop branchNow, we will make a develop branch based on master branch. As mentioned above, the commits are going to be the most function orientated and smallest in develop branch, while the ones in master branch are going to be compliant with production standard. Firstly, let’s build develop branch based on master branch which has completed .gitignore setting. git checkout -b develop feature branchAnd then, we could start developing Make a feature branch This feature branch represents the currently developing function The function mentioned here is not the function we define on our own, instead, is required by company compliant with production standard. So, a function with production standard is equal to a feature branchgit checkout -b feature; Commit freely On feature branch , we could make commits arbitrarily as long as you feel comfortable. Create file 1~4, and then each of them represents a smallest commit.touch &#123;1..4&#125;;git add 1;git commit 1 -m 'small function 1';git add 2;git commit 2 -m 'small function 2';git add 3;git commit 3 -m 'small function 3';git add 4;git commit 4 -m 'small function 4'; The function is completed! After testing, we are pretty sure that everything is okay, so we are going to turn our arbirarily made commit into production standard commit. as mentioned previouly, the coverage of a feature branch is a required function of production standard. So? We are going to turn an entire branch into a single commit for production standard. Since we are going to keep both branches with respective histories, we can’t directly do this on feature branch. Because develop branch is going to need it later. Actually in this git flow, it’s not neccesary to keep develop branch. However, in this article, I will demonstrate it in the condition that the develop branch will be kept. If you don’t want to keep it, it will be mush simpler. A branch for being merged Let’s build a disposable branch called toBeMerged production standard master branch. git checkout -b toBeMerged Now, let’s make toBeMerged branch ready to be merged by master branch. git rebase -i master Compress, rename commit I mentioned I was going to compress several small commits into a commit with production standard, right? So now I’m going to squash all of the small commits. We could use fixup option. Moreover, the commit name with production standard is defintely different from the commit we make during development, so we are going to rename this compressed commit as follows: reword 96c6c18 small function 1fixup 1dd84d2 small function 2fixup 1a71401 small function 3fixup f9c90c6 small function 4 I’m going to name this compressed commit as big function 1 Then, type :wq and leave Now, we use git log to check it, it should look like as follows:git log merge Let’s checkout master and merge this branch! git checkout master;git merge toBeMerged; And then, let’s checkout develop branch and merge feature branch git checkout develop;git merge feature; Finally, let’s delete merged feature branch and toBeMerged branch. git branch -D feature toBeMerged Let’s review it. Remember what we want? On develop branch, the commits are smallest. On master branch, the commits are compliant with production standard. The content on both two branches should be the same. (optional)Keep both branches Check if the master branch looks like the one we want. git checkout master;git log Check the contentls Check commits on develop branch git checkout develop;git tag 'bigFunction1'git log Check the content ls The second phrase The same as before, feature branch first, and then toBeMerged branch git checkout develop;git checkout -b feature;touch &#123;5..8&#125;;git add 5;git commit -m 'small function 5';git add 6;git commit -m 'small function 6';git add 7;git commit -m 'small function 7';git add 8;git commit -m 'small function 8';git checkout -b toBeMerged; Pay attention! in this case, we can’t turn toBeMerged branch into a right one for master branch with traditional rebase because they don’t have a mutual history. Let’s think about it for a moment, what the toBeMerged branch should look like to match what we need for being merged by master branch? They need mutual history (Identical sha1 checksum) Those previously merged uncompressed commits that already exist in develop branch shouldn’t appear in toBeMerged branch. Simply speaking, small function 1~4 were already compressed as big function 1, so small function 1~4 should appear again Those newly added commit should be compressed into a single commit After all above listed are done, you are ready to go The second rebasing and compressing. So what are the steps? We will use git rebase, git rebase --onto. We are going to rebase toBeMerged branch onto master, and omit whatever on develop, and then the one should be rebased is toBeMerged. Follow this order, we get the command as follows. You could refer to official document for more detail about git rebase --onto git rebase -i --onto master develop toBeMerged The same as previous action, we compress the samll commits into the one compliant with production standard. reword 3668e72 small function 5fixup fd05fa1 small function 6fixup 3a87c08 small function 7fixup c38957e small function 8 The name of compressed commit is big function 2 Repeat mentioned steps, merge them first and delete them. Let’s check the commit on develop branch, and the content git checkout develop;git tag bigFunction2;git log --oneline The commit on master ls The content on master Let’s check the commit on master, and its content git checkout master;git log commit on develop branch ls content on develop branch ConclusionThe git flow in this article enables us to make commit as small as possible in development, even in the way we personally like, and no need to sacrifice for production standard.The develop branch in this article is not necessary to be kept, because if there is some error in the commit with production standard, you will still need to fix it on the one with production standard. However, if you keep it, I reckon that there might be some further usage there. Well, I will leave it for your own explorations.If you have any comments, feel free to drop me a message. I believe that communication and idea sharing is the shortcut of improving ourselves.","link":"/flexibleGitFlow/"},{"title":"Easy Payment Gateway with PayPal REST API","text":"IntroductionIn this article, we are going to share how to do the follows with PayPal REST API Create authorization order Authorization Capture Refund Place funds on hold Since it’s a learning technical diary, it will contain my personal project. You could selectively refer to this article. Install PayPal REST API official SDKIn this article, we use the latest released version of the official SDK Installcomposer require paypal/paypal-checkout-sdk SettingPersonal setting After installation, you could find the example under SDK directory as photo below: Configure PayPal Client.php as follows: Apply for a developer account and login Create an App Get your Client ID and Secret Fill in with the got Client ID and Secret, Ray set them as environment variables. public static function environment()&#123; $clientId = env('PAYPAL_SANDBOX_API_ClientID'); $clientSecret = env('PAYPAL_SANDBOX_API_SECRET'); return new SandboxEnvironment($clientId, $clientSecret);&#125; Let’s beginAs mentioned previously, we could find almost all of the examples for every situation in the official sample directory. You could customize it according to your need. The following will be Ray’s version.If you have any questions, feel free to refer to the samples under sample directory, and the official document as follows:orderpayment The difference between order and paymentHere are some main differences: order： It only supports members of PayPal. You could delay your payment, and partially capture the payment upon what you need. payment: You could delay the payment, but you can’t partially capture it. For more information, you could refer to the official document Create an orderpublic function createOrder($toBeSavedInfo, Recipient $recipient, $debug = false)&#123; // Use SDK $request = new OrdersCreateRequest(); $request-&gt;headers[\"prefer\"] = \"return=representation\"; // We will show this part later. $request-&gt;body = self::buildRequestBody($toBeSavedInfo, $recipient); // We use the PayPalClient we just set up $client = PayPalClient::client(); $response = $client-&gt;execute($request); if ($debug) &#123; print \"Status Code: &#123;$response-&gt;statusCode&#125;\\n\"; print \"Status: &#123;$response-&gt;result-&gt;status&#125;\\n\"; print \"Order ID: &#123;$response-&gt;result-&gt;id&#125;\\n\"; print \"Intent: &#123;$response-&gt;result-&gt;intent&#125;\\n\"; print \"Links:\\n\"; foreach ($response-&gt;result-&gt;links as $link) &#123; print \"\\t&#123;$link-&gt;rel&#125;: &#123;$link-&gt;href&#125;\\tCall Type: &#123;$link-&gt;method&#125;\\n\"; &#125; // To toggle printing the whole response body comment/uncomment below line echo json_encode($response-&gt;result, JSON_PRETTY_PRINT), \"\\n\"; &#125; // After the order is created, I only take the approve link. In default, PayPal provides several links for difference usage. However, we could achieve others except for approve with REST API. foreach (($response-&gt;result-&gt;links) as $link) &#123; if ($link-&gt;rel === 'approve') &#123; $linkForApproval = $link-&gt;href; break; &#125; &#125; // We get some information which we are going to use later, and return. $toBeSavedInfo['payment_id'] = $response-&gt;result-&gt;id; $toBeSavedInfo['statusCode'] = $response-&gt;statusCode; $toBeSavedInfo['custom_id'] = $response-&gt;result-&gt;purchase_units[0]-&gt;custom_id; $toBeSavedInfo['PayPal_total_amount'] = $response-&gt;result-&gt;purchase_units[0]-&gt;amount-&gt;value; $toBeSavedInfo['orderStatus'] = $response-&gt;result-&gt;status; $toBeSavedInfo['linkForApproval'] = $linkForApproval; return $toBeSavedInfo;&#125; Please refer to the RequestBody for creating an order as follows:public static function buildRequestBody($toBeSavedInfo, Recipient $recipient)&#123; // The setting here allows us to see items in detail in PayPal payment page $item = []; $i = 1; foreach ($toBeSavedInfo['orders'] as $order) &#123; $item[] = [ 'name' =&gt; $order-&gt;item_name, 'description' =&gt; $order-&gt;item_description, 'sku' =&gt; $i, 'unit_amount' =&gt; [ 'currency_code' =&gt; $toBeSavedInfo['mc_currency'], 'value' =&gt; $order-&gt;unit_price, ], 'quantity' =&gt; $order-&gt;quantity, ]; $i ++; &#125; // Here we specify the intent, which I had set as a environment variable return [ 'intent' =&gt; env('PAYPAL_SANDBOX_INTENT_OF_CREATED_ORDERS'), 'application_context' =&gt; [ 'return_url' =&gt; env('PAYPAL_SANDBOX_RETURN_URL'), 'cancel_url' =&gt; env('PAYPAL_SANDBOX_CANCEL_URL'), 'brand_name' =&gt; env('APP_NAME'), 'locale' =&gt; env('PAYPAL_SANDBOX_LOCALE'), 'landing_page' =&gt; env('PAYPAL_SANDBOX_LANDING_PAGE'), 'shipping_preferences' =&gt; env('PAYPAL_SANDBOX_SHIPPING_PREFERENCES'), 'user_action' =&gt; env('PAYPAL_SANDBOX_USER_ACTION'), ], // Here we could set purchase_unit. We could set tax, shipping fee, etc... under purchase_unit. We will skip those here. 'purchase_units' =&gt; [ [ 'custom_id' =&gt; $toBeSavedInfo['merchant_trade_no'], 'amount' =&gt; [ 'currency_code' =&gt; $toBeSavedInfo['mc_currency'], 'value' =&gt; $toBeSavedInfo['total_amount'], 'breakdown' =&gt; [ 'item_total' =&gt; [ 'currency_code' =&gt; $toBeSavedInfo['mc_currency'], 'value' =&gt; $toBeSavedInfo['total_amount'], ], ], ], 'items' =&gt; $item, // We could specify the recipient here. 'shipping' =&gt; array( 'name' =&gt; array( 'full_name' =&gt; $recipient-&gt;name, ), 'address' =&gt; array( 'address_line_1' =&gt; $recipient-&gt;others, 'admin_area_2' =&gt; $recipient-&gt;district, 'admin_area_1' =&gt; $recipient-&gt;city, 'postal_code' =&gt; $recipient-&gt;postcode, 'country_code' =&gt; $recipient-&gt;country_code, ), ), ], ], ];&#125; AuthorizationNow, we are going to use one of the important functions in REST API, authorization. After authorization, we will be able to capture the authorized amount within 29 days. However, PayPal only guarantees that the authorized amount will be available for three days right after a single authorization. It means that PayPal will temporarily place authorized funds on hold within buyer’s account for only three days after authorization. Please note that it’s only for three days, and it’s called Honor Period. After the first authorization, we will be able to apply for multiple authorization up to 10 times, which is called reauthorizeIf you think the number is too less, you could contact PayPal, and raise the number to up to 99 times. Actually if you count the time properly and precisely, 10-time authorization should be enough. If you authorize once every three days, you could place funds on hold for a month with 10-time authorization, which is even enough for sea fright. You will be allowed to change the order amount for up to 115% or not more than USD 75. You could use this feature when there are some required changes on tax or shipping fee. You could refer to official document Here is the authorization example as follows.Please note that it’s Ray’s version. You could refer to official version and then modify it according to your need, or make one on our own with a reference on its SDK, which I think might be the best solution. /** * This function can be used to perform authorization on the approved order. * Valid Approved order id should be passed as an argument. */ // Here we could revise the authorized amount upon your need.public static function authorizeOrder($orderId, $amount = null, $debug = false)&#123; $request = new OrdersAuthorizeRequest($orderId); // RequestBody as mentioned above. You could refer to the official example. $request-&gt;body = self::buildRequestBodyForAuthorizeOrder($amount); $client = PayPalClient::client(); $response = $client-&gt;execute($request); if ($debug) &#123; print \"Status Code: &#123;$response-&gt;statusCode&#125;\\n\"; print \"Status: &#123;$response-&gt;result-&gt;status&#125;\\n\"; print \"Order ID: &#123;$response-&gt;result-&gt;id&#125;\\n\"; print \"Authorization ID: &#123;$response-&gt;result-&gt;purchase_units[0]-&gt;payments-&gt;authorizations[0]-&gt;id&#125;\\n\"; print \"Links:\\n\"; foreach ($response-&gt;result-&gt;links as $link) &#123; print \"\\t&#123;$link-&gt;rel&#125;: &#123;$link-&gt;href&#125;\\tCall Type: &#123;$link-&gt;method&#125;\\n\"; &#125; print \"Authorization Links:\\n\"; foreach ($response-&gt;result-&gt;purchase_units[0]-&gt;payments-&gt;authorizations[0]-&gt;links as $link) &#123; print \"\\t&#123;$link-&gt;rel&#125;: &#123;$link-&gt;href&#125;\\tCall Type: &#123;$link-&gt;method&#125;\\n\"; &#125; // To toggle printing the whole response body comment/uncomment below line echo json_encode($response-&gt;result, JSON_PRETTY_PRINT), \"\\n\"; &#125; return $response;&#125; After authorization, we need to check if the authorization is successful, and therefore Ray made a validation function with the response got from the SDKpublic static function checkIfAuthorizedSuccessfully($response)&#123; $newPayPal = (new NewPayPal())-&gt;where('payment_id', request()-&gt;token)-&gt;first(); // Check if the authorization is completed if (($response-&gt;result-&gt;status) !== 'COMPLETED') return 'Authorization isn\\'t completed'; // Check if the authorization has started. if (($response-&gt;result-&gt;purchase_units[0]-&gt;payments-&gt;authorizations[0]-&gt;status) !== 'CREATED') return 'Authorization was not created'; // Check if the currency is matched if (($response-&gt;result-&gt;purchase_units[0]-&gt;payments-&gt;authorizations[0]-&gt;amount-&gt;currency_code) !== ($newPayPal-&gt;mc_currency)) return 'The currency is mismatched'; // Check if authorized amount is correct. Here is my own version, and you could revise the amount if you need. if (intval($response-&gt;result-&gt;purchase_units[0]-&gt;payments-&gt;authorizations[0]-&gt;amount-&gt;value) !== ($newPayPal-&gt;total_amount)) return 'The total amount is not correct';&#125; Capture Just like mentioned above, we will be allowed to capture the order after a successful authorization. However, PayPal only guarantees the authorized amount will be available for three days, which is also called honor period. Generally speaking, a proper and precise time counting with authorization and reauthorizing will be able to temporarily place funds on hold for 30 days. Here is the capture examplepublic static function captureAuthorization(NewPayPal $newPayPal, $final_capture = false, $debug = false)&#123; $NewPayPal = (new NewPayPal)-&gt;where('merchant_trade_no', $newPayPal-&gt;merchant_trade_no)-&gt;first(); // Capture function requires an authorization id $request = new AuthorizationsCaptureRequest($newPayPal-&gt;authorization_id); // Here we need to fill in to-be-captured amount. As mentioned above, amount capture could be partial. If final_capture is set to true, this authorization will end, and reauthorizing will be required for any further capture. $request-&gt;body = self::buildRequestBodyForCaptureAuthorization($NewPayPal-&gt;to_be_captured_amount, $final_capture, $newPayPal-&gt;mc_currency); $client = PayPalClient::client(); $response = $client-&gt;execute($request); if ($debug) &#123; print \"Status Code: &#123;$response-&gt;statusCode&#125;\\n\"; print \"Status: &#123;$response-&gt;result-&gt;status&#125;\\n\"; print \"Capture ID: &#123;$response-&gt;result-&gt;id&#125;\\n\"; print \"Links:\\n\"; foreach ($response-&gt;result-&gt;links as $link) &#123; print \"\\t&#123;$link-&gt;rel&#125;: &#123;$link-&gt;href&#125;\\tCall Type: &#123;$link-&gt;method&#125;\\n\"; &#125; // To toggle printing the whole response body comment/uncomment below line echo json_encode($response-&gt;result, JSON_PRETTY_PRINT), \"\\n\"; &#125; return $response;&#125; Here is RequestBody for capture.public static function buildRequestBodyForCaptureAuthorization($amount = null, $final_capture = false, $currency = 'USD')&#123; if ($amount != null) &#123; // We specify the amount and currency of capture, which need to match the ones for authorization. return [ \"amount\" =&gt; [ 'currency_code' =&gt; $currency, 'value' =&gt; $amount, ], 'final_capture' =&gt; $final_capture ]; &#125; return \"&#123;&#125;\";&#125; Here is the logic of capture as follows:Ray’s logic is to set a to-be-captured amount to decide when the amount will be captured, which could save handing fee because each time a refund request will cost some handing fee. So Ray’s logic is to place funds on hold, and only revise to-be-captured amount when a refund request is made before to-be-captured date. Therefore, we could at the most extend save the handing fee on the seller side. The allowable refund period is 7 days in Ray’s logic, and capture the authorization with the final to-be-captured amount.So the following function only runs once a day. If the current time is beyond the to-be-captured date, the authorization will be captured and update order state accordingly.public static function dailyCaptureAuthorization()&#123; $toBeCapturedPayments = NewPayPal::whereNotNull(&apos;authorization_id&apos;)-&gt;whereNull(&apos;capture_id&apos;)-&gt;where(&apos;to_be_captured_date&apos;, &apos;&lt;&apos;, Carbon::now()-&gt;toDateTimeString())-&gt;get(); foreach ($toBeCapturedPayments as $toBeCapturedPayment) &#123; $response = NewPayPal::captureAuthorization($toBeCapturedPayment); if (($response-&gt;result-&gt;status) === &apos;COMPLETED&apos;) &#123; $toBeCapturedPayment-&gt;update([&apos;capture_id&apos; =&gt; $response-&gt;result-&gt;id, &apos;status&apos; =&gt; 7]); foreach ($toBeCapturedPayment-&gt;orderRelations as $orderRelation) &#123; if (($orderRelation-&gt;status == 5) || ($orderRelation-&gt;status == 6)) &#123; $orderRelation-&gt;order-&gt;update([&apos;status&apos; =&gt; 7]); $orderRelation-&gt;update([&apos;status&apos; =&gt; 7]); &#125; &#125; &#125; &#125;&#125; Refund The rule of refund is to refund an amount of money partially or one-time towards specific authorization. If you specify an amount, you refund the order partially. If you would like to fund it at a time, you could leave a empty RequestBody as the official example.public static function refundOrder($captureId, $amount, $currency, $debug = false)&#123; $request = new CapturesRefundRequest($captureId); // The required to-be-refunded amount and currency should match the ones of the authorization. $request-&gt;body = self::buildRequestBodyForRefundOrder($amount, $currency); $client = PayPalClient::client(); $response = $client-&gt;execute($request); if ($debug) &#123; print \"Status Code: &#123;$response-&gt;statusCode&#125;\\n\"; print \"Status: &#123;$response-&gt;result-&gt;status&#125;\\n\"; print \"Order ID: &#123;$response-&gt;result-&gt;id&#125;\\n\"; print \"Links:\\n\"; foreach ($response-&gt;result-&gt;links as $link) &#123; print \"\\t&#123;$link-&gt;rel&#125;: &#123;$link-&gt;href&#125;\\tCall Type: &#123;$link-&gt;method&#125;\\n\"; &#125; // To toggle printing the whole response body comment/uncomment below line echo json_encode($response-&gt;result, JSON_PRETTY_PRINT), \"\\n\"; &#125; return $response;&#125; The following is the RequestBody for refund.public static function buildRequestBodyForRefundOrder($amount = null, $currency = 'USD', $final_capture = false)&#123; // If the amount is specified, it will be a specified amount. If not, it will be default setting. if ($amount != null) &#123; return [ \"amount\" =&gt; [ 'currency_code' =&gt; $currency, 'value' =&gt; $amount, ], 'final_capture' =&gt; $final_capture ]; &#125; return \"&#123;&#125;\";&#125; The logic for refund. Corresponding to the capture action, before the seller make any capture to buyers, all those refund requests from buyers are only to revise numbers in the database. If 7 days have passed, but in a particular case, a refund request still raised by a buyer, the amount could still be refunded with inevitable handing fee. All logic mentioned above is only for PayPal. Since this project integrate with two payment gateway, the above mentioned logic doens’t suit AllPay. However, generally speaking, it makes no difference to buyers.public static function refund(Order $order, NewPayPal $paymentServiceInstance, OrderRelations $orderRelation)&#123; // When the order is authorized but not yet captured. if (($paymentServiceInstance-&gt;capture_id === null) &amp;&amp; ($paymentServiceInstance-&gt;authorization_id !== null)) &#123; // As mentioned above, we only revise to-be-captured amount in the database. $paymentServiceInstance-&gt;update([ &apos;to_be_captured_amount&apos; =&gt; $paymentServiceInstance-&gt;to_be_captured_amount - $order-&gt;total_amount, &apos;total_amount&apos; =&gt; $paymentServiceInstance-&gt;total_amount - $order-&gt;total_amount ]); $order-&gt;update([&apos;status&apos; =&gt; 4]); $orderRelation-&gt;update([&apos;status&apos; =&gt; 4]); &#125; // When the order has been captured if ($paymentServiceInstance-&gt;capture_id !== null) &#123; // We do implement refund API, returning the amount to buyers. $response = self::refundOrder($paymentServiceInstance-&gt;capture_id, $order-&gt;total_amount, $paymentServiceInstance-&gt;mc_currency); // If the refund is completed, the order state will be updated. if ($response-&gt;result-&gt;status == &apos;COMPLETED&apos;) &#123; $order-&gt;update([&apos;status&apos; =&gt; 4]); $orderRelation-&gt;update([&apos;status&apos; =&gt; 4]); $paymentServiceInstance-&gt;update([ &apos;total_amount&apos; =&gt; $paymentServiceInstance-&gt;total_amount - $order-&gt;total_amount ]); &#125; &#125;&#125; Cancel an authorization.Cancelling an authorization is pretty easy with official example. You only have to provide authorization ID with required format, we are not going to explain explicitly.The authorization ID will be returned after a successful authorization, so remember to save it. Get authorization data.Getting an authorization is pretty easy with official example. You only have to provide authorization ID with required format, we are not going to explain explicitly.The authorization ID will be returned after a successful authorization, so remember to save it. Getting capture dataGetting a capture data is pretty easy with official example. You only have to provide authorization ID with required format, we are not going to explain explicitly.The capture ID will be returned after a successful authorization, so remember to save it. ConclusionAccording to the official document, you could use Smart Button of JavaScript SDK with PayPal REST APIO. However, Ray is responsible for backend, so this part wasn’t deeply dug.It looks interesting. If you are interested, you could spend some time on it.PayPal is veritably an international payment gateway. It provides various features and supports. What a pity that PayPal has taken back its service from Taiwan. However, as far as I know, it happened due to tax safeguarding in Taiwan. It’s hard to judge good or bad.I’ve spent some time those days digging in PayPal gateway. Surely there are still some dedicate features that I haven’t tried. I will write another article for that after I give it a shot! You are free to share this article wherever you want, but kindly cite the source. Thanks!","link":"/PayPalRestAPI/"},{"title":"Git-  Where to start?","text":"Hello everyone! It’s Ray. As mentioned in my the article I posted last time, Git is kind of an integral tool to coders.Today I’m going to share the basics of Git. At the first, let’s create an example folder, it could be my-git-repository. Le’t go to command line cd the idea patch you like for this folder let’s typemkdir my-git-repository Now typecd code/my-git-repository to get into the folder in command line. Code is the name of my own folder, which is different from yours. Please type your own. Now we are in the folder as follows:￼ Let’s make a file heretouch example1.html And then we add the content below in the file:&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;First example&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;This is the first example&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; Now typegit init ￼ And then let’s type and take a look git status ￼ As image shown above, now we could start to use git’s feature.Currently the example1 is still untracked. Remember that before we make any commit, sounds like that we have to follow those celebrities before receiving what’s new of them. Let’s add the file and start to track itgit add example1.html As image below:￼ Okay. After tracking, now we are going to make our first commit.Entergit commit as image below:￼ Supposedly, the new window would pop up as image below:￼ Now we enter the message for this commit for further better recognising. Finally enter:wq it means save and exit this window Now let’s typegit status , and it should look like image above. Entergit log , and you could see a series of number which represents the identify number of this commit.￼ Please note that the number varies out of the content of commit, so each commit is unique. If your commit number is different from mine, rest-assured that that’s pretty normal. Now we’ve completed our very first commit, and we will be able to go back to this commit whenever we need in the future. Okay. Let’s call it a day! I will bring more to you in the following days","link":"/gitInit/"},{"title":"What if I push a wrong commit?","text":"Sometimes after pushing a new commit, we realise that there seems to be something wrong.Don’t panic. In this case we could use git revert to cancel the commit.Now let me illustrate it as follows: Build a simulating remote folder locally Due to the inaccessibility of internet of some people, we are going to create a simulating remote folder locally Go to the folder where normally you put your projects mkdir git_demonstration git_demonstration_central cd git_demonstration_central git init --bare git_demonstration_central will be the remote repository in this article. Build testing environment locally Go to testing folder cd ../git_demonstration Intialize git git init Create a file called test touch test Add number 1 into the file test cat 1 &gt; test Add test file into git tracking list git add test Make a commit towards current file and content git commit -m&#39;1&#39; Add number 2 into file test, and make a commit named 2 cat 2 &gt;&gt; test;git commit -am&#39;2&#39; Add number 3 into file test, and make a commit named 3 cat 3 &gt;&gt; test;git commit -am&#39;3&#39; Build remote branch Add the simulating remote repository as the remote of our testing folder. git remote add origin /user/yourUserName/yourDirectory/git_demonstration_central put current master branch to remote, and set the newly created remote branch as the local one’s upstream branch git push -u origin master Check the history of remote repository cd ../git_demonstration_central;git log Revert existing commit For example, we would like to remove the content recorded in commit 3 git revert f06550f7 Update the change to remote git push Check if the content of file test has changed cat test Got value 1 2, and the number 3 existed in commit 3 was already removed Check the history of remote repository cd ../git_demonstration_central;git log ConclusionSome git novices might have the same confusion as mine when I learnt this part. Why don’t we just eliminate the commit? instead, we would we add one more?Here I would like to make a further explanation.Normally, after pushing our commit to mutual repository, I strongly urge you not to revise the existing history. Because once you revise the existing history and push it to mutual repository, it could cause a huge impact to the history on everyone’s repository. After revising, every collaborator’s history will be different from yours, which would cause a lot of confusion and conflict.What we want to take out is a code existing in the file, so realistically, we want to cancel the code, not history. In multi-collaboration, you could add new history, and not recommended revising old one. You could add a new commit specifying what you’ve done, but not to revise the history on your side, because only you know what you’ve done, and other people know nothing on your side.In other words, before you push your part to mutual repository, you could do whatever you want (only to what you haven’t pushed. Don’t revise anything you’ve pushed), however, after pushing, don’t revise the history. If you want to do some revising on the file, just make a new commit explaining what you’ve done and push it, and then you could avoid possible confusion and conflict.It’s my sharing today. See you guys.","link":"/gitRevert/"},{"title":"My learning note on Gitlab","text":"IntroductionThis is a learning note on Gitlab, and there will no be a English version because the contents are mostly unorganised","link":"/gitlab/"},{"title":"Let’s specify a reversion number","text":"Hello everyone, It’s Ray! Today I am going to share with you how to use git tag to specify a reversion number After we complete a series of small functions, it could mean that we are going to release a new reversion. For example, think about the online games that you’ve played. Every time when it released a new reversion, it came with some new function. This reversion always denotes that all those functions have been completed, also works functionally after internal testing. This reversion number is quite convenient and important to developers. For example, a series of small functions build a big function, and the completion of this big function means that a new reversion is going to be released. Every time when we complete a small function, we commit it, and when we finish a series of small functions and make them a big one, we use git tag to specify, denoting a reversion’s release. It’s very essential and important to developers when wanting to do some testing some time after the release. Let’s begin with git log --oneline輸入 git log --oneline Above image shows what log looks like before adding a tag. Typegit tag -a v1.0 -m “The stable version of example” As image above shown, you could see the reversion number we just added. enter git tag You could see the reversions that we’ve made so far. Now let’s create a new file, example2.html, and add some code on it. &lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;This is the experimental file created after reversion v1.0&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; Then typeGit add example2.htmlgit commit -am “An example2 file after v1.0”Git log --oneline As image above shown, we are now at sixth commit, and our reversion only covers to fifth commit. When we want to go back to v1.0 reversion to check, we don’t need to checkout the name of fifth commit, instead, we type the reversion name as follows: Git checkout v1.0Git log --oneline As image above, we’ve gone back to v1.0. Hope that today’s article will be helpful and useful to you. See you tomorrow.","link":"/gitTag/"},{"title":"Deploy project on GCP virtual machine via Gitlab CI/CD","text":"IntroductionThis article is about: Open a GCP instance with gcloud Import ssh key into an instance with gcloud Running your project in the background with Daemon Deploy your project on GCP virtual machine via gitlab pusher EnvironmentCreate a GCP virtual machineHere is how I would do, you could have your own way. Ray use Mac, so I install Google Cloud SDK locally. As to the installation, you could refer to official document Create a VM Create a VM called example-instance-1 The boot drive storage is 10GB Pull image we need from ubuntu-os-cloud We use ubuntu-1804-lts as the image-family, so the latest version of this family will be used automatically. The type of boot-drive is pd-stand, you could check the types with command gcloud compute disk-types list The machine type is f1-micro, you could check the types wit command gcloud compute machine-types list We identify each instance with tags, and we will it when we want to create a firewall-rules. We specify the zone of the instance. Some resources are limited in certain zone and region As follows:gcloud compute instances create example-instance-1 \\--image-project=ubuntu-os-cloud \\--image-family=ubuntu-1804-lts \\--boot-disk-size=10GB \\--boot-disk-type=pd-standard \\--machine-type=f1-micro \\--tags=example-instance-1,http-server,https-server \\--zone=asia-east1-a After creating, let’s produce ssh-key firstssh-keygen -t rsa -b 4096 -C \"root@example\" Assume that the key is named examplecat example.pub &gt; instanceSSHConfig &amp;&amp; vim instanceSSHList Put root before the key in instanceSSHList file, whose format is as follows:[USERNAME]:ssh-rsa [KEY] [USERNAME] Get the name of the instancegcloud compute instances list Add the public key into the instance(Be careful! This command will replace all of your SSH keys on this instance, that said, any keys without appearing on this file will be gone)gcloud compute instances add-metadata instanceName --metadata-from-file ssh-keys=instanceSSHList InstallationHere we mainly install nvm, node with version v12.1.0, and npm. You could get more detail via the official documentapt-get update -y &amp;&amp; apt-get install curl -y &amp;&amp; curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.34.0/install.sh | bash &amp;&amp; export NVM_DIR=\"$HOME/.nvm\" &amp;&amp; [ -s \"$NVM_DIR/nvm.sh\" ] &amp;&amp; \\. \"$NVM_DIR/nvm.sh\" &amp;&amp; [ -s \"$NVM_DIR/bash_completion\" ] &amp;&amp; \\. \"$NVM_DIR/bash_completion\" &amp;&amp; nvm install v12.1.0 &amp;&amp; apt-get install npm -y DaemonNow, let’s config Daemon. We will run our service with Daemon so it will be run automatically when it’s disconnected.sudo vim /etc/init.d/serviceName #!/bin/sh### BEGIN INIT INFO# Provides: yourServiceName (optional)# Required-Start: $remote_fs $syslog# Required-Stop: $remote_fs $syslog# Default-Start: 2 3 4 5# Default-Stop: 0 1 6# Short-Description: Start daemon at boot time# Description: Enable service provided by daemon.### END INIT INFOdir=\"yourProjectLocation\"cmd=\"theCommandItRequiresToStartYourService\"user=\"root\"name=`basename $0`pid_file=\"/var/run/$name.pid\"stdout_log=\"/var/log/$name.log\"stderr_log=\"/var/log/$name.log\"get_pid() &#123; cat \"$pid_file\"&#125;is_running() &#123; [ -f \"$pid_file\" ] &amp;&amp; ps -p `get_pid` &gt; /dev/null 2&gt;&amp;1&#125;case \"$1\" in start) if is_running; then echo \"Already started\" else echo \"Starting $name\" cd \"$dir\" export NODE_ENV=test if [ -z \"$user\" ]; then sudo $cmd &gt;&gt; \"$stdout_log\" 2&gt;&gt; \"$stderr_log\" &amp; else sudo -u \"$user\" $cmd &gt;&gt; \"$stdout_log\" 2&gt;&gt; \"$stderr_log\" &amp; fi echo $! &gt; \"$pid_file\" if ! is_running; then echo \"Unable to start, see $stdout_log and $stderr_log\" exit 1 fi fi ;; stop) if is_running; then echo -n \"Stopping $name..\" kill `get_pid` for i in 1 2 3 4 5 6 7 8 9 10 # for i in `seq 10` do if ! is_running; then break fi echo -n \".\" sleep 1 done echo if is_running; then echo \"Not stopped; may still be shutting down or shutdown may have failed\" exit 1 else echo \"Stopped\" if [ -f \"$pid_file\" ]; then rm \"$pid_file\" fi fi else echo \"Not running\" fi ;; restart) $0 stop if is_running; then echo \"Unable to stop, will not attempt to start\" exit 1 fi $0 start ;; status) if is_running; then echo \"Running\" else echo \"Stopped\" exit 1 fi ;; *) echo \"Usage: $0 &#123;start|stop|restart|status&#125;\" exit 1 ;;esacexit 0 If it shows that the service is not found, we need to reload the daemon sudo systemctl daemon-reload Note that the authority has to been revised, making Daemon executable sudo chmod 755 serviceName Set up auto-restart, when VM reboots, the service will auto start sudo systemctl enable serviceName In this example, the name of Daemon will be equal to the name of project CI/CDGitlab variables setting We are going to do CI/CD with Gitlab pusher, so we have to create a pair of ssh key , and set the private key as $SSH_PRIVATE_KEY in variable settingssh-keyscan to-be-conneted-instance-ip Gitlab yaml config fileWe will set up the yaml file of Gitlab pusherIn our projectvim .gitlab-ci.yml # This file is a template, and might need editing before it works on your project.# Official framework image. Look for the different tagged releases at:# https://hub.docker.com/r/library/node/tags/image: node:8# This folder is cached between builds# http://docs.gitlab.com/ce/ci/yaml/README.html#cachecache: paths: - node_modules/stages:- build- deploynpm-build: stage: build script: - rm -rf node_modules/ &amp;&amp; npm i npm@latest -g &amp;&amp; npm install depoly-test: stage: deploy script: # cfr. https://docs.gitlab.com/ee/ci/ssh_keys/README.html # Install ssh-agent if not already installed, it is required by Docker. # (change apt-get to yum if you use a CentOS-based image) - 'which ssh-agent || ( apt-get update -y &amp;&amp; apt-get install openssh-client -y )' # Run ssh-agent (inside the build environment) - eval $(ssh-agent -s) # Add the SSH key stored in SSH_PRIVATE_KEY variable to the agent store - ssh-add &lt;(echo \"$SSH_PRIVATE_KEY\") - mkdir -m 700 -p /root/.ssh - tar zcf ../$CI_PROJECT_NAME.tar.gz ./ - scp -o StrictHostKeyChecking=no ../$CI_PROJECT_NAME.tar.gz root@35.201.171.244:/locationYouPrefer - ssh root@yourIP \"rm -rf /locationYouPrefer/$CI_PROJECT_NAME &amp;&amp; mkdir -p locationYouPrefer/$CI_PROJECT_NAME &amp;&amp; tar zxf locationYouPrefer/$CI_PROJECT_NAME.tar.gz -C locationYouPrefer/$CI_PROJECT_NAME &amp;&amp; chmod -R 655 locationYouPrefer/$CI_PROJECT_NAME &amp;&amp; cd locationYouPrefer/$CI_PROJECT_NAME &amp;&amp; npm rebuild &amp;&amp; /etc/init.d/$CI_PROJECT_NAME restart\" only: - branchYouPrefer ConclusionUntil now, when we use git push to specified branch, we should be able to trigger gitlab pusher to achieve automatic deployment","link":"/gitlabCICDOnGCP/"},{"title":"Google Cloud Pub/Sub:Qwik Start - Console","text":"Refer to QWIKLABS","link":"/googleCloudPubSubQwikStartConsole/"},{"title":"Get information via Facebook graph API","text":"IntroductionIn this article, I’m going to share how to get user information from Facebook by submitting a token with PHP SDK, which is got by providing user a login page with JaveScript code. Go to FB develop page, and sign up, and then go to console and add a new application In the user information, copy App key and App secret Create a Laravel projectlaravel new Facebook Initiate Gitgit init Install Facebook PHP SDK Under the projectcomposer require facebook/graph-sdk Create a controller which we could interact with FB later withphp artisan make:controller FBController Create a function called getFacebookResources Copy the SDK example code in its page, and paste it in the functionrequire_once __DIR__ . &apos;/vendor/autoload.php&apos;; // change path as needed$fb = new \\Facebook\\Facebook([ &apos;app_id&apos; =&gt; &apos;&#123;app-id&#125;&apos;, &apos;app_secret&apos; =&gt; &apos;&#123;app-secret&#125;&apos;, &apos;default_graph_version&apos; =&gt; &apos;v2.10&apos;, //&apos;default_access_token&apos; =&gt; &apos;&#123;access-token&#125;&apos;, // optional]);// Use one of the helper classes to get a Facebook\\Authentication\\AccessToken entity.// $helper = $fb-&gt;getRedirectLoginHelper();// $helper = $fb-&gt;getJavaScriptHelper();// $helper = $fb-&gt;getCanvasHelper();// $helper = $fb-&gt;getPageTabHelper();try &#123; // Get the \\Facebook\\GraphNodes\\GraphUser object for the current user. // If you provided a &apos;default_access_token&apos;, the &apos;&#123;access-token&#125;&apos; is optional. $response = $fb-&gt;get(&apos;/me&apos;, &apos;&#123;access-token&#125;&apos;);&#125; catch(\\Facebook\\Exceptions\\FacebookResponseException $e) &#123; // When Graph returns an error echo &apos;Graph returned an error: &apos; . $e-&gt;getMessage(); exit;&#125; catch(\\Facebook\\Exceptions\\FacebookSDKException $e) &#123; // When validation fails or other local issues echo &apos;Facebook SDK returned an error: &apos; . $e-&gt;getMessage(); exit;&#125;$me = $response-&gt;getGraphUser();echo &apos;Logged in as &apos; . $me-&gt;getName(); Enter App key and App secret In the example above, we need to fill in some area with some information got from FB developer account as follows:$fb = new \\Facebook\\Facebook([ &apos;app_id&apos; =&gt; &apos;App Key&apos;, &apos;app_secret&apos; =&gt; &apos;App Secret&apos;, &apos;default_graph_version&apos; =&gt; &apos;Current version&apos;, //&apos;default_access_token&apos; =&gt; &apos;&#123;access-token&#125;&apos;, // optional]); Create a user login button User need to login in and get the token, and then we could use the token for further processing. In routes/web.php file, create a route for the login page Route::get(&apos;/FBToken&apos;, function()&#123;return view(&apos;FBToken&apos;);&#125;); Under resources/views folder, create a php file called FBtoken.blade, and paste the example code of JS as follows: &lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Facebook Login JavaScript Example&lt;/title&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;/head&gt;&lt;body&gt;&lt;script&gt; // This is called with the results from from FB.getLoginStatus(). function statusChangeCallback(response) &#123; console.log(&apos;statusChangeCallback&apos;); console.log(response); // The response object is returned with a status field that lets the // app know the current login status of the person. // Full docs on the response object can be found in the documentation // for FB.getLoginStatus(). if (response.status === &apos;connected&apos;) &#123; // Logged into your app and Facebook. testAPI(); &#125; else &#123; // The person is not logged into your app or we are unable to tell. document.getElementById(&apos;status&apos;).innerHTML = &apos;Please log &apos; + &apos;into this app.&apos;; &#125; &#125; // This function is called when someone finishes with the Login // Button. See the onlogin handler attached to it in the sample // code below. function checkLoginState() &#123; FB.getLoginStatus(function(response) &#123; statusChangeCallback(response); &#125;); &#125; window.fbAsyncInit = function() &#123; FB.init(&#123; appId : &apos;&#123;your-app-id&#125;&apos;, cookie : true, // enable cookies to allow the server to access // the session xfbml : true, // parse social plugins on this page version : &apos;&#123;api-version&#125;&apos; // The Graph API version to use for the call &#125;); // Now that we&apos;ve initialized the JavaScript SDK, we call // FB.getLoginStatus(). This function gets the state of the // person visiting this page and can return one of three states to // the callback you provide. They can be: // // 1. Logged into your app (&apos;connected&apos;) // 2. Logged into Facebook, but not your app (&apos;not_authorized&apos;) // 3. Not logged into Facebook and can&apos;t tell if they are logged into // your app or not. // // These three cases are handled in the callback function. FB.getLoginStatus(function(response) &#123; statusChangeCallback(response); &#125;); &#125;; // Load the SDK asynchronously (function(d, s, id) &#123; var js, fjs = d.getElementsByTagName(s)[0]; if (d.getElementById(id)) return; js = d.createElement(s); js.id = id; js.src = &quot;https://connect.facebook.net/en_US/sdk.js&quot;; fjs.parentNode.insertBefore(js, fjs); &#125;(document, &apos;script&apos;, &apos;facebook-jssdk&apos;)); // Here we run a very simple test of the Graph API after login is // successful. See statusChangeCallback() for when this call is made. function testAPI() &#123; console.log(&apos;Welcome! Fetching your information.... &apos;); FB.api(&apos;/me&apos;, function(response) &#123; console.log(&apos;Successful login for: &apos; + response.name); document.getElementById(&apos;status&apos;).innerHTML = &apos;Thanks for logging in, &apos; + response.name + &apos;!&apos;; &#125;); &#125;&lt;/script&gt;&lt;!-- Below we include the Login Button social plugin. This button uses the JavaScript SDK to present a graphical Login button that triggers the FB.login() function when clicked.--&gt;&lt;fb:login-button scope=&quot;public_profile,email&quot; onlogin=&quot;checkLoginState();&quot;&gt;&lt;/fb:login-button&gt;&lt;div id=&quot;status&quot;&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; Same here, we need to fill in App key and current version there as follows: FB.init(&#123; appId : &apos;App key&apos;, cookie : true, // enable cookies to allow the server to access // the session xfbml : true, // parse social plugins on this page version : &apos;version&apos; // The Graph API version to use for the call&#125;); Familiar yourself with FB Graph API tool We could we the API we need with FB Graph API tool Customize endpoint Because we might specify our endpoint simply by copying and pasting as follows: So we could move endpoint to .env as follows: $endpoint = env(&apos;FBEndpoint&apos;);try&#123; // Get the \\Facebook\\GraphNodes\\GraphUser object for the current user. // If you provided a &apos;default_access_token&apos;, the &apos;&#123;access-token&#125;&apos; is optional. $response = $fb-&gt;get($endpoint, $token); And then in the .env FBEndpoint=me?fields=id,name,email So, in the future, we could simply copy the endpoint from FB, and paste it on .env Revise the error return In the default setting of PHP SDK, it would return error message according to the situation, which might be good. However, I only need to know true or false, and that’s it. A ineffective token might be caused by several factors as follows: It doesn’t exist Wrong token It expired It doesn’t matter which one it is, the only thing we have to do is inform front end of this matter, and ask them to provide make a request to FB again and provide the valid token to us. Therefore, we need to determine what we are going to by a simple true or false feedback from FB PHP SDK, so we revise it as follows:catch (\\Facebook\\Exceptions\\FacebookResponseException $e) { return false; // echo &apos;Graph returned an error: &apos; . $e-&gt;getMessage(); // exit; } Get a public URL Use ngrok to get a public URL for the HTML page that we will use to get token from users. Login the application =&gt; Find login product =&gt; shortcut =&gt; website =&gt; paste the public URL Login and get tokenFeed the token to getFacebookResources function in FBController.Insert the data into our databaseWe are done here","link":"/getINFOViaFBToken/"},{"title":"Hello World","text":"FeaturesEnglish version中文版日本語版 Do not modify this note. Thank you very much :smile:If you want to say hello or play with something, please go to Playground Introduction HackMD is a realtime, multi-platform collaborative markdown note editor.This means that you can write notes with other people on your desktop, tablet or even on the phone.You can sign-in via multiple auth providers like Facebook, Twitter, GitHub and many more on the homepage. Please report new issues in GitHub.If you need instant help, please send us a Facebook message.Thank you very much! WorkspaceModesDesktop &amp; Tablet Edit: See only the editor. View: See only the result. Both: See both in split view. Mobile View: See only the result. Edit: See only the editor. Image Upload:You can upload an image simply by clicking on the camera button .Alternatively, you can drag-n-drop an image into the editor. Even pasting images is possible!This will automatically upload the image to imgur, nothing to worry. :tada: Share Notes:If you want to share an editable note, just copy the URL.If you want to share a read-only note, simply press publish button and copy the URL. Save a Note:Currently, you can save to Dropbox or save an .md file locally. Import Notes:Similarly to the save feature, you can also import an .md file from Dropbox ,or import content from your clipboard , and that can parse some html which might be useful :smiley: Permissions:It is possible to change the access permission to a note through the little button on the top right of the view.There are six possible options: Owner read/write Signed-in read Signed-in write Guest read Guest write Freely ✔ ✔ ✔ ✔ ✔ Editable ✔ ✔ ✔ ✔ ✖ Limited ✔ ✔ ✔ ✖ ✖ Locked ✔ ✔ ✖ ✔ ✖ Protected ✔ ✔ ✖ ✖ ✖ Private ✔ ✖ ✖ ✖ ✖ Only the owner of the note can change the note’s permissions. Embed a Note:Notes can be embedded as follows: &lt;iframe width=\"100%\" height=\"500\" src=\"https://hackmd.io/features\" frameborder=\"0\"&gt;&lt;/iframe&gt; Slide Mode:You can use a special syntax to organize your note into slides.After that, you can use the Slide Mode to make a presentation.Visit the above link for details. Book Mode:You can make your notes into a book.List your links in order or nest them.Then use the Book Mode to make a collection.Visit the above link for details. ViewTable of Contents:You can look at the bottom right section of the view area, there is a ToC button .Pressing that button will show you a current Table of Contents, and will highlight which section you’re at.ToCs support up to three header levels. PermalinkEvery header will automatically add a permalink on the right side.You can hover and click to anchor on it. Edit:Shortcut Keys:Just like Sublime text, which is pretty quick and convenient. For more infomation, see here. Auto-Complete:This editor provides full auto-complete hints in markdown. Emojis: type : to show hints. Code blocks: type ` and plus a character to show hint. ```- Headers: type `#` to show hint.- Referrals: type `[]` to show hint.- Externals: type `&#123;&#125;` to show hint.- Images: type `!` to show hint.## Title:This will take the first **level 1 header** as the note title.## Tags:Using tags as follows, the specified tags will show in your **history**.###### tags: `features` `cool` `updated`## [YAML Metadata](/yaml-metadata)You can provide advanced note information to set the browser behavior (visit above link for details):- title: set note title- description: set note description- image: set note default image (for link preview)- tags: set note tags- robots: set web robots meta- lang: set browser language- dir: set text direction- breaks: set to use line breaks- GA: set to use Google Analytics- disqus: set to use Disqus- slideOptions: setup slide mode options## ToC:Use the syntax `[TOC]` to embed table of content into your note.[TOC]## EmojiYou can type any emoji like this :smile: :smiley: :cry: :wink:&gt; See full emoji list [here](http://www.emoji-cheat-sheet.com/).## ToDo List:- [ ] ToDos - [x] Buy some salad - [ ] Brush teeth - [x] Drink some water## Code Block:We support many programming languages, use the auto complete function to see the entire list.```javascript=var s = &quot;JavaScript syntax highlighting&quot;;alert(s);function $initHighlight(block, cls) &#123; try &#123; if (cls.search(/\\bno\\-highlight\\b/) != -1) return process(block, true, 0x0F) + &apos; class=&quot;&quot;&apos;; &#125; catch (e) &#123; /* handle exception */ &#125; for (var i = 0 / 2; i &lt; classes.length; i++) &#123; if (checkCondition(classes[i]) === undefined) return /\\d+[\\s/]/g; &#125;&#125; If you want line numbers, type = after specifying the code block languagues.Also, you can specify the start line number.Like below, the line number starts from 101:var s = \"JavaScript syntax highlighting\";alert(s);function $initHighlight(block, cls) &#123; try &#123; if (cls.search(/\\bno\\-highlight\\b/) != -1) return process(block, true, 0x0F) + ' class=\"\"'; &#125; catch (e) &#123; /* handle exception */ &#125; for (var i = 0 / 2; i &lt; classes.length; i++) &#123; if (checkCondition(classes[i]) === undefined) return /\\d+[\\s/]/g; &#125;&#125; Or you might want to continue the previous code block’s line number, use =+ var s = \"JavaScript syntax highlighting\";alert(s); Somtimes you have a super long text without breaks. It’s time to use ! to wrap your code. When you’re a carpenter making a beautiful chest of drawers, you’re not going to use a piece of plywood on the back. Blockquote Tags: Using the syntax below to specifiy your name, time and color to vary the blockquotes.[name=ChengHan Wu] [time=Sun, Jun 28, 2015 9:59 PM] [color=#907bf7] Even support the nest blockquotes![name=ChengHan Wu] [time=Sun, Jun 28, 2015 10:00 PM] [color=red] ExternalsYouTube Vimeo Gist SlideShareMathJaxYou can render LaTeX mathematical expressions using MathJax, as on math.stackexchange.com, except the space after the start $ and the space before the end $ are not allowed in the inline math: The Gamma function satisfying $\\Gamma(n) = (n-1)!\\quad\\forall n\\in\\mathbb N$ is via the Euler integral $$x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}.$$ $$\\Gamma(z) = \\int_0^\\infty t^{z-1}e^{-t}dt\\,.$$ More information about LaTeX mathematical expressions here. UML DiagramsSequence DiagramsYou can render sequence diagrams like this: Alice-&gt;Bob: Hello Bob, how are you?Note right of Bob: Bob thinksBob--&gt;Alice: I am good thanks!Note left of Alice: Alice respondsAlice-&gt;Bob: Where have you been? Flow ChartsFlow charts can be specified like this:st=&gt;start: Starte=&gt;end: Endop=&gt;operation: My Operationop2=&gt;operation: lalalacond=&gt;condition: Yes or No?st-&gt;op-&gt;op2-&gt;condcond(yes)-&gt;econd(no)-&gt;op2 Graphvizdigraph hierarchy &#123; nodesep=1.0 // increases the separation between nodes node [color=Red,fontname=Courier,shape=box] //All nodes will this shape and colour edge [color=Blue, style=dashed] //All the lines look like this Headteacher-&gt;&#123;Deputy1 Deputy2 BusinessManager&#125; Deputy1-&gt;&#123;Teacher1 Teacher2&#125; BusinessManager-&gt;ITManager &#123;rank=same;ITManager Teacher1 Teacher2&#125; // Put them on the same level&#125; Mermaidgantt title A Gantt Diagram section Section A task :a1, 2014-01-01, 30d Another task :after a1 , 20d section Another Task in sec :2014-01-12 , 12d anther task : 24d AbcX:1T:Speed the PloughM:4/4C:Trad.K:G|:GABc dedB|dedB dedB|c2ec B2dB|c2A2 A2BA|GABc dedB|dedB dedB|c2ec B2dB|A2F2 G4:||:g2gf gdBd|g2f2 e2d2|c2ec B2dB|c2A2 A2df|g2gf g2Bd|g2f2 e2d2|c2ec B2dB|A2F2 G4:| More information about sequence diagrams syntax here.More information about flow charts syntax here.More information about graphviz syntax hereMore information about mermaid syntax hereMore information about abc syntax here Alert Area:::successYes :tada:::: :::infoThis is a message :mega:::: :::warningWatch out :zap:::: :::dangerOh No! :fire:::: TypographyHeaders# h1 Heading## h2 Heading### h3 Heading#### h4 Heading##### h5 Heading###### h6 Heading Horizontal Rules Typographic ReplacementsEnable typographer option to see result. (c) (C) (r) (R) (tm) (TM) (p) (P) +- test.. test… test….. test?….. test!…. !!!!!! ???? ,, Remarkable – awesome “Smartypants, double quotes” ‘Smartypants, single quotes’ EmphasisThis is bold text This is bold text This is italic text This is italic text Deleted text lu~lala~ Superscript: 19^th^ Subscript: H~2~O ++Inserted text++ ==Marked text== Blockquotes Blockquotes can also be nested… …by using additional greater-than signs right next to each other… …or with spaces between arrows. ListsUnordered Create a list by starting a line with +, -, or * Sub-lists are made by indenting 2 spaces: Marker character change forces new list start: Ac tristique libero volutpat at Facilisis in pretium nisl aliquet Nulla volutpat aliquam velit Very easy! Ordered Lorem ipsum dolor sit amet Consectetur adipiscing elit Integer molestie lorem at massa You can use sequential numbers… …or keep all the numbers as 1. feafw 332 242 2552 e2 Start numbering with offset: foo bar CodeInline code Indented code // Some comments line 1 of code line 2 of code line 3 of code Block code “fences” Sample text here... Syntax highlighting var foo = function (bar) &#123; return bar++;&#125;;console.log(foo(5)); Tables Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. Right aligned columns Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. Left aligned columns Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. Center aligned columns Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. Linkslink textlink with titleAutoconverted link https://github.com/nodeca/pica ImagesLike links, Images also have a footnote style syntaxWith a reference later in the document defining the URL location: Show the image with given size FootnotesFootnote 1 link[^first].Footnote 2 link[^second].Inline footnote^[Text of inline footnote] definition.Duplicated footnote reference[^second]. [^first]: Footnote can have markup and multiple paragraphs.[^second]: Footnote text. Definition ListsTerm 1 : Definition 1with lazy continuation. Term 2 with inline markup : Definition 2 { some code, part of Definition 2 } Third paragraph of definition 2. Compact style: Term 1 ~ Definition 1 Term 2 ~ Definition 2a ~ Definition 2b AbbreviationsThis is an HTML abbreviation example.It converts “HTML”, but keeps intact partial entries like “xxxHTMLyyy” and so on. *[HTML]: Hyper Text Markup Language","link":"/hello-world/"},{"title":"Deploy multiple projects on AWS","text":"Launch a AWS EC2 instance, the testing instance is Amazon Linux 2 AMI (HVM), SSD Volume Type - ami-0d7ed3ddb85b521a6 Connect to your EC2 instance, and entersudo vim /etc/httpd/conf.d/yourProjectName.conf paste the following code &lt;VirtualHost *:443&gt; # port 443 for https ServerName letussleep.space # Your domin name DocumentRoot &quot;/var/www/html/yourLaravelProjectName/public&quot; # The absolute address of your project on EC2 SSLEngine on SSLCertificateFile /whateverLocationYouWant/certificate.crt SSLCertificateKeyFile /whateverLocationYouWant/private.key SSLCertificateChainFile /whateverLocationYouWant/ca_bundle.crt # They are for SSL signing purpose, corresponding to those validation files you get from SSL signing service.&lt;/VirtualHost&gt;&lt;VirtualHost *:80&gt; # port 80 is for http ServerName letussleep.space DocumentRoot &quot;/var/www/html/yourLaravelProjectName/public&quot; redirect / Https://letussleep.space # When user connect this project via http, redirect to https&lt;/VirtualHost&gt;&lt;VirtualHost *:80&gt;ServerName oldletussleep.space # So, basically in a conf file, we could complete multiple project deployment once we set the domain name properly.DocumentRoot &quot;/var/www/html/yourProjectName/public&quot;&lt;/VirtualHost&gt; Although we could complete multiple project deployment in a single config file once we set the domain name and project address properly, I personally prefer one config file to one project to prevent any possible confusion in the future. So simply repeat all the steps mentioned above, creating a new config file, and config it properly, and then type sudo service httpd restart Connect to your domain, it should work now.","link":"/howToDeployMultipleProjectOnAWS/"},{"title":"Send email via AWS SES in Laravel","text":"Apply for AWS SES (simple email service) Create an user, and SES full accessible policy, along with the access key and secret key. Go to AWS console, click email address option on left side, and verify your email. Go to AWS support center to submit a service limit increase case, and choose SES Sending Limits, called ‘Remove it out of SandBox’ Otherwise the capacity of the mail you are allowed to send and its rate will be limited to a large extend, besides that, all of the recipients will have to be verified by SES. Create a Laravel Project Install mail package composer require guzzlehttp/guzzle Install AWS SDK composer require aws/aws-sdk-php Go to config/mail.php, and revise the driver toses Go to config/services.php, and config it as follows: &apos;ses&apos; =&gt; [ &apos;key&apos; =&gt; &apos;your-ses-key&apos;, &apos;secret&apos; =&gt; &apos;your-ses-secret&apos;, &apos;region&apos; =&gt; &apos;ses-region&apos;, // e.g. us-east-1], You should config all above mentioned in your .env file as follows: MAIL_DRIVER=sesMAIL_FROM_ADDRESS=your-mail-addressMAIL_FROM_NAME=BuyBuyGoSES_KEY=your-ses-keySES_SECRET=your-ses-secretSES_REGION=us-west-2 Create class，php artisan make:mail OrderCreated --markdown=emails.orders.created Go to OrderCreated.php, config your build as follows: &lt;?phpnamespace App\\Mail;use Illuminate\\Bus\\Queueable;use Illuminate\\Mail\\Mailable;use Illuminate\\Queue\\SerializesModels;use Illuminate\\Contracts\\Queue\\ShouldQueue;class OrderShipped extends Mailable&#123; use Queueable, SerializesModels; protected $order; /** * Create a new message instance. * * @return void */ public function __construct($order) &#123; $this-&gt;order = $order; // &#125; /** * Build the message. * * @return $this */ public function build() &#123; return $this-&gt;markdown(&apos;emails.orders.created&apos;) -&gt;with([ &apos;buyer&apos; =&gt; $this-&gt;order-&gt;user-&gt;name, &apos;order&apos; =&gt; $this-&gt;order-&gt;name, &apos;item_name&apos; =&gt; $this-&gt;order-&gt;item_name, &apos;item_description&apos; =&gt; $this-&gt;order-&gt;item_description, &apos;quantity&apos; =&gt; $this-&gt;order-&gt;quantity, &apos;total_amount&apos; =&gt; $this-&gt;order-&gt;total_amount, &apos;unit_price&apos; =&gt; $this-&gt;order-&gt;unit_price, &apos;expiry_time&apos; =&gt; $this-&gt;order-&gt;expiry_time, ]); &#125;&#125; Go to created.blade.php to customize the view as follows: @component(&apos;mail::message&apos;)# Dear &#123;&#123; $buyer &#125;&#125;Thanks for your patronage!- Order: &#123;&#123;$order&#125;&#125;- Item: &#123;&#123;$item_name&#125;&#125;- Item description: &#123;&#123;$item_description&#125;&#125;- Quantity: &#123;&#123;$quantity&#125;&#125;- Unit price: &#123;&#123;$unit_price&#125;&#125;- Amount: &#123;&#123;$total_amount&#125;&#125;## Kindly make this payment before &lt;span style=&quot;color: red&quot;&gt;&#123;&#123;$expiry_time&#125;&#125;&lt;/span&gt;&lt;hr&gt;&lt;br&gt;## If you have any question, feel free to contact us@component(&apos;mail::button&apos;, [&apos;url&apos; =&gt; &apos;https://tn710617.github.io/&apos;])Contact Us@endcomponentThanks,&lt;br&gt;&#123;&#123; config(&apos;app.name&apos;) &#125;&#125;@endcomponent Now you could use mail to send email wherever you want. Mail::to($buyer-&gt;email)-&gt;send(new OrderCreated($order)); Now it should work Do you think “that’s it?”, yeah almost. However, there is one more thing.I spent one day figuring out all above mentioned, and then I came across something tricky, and it took me one another day.As a backend programmer, whenever I need to connect a third party payment service, I use ngrok to help me develop.It’s so weird this time. I made my script to do some things in my controller after I received the response from payment service. However, it did every function I wrote except for the mail function… and here is the error message: &quot;message&quot;: &quot;Expected response code 250 but got code \\&quot;530\\&quot;, with message \\&quot;530 5.7.1 Authentication required\\r\\n\\&quot;&quot;,&quot;exception&quot;: &quot;Swift_TransportException&quot;,&quot;file&quot;: &quot;/Users/ray/code/FacebookOptimizedSellingSystem/vendor/swiftmailer/swiftmailer/lib/classes/Swift/Transport/AbstractSmtpTransport.php&quot;,&quot;line&quot;: 457,&quot;trace&quot;: [ 1000 lines omitted. After tormenting debugging, I found out if I used valet share, this error would not occur, and if I used php artisan serve --port=yourPort, and then ngrok http yourPort, and the error came out. although I solved the error eventually, to be honest I still didn’t know why.. If you know why the error occurred, kindly drop me a message or a mail, it will really help!","link":"/howToSendMailViaAWSSES/"},{"title":"How to skip git add?","text":"Do you think it’s extremely troublesome to use git add every time before we want to make a commit? Let’s try git commit -am Hello everyone. It’s Ray! Today I am going to share how to simplify git add and git commit, let’s welcome git commit -am As shared previously, every time before making a commit, we need to use git add to update the progress to be committed, and then leave the specific message for this commit before completing this commit. Some think it’s a good design, after all, it’s best to err on the side of caution. However, some don’t, thinking that it’s a bit troublesome. No matter which one you are belong to. today I’m going to share with you how to combine and turn them into one move. Firstly, let’s add a new code in example1.html file as follows:&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;First example&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;This is the first example&lt;/p&gt;&lt;p&gt;We add a new paragraph on the first example&lt;/p&gt;&lt;p&gt;This is the example commit for git commit -am&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; enter git status As image below, the example1.html has been modified, and it requires git add to update what will be committed before a commit. According to articles that I posted previously, we need to git add, and then git commit, and finally leave the specific message before a completed commit. Now let’s try something simpler. Enter Git commit -am &quot;example for git commit -am&quot; Enter git status to check the condition. enter git log As image below, we’ve successfully committed. Here I’m going to further explain how git add works. When we create a new file, we need to add this file into the list of tracked files, and to do so, we use git add When one of the tracked file is modified, and we would like to make a commit, we would need to update what will be committed, and we also use git add to do so. That said, git commit -am would not work on a newly added file which hasn’t been added into tracked file list. Caution! -a here means automatic, which would automatically add ALL those modified file from tracked file list. After reading through this article, are you more familiar with Git? See you guys!","link":"/howToSkipGitAdd/"},{"title":"Import Chinese into Database without garbles","text":"Some detail when importing Chinese from CSV file into database via PHP script Hello everyone. It’s Ray!Today I am going to share more details of importing Chinese characters into database from CSV file via PHP script Firstly, let’s start from PHP script &lt;?phpmysqli_set_charset($dbc,&quot;utf8&quot;); After the code of connecting to database, bear in mind that the code above should be added in order to specify the default format of data from and to database. As to CSV file: Firstly, open it with Excel, open new Secondly, choose data, and click from text Use delimiter Use comma to delimit the data Finally, general is fine. As to database: If you use GUI tool such as Sequel Pro, remember to choose UTT-8 when creating a new table If you use terminal, as image below, remember to specify the utf8 format when creating a new table If garble still occurs, check if the format for each column is utf-8 Basically, if all above mentioned is followed, you should be able to import Chinese and show it in database without any trouble as image below:","link":"/howToImportChineseIntoDatabaseWithoutGarble/"},{"title":"How to configure Git?","text":"Hello It’s Ray! Today I’m going to share with you how to configure basic information of Git. Ｏkay now let’s add a new code on our example file as follows: &lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;First example&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;This is the first example&lt;/p&gt;&lt;p&gt;We add a new paragraph on the first example&lt;/p&gt;&lt;p&gt;This is the example commit for git commit -am&lt;/p&gt;&lt;p&gt;This is the example1 for git configuration&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; Git commit -am “Before configuration” Git log Take a look on the image above, which shows the author information of this commit in current configuration. Now we add another description in the example1.html file as follows: &lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;First example&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;This is the first example&lt;/p&gt;&lt;p&gt;We add a new paragraph on the first example&lt;/p&gt;&lt;p&gt;This is the example commit for git commit -am&lt;/p&gt;&lt;p&gt;This is the example1 for git configuration&lt;/p&gt;&lt;p&gt;This is the example after git configuration&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; Let’s configure the user information. enter the following code. Git config --global user.name RayGit config --global user.email example@email.com Please fill in yours in “Ray” and “example@email.com” And then enter: Git commit -am “after configuration” Git log Through image above we could see that we’ve successfully configured the user information. Let me explain further. We use –global to configure, so it applies to ALL, simply speaking, all of the repositories in your computer are applied with this setting. We could also configure a local setting, which means the configuration only apply to local repository. We will talk about it further! Let’s call it a day. See you guys!","link":"/howToConfigureGit/"},{"title":"How to use checkout","text":"Hello everyone, it’s Ray! Remember where we were in my last article? I hope that the image above would do some help. You are right, last time we introduced how to initialise Git, and create a file called example1.html, and then complete our first commit. As mentioned previously, Git allows us to go back to whatever commit whenever we want. Today I’m going to share how to freely switch among different commits. Now let’s add some experimental code &lt;p&gt;We add a new paragraph on the first example&lt;/p&gt; in the example1.html file as follows:現在，讓我們在檔案內加入下面highlight的一段 &lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;First example&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;This is the first example&lt;/p&gt;&lt;p&gt;We add a new paragraph on the first example&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; And then we go to command line, and type git status You will see what looks like the following image, which indicating that the example1.html file has been modified. As mentioned in the last article, before making any commit, we need to use git add to specify what we want to commit. So let’s type git add example1.html and type git status As the image above, we’ve specified what we are going to commit Now type git commit And leave the message “New paragraph added in example1.html file” for this commit. After that we type git status to check it And then git log We will see the second commit that we just made as follows: Okay, now let’s go back to our first commit. The git log shows the history of all of the commits, and therefore we could use the information within to switch among different commits Type git checkout b45934852da471efbbbc52b5a119e8723fb01866 This checksum is my version, and it varies upon different time, author, even the data. In other words, it’s unique, so yours will be different from mine. As image shown below, now we are already at our first commit Now let’s open editor to check. The experimental code &lt;p&gt;We add a new paragraph on the first example&lt;/p&gt; is gone. Now we go back to our first commit, and it doesn’t matter if we’ve saved it with our editor or IDE. So now how could we go back to our latest commit? Type git checkout master As image shown above, now we are at our latest commit. Now go to editor to check. See! The disappeared “new paragraph” appears again! Isn’t it a magic? Hope that it will do some help on the understanding of git of yours. See you guys!","link":"/howToUseCheckout/"},{"title":"Japanese Practice Note","text":"IntroductionHello! It’s my Japanese learning note, so there will not be a English version for this.","link":"/japanesePractice/"},{"title":"Implement CI with Jenkins on AWS","text":"IntroductionHere are the points in this article: Deploy jenkins on AWS EC2 with Amazon Linux 2 AMI (HVM) Deploy jenkins on AWS EC2 with Amazon Linux AMI 2018.03.0 (HVM) When specified branch on GitHub is updated, automatically implement git pull on AWS EC2 and synchronize with your project on GitHub Launch EC2 instance Connect toAWS EC2 with SSH Click connect, and follow the instruction Amazon Linux 2 AMI (HVM)Installsudo yum install java-1.8.0 sudo yum update –y sudo rpm --import https://pkg.jenkins.io/redhat/jenkins.io.key sudo yum install jenkins -y Configsudo vim /etc/sysconfig/jenkins and revise setting as JENKINS_USER=&quot;root&quot; sudo service jenkins start sudo systemctl enable jenkins.service Config Jenkins on Browser Open the following link on Browserhttp://yourPublicDNS:8080 On server sudo cat /var/lib/jenkins/secrets/initialAdminPassword copy the password and paste it in order to login install suggested plugins Sign up your account Save and go ahead Go to ‘Jenkins management’ Install GitHub integration plugin Start a free style project Go to configuration Enter your project url Check ‘git’, and enter your Git Repository url check ‘GitHub hook trigger for GITScm polling’ Enter the shell script you likeIf you install jenkins on the machine where your project is installed: ssh -i /root/.ssh/yourKey.pem ec2-user@127.0.0.1 \"cd /var/www/html/yourProjectName;git reset @^ --hard;git pull;/usr/local/bin/composer install;php artisan migrate --force;\" Config GitHub Go to GitHub-&gt;setting build the webhook as follows: Amazon Linux AMI 2018.03.0 (HVM)Installsudo yum update –y sudo yum remove java-1.7.0-openjdk sudo yum install java-1.8.0 sudo wget -O /etc/yum.repos.d/jenkins.repo http://pkg.jenkins.io/redhat/jenkins.repo sudo rpm --import https://pkg.jenkins.io/redhat/jenkins.io.key sudo yum install jenkins -y Configsudo vim /etc/sysconfig/jenkins Revise setting as JENKINS_USER=&quot;root&quot; sudo service jenkins start Set automatic startup when Server rebootsudo chkconfig jenkins on Config Jenkins on Browser Open the following link on Browserhttp://yourPublicDNS:8080 On server sudo cat /var/lib/jenkins/secrets/initialAdminPassword copy the password and paste it in order to login install suggested plugins Sign up your account Save and go ahead Go to ‘Jenkins management’ Install GitHub integration plugin Start a free style project Go to configuration Enter your project url Check ‘git’, and enter your Git Repository url check ‘GitHub hook trigger for GITScm polling’ Enter the shell script you likeIf you install jenkins on the machine where your project is installed: ssh -i /root/.ssh/yourKey.pem ec2-user@127.0.0.1 \"cd /var/www/html/yourProjectName;git reset @^ --hard;git pull;/usr/local/bin/composer install;php artisan migrate --force;\" Config GitHub Go to GitHub-&gt;setting build the webhook as follows:","link":"/implementCIWithJenkinsOnAWS/"},{"title":"Implement a transaction via PayPal Payment Standard and PayPal IPN Message","text":"IntroductionIf you’ve once tried PayPal Payment service, you should know that PayPal provides several ways for users to pay and receive paymentThose are included in this article: How to pay via PayPal Payment Standard How to validate the payment result via PayPal IPN Message With PayPal Payment Standard, how to submit several items with their names, unit prices, and quantities. In this article, the language I use is Laravel, the framework of PHP.Since this article basically is a record of a project I was working, there may be some parts that don’t have so much to do with payment service.You could skip those parts and start from ‘Make a payment order’ ValidationIt’s part of the whole process, and doesn’t have anything to do with payment service. You could just skip it.$toBeValidatedCondition = [ 'order_id' =&gt; 'required|array',];$failMessage = Helpers::validation($toBeValidatedCondition, $request);if ($failMessage) return Helpers::result(false, $failMessage, 400);if (!Helpers::checkIfIDExists($request, new Order(), 'order_id')) return Helpers::result(false, 'The orders doesn\\'t exist', 400);if (!Helpers::checkIfBelongToTheUser($request, new Order(), 'order_id')) return Helpers::result(false, 'The order doesn\\'t belong to this user', 400);$orders = Order::whereIn('id', $request-&gt;order_id)-&gt;get();if (Order::checkIfOrderPaid($orders)) return Helpers::result(false, 'The order has already been paid', 400);if (Order::checkIfOrderExpired($orders)) return Helpers::result(false, 'The order has expired', 400);if ($recipient-&gt;user_id !== User::getUserID($request)) return Helpers::result(false, 'The recipient doesn\\'t belong to the user', 400); Collect required information.When I was working, it seemed that I had more time than front end, lol, so I decided to take care as mush information as possible, managing to let front end do more things with the least information.$toBeSavedInfo = [ 'total_amount' =&gt; Order::getTotalAmountForPayments($orders), 'orders_name' =&gt; Order::getOrdersNameForPayments($orders), 'merchant_trade_no' =&gt; time() . Helpers::createAUniqueNumber(), 'merchant_trade_date' =&gt; date('Y/m/d H:i:s'), 'trade_desc' =&gt; 'BuyBuyGo', 'quantity' =&gt; 1, 'user_id' =&gt; User::getUserID($request), 'payment_service' =&gt; $thirdPartyPaymentService, 'expiry_time' =&gt; (new Carbon())-&gt;now()-&gt;addDay(1)-&gt;toDateTimeString(), 'orders' =&gt; $orders, 'mc_currency' =&gt; 'TWD', 'ClintBackURL' =&gt; $request-&gt;ClintBackURL]; Splitting pointSince I use two payment services in this project, so I need a place to determine where the request is from and should goswitch ($thirdPartyPaymentService-&gt;id)&#123; case 1: $error = (new AllPay)-&gt;make($toBeSavedInfo, $request, $recipient); if($error) return Helpers::result(false, $error,400); return (new AllPay())-&gt;send($toBeSavedInfo, $request); break; case 2: $error = (new PayPal)-&gt;make($toBeSavedInfo, $request, $recipient); if($error) return Helpers::result(false, $error, 400); $url = (new PayPal)-&gt;send($toBeSavedInfo, $request, $recipient); return Helpers::result(true, $url, 200); break;&#125; Make a payment orderWhenever the user call PAY API, a temporary order will be built, which is only between the seller and PayPal.Because I’m going to insert data into two tables at a time, we I am going to use Laravel’s Transaction to implement the data inserting work. If you are interested in Transaction of Laravel, you could refer to a short section in my another article, which I mentioned a bit.public function make(Array $toBeSavedInfo, Request $request, Recipient $recipient)&#123; DB::beginTransaction(); try &#123; $PayPal = new self(); $PayPal-&gt;user_id = $toBeSavedInfo['user_id']; $PayPal-&gt;payment_service_id = $toBeSavedInfo['payment_service']-&gt;id; $PayPal-&gt;expiry_time = $toBeSavedInfo['expiry_time']; $PayPal-&gt;merchant_trade_no = $toBeSavedInfo['merchant_trade_no']; $PayPal-&gt;total_amount = $toBeSavedInfo['total_amount']; $PayPal-&gt;trade_desc = $toBeSavedInfo['trade_desc']; $PayPal-&gt;item_name = $toBeSavedInfo['orders_name']; $PayPal-&gt;mc_currency = $toBeSavedInfo['mc_currency']; $PayPal-&gt;recipient_id = $recipient-&gt;id; $PayPal-&gt;save(); foreach ($toBeSavedInfo['orders'] as $order) &#123; $order_relations = new OrderRelations(); $order_relations-&gt;payment_service_id = $toBeSavedInfo['payment_service']-&gt;id; $order_relations-&gt;payment_service_order_id = $PayPal-&gt;id; $order_relations-&gt;order_id = $order-&gt;id; $order_relations-&gt;save(); &#125; &#125; catch (Exception $e) &#123; DB::rollBack(); return 'something went wrong with DB'; &#125; DB::commit();&#125; Make a URL for submitting the payment request to PayPalHere we will use a lot of variables of PayPal Payment Standard. You could refer to the usage of every of them from this articleBy the way, because when Ray doing this project, the front end’s schedule was a bit tighter than Ray, so Ray decided to handle as much information as possible. The backend will collect all those information from orders that have been built, and feed PayPal with those information. So basically the front end only has to let me know what orders the user want to pay.public function send(Array $toBeSavedInfo, Request $request, Recipient $recipient)&#123; $enableSandbox = env('PAYPAL_SANDBOX_ENABLESANDBOX'); $paypalUrl = $enableSandbox ? 'https://www.sandbox.paypal.com/cgi-bin/webscr' : 'https://www.paypal.com/cgi-bin/webscr'; $data = []; // Set PayPal account. You might need to apply test account of either seller or buyer via the link below. We will need to enter seller's account here, so whenever an order is paid, the payment will be automatically transferred into this account. // https://developer.paypal.com/developer/accounts/ $data['business'] = env('PAYPAL_SANDBOX_MAIL'); // Set the PayPal return addresses, after the transaction is completed, the user could be back via this URL. $data['return'] = $toBeSavedInfo['ClintBackURL']; // During the transaction process on PayPal's site, the user could cancel the transaction and go back via this URL. $data['cancel_return'] = env('PAYPAL_SANDBOX_CANCEL_URL'); // After the transaction is completed, PayPal will send IPN message to this URL. $data['notify_url'] = env('PAYPAL_SANDBOX_NOFITY_URL'); // Set the details about the products being purchased, including the price for every individual // and currency so that these aren't overridden by the form data. $i = 1; foreach ($toBeSavedInfo['orders'] as $order) &#123; $data[\"item_name_$i\"] = $order-&gt;item_name; $data[\"item_number_$i\"] = $order-&gt;quantity; $data[\"amount_$i\"] = $order-&gt;total_amount; $i++; &#125; // Here we specify the currency, you could refer to the supported currency from the link below // https://developer.paypal.com/docs/classic/api/currency_codes/ $data['currency_code'] = $toBeSavedInfo['mc_currency']; // Add any custom fields for the query string. We will pass this value to PayPal, and it will return along with IPN Message from PayPal. In this case, I pass the order number of payment order. $data['custom'] = $toBeSavedInfo['merchant_trade_no']; // Add recipient's information, and show it on paying process $data['address_override'] = 1; $data['country'] = $recipient-&gt;country_code; $data['city'] = $recipient-&gt;city; $data['address1'] = $recipient-&gt;others; $data['zip'] = $recipient-&gt;postcode; $data['first_name'] = $recipient-&gt;name; // This setting allow to add multiple items with IPN method $data['upload'] = '1'; $data['cmd'] = \"_cart\"; // Add charset $data['charset'] = 'utf-8'; // Build the query string from the data. $queryString = http_build_query($data); // Build the URL to PayPal $url = $paypalUrl . '?' . $queryString; return $url; &#125; Pay the payment The user reach the PayPal payment page via the URL we produced above. Please register test account via link here Reach payment page Here we could see the items in detail, including price and quantity. Click continue to go on Here we could see the shipping address we designated Transaction completed, and here we could see all the details Verify payment stateAfter the payment is completed, PayPal will send an IPN message to us. You could check the IPN in detail through the official document Firstly, let’s install PayPal’s official IPN CODE SAMPLES git clone https://github.com/paypal/ipn-code-samples In php directory cd ipn-code-samples/php And then, let’s copy PaypalIPN.php into our project, Ray personally put it under app Now, put the folder cert that is under ipn-code-samples also into app as image below: In composer.json file, search files under autoload-dev, and add PaypalIPN.php. If there is no files in your composer.json, you might need to create one yourself \"autoload-dev\": &#123; \"psr-4\": &#123; \"Tests\\\\\": \"tests/\" &#125;, \"files\": [ \"app/Helpers.php\", \"app/AllPay.Payment.Integration.php\", \"app/PaypalIPN.php\" ]&#125;, On terminal window, in our project folder, execute composer command composer install Now basically we have everything except for the one last step. Copy the content of example_usage_advanced.php into wherever you want. It could be one of your controllers, or a function under certain class as follows:The code below is a bit long. It should be almost the same as the original sample code except for some I put comment to, so you don’t have to go through every of them. public function listen(Request $request) &#123; // Since the offical sample is to catch $_POST, so I convert the request of Laravel into POST. You could modify it on your own. $_POST = $request-&gt;post(); // It shows if the payment is cleared. $payment_status = $_POST['payment_status']; // Remember the payment service order we passed to PayPal that I mentioned earlier $merchant_trade_no = $_POST['custom']; // Very important. We will use it later $txn_id = $_POST['txn_id']; $txn_type = $_POST['txn_type']; // When the payment is paid $payment_date = Carbon::parse($_POST['payment_date'])-&gt;setTimezone('UTC'); // The total amount $mc_gross = $_POST['mc_gross']; $mc_currency = $_POST['mc_currency']; $enable_sandbox = env('PAYPAL_SANDBOX_ENABLESANDBOX');// Use this to specify all of the email addresses that you have attached to paypal: $my_email_addresses = array(env('PAYPAL_SANDBOX_MAIL'));// Set this to true to send a confirmation email: $send_confirmation_email = env('PAYPAL_SANDBOX_SEND_CONFIRMATION_EMAIL'); $confirmation_email_address = \"buybuybuygogo@gmail.com\"; $from_email_address = \"test@gmail.com\";// Set this to true to save a log file: $save_log_file = env('PAYPAL_SANDBOX_SAVE_LOG_FILE'); $log_file_dir = storage_path() . \"/app/payment_logs\";// Here is some information on how to configure sendmail:// http://php.net/manual/en/function.mail.php#118210// Here is the function verifying the IPN message. $ipn = new PaypalIPN(); if ($enable_sandbox) &#123; $ipn-&gt;useSandbox(); &#125; $verified = $ipn-&gt;verifyIPN(); $data_text = \"\"; foreach ($_POST as $key =&gt; $value) &#123; $data_text .= $key . \" = \" . $value . \"\\r\\n\"; &#125; $test_text = \"\"; if ($_POST[\"test_ipn\"] == 1) &#123; $test_text = \"Test \"; &#125;// Check the receiver email to see if it matches your list of paypal email addresses $receiver_email_found = false; foreach ($my_email_addresses as $a) &#123; if (strtolower($_POST[\"receiver_email\"]) == strtolower($a)) &#123; $receiver_email_found = true; break; &#125; &#125; date_default_timezone_set(\"America/Los_Angeles\"); list($year, $month, $day, $hour, $minute, $second, $timezone) = explode(\":\", date(\"Y:m:d:H:i:s:T\")); $date = $year . \"-\" . $month . \"-\" . $day; $timestamp = $date . \" \" . $hour . \":\" . $minute . \":\" . $second . \" \" . $timezone; $dated_log_file_dir = $log_file_dir . \"/\" . $year . \"/\" . $month; $paypal_ipn_status = \"VERIFICATION FAILED\"; if ($verified) &#123; // When it passes the if below, it means that the IPN is verified, so we could do something after that. $paypal_ipn_status = \"RECEIVER EMAIL MISMATCH\"; if ($receiver_email_found) &#123; $paypal_ipn_status = \"Completed Successfully\"; $PayPal = (new PayPal())-&gt;where('merchant_trade_no', $merchant_trade_no)-&gt;first(); // Here we check a few things as follows: // 1. Check txd_id to prevent double processing some transaction that was previously processed. If this txd_id already exists in our database, we should ignore it. // 2. Check mc_gross, which should be exactly the same as the total amount in our payment service order. // 3. Check mc_currency to make sure it's the same as the one in our payment service order. // 4. Check payment_status to make sure that the transaction is completed. if ((!PayPal::checkIfTxnIdExists($txn_id)) &amp;&amp; ($mc_gross == $PayPal-&gt;total_amount) &amp;&amp; ($mc_currency == $PayPal-&gt;mc_currency) &amp;&amp; ($payment_status == 'Completed')) &#123; // Insert txd_id into the payment service order and update some values, which shows if this order is cleared or not. $PayPal-&gt;update(['txn_id' =&gt; $txn_id, 'txn_type' =&gt; $txn_type, 'payment_date' =&gt; $payment_date, 'status' =&gt; 1, 'expiry_time' =&gt; null]); $recipient = $PayPal-&gt;recipient; $orderRelations = $PayPal-&gt;orderRelations-&gt;where('payment_service_id', 2); // After updating the payment service order, we update the user order accordingly. Order::updateStatus($orderRelations, $recipient); // After everything is perfectly done, we send a notification mail to the buyer and seller Helpers::mailWhenPaid($PayPal, $orderRelations); &#125; &#125; &#125; elseif ($enable_sandbox) &#123; if ($_POST[\"test_ipn\"] != 1) &#123; $paypal_ipn_status = \"RECEIVED FROM LIVE WHILE SANDBOXED\"; &#125; &#125; elseif ($_POST[\"test_ipn\"] == 1) &#123; $paypal_ipn_status = \"RECEIVED FROM SANDBOX WHILE LIVE\"; &#125; if ($save_log_file) &#123; // Create log file directory if (!is_dir($dated_log_file_dir)) &#123; if (!file_exists($dated_log_file_dir)) &#123; mkdir($dated_log_file_dir, 0777, true); if (!is_dir($dated_log_file_dir)) &#123; $save_log_file = false; &#125; &#125; else &#123; $save_log_file = false; &#125; &#125; // Restrict web access to files in the log file directory $htaccess_body = \"RewriteEngine On\" . \"\\r\\n\" . \"RewriteRule .* - [L,R=404]\"; if ($save_log_file &amp;&amp; (!is_file($log_file_dir . \"/.htaccess\") || file_get_contents($log_file_dir . \"/.htaccess\") !== $htaccess_body)) &#123; if (!is_dir($log_file_dir . \"/.htaccess\")) &#123; file_put_contents($log_file_dir . \"/.htaccess\", $htaccess_body); if (!is_file($log_file_dir . \"/.htaccess\") || file_get_contents($log_file_dir . \"/.htaccess\") !== $htaccess_body) &#123; $save_log_file = false; &#125; &#125; else &#123; $save_log_file = false; &#125; &#125; if ($save_log_file) &#123; // Save data to text file file_put_contents($dated_log_file_dir . \"/\" . $test_text . \"paypal_ipn_\" . $date . \".txt\", \"paypal_ipn_status = \" . $paypal_ipn_status . \"\\r\\n\" . \"paypal_ipn_date = \" . $timestamp . \"\\r\\n\" . $data_text . \"\\r\\n\", FILE_APPEND); &#125; &#125; if ($send_confirmation_email) &#123; // Send confirmation email mail($confirmation_email_address, $test_text . \"PayPal IPN : \" . $paypal_ipn_status, \"paypal_ipn_status = \" . $paypal_ipn_status . \"\\r\\n\" . \"paypal_ipn_date = \" . $timestamp . \"\\r\\n\" . $data_text, \"From: \" . $from_email_address); &#125;// Reply with an empty 200 response to indicate to paypal the IPN was received correctly header(\"HTTP/1.1 200 OK\"); &#125; ConclusionAbove mentioned is the whole process of using PayPal Payment Standard and PayPal IPN Message to complete a transaction.Here is breakdown of every individual step: A user clicks a PayPal button to kick off a checkout flow; your web application makes an API call; your back-office system makes an API call; or PayPal observes an event. PayPal HTTPS POSTs your listener an IPN message that notifies you of this event. Your listener returns an empty HTTP 200 response. Your listener HTTPS POSTs the complete, unaltered message back to PayPal. PayPal sends a single word back - either VERIFIED (if the message matches the original) or INVALID (if the message does not match the original).","link":"/implementATransactionViaPayPalIPN/"},{"title":"Import data into MySQL from CSV via PHP script","text":"Hello everyone. My name is Ray. I would like to share how to import data from CSV file into MySQL database via PHP scriptFirstly, take a look on the screenshot of CSV file below: Take a look on the PHP script below. Please put them in the same repository. &lt;?php// Connect to the database$dbc = mysqli_connect('Your location', 'Your MySQL user_name', 'Your MySQL password', 'Your Database Name'); // Set the charset to utf8mysqli_set_charset($dbc,\"utf8\");// Read the data$handle = fopen(\"The file name.csv\", \"r\");// Set $i = 0 for further usage$i=0;// Use fgetcsv function along with while loop to get all of the rows in the filewhile (($data = fgetcsv($handle, 1000, ',')))&#123; // Since the first line in the file is column name, // so we are going to skip the first line. // When $i = 0, it should be in the first line, // it gets into the if function, // and the continue skip all the codes afterwards // and get back to the top of the loop, // and in this round the $i = 1. So it will not get into if function, // only skip the first line that we don't want. if($i == 0) &#123; $i++; continue; &#125;// As shown on the image of csv, there is a string \"NaN\" on the rainfall column.// If we want to set the data type of this column as float or decimal,// we should take care of this string before inserting into the database.// So we use condition sentence to replace 'NaN' with 0,// and then it will not cause any problem when inserting data into this// column with data type as either float or decimal. if($data[2] == 'NaN') &#123; $data[2] = 0; &#125; // Finally, we insert the data into our database. $query = 'INSERT INTO rainfall (district, date, rainfall)VALUES (\"'.$data[0] . '\", \"' . $data[1] . '\", \"' . $data[2].'\")'; echo $query; $result = mysqli_query($dbc, $query); if ($result == false) &#123; echo 'Error description &lt;br/&gt;' . mysqli_error($dbc); &#125;&#125;?&gt; Finally, execute the script in terminal, php -f scriptName, and here you go!￼","link":"/importDataFromCSVIntoMySQLDatabaseViaPHP/"},{"title":"Automatically sign and renew SSL cert with Let's Encrypt","text":"ReferenceLet’s Encrypt Web","link":"/letsencrypt/"},{"title":"Logging with Stackdriver on Kubernetes Engine","text":"Refer to QWIKLABS","link":"/loggingWithStackdriverOnKubernetesEngine/"},{"title":"Monitoring and Logging for Cloud Functions","text":"Refer to QWIKLABS","link":"/monitoringAndLoggingForCloudFunctions/"},{"title":"My learning note on MySQL","text":"IntroductionSince it’s a unorganised learning note, I’m sorry that there may not be a English version.","link":"/mysql/"},{"title":"pm2 - My learning note","text":"IntroductionWhat’s pm2? pm2 is a process manager of Node.js What does pm2 solve? pm2 can re-launch Node service after it crashes. pm2 can re-launch Node service after the server reboot pm2 can run multiple processes with multiple cores of CPU to achieve Load Balancer like effect. It features kind of rolling update, 0 downtime upgrade with Graceful Reload Multiple services with multiple processes, significantly boost the performance. Schedule to restart periodically pm2 provides much information, including restart number, CPU usage, memory usage, process id, etc. pm2 allows auto-restart under specific condition, such as ‘up-time’, ‘memory usage’, etc. pm2 can organise log, periodically split the log and keep the number we specify, delete exceeded ones. pm2 provides simple deployment method, and support multiple server deployment pm2 can integrate with CI / CD tool, as well as CI / CD deployment What are you waiting for? Here are the coverage of this article: Installation pm2 with CLI pm2 with ecosystem pm2 with ecosystem on deployment pm2 deployment with GitLab CI / CD Runner installation Global installationnpm install pm2@latest -g pm2 with CLILaunch node project with pm2 with CLI, see the example below:pm2 start location/fileName.js --name appName \\--watch true \\--max-memory-restart 500M \\--log ~/.pm2/logs/appName/ \\--time true \\--cron \"0 17 * * *\" \\--no-daemon true \\--merge-logs As to the meaning of CLI mentioned above, refer to the followings The flag --nameSpecify an app name --watchWatch and Restart app when files change --max-memory-restartSet memory threshold for app reload --logSpecify log file --outputspecify out log file --errorspecify error log file --log-date-formatprefix logs with custom formated timestamp --merge-logswhen running mutiple process with same app name, do not split file by id --arg1 --arg2 --arg3Pass extra arguments to the script --restart-delayDelay between automatic restarts --timePrefix logs with time --no-autorestartDo not auto restart app --cronSpecify cron for forced restart --no-daemonAttach to application log cluster mode pm2 automatically detect the number of CPU, launching as many processes as possible. The above mentioned flags could be attached on cluster mode. Specify how many process you would like after -i. pm2 would automatically detect max number if you put 0 or maxpm2 start app.js -i max Process management Kill the process directly and restart a new process pm2 restart app_name If it’s cluster mode, reload would reload process one by one and always keep one alive to achieve 0 downtime upgrade pm2 reload app_name Stop the app pm2 stop app_name Stop and delete the app pm2 delete app_name except for specifying app_name, you could also:all : all the Appsid : the id of the process Show the status of managementpm2 [list|ls|status] Logs specify filepath to output both out and error logs pm2 logs Display X lines of api log file pm2 logs --lines 200 Show logs at specified App id pm2 logs id Formatted output pm2 logs --format Output logs in json format pm2 logs --json Empty all log files pm2 flush Cancel logsBy specifying log path to dev/null, you could cancel log Rotated LogIf you’ve ever seen a single extremely big file with years of log, or you’ve ever found thousands of log files in a log folder, or you’ve ever come across weird log file naming, or you found a considerably huge amount consumed after you type du -sh in a folder, congratulations! Here is the solution. Installationpm2 install pm2-logrotate Find the config file at /home/user/.pm2/module_conf.jsonParameters max_size (Defaults to 10M):When a file size becomes higher than this value it will rotate it (its possible that the worker check the file after it actually pass the limit) . You can specify the unit at then end: 10G, 10M, 10K retain (Defaults to 30 file logs):This number is the number of rotated logs that are keep at any one time, it means that if you have retain = 7 you will have at most 7 rotated logs and your current one. compress (Defaults to false):Enable compression via gzip for all rotated logs dateFormat (Defaults to YYYY-MM-DD_HH-mm-ss) :Format of the data used the name the file of log rotateModule (Defaults to true) :Rotate the log of pm2’s module like other apps workerInterval (Defaults to 30 in secs) :You can control at which interval the worker is checking the log’s size (minimum is 1) rotateInterval (Defaults to 0 0 * everyday at midnight):This cron is used to a force rotate when executed. We are using node-schedule to schedule cron, so all valid cron for node-schedule is valid cron for this option. Cron style : TZ (Defaults to system time):This is the standard tz database timezone used to offset the log file saved. For instance, a value of Etc/GMT-1, with an hourly log, will save a file at hour 14 GMT with hour 13 GMT-1 in the log name. Graph* * * * * *┬ ┬ ┬ ┬ ┬ ┬│ │ │ │ │ |│ │ │ │ │ └ day of week (0 - 7) (0 or 7 is Sun)│ │ │ │ └───── month (1 - 12)│ │ │ └────────── day of month (1 - 31)│ │ └─────────────── hour (0 - 23)│ └──────────────────── minute (0 - 59)└───────────────────────── second (0 - 59, OPTIONAL) Terminal Based Dashboardpm2 monit pm2 ecosystemCLI tool is good though, typo is so difficult to be eliminated. We could easily solve this problem by carefully crafting our ecosystem file. Except that some configs are meant to be changed in the future, we could eliminate typo issue. Besides, ecosystem cloud be controlled by Version Control System, like Git. Generate ecosystem filepm2 ecosystem CLISame as above mentioned.pm2 start ecosystem.config.js Start specific App via ecosystem fileWe could start specific App that we’d crafted in the ecosystem.config.js file.pm2 start ecosystem.config.js --only yourApp Parameter injectionTake a look on the following example. If I key in pm2 start ecosystem --only app1 --env production, then pm2 wil use the environment within env_production object. Parameter exampleYou could find tons of parameters below. Surely we are not going to use all of them, you could take a look on each of them and only leave those you need.module.exports = &#123; apps: [ // First application &#123; // application name (default to script filename without extension) name: 'app1', // script path relative to pm2 start script: './server.js', // the directory from which your app will be launched cwd: 'var/www/yourApp/', // mode to start your app, can be “cluster” or “fork”, default fork exec_mode: 'cluster', // number of app instance to be launched instances: 0, // enable watch &amp; restart feature, if a file change in the folder or subfolder, your app will get reloaded watch: false, // your app will be restarted if it exceeds the amount of memory specified. human-friendly format : it can be “10M”, “100K”, “2G” and so on… max_memory_restart: '500M', // interpreter absolute path (default to node) interpreter: '/root/.nvm/versions/node/v8.16.0/bin/node', // option to pass to the interpreter interpreter_args: \"port=3001 sitename='first pm2 app'\", // alias to interpreter_args node_args: \"port=3001 sitename='first pm2 app'\", // Specify cron for forced restart cron_restart: \"0 17 * * *\", // Prefix logs with time time: true, // string containing all arguments passed via CLI to script args: '-a 13 -b 12', // list of regex to ignore some file or folder names by the watch feature // Format could be array like \"args\": [\"--toto=heya coco\", \"-d\", \"1\"], or string like \"args\": \"--to='heya coco' -d 1\" ignore_watch: [\"[\\/\\\\]\\./\", \"node_modules\"], // default to true, [enable/disable source map file] // http://pm2.keymetrics.io/docs/usage/source-map-support/ // https://www.html5rocks.com/en/tutorials/developertools/sourcemaps/ source_map_support: true, // instance_var, see documentation // http://pm2.keymetrics.io/docs/usage/environment/#specific-environment-variables instance_var: 'NODE_APP_INSTANCE', // log date format (see log section) log_date_format: 'YYYY-MM-DD HH:mm Z', // error file path (default to $HOME/.pm2/logs/XXXerr.log) error_file: '/var/log', // output file path (default to $HOME/.pm2/logs/XXXout.log) out_file: '/var/log', // if set to true, avoid to suffix logs file with the process id combine_logs: true, // alias to combine_logs merge_logs: true, // pid file path (default to $HOME/.pm2/pid/app-pm_id.pid) pid_file: 'user/.pm2/pid/app-pm_id.pid', // min uptime of the app to be considered started // format could be number 或 string. In number, 3000 means 3000 ms. If it's string, '1h' means 1 hour, '5m' means 5 minutes, '10s' means 10 seconds min_uptime: '5', // time in ms before forcing a reload if app not listening listen_timeout: 8000, // time in milliseconds before sending a final SIGKILL // Refer to official documentation http://pm2.keymetrics.io/docs/usage/signals-clean-restart/ kill_timeout: 1600, // Instead of reload waiting for listen event, wait for process.send(‘ready’) // Refer to documentation http://pm2.keymetrics.io/docs/usage/signals-clean-restart/ wait_ready: false, // number of consecutive unstable restarts (less than 1sec interval or custom time via min_uptime) before your app is considered errored and stop being restarted // Refer to documentation http://pm2.keymetrics.io/docs/usage/signals-clean-restart/ max_restarts: 10, // time to wait before restarting a crashed app (in milliseconds). defaults to 0. restart_delay: 4000, // true by default. if false, PM2 will not restart your app if it crashes or ends peacefully autorestart: true, // true by default. if false, PM2 will start without vizion features (versioning control metadatas) vizion: true, // a list of commands which will be executed after you perform a Pull/Upgrade operation from Keymetrics dashboard post_update: [\"npm install\", \"echo launching the app\"], // defaults to false. if true, you can start the same script several times which is usually not allowed by PM2 force: false, // If no environment parameters are passed in, the default env will be within `env` object env: &#123; COMMON_VARIABLE: 'true', NODE_ENV: '', ID: '44' &#125;, // If env is specified, env parameter will be within `env_specifiedEnvironment` object, for example, pm2 start ecosystem.js --env production env_production: &#123; NODE_ENV: 'production', ID: '55' &#125;, // Same as above env_development: &#123; NODE_ENV: 'development' &#125; &#125;, // Second app, those mentioned above will not be repeated below &#123; name: 'app2', script: 'server.js', // Default mode, and it supports other languages as opposed to cluster mode. exec_mode: 'fork', instances: 0, watch: false, max_memory_restart: '500M', interpreter: '/root/.nvm/versions/node/v8.16.0/bin/node', time: true, env: &#123; COMMON_VARIABLE: 'true', NODE_ENV: '' &#125;, env_staging: &#123; NODE_ENV: 'staging' &#125;, env_test: &#123; NODE_ENV: 'test' &#125; &#125; ], // Deployment section deploy: &#123; // production production: &#123; // SSH user user: 'root', // SSH host host: ['host1', 'host2'], // SSH key path key: 'path/to/some.pem', // GIT remote/branch ref: 'origin/master', // GIT remote repo: 'git@gitlab.com:user/yourProject.git', // path in the server path: '/var/www/yourProjectName', // Can be used to give options in the format used in the // configuration file. // This is useful for specifying options for which there // is no separate command-line flag, see 'man ssh' can be // either a single string or an array of strings \"ssh_options\": \"StrictHostKeyChecking=no\", // 在 pm2 要從 local 端連到 remote 端之前要執行的指令，可以多個指令，由 ; 分割，也可以指定 shell script 的檔案路徑 \"pre-setup\": 'apt update -y; apt install git -y', // To prepare the host by installing required software (eg: git) // even before the setup process starts // can be multiple commands separated by the character \";\" // or path to a script on your local machine \"post-setup\": \"ls -la\", // Commands to execute locally (on the same machine you deploy things) // Can be multiple commands separated by the character \";\" \"pre-deploy-local\" : \"echo 'This is a local executed command'\", // Commands to be executed on the server after the repo has been cloned 'post-deploy': 'sudo /root/.nvm/versions/node/v8.16.0/bin/npm install &amp;&amp; sudo /root/.nvm/versions/node/v8.16.0/bin/npm rebuild &amp;&amp; /root/.nvm/versions/node/v8.16.0/bin/pm2 reload ecosystem.config.js', // Environment variables that must be injected in all applications on this env env_production: &#123; NODE_ENV: 'production' &#125; &#125;, staging: &#123; user: 'root', host: ['host3', 'host4'], ref: 'origin/staging', repo: 'git@gitlab.com:user/yourProject.git', path: '/var/www/yourProjectName', \"ssh_options\": \"StrictHostKeyChecking=no\", \"pre-setup\": 'apt update -y; apt install git -y', \"post-setup\": \"ls -la\", \"pre-deploy-local\" : \"echo 'This is a local executed command'\", 'post-deploy': 'sudo /root/.nvm/versions/node/v8.16.0/bin/npm install &amp;&amp; sudo /root/.nvm/versions/node/v8.16.0/bin/npm rebuild &amp;&amp; /root/.nvm/versions/node/v8.16.0/bin/pm2 reload ecosystem.config.js', env_production: &#123; NODE_ENV: 'staging' &#125; &#125;, &#125;,&#125;; pm2 Deploymentpm2 Deployment supports multiple server deployment, also, which could integrate with CI / CD tool, automatically deploy after submitting a commit. Prerequisite Firstly, have you prepared the ssh key for local to remote? The connection between local and remote is required. Simply speaking, you need to put a private key locally, and put public key remotely. You could Google how to set up ssh key. Secondly, since pm2 will ssh to remote server, and then clone our project from either GitHub or Gitlab. So make sure that cloning from Git Repository to remote server is feasible. You will need to put a private key on your remote server, and the public key on Git Repository. Please also Google how to set up the key on GitHub or GitLab Since the first time we connect to remote server, ssh would prompt to ask if it’s okay to put the public key of remote server to local known host, we will need to config it in advance. Otherwise, the deployment would fail. We could cancel the hostKeyChecking feature. echo -e \"Host *\\n\\tStrictHostKeyChecking no\\n\\n\" &gt; ~/.ssh/config And then, we need to properly craft ecosystem file, let’s refer to the deploy example above. Finally, make sure ssh tunnel is not blocked (default port 22) Initialise remote folderBefore deploying, we need to set up the project on remote server. We could pass different parameters and pm2 would deploy accordingly.pm2 deploy ecosystem.config.js production setup Deploy DeployAfter initially setting up our project on remote server, we could start to deploy. pm2 deploy ecosystem.config.js production Here I’ve listed some parameters as follows, and you could also check details by pm2 deploy help pm2 deploy &lt;configuration_file&gt; &lt;environment&gt; &lt;command&gt; Commands: setup run remote setup commands update update deploy to the latest release revert [n] revert to [n]th last deployment or 1 curr[ent] output current release commit prev[ious] output previous release commit exec|run &lt;cmd&gt; execute the given &lt;cmd&gt; list list previous deploy commits [ref] deploy to [ref], the \"ref\" setting, or latest tag Relative commands of Deployment pm2 startOrRestart all.json # Invoke restart on all apps in JSONpm2 startOrReload all.json # Invoke reload Force deploymentThat means that you have changes in your local system that aren’t pushed inside your git repository, and since the deploy script get the update via git pull they will not be on your server. If you want to deploy without pushing any data, you can append the –force option: pm2 deploy ecosystem.json production --force CI / CD Deployment Implement deployment by integrating pm2 with GitLab CI / CD Runner, and here is the gitlab.yml example below: # Use small-size imageimage: keymetrics/pm2:latest-alpinestages:- deployDeploy: stage: deploy script: # If ssh-agent hasn't been installed, install it. - 'which ssh-agent || ( apk add --update openssh )' # Install bash for pm2 CLI - apk add --update bash # Install Git for connecting to remote server with pm2 - apk add --update git # Implement ssh agent - eval $(ssh-agent -s) # Add ssh key to ssh agent. You could config the public key as GitLab's variable. - echo \"$SSH_PRIVATE_KEY\" | ssh-add - # Execute pm2 CLI - pm2 deploy ecosystem.config.js production update only: - master If you set it properly, a simple git push would trigger the CI / CD deployment Auto start after reboot Generate startup script pm2 startup Cancel startup script pm2 unstartup Save the current process for next default startup pm2 save 如果有更新 node 的版本，記得更新 script If you upgrade your node, udpate your script as wellpm2 unstartup &amp;&amp; pm2 startup &amp;&amp; pm2 save Reload after when content changesMonitor files under the project folder and subfolder, and ignore node_modulecd /path/to/my/apppm2 start env.js --watch --ignore-watch=\"node_modules\" update pm2npm install pm2@latest -g &amp;&amp; pm2 update pm2 cheat sheet# Fork modepm2 start app.js --name my-api # Name process# Cluster modepm2 start app.js -i 0 # Will start maximum processes with LB depending on available CPUspm2 start app.js -i max # Same as above, but deprecated.pm2 scale app +3 # Scales `app` up by 3 workerspm2 scale app 2 # Scales `app` up or down to 2 workers total# Listingpm2 list # Display all processes statuspm2 jlist # Print process list in raw JSONpm2 prettylist # Print process list in beautified JSONpm2 describe 0 # Display all informations about a specific processpm2 monit # Monitor all processes# Logspm2 logs [--raw] # Display all processes logs in streamingpm2 flush # Empty all log filespm2 reloadLogs # Reload all logs# Actionspm2 stop all # Stop all processespm2 restart all # Restart all processespm2 reload all # Will 0s downtime reload (for NETWORKED apps)pm2 stop 0 # Stop specific process idpm2 restart 0 # Restart specific process idpm2 delete 0 # Will remove process from pm2 listpm2 delete all # Will remove all processes from pm2 list# Miscpm2 reset &lt;process&gt; # Reset meta data (restarted time...)pm2 updatePM2 # Update in memory pm2pm2 ping # Ensure pm2 daemon has been launchedpm2 sendSignal SIGUSR2 my-app # Send system signal to scriptpm2 start app.js --no-daemon # Do not run in the backgroundpm2 start app.js --no-vizion # By default, as well as ssh key is okay, pm2 would compare local and remote when restarting, and automatically pull the latest.pm2 start app.js --no-autorestart # Do not auto restart Auto completion pm2 command support auto completionpm2 completion install 疑難雜症 Encounter Error: ENOENT: no such file or directory, uv_cwd Refer here參考資料pm2 官網pm2 logrotate","link":"/pm2/"},{"title":"My learning journey on Sequelize","text":"IntroductionThis page is my learning note on Sequelize, and it’s unorganised, so currently there is no English version.","link":"/sequelize/"},{"title":"My learning note on SSH","text":"IntroductionThis page is my learning note on SSH, and it’s unorganised, so currently there is no English version.","link":"/ssh/"},{"title":"Deploy Supervisor on AWS and MacOS","text":"IntroductionHere are what this article is going to cover: Deploy Supervisor on MacOS Deploy Supervisor on AWS What is Supervisor?Supervisor is a process monitor and control system. Because Ray do use Laravel Queue on a project, and queue worker has to be running on the background continuously. So what if the queue work fails and disconnect? With Supervisor, we will be able to restart them after they either fail or close. Mac OSInstall Install Supervisorbrew install supervisor Deployment Enter the default configuration file sudo vim /usr/local/etc/supervisord.ini Change the default include directory at the end as follows: [include]files = /usr/local/etc/supervisor.d/*.conf Add a customized directory and configuration file mkdir /usr/local/etc/supervisor.d;vim /usr/local/etc/supervisor.d/processNameYouLike.conf; Give the setting below [program:programNameYouLike]process_name=%(program_name)s_%(process_num)02dcommand=php absoluteAddressOfYourProject/artisan queue:work sqs --sleep=3 --tries=3 --daemonautostart=trueautorestart=trueuser=raynumprocs=8redirect_stderr=truestdout_logfile=/absoluteAddressOfLocationYouWouldLikeToPutTheLog/worker.log Launch Launch the service sudo supervisord -c /usr/local/etc/supervisord.ini Go into service control sudo supervisorctl -c /usr/local/etc/supervisord.ini Update the configuration update Check the status status It should look like that AWSHere is the specification of the instance we use Amazon Linux 2 AMI (HVM), SSD Volume Type - ami-0f9ae750e8274075b t2.micro (Variable ECUs, 1 vCPUs, 2.5 GHz, Intel Xeon Family, 1 GiB memory, EBS only) Install Install Supervisorsudo yum install -y supervisor Configuration Go to the default configuration file sudo vim /etc/supervisord.conf Change the include directory at the end [include]files = supervisord.d/*.conf Add a new configuration file. If the directory doesn’t exist, then make one. sudo mkdir /etc/supervisord.d;sudo vim /etc/supervisord.d/projectFileNameYouLike.conf Give the setting. [program:laravel-worker]process_name=%(program_name)s_%(process_num)02dcommand=sudo php absoluteAddressOfYourProject/artisan queue:work sqs --sleep=3 --tries=3 --daemonautostart=trueautorestart=trueuser=rootnumprocs=8redirect_stderr=truestdout_logfile=absoluteAddressOfYourProject/worker.log Launch Launch Supervisor sudo supervisord -c /etc/supervisord.conf Apply new setting and check the status sudo supervisorctl update;sudo supervisorctl status Automatic start after system reboot Add a new configuration of restart Supervisor sudo vim /etc/init.d/supervisord Give the setting as follows: #! /bin/sh### BEGIN INIT INFO# Provides: supervisord# Required-Start: $remote_fs# Required-Stop: $remote_fs# Default-Start: 2 3 4 5# Default-Stop: 0 1 6# Short-Description: Example initscript# Description: This file should be used to construct scripts to be# placed in /etc/init.d.### END INIT INFO# Author: Dan MacKinlay &lt;danielm@phm.gov.au&gt;# Based on instructions by Bertrand Mathieu# http://zebert.blogspot.com/2009/05/installing-django-solr-varnish-and.html# Do NOT &quot;set -e&quot;# PATH should only include /usr/* if it runs after the mountnfs.sh scriptPATH=/sbin:/usr/sbin:/bin:/usr/binDESC=&quot;Description of the service&quot;NAME=supervisordDAEMON=/usr/local/bin/supervisordDAEMON_ARGS=&quot;&quot;PIDFILE=/var/run/$NAME.pidSCRIPTNAME=/etc/init.d/$NAME# Exit if the package is not installed[ -x &quot;$DAEMON&quot; ] || exit 0# Read configuration variable file if it is present[ -r /etc/default/$NAME ] &amp;&amp; . /etc/default/$NAME# Load the VERBOSE setting and other rcS variables. /lib/init/vars.sh# Define LSB log_* functions.# Depend on lsb-base (&gt;= 3.0-6) to ensure that this file is present.. /lib/lsb/init-functions## Function that starts the daemon/service#do_start()&#123; # Return # 0 if daemon has been started # 1 if daemon was already running # 2 if daemon could not be started start-stop-daemon --start --quiet --pidfile $PIDFILE --exec $DAEMON --test &gt; /dev/null \\ || return 1 start-stop-daemon --start --quiet --pidfile $PIDFILE --exec $DAEMON -- \\ $DAEMON_ARGS \\ || return 2 # Add code here, if necessary, that waits for the process to be ready # to handle requests from services started subsequently which depend # on this one. As a last resort, sleep for some time.&#125;## Function that stops the daemon/service#do_stop()&#123; # Return # 0 if daemon has been stopped # 1 if daemon was already stopped # 2 if daemon could not be stopped # other if a failure occurred start-stop-daemon --stop --quiet --retry=TERM/30/KILL/5 --pidfile $PIDFILE --name $NAME RETVAL=&quot;$?&quot; [ &quot;$RETVAL&quot; = 2 ] &amp;&amp; return 2 # Wait for children to finish too if this is a daemon that forks # and if the daemon is only ever run from this initscript. # If the above conditions are not satisfied then add some other code # that waits for the process to drop all resources that could be # needed by services started subsequently. A last resort is to # sleep for some time. start-stop-daemon --stop --quiet --oknodo --retry=0/30/KILL/5 --exec $DAEMON [ &quot;$?&quot; = 2 ] &amp;&amp; return 2 # Many daemons don&apos;t delete their pidfiles when they exit. rm -f $PIDFILE return &quot;$RETVAL&quot;&#125;## Function that sends a SIGHUP to the daemon/service#do_reload() &#123; # # If the daemon can reload its configuration without # restarting (for example, when it is sent a SIGHUP), # then implement that here. # start-stop-daemon --stop --signal 1 --quiet --pidfile $PIDFILE --name $NAME return 0&#125;case &quot;$1&quot; in start) [ &quot;$VERBOSE&quot; != no ] &amp;&amp; log_daemon_msg &quot;Starting $DESC&quot; &quot;$NAME&quot; do_start case &quot;$?&quot; in 0|1) [ &quot;$VERBOSE&quot; != no ] &amp;&amp; log_end_msg 0 ;; 2) [ &quot;$VERBOSE&quot; != no ] &amp;&amp; log_end_msg 1 ;; esac ;; stop) [ &quot;$VERBOSE&quot; != no ] &amp;&amp; log_daemon_msg &quot;Stopping $DESC&quot; &quot;$NAME&quot; do_stop case &quot;$?&quot; in 0|1) [ &quot;$VERBOSE&quot; != no ] &amp;&amp; log_end_msg 0 ;; 2) [ &quot;$VERBOSE&quot; != no ] &amp;&amp; log_end_msg 1 ;; esac ;; #reload|force-reload) # # If do_reload() is not implemented then leave this commented out # and leave &apos;force-reload&apos; as an alias for &apos;restart&apos;. # #log_daemon_msg &quot;Reloading $DESC&quot; &quot;$NAME&quot; #do_reload #log_end_msg $? #;; restart|force-reload) # # If the &quot;reload&quot; option is implemented then remove the # &apos;force-reload&apos; alias # log_daemon_msg &quot;Restarting $DESC&quot; &quot;$NAME&quot; do_stop case &quot;$?&quot; in 0|1) do_start case &quot;$?&quot; in 0) log_end_msg 0 ;; 1) log_end_msg 1 ;; # Old process is still running *) log_end_msg 1 ;; # Failed to start esac ;; *) # Failed to stop log_end_msg 1 ;; esac ;; *) #echo &quot;Usage: $SCRIPTNAME &#123;start|stop|restart|reload|force-reload&#125;&quot; &gt;&amp;2 echo &quot;Usage: $SCRIPTNAME &#123;start|stop|restart|force-reload&#125;&quot; &gt;&amp;2 exit 3 ;;esac: script source Add execute authority sudo chmod +x /etc/init.d/supervisord Add the configuration into system sudo chkconfig --add supervisord Switch on the configuration and start sudo chkconfig supervisord onsudo service supervisord start ConclusionAfter the configuration, whenever AWS is rebooted, Supervisor will automatically restart","link":"/supervisor/"},{"title":"Add multiple items on PayPal IPN method","text":"IntroductionIn this article, we are going to share how to add multiple items in PayPal’s IPN methodThis page is just a clone from the official website, and I clone it because I am lazy to look for it again whenever I need it in the future. BeginsSome web developers may wish to integrate PayPal payment processing with their own 3rd party shopping cart instead of the standard PayPal Shopping Cart. Please use the instructions below to allow your buyers to pay with PayPal when they are ready to check out after adding all of their items to your 3rd party shopping cart. There are now two ways to integrate your 3rd party shopping cart with the PayPal payment flow. The first is to pass in the aggregate amount of the Cart payment, rather than of the individual items. The second is to pass details of the items that have been selected to PayPal, instead of an aggregated amount for the entire Cart. Note: Posting the necessary variables to PayPal as described below will probably require you to implement some scripting on your website. Method 1. Passing the Aggregate Cart Amount to PayPal Method 2. Passing Individual Items to PayPal Method 1. Passing the Aggregate Cart Amount to PayPalIf you wish, you may aggregate your entire shopping cart and pass the total amount into PayPal’s Buy Now Button code (that is, you will need to post a single name for the entire cart and the total price of the cart’s contents as though it were a purchase of a single item). One drawback of this method is that your buyers will not be able to see the individual items appearing in their carts. In addition, you cannot change our variable names, nor can you add your own variable names. If you have additional technical questions after reviewing the information below, please visit our Developer Support area. For additional information about Buy Now Buttons code or the variables below, please see the Website Payments Standard Integration Guide. Required VariablesThe code for your PayPal post requires the following 4 hidden variables and an image as the form submit: Name Value business Email address on your PayPal account item_name Name of the item (or a name for the shopping cart) currency_code Defines the currency in which the monetary variables (amount, shipping, shipping2, handling, tax) are denoted. Possible values are “USD”, “EUR”, “GBP”, “CAD”, “JPY”. amount Price of the item (the total price of all items in the shopping cart) image The image for the button your buyer will press to initiate the PayPal payment process. You can substitute your own image by replacing the src with the URL of your image This means that the minimum required code for your post to PayPal will look like this &lt;form action=\"https://www.paypal.com/cgi-bin/webscr\" method=\"post\"&gt;&lt;input type=\"hidden\" name=\"cmd\" value=\"_xclick\"&gt;&lt;input type=\"hidden\" name=\"business\" value=\"you@youremail.com\"&gt;&lt;input type=\"hidden\" name=\"item_name\" value=\"Item Name\"&gt;&lt;input type=\"hidden\" name=\"currency_code\" value=\"USD\"&gt;&lt;input type=\"hidden\" name=\"amount\" value=\"0.00\"&gt;&lt;input type=\"image\" src=\"http://www.paypal.com/en_US/i/btn/x-click-but01.gif\" name=\"submit\" alt=\"Make payments with PayPal - it's fast, free and secure!\"&gt;&lt;/form&gt; PayPal offers additional variables to customize your form post. All of the available variables are listed below (variable names must be in lower case): Name Value business Email address on your PayPal account quantity Number of items. This will multiply the amount if greater than one item_name Name of the item (or a name for the shopping cart). Must be alpha-numeric, with a 127character limit item_number Optional pass-through variable for you to track payments. Must be alpha-numeric, with a 127 character limit amount Price of the item (the total price of all items in the shopping cart) shipping The cost of shipping the item shipping2 The cost of shipping each additional item handling The cost of handling tax Transaction-based tax value. If present, the value passed here will override any profile tax settings you may have (regardless of the buyer’s location). no_shipping Shipping address. If set to “1,” your customer will not be asked for a shipping address. This is optional; if omitted or set to “0,” your customer will be prompted to include a shipping address cn Optional label that will appear above the note field (maximum 40 characters) no_note Including a note with payment. If set to “1,” your customer will not be prompted to include a note. This is optional; if omitted or set to “0,” your customer will be prompted to include a note. on0 First option field name. 64 character limit os0 First set of option value(s). 200 character limit. “on0” must be defined for “os0” to be recognized. on1 Second option field name. 64 character limit os1 Second set of option value(s). 200 character limit. “on1” must be defined for “os1” to be recognized. custom Optional pass-through variable that will never be presented to your customer. Can be used to track inventory invoice Optional pass-through variable that will never be presented to your customer. Can be used to track invoice numbers notify_url Only used with IPN. An internet URL where IPN form posts will be sent return An internet URL where your customer will be returned after completing payment cancel_return An internet URL where your customer will be returned after cancelling payment image_url The internet URL of the 150 X 50 pixel image you would like to use as your logo cs Sets the background color of your payment pages. If set to “1,” the background color will be black. This is optional; if omitted or set to “0,” the background color will be white Extended VariablesPayPal allows you to post extended variables if you change this “cmd” input: &lt;input type=&quot;hidden&quot; name=&quot;cmd&quot; value=&quot;_xclick&quot;&gt; to:&lt;input type=&quot;hidden&quot; name=&quot;cmd&quot; value=&quot;_ext-enter&quot;&gt;&lt;input type=&quot;hidden&quot; name=&quot;redirect_cmd&quot; value=&quot;_xclick&quot;&gt; By making the above change to the “cmd” input, you can also use the variables below: Name Value email Customer’s email address first_name Customer’s first name. Must be alpha-numeric, with a 32 character limit last_name Customer’s last name. Must be alpha-numeric, with a 64 character limit address1 First line of customer’s address. Must be alpha-numeric, with a 100 character limit address2 Second line of customer’s address. Must be alpha-numeric, with a 100 character limit city City of customer’s address. Must be alpha-numeric, with a 100 character limit state State of customer’s address. Must be official 2 letter abbreviation zip Zip code of customer’s address night_phone_a Area code of customer’s night telephone number night_phone_b irst three digits of customer’s night telephone number day_phone_a Area code of customer’s daytime telephone number day_phone_b First three digits of customer’s daytime telephone number Note:To specify shipping &amp; handling amounts that differ from the default shipping amounts set in your Profile, please go to your Profile, edit your Shipping Calculations, and click the “allow transaction-based shipping override” checkbox. Method 2. Passing Individual Items to PayPalIf your 3rd party shopping cart can be configured to pass individual items to PayPal, information about the items will be included in the buyers’ and sellers’ History logs and notifications. To include information about the items, you will post HTML form elements to a new version of PayPal’s Shopping Cart flow. This process is much like the one described in Section #1 “Passing Aggregate Cart Amount to PayPal” with the following exceptions: Set the “cmd” variable to “_cart”Replace this required HTML line&lt;input type=&quot;hidden&quot; name=&quot;cmd&quot; value=&quot;_xclick&quot;&gt; with&lt;input type=&quot;hidden&quot; name=&quot;cmd&quot; value=&quot;_cart&quot;&gt; Add a new variable called “upload”Add the following line between the and tags: &lt;input type=&quot;hidden&quot; name=&quot;upload&quot; value=&quot;1&quot;&gt; Define item detailsFor each of the following item-specific parameters, define a new set of values that correspond to each item that was purchased via your 3rd party cart. Append “_x” to the variable name, where x is the item number, starting with 1 and increasing by one for each item that is added. Name Value item_name_x (Required for item #x) Name of item #x in the cart. Must be alpha-numeric, with a 127 character limit item_number_x Optional pass-through variable associated with item #x in the cart. Must be alpha-numeric, with a 127 character limit amount_x (Required for item #x) Price of the item #x shipping_x The cost of shipping the first piece (quantity of 1) of item #x shipping2_x The cost of shipping each additional piece (quantity of 2 or above) of item #x handling_x The cost of handling for item #x on0_x First option field name for item #x. 64 character limit os0_x First set of option value(s) for item #x. 200 character limit. “on0_x” must be defined in order for “os0_x” to be recognized. on1_x Second option field name for item #x. 64 character limit os1_x Second set of option value(s) for item #x. 200 character limit. “on1_x” must be defined in order for “os1_x” to be recognized. Repeat for each item included in cartInclude a set of required variables and any optional variables from the table above for each item included in your buyers’ cart. The first item included in the cart should be defined with parameters ending in “_1”, such as “item_name_1”, “amount_1”, etc. Similarly the second item should be denoted with variables like “item_name_2”, “amount_2”, etc. Note: the “_x” values must increment by one continuously in order to be recognized. If you skip from item #1 to item #3 without defining an item #2, the third item will be ignored. To specify currency: All monetary variables (amount, shipping, shipping2, handling, tax) will be interpreted in the currency designated by the “currency_code” variable that is posted with the payment. Since it is not item-specific, there is no need to append a “_x” to the variable name. If no “currency_code” variable is posted, we will assume that all monetary values are in U.S. Dollars.","link":"/submitMultipleItemsInPayPalIPNmethod/"},{"title":"Task Scheduling of Laravel","text":"Open Task Scheduling fileOpen yourProjectName/app/Console/Kernel.php Config your scheduleHere is a schedule exampleprotected function schedule(Schedule $schedule)&#123; $schedule-&gt;call(function () &#123; Token::where(&apos;expiry_time&apos;, &apos;&lt;&apos;, time())-&gt;delete(); PaymentServiceOrders::deleteExpiredOrders(); Order::where(&apos;expiry_time&apos;, &apos;&lt;&apos;, Carbon::now())-&gt;delete(); &#125;)-&gt;daily();&#125; In my case, it’s to daily delete the expired orders Add the Task Scheduling into crontab sudo vim /etc/crontab * * * * * apache cd /var/www/html/yourProjectName &amp;&amp; php artisan schedule:run &gt;&gt; /dev/null 2&gt;&amp;1 Here are the meaning of * in orders Minute(0-59) Hour(0-23) What date in a month(1-31) Month(1-12) What day in a week(0-6) apacheit represents the user. It’s important here, because if you don’t set it properly, when error occurs as you execute the schedule, the log owner will be the user you set here, which might have authority problem. If you also log other information in other place, and the whole project might not be able to work properly when the log file reject to be written. cd ray cd /var/www/html/yourProjectName To where your project is php artisan schedule:run &gt;&gt; /dev/null 2&gt;&amp;1 Run the Task Scheduling command in your Laravel project Here you go!","link":"/taskSchedulingInLaravel/"},{"title":"Organise database with MySQL group by","text":"Hello everyone. It’s Ray! I shared how to import Chinese data into database yesterday, and today I’m going to share how to use MySQL group by to organise your database. Through the image above you could see that the data is divided with different district to each day. Let’s assume that the data of the rightest column is rainfall data, what if we want to access the average rainfall of each day from all districts?We could use MySQL-group by to achieve it. Take a look on the snippet of code below:select date, avg(rainfall) rainfall from rainfall group by date; The first date in the above code means name of the column, avg means to average the amount inside the braces, which means to average the amount of value on the rainfall column.The second rainfall is the name of this table, and the final date means that we reorganise the data with date as its unit. It would enable automatic calculation of averaging on the data on the same date. The result is as follows:￼Here you go! I hope my sharing has been helpful.","link":"/useGroupByToOrganiseYourDatabase/"},{"title":"Using BigQuery and Stackdriver to Analyze BigQuery Usage","text":"Refer to QWIKLABS","link":"/usingBigQueryAndStackdriverToAnalyzeBigQuerryUsage/"},{"title":"Organise database with MySQL group by 2","text":"Hello everyone, it’s Ray! Today I’m going to share with you the further usage about how to manipulate database with group by, and inserting refined data into a new table. First, let’s start from the final image got on yesterday. What if we need the total rainfall of months, or years?￼ Please take a look on code below: &lt;?php// The year(date) and month(date) after select mean what data we want,// and the second year and month after braces means the name of the// column on shown data. Sum means to total all the of values of the// column within braces followed by, and the second rainfall means // the name of the column on shown data. Use &quot;group by&quot; to make shown// data grouped by month and year, and &quot;order by&quot; makes the data// arranged in ascending order.$selectQuery = &apos;SELECT year(date) year, month(date) month, sum(rainfall) rainfall from rainfall_by_date group by month(date), year(date) order by year(date) asc, month(date) asc;&apos;;// Make a select request to the database$selectResult = mysqli_query($dbc, $selectQuery);// Use while loop to repeat select request until all of the arrays// in $selectResult object are takenwhile ($selectRow = mysqli_fetch_array($selectResult))&#123; // Insert the data taken from table rainfall_by_date // into the table rainfall_by_month $insertQuery = &apos;INSERT INTO rainfall_by_month (year, month, rainfall) VALUES(&quot;&apos; . $selectRow[&apos;year&apos;] . &apos;&quot;, &quot;&apos; . $selectRow[&apos;month&apos;] . &apos;&quot;, &quot;&apos; . $selectRow[&apos;rainfall&apos;] . &apos;&quot;)&apos;; // Make an insert request. $insertResult = mysqli_query($dbc, $insertQuery);&#125; After executing the script above, you will be able to get the new table with refined data, as table below:￼ It’s my sharing today, see you guys tomorrow!","link":"/useGroupByToOrganiseYourDatabasePart2/"},{"title":"What is in git log?","text":"Hello everyone, It’s Ray! Today I am going to share with you some detail in git log Firstly, take a look on the image below: We could see that there is a long-random-looking string on every commit, and what the heck is that? This is a checksum produced by Git with SHA1 according to the committed content, by the way, what’s SHA1? SHA is the abbreviation of “security hash algorithm” There are several algorithm like this, and, moreover, SHA is not reversible, which means that if you got a hashed string like the one above, you wouldn’t be able to decode and reverse it back to the one before hashed. If you are interested in that, you could google it. I think google serves as a better teacher than me, lol. Now I am going to share a very very useful code! Git log --oneline Type git log --oneline You could see the difference between git log and git log --oneline As image shown above, you could see that git takes author, date information off, also only keep 7 characters from the original long-random-looking checksum. So could we use git checkout that we previously mentioned to switch between different commits? The answer is yes! Type git checkout cc92d2f (please note that yours will be different from mine, so just type the one shown on your computer) As photo shown above, we’ve successfully switched to the previous commit Type git checkout master Type git log --oneline Now we are back. After reading through article today, do you have better understanding on Git? See you guys!","link":"/whatIsInGitLog/"},{"title":"Why git is so much required?","text":"Hello everyone, it’s Ray. Today I’m going to share why Git is so a lot required. Firstly, have you once encountered that situation that something comes up when you are coding, it could be that your mom calls you, or even more serious that you forget to pick up your girlfriend. Unfortunately, at that very moment you happens to do debugging or develop a new feature. When you finally get some free time to proceed your coding, holly shit… something goes wrong! It’s hard to debug among a sea of code especially when you don’t know where to start. Or, sometimes when developing a new feature, unluckily it happens to affect the current feature and cause some error. When we realise that searching from nowhere might lack efficiency and want to go back to the moment when the new feature is not yet started, our good habit of saving file regularly just cover the light at the end of the tunnel. At this moment, we regret that we didn’t’ use git earlier. When you encounter some emergency during coding, or you want to start a new feature based on current one that works, you could simply use git to save it, and after that you could go there whenever you need. Also, this kind of saving takes the precedence over the built in saving function of editors, or IDEs that you use. In other words, even though you’ve saved the file on your editor or IDE, you could still go back to the point that you saved with Git. In other circumstance, except for the small project that you could complete on your own, it required multi-collaboration when it comes to a big project. Have you thought of how to efficiently collaborate with each other? After all, coding is sort of delicate work. One typo sometimes could keep the function from working properly. At this circumstance we always use Git to do the integration. Imaging that you do your portion on your own computer, and upload to a mutual folder after you finish it. Other team member do the same thing, and Git could do the integration. So to a coder, Git seems to be an integral tool.","link":"/whyGitIsSoMuchRequired/"},{"title":"Why should we use VIM?","text":"Hello everyone, it’s Ray! Today I’m going to share an amazing, very famous and powerful editor with a long history of over 50 years, it’s called “Vim” Sorry but I’m not going to introduce its history, if you are interested, you could google it. I think google serves as a better history teacher than me. Except for an editor specially designed for coding, it’s ubiquitous among all of those popular editors, or even IDEs, such as those I am using, PHPSTORM, or Sublime. Before further digging into Vim, let’s talk about, why would we use Vim? Before opting for my career as an coder, I already started to use touch typing, which means using the jutted point on F and J key to locate, so I could type without looking at my keyboard even I had my eyes covered. After starting to code, what annoyed me the most was not the logic, neither the syntax, instead, it’s the necessity of switching among the mouse, main key section, and arrow key section on my keyboard. Before the serendipity with Vim, I had been looking for keyboard with key.mapping function, because I reckon that the ideal way of typing is being able to complete all those required maneouvres with my palm fixed and stay on the main key area. Theoretically speaking, if there are two coders with same experience, logic, and skill, the one who could type faster definitely has more output, which means he could finish his job earlier. So you ask me, why should I finish my job so early? Hey bros, time is priceless! The earlier you finish your job, the more time will be at your disposal! For some tech fanatics, oh! Sorry, I mean with great passion on tech, like me, it means that I could have more time for tech stuff. Time is the most valuable currency, even more precious than Bitcoin! You could utilise it on companying with your family, friends, binge watching, or even with your girlfriend! Oh, sorry but you’ve got to have a girlfriend first, for someone who doesn’t, like me, I’m so sorry! The most basic and useful function of Vim is that arrow key function like up, down, left, and right could be achieved by simply pressing h, j, k, and l. In other words, it solves the irritant of switching from main key section and arrow key section with your right hand. Basically Vim is divided with three modes- normal, insert, and visual. That said moving your cursor on normal mode, coding on insert mode, and it’s visual mode where from time to time we highlight a whole line or a couple of characters for further copying or cutting or even something more delicate. After the dissection above, have you found the charm of Vim? I hope that you’ve been enjoyable on this article. See you guys!","link":"/whyWouldWeUseVIM/"}],"tags":[{"name":"Google Cloud Shell","slug":"Google-Cloud-Shell","link":"/tags/Google-Cloud-Shell/"},{"name":"GCP Essentials","slug":"GCP-Essentials","link":"/tags/GCP-Essentials/"},{"name":"QWIKLABS","slug":"QWIKLABS","link":"/tags/QWIKLABS/"},{"name":"GCP Essential","slug":"GCP-Essential","link":"/tags/GCP-Essential/"},{"name":"Apache","slug":"Apache","link":"/tags/Apache/"},{"name":"MySQL","slug":"MySQL","link":"/tags/MySQL/"},{"name":"Composer","slug":"Composer","link":"/tags/Composer/"},{"name":"Laravel","slug":"Laravel","link":"/tags/Laravel/"},{"name":"PHP","slug":"PHP","link":"/tags/PHP/"},{"name":"AllPay","slug":"AllPay","link":"/tags/AllPay/"},{"name":"Laravel Transaction","slug":"Laravel-Transaction","link":"/tags/Laravel-Transaction/"},{"name":"Laravel Log","slug":"Laravel-Log","link":"/tags/Laravel-Log/"},{"name":"ngrok","slug":"ngrok","link":"/tags/ngrok/"},{"name":"Laravel Middleware","slug":"Laravel-Middleware","link":"/tags/Laravel-Middleware/"},{"name":"Google Load Balancers","slug":"Google-Load-Balancers","link":"/tags/Google-Load-Balancers/"},{"name":"Facebook long-lived token","slug":"Facebook-long-lived-token","link":"/tags/Facebook-long-lived-token/"},{"name":"Facebook never expired token","slug":"Facebook-never-expired-token","link":"/tags/Facebook-never-expired-token/"},{"name":"GCP Compute Engine","slug":"GCP-Compute-Engine","link":"/tags/GCP-Compute-Engine/"},{"name":"GCP Marketplace","slug":"GCP-Marketplace","link":"/tags/GCP-Marketplace/"},{"name":"Google Load Baalancers","slug":"Google-Load-Baalancers","link":"/tags/Google-Load-Baalancers/"},{"name":"Google Kubernetes","slug":"Google-Kubernetes","link":"/tags/Google-Kubernetes/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"MongoDB","slug":"MongoDB","link":"/tags/MongoDB/"},{"name":"Node.js","slug":"Node-js","link":"/tags/Node-js/"},{"name":"Kubernetes","slug":"Kubernetes","link":"/tags/Kubernetes/"},{"name":"GCP","slug":"GCP","link":"/tags/GCP/"},{"name":"AWS SQS","slug":"AWS-SQS","link":"/tags/AWS-SQS/"},{"name":"Laravel Queue","slug":"Laravel-Queue","link":"/tags/Laravel-Queue/"},{"name":"Laravel blade","slug":"Laravel-blade","link":"/tags/Laravel-blade/"},{"name":"Laravel template","slug":"Laravel-template","link":"/tags/Laravel-template/"},{"name":"Laravel view","slug":"Laravel-view","link":"/tags/Laravel-view/"},{"name":"class","slug":"class","link":"/tags/class/"},{"name":"object","slug":"object","link":"/tags/object/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"minos","slug":"minos","link":"/tags/minos/"},{"name":"bilingual","slug":"bilingual","link":"/tags/bilingual/"},{"name":"blog","slug":"blog","link":"/tags/blog/"},{"name":"multilingual","slug":"multilingual","link":"/tags/multilingual/"},{"name":"Baseline: Infrastructure","slug":"Baseline-Infrastructure","link":"/tags/Baseline-Infrastructure/"},{"name":"GCP Cloud Functions","slug":"GCP-Cloud-Functions","link":"/tags/GCP-Cloud-Functions/"},{"name":"GCP IAM","slug":"GCP-IAM","link":"/tags/GCP-IAM/"},{"name":"Google Cloud Storage","slug":"Google-Cloud-Storage","link":"/tags/Google-Cloud-Storage/"},{"name":"GCP-Baseline:Infrastructure","slug":"GCP-Baseline-Infrastructure","link":"/tags/GCP-Baseline-Infrastructure/"},{"name":"GCP Storage","slug":"GCP-Storage","link":"/tags/GCP-Storage/"},{"name":"GCP Computer Engine","slug":"GCP-Computer-Engine","link":"/tags/GCP-Computer-Engine/"},{"name":"Docker Image","slug":"Docker-Image","link":"/tags/Docker-Image/"},{"name":"Docker Container","slug":"Docker-Container","link":"/tags/Docker-Container/"},{"name":"Docker Swarm","slug":"Docker-Swarm","link":"/tags/Docker-Swarm/"},{"name":"Docker Multi Stage","slug":"Docker-Multi-Stage","link":"/tags/Docker-Multi-Stage/"},{"name":"Docker Compose","slug":"Docker-Compose","link":"/tags/Docker-Compose/"},{"name":"Docker Service","slug":"Docker-Service","link":"/tags/Docker-Service/"},{"name":"Docker Rolling Update","slug":"Docker-Rolling-Update","link":"/tags/Docker-Rolling-Update/"},{"name":"Docker Push","slug":"Docker-Push","link":"/tags/Docker-Push/"},{"name":"Docker Deployment","slug":"Docker-Deployment","link":"/tags/Docker-Deployment/"},{"name":"QUIKLABS","slug":"QUIKLABS","link":"/tags/QUIKLABS/"},{"name":"Stackdriver","slug":"Stackdriver","link":"/tags/Stackdriver/"},{"name":"Laravel Image","slug":"Laravel-Image","link":"/tags/Laravel-Image/"},{"name":"Laravel package Intervention","slug":"Laravel-package-Intervention","link":"/tags/Laravel-package-Intervention/"},{"name":"Stackdriver Logging","slug":"Stackdriver-Logging","link":"/tags/Stackdriver-Logging/"},{"name":"GCP Stackdriver","slug":"GCP-Stackdriver","link":"/tags/GCP-Stackdriver/"},{"name":"gcloud shell","slug":"gcloud-shell","link":"/tags/gcloud-shell/"},{"name":"vsftpd","slug":"vsftpd","link":"/tags/vsftpd/"},{"name":"ftp","slug":"ftp","link":"/tags/ftp/"},{"name":"git rebase -i","slug":"git-rebase-i","link":"/tags/git-rebase-i/"},{"name":"git rebase -i --onto","slug":"git-rebase-i-onto","link":"/tags/git-rebase-i-onto/"},{"name":"git reset --hard","slug":"git-reset-hard","link":"/tags/git-reset-hard/"},{"name":"git reset @^ --hard","slug":"git-reset-hard","link":"/tags/git-reset-hard/"},{"name":"git checkout -b","slug":"git-checkout-b","link":"/tags/git-checkout-b/"},{"name":"git flow","slug":"git-flow","link":"/tags/git-flow/"},{"name":"PayPal REST API","slug":"PayPal-REST-API","link":"/tags/PayPal-REST-API/"},{"name":"PayPal refund","slug":"PayPal-refund","link":"/tags/PayPal-refund/"},{"name":"PayPal authorization","slug":"PayPal-authorization","link":"/tags/PayPal-authorization/"},{"name":"PayPal capture","slug":"PayPal-capture","link":"/tags/PayPal-capture/"},{"name":"PayPal void","slug":"PayPal-void","link":"/tags/PayPal-void/"},{"name":"PayPal create order","slug":"PayPal-create-order","link":"/tags/PayPal-create-order/"},{"name":"PayPal place funds on hold","slug":"PayPal-place-funds-on-hold","link":"/tags/PayPal-place-funds-on-hold/"},{"name":"git init","slug":"git-init","link":"/tags/git-init/"},{"name":"git revert","slug":"git-revert","link":"/tags/git-revert/"},{"name":"git tag -a","slug":"git-tag-a","link":"/tags/git-tag-a/"},{"name":"git checkout","slug":"git-checkout","link":"/tags/git-checkout/"},{"name":"git log --oneline","slug":"git-log-oneline","link":"/tags/git-log-oneline/"},{"name":"GCP virtual machine","slug":"GCP-virtual-machine","link":"/tags/GCP-virtual-machine/"},{"name":"Daemon","slug":"Daemon","link":"/tags/Daemon/"},{"name":"SSH","slug":"SSH","link":"/tags/SSH/"},{"name":"Gitlab pusher","slug":"Gitlab-pusher","link":"/tags/Gitlab-pusher/"},{"name":"GCP Pub/Sub","slug":"GCP-Pub-Sub","link":"/tags/GCP-Pub-Sub/"},{"name":"GCP-Baseline: Infrastructure","slug":"GCP-Baseline-Infrastructure","link":"/tags/GCP-Baseline-Infrastructure/"},{"name":"Facebook Graph API","slug":"Facebook-Graph-API","link":"/tags/Facebook-Graph-API/"},{"name":"AWS","slug":"AWS","link":"/tags/AWS/"},{"name":"AWS SES","slug":"AWS-SES","link":"/tags/AWS-SES/"},{"name":"Ngrok","slug":"Ngrok","link":"/tags/Ngrok/"},{"name":"Laravel Mail","slug":"Laravel-Mail","link":"/tags/Laravel-Mail/"},{"name":"git add","slug":"git-add","link":"/tags/git-add/"},{"name":"git commit","slug":"git-commit","link":"/tags/git-commit/"},{"name":"git commit -a","slug":"git-commit-a","link":"/tags/git-commit-a/"},{"name":"garbles","slug":"garbles","link":"/tags/garbles/"},{"name":"git config","slug":"git-config","link":"/tags/git-config/"},{"name":"git config --global user.name","slug":"git-config-global-user-name","link":"/tags/git-config-global-user-name/"},{"name":"git config --global user.email","slug":"git-config-global-user-email","link":"/tags/git-config-global-user-email/"},{"name":"Japanese","slug":"Japanese","link":"/tags/Japanese/"},{"name":"Jenkins","slug":"Jenkins","link":"/tags/Jenkins/"},{"name":"CI/CD","slug":"CI-CD","link":"/tags/CI-CD/"},{"name":"PayPal Payment Standard","slug":"PayPal-Payment-Standard","link":"/tags/PayPal-Payment-Standard/"},{"name":"PayPal IPN","slug":"PayPal-IPN","link":"/tags/PayPal-IPN/"},{"name":"CSV","slug":"CSV","link":"/tags/CSV/"},{"name":"Let's Encrypt","slug":"Let-s-Encrypt","link":"/tags/Let-s-Encrypt/"},{"name":"SSL","slug":"SSL","link":"/tags/SSL/"},{"name":"GCP Kubernetes Engine","slug":"GCP-Kubernetes-Engine","link":"/tags/GCP-Kubernetes-Engine/"},{"name":"pm2","slug":"pm2","link":"/tags/pm2/"},{"name":"GitLab CI / CD","slug":"GitLab-CI-CD","link":"/tags/GitLab-CI-CD/"},{"name":"Sequelize","slug":"Sequelize","link":"/tags/Sequelize/"},{"name":"ssh-add","slug":"ssh-add","link":"/tags/ssh-add/"},{"name":"ssh-agent","slug":"ssh-agent","link":"/tags/ssh-agent/"},{"name":"Supervisor","slug":"Supervisor","link":"/tags/Supervisor/"},{"name":"MacOS","slug":"MacOS","link":"/tags/MacOS/"},{"name":"multiple items","slug":"multiple-items","link":"/tags/multiple-items/"},{"name":"variables","slug":"variables","link":"/tags/variables/"},{"name":"Laravel Task Scheduling","slug":"Laravel-Task-Scheduling","link":"/tags/Laravel-Task-Scheduling/"},{"name":"Linux crontab","slug":"Linux-crontab","link":"/tags/Linux-crontab/"},{"name":"group by","slug":"group-by","link":"/tags/group-by/"},{"name":"GCP BigQuery","slug":"GCP-BigQuery","link":"/tags/GCP-BigQuery/"},{"name":"git log","slug":"git-log","link":"/tags/git-log/"},{"name":"VIM","slug":"VIM","link":"/tags/VIM/"}],"categories":[{"name":"GCP","slug":"GCP","link":"/categories/GCP/"},{"name":"Deployment","slug":"Deployment","link":"/categories/Deployment/"},{"name":"Payment Gateway","slug":"Payment-Gateway","link":"/categories/Payment-Gateway/"},{"name":"Facebook","slug":"Facebook","link":"/categories/Facebook/"},{"name":"Database","slug":"Database","link":"/categories/Database/"},{"name":"Node.js","slug":"Node-js","link":"/categories/Node-js/"},{"name":"Laravel","slug":"Laravel","link":"/categories/Laravel/"},{"name":"OOP","slug":"OOP","link":"/categories/OOP/"},{"name":"Hexo","slug":"Hexo","link":"/categories/Hexo/"},{"name":"Git","slug":"Git","link":"/categories/Git/"},{"name":"PHP","slug":"PHP","link":"/categories/PHP/"},{"name":"Languages","slug":"Languages","link":"/categories/Languages/"},{"name":"ssh","slug":"ssh","link":"/categories/ssh/"},{"name":"MySQL","slug":"MySQL","link":"/categories/MySQL/"},{"name":"VIM","slug":"VIM","link":"/categories/VIM/"}]}